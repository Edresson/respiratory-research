{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 2\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 2 - slide5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'slide5'\n",
    "GROUP_TEST = 'slide5'\n",
    "DATASET = 'dataset_2'\n",
    "DURATION = 5\n",
    "SIZE = 216\n",
    "CSV_TRAIN = 'train2.csv'\n",
    "CSV_TEST = 'test2.csv'\n",
    "MODEL_NAME = f'CNN2_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  123  Healthy\n",
       "1  125  Healthy\n",
       "2  126  Healthy\n",
       "3  127  Healthy\n",
       "4  136  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  896  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['256' '192']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['24' '104']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 40, 216)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 40, 216, 1) (448, 2)\n",
      "(128, 40, 216, 1) (128, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 215, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 107, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 107, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 106, 16)       2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 53, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 53, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 52, 8)          520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 26, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 26, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 25, 4)          132       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 12, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 12, 4)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 2,886\n",
      "Trainable params: 2,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "128/128 [==============================] - 1s 7ms/sample - loss: 1.9915 - accuracy: 0.8125\n",
      "Pre-training accuracy: 81.2500%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358 samples, validate on 90 samples\n",
      "Epoch 1/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 4.6879 - accuracy: 0.5643\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51111, saving model to models/CNN2_dataset_2_slide5_01.h5\n",
      "358/358 [==============================] - 1s 3ms/sample - loss: 4.0652 - accuracy: 0.5559 - val_loss: 0.6933 - val_accuracy: 0.5111\n",
      "Epoch 2/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.5389 - accuracy: 0.4857\n",
      "Epoch 00002: val_accuracy improved from 0.51111 to 0.56667, saving model to models/CNN2_dataset_2_slide5_02.h5\n",
      "358/358 [==============================] - 0s 710us/sample - loss: 1.4254 - accuracy: 0.5140 - val_loss: 0.6920 - val_accuracy: 0.5667\n",
      "Epoch 3/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 1.0034 - accuracy: 0.5444\n",
      "Epoch 00003: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.9710 - accuracy: 0.5587 - val_loss: 0.6909 - val_accuracy: 0.5667\n",
      "Epoch 4/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.7651 - accuracy: 0.6074\n",
      "Epoch 00004: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.7643 - accuracy: 0.5978 - val_loss: 0.6900 - val_accuracy: 0.5667\n",
      "Epoch 5/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.7645 - accuracy: 0.5862\n",
      "Epoch 00005: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 641us/sample - loss: 0.7513 - accuracy: 0.5894 - val_loss: 0.6897 - val_accuracy: 0.5667\n",
      "Epoch 6/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.7291 - accuracy: 0.5714\n",
      "Epoch 00006: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.7192 - accuracy: 0.5754 - val_loss: 0.6896 - val_accuracy: 0.5667\n",
      "Epoch 7/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.6891 - accuracy: 0.6000\n",
      "Epoch 00007: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.7020 - accuracy: 0.6061 - val_loss: 0.6897 - val_accuracy: 0.5667\n",
      "Epoch 8/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.7059 - accuracy: 0.5828\n",
      "Epoch 00008: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.6924 - accuracy: 0.5894 - val_loss: 0.6892 - val_accuracy: 0.5667\n",
      "Epoch 9/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6384 - accuracy: 0.6286\n",
      "Epoch 00009: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 642us/sample - loss: 0.6577 - accuracy: 0.6285 - val_loss: 0.6894 - val_accuracy: 0.5667\n",
      "Epoch 10/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6905 - accuracy: 0.6036\n",
      "Epoch 00010: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.6787 - accuracy: 0.6117 - val_loss: 0.6890 - val_accuracy: 0.5667\n",
      "Epoch 11/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6717 - accuracy: 0.6000\n",
      "Epoch 00011: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.6778 - accuracy: 0.5922 - val_loss: 0.6891 - val_accuracy: 0.5667\n",
      "Epoch 12/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6805 - accuracy: 0.5964\n",
      "Epoch 00012: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.6694 - accuracy: 0.6173 - val_loss: 0.6888 - val_accuracy: 0.5667\n",
      "Epoch 13/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6465 - accuracy: 0.6357\n",
      "Epoch 00013: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 639us/sample - loss: 0.6571 - accuracy: 0.6257 - val_loss: 0.6886 - val_accuracy: 0.5667\n",
      "Epoch 14/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.6520 - accuracy: 0.6172\n",
      "Epoch 00014: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.6571 - accuracy: 0.6173 - val_loss: 0.6883 - val_accuracy: 0.5667\n",
      "Epoch 15/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6505 - accuracy: 0.5964\n",
      "Epoch 00015: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.6551 - accuracy: 0.5978 - val_loss: 0.6880 - val_accuracy: 0.5667\n",
      "Epoch 16/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6599 - accuracy: 0.6286\n",
      "Epoch 00016: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 0.6612 - accuracy: 0.6257 - val_loss: 0.6877 - val_accuracy: 0.5667\n",
      "Epoch 17/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6608 - accuracy: 0.6107\n",
      "Epoch 00017: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.6576 - accuracy: 0.6034 - val_loss: 0.6875 - val_accuracy: 0.5667\n",
      "Epoch 18/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6654 - accuracy: 0.6107\n",
      "Epoch 00018: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.6536 - accuracy: 0.6313 - val_loss: 0.6871 - val_accuracy: 0.5667\n",
      "Epoch 19/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.6539 - accuracy: 0.6310\n",
      "Epoch 00019: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 0.6538 - accuracy: 0.6285 - val_loss: 0.6868 - val_accuracy: 0.5667\n",
      "Epoch 20/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6541 - accuracy: 0.6214\n",
      "Epoch 00020: val_accuracy did not improve from 0.56667\n",
      "358/358 [==============================] - 0s 647us/sample - loss: 0.6456 - accuracy: 0.6313 - val_loss: 0.6857 - val_accuracy: 0.5667\n",
      "Epoch 21/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.6555 - accuracy: 0.6034\n",
      "Epoch 00021: val_accuracy improved from 0.56667 to 0.57778, saving model to models/CNN2_dataset_2_slide5_21.h5\n",
      "358/358 [==============================] - 0s 706us/sample - loss: 0.6396 - accuracy: 0.6173 - val_loss: 0.6847 - val_accuracy: 0.5778\n",
      "Epoch 22/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6323 - accuracy: 0.6000\n",
      "Epoch 00022: val_accuracy improved from 0.57778 to 0.60000, saving model to models/CNN2_dataset_2_slide5_22.h5\n",
      "358/358 [==============================] - 0s 729us/sample - loss: 0.6230 - accuracy: 0.6201 - val_loss: 0.6820 - val_accuracy: 0.6000\n",
      "Epoch 23/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6228 - accuracy: 0.6250\n",
      "Epoch 00023: val_accuracy improved from 0.60000 to 0.61111, saving model to models/CNN2_dataset_2_slide5_23.h5\n",
      "358/358 [==============================] - 0s 712us/sample - loss: 0.6276 - accuracy: 0.6229 - val_loss: 0.6799 - val_accuracy: 0.6111\n",
      "Epoch 24/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.6033 - accuracy: 0.6321\n",
      "Epoch 00024: val_accuracy improved from 0.61111 to 0.64444, saving model to models/CNN2_dataset_2_slide5_24.h5\n",
      "358/358 [==============================] - 0s 717us/sample - loss: 0.6006 - accuracy: 0.6313 - val_loss: 0.6748 - val_accuracy: 0.6444\n",
      "Epoch 25/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.5949 - accuracy: 0.7000\n",
      "Epoch 00025: val_accuracy did not improve from 0.64444\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.5999 - accuracy: 0.6816 - val_loss: 0.6650 - val_accuracy: 0.6444\n",
      "Epoch 26/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.5795 - accuracy: 0.6893\n",
      "Epoch 00026: val_accuracy improved from 0.64444 to 0.67778, saving model to models/CNN2_dataset_2_slide5_26.h5\n",
      "358/358 [==============================] - 0s 719us/sample - loss: 0.5915 - accuracy: 0.6648 - val_loss: 0.6343 - val_accuracy: 0.6778\n",
      "Epoch 27/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.5604 - accuracy: 0.7214\n",
      "Epoch 00027: val_accuracy improved from 0.67778 to 0.70000, saving model to models/CNN2_dataset_2_slide5_27.h5\n",
      "358/358 [==============================] - 0s 729us/sample - loss: 0.5682 - accuracy: 0.6899 - val_loss: 0.6053 - val_accuracy: 0.7000\n",
      "Epoch 28/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.5474 - accuracy: 0.7407\n",
      "Epoch 00028: val_accuracy improved from 0.70000 to 0.80000, saving model to models/CNN2_dataset_2_slide5_28.h5\n",
      "358/358 [==============================] - 0s 735us/sample - loss: 0.5277 - accuracy: 0.7374 - val_loss: 0.5635 - val_accuracy: 0.8000\n",
      "Epoch 29/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.5159 - accuracy: 0.7357\n",
      "Epoch 00029: val_accuracy did not improve from 0.80000\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.4960 - accuracy: 0.7486 - val_loss: 0.5167 - val_accuracy: 0.7889\n",
      "Epoch 30/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.4623 - accuracy: 0.7931\n",
      "Epoch 00030: val_accuracy did not improve from 0.80000\n",
      "358/358 [==============================] - 0s 647us/sample - loss: 0.4622 - accuracy: 0.7877 - val_loss: 0.4883 - val_accuracy: 0.7222\n",
      "Epoch 31/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.4327 - accuracy: 0.8107\n",
      "Epoch 00031: val_accuracy did not improve from 0.80000\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.4306 - accuracy: 0.8045 - val_loss: 0.4731 - val_accuracy: 0.7222\n",
      "Epoch 32/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3982 - accuracy: 0.8036\n",
      "Epoch 00032: val_accuracy did not improve from 0.80000\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.4127 - accuracy: 0.7849 - val_loss: 0.4936 - val_accuracy: 0.7000\n",
      "Epoch 33/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.4093 - accuracy: 0.7897\n",
      "Epoch 00033: val_accuracy did not improve from 0.80000\n",
      "358/358 [==============================] - 0s 640us/sample - loss: 0.4110 - accuracy: 0.7905 - val_loss: 0.4237 - val_accuracy: 0.7889\n",
      "Epoch 34/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3965 - accuracy: 0.7929\n",
      "Epoch 00034: val_accuracy improved from 0.80000 to 0.84444, saving model to models/CNN2_dataset_2_slide5_34.h5\n",
      "358/358 [==============================] - 0s 717us/sample - loss: 0.3772 - accuracy: 0.8045 - val_loss: 0.4008 - val_accuracy: 0.8444\n",
      "Epoch 35/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3914 - accuracy: 0.8071\n",
      "Epoch 00035: val_accuracy did not improve from 0.84444\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.3832 - accuracy: 0.8212 - val_loss: 0.4001 - val_accuracy: 0.8222\n",
      "Epoch 36/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3657 - accuracy: 0.8357\n",
      "Epoch 00036: val_accuracy did not improve from 0.84444\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.3740 - accuracy: 0.8240 - val_loss: 0.4337 - val_accuracy: 0.7667\n",
      "Epoch 37/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.4014 - accuracy: 0.8071\n",
      "Epoch 00037: val_accuracy improved from 0.84444 to 0.85556, saving model to models/CNN2_dataset_2_slide5_37.h5\n",
      "358/358 [==============================] - 0s 722us/sample - loss: 0.3686 - accuracy: 0.8324 - val_loss: 0.3750 - val_accuracy: 0.8556\n",
      "Epoch 38/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3588 - accuracy: 0.8286\n",
      "Epoch 00038: val_accuracy improved from 0.85556 to 0.86667, saving model to models/CNN2_dataset_2_slide5_38.h5\n",
      "358/358 [==============================] - 0s 709us/sample - loss: 0.3492 - accuracy: 0.8352 - val_loss: 0.3511 - val_accuracy: 0.8667\n",
      "Epoch 39/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.3379 - accuracy: 0.8370\n",
      "Epoch 00039: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 678us/sample - loss: 0.3282 - accuracy: 0.8436 - val_loss: 0.3626 - val_accuracy: 0.8444\n",
      "Epoch 40/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.3309 - accuracy: 0.8259\n",
      "Epoch 00040: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.3495 - accuracy: 0.8212 - val_loss: 0.3582 - val_accuracy: 0.8667\n",
      "Epoch 41/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3377 - accuracy: 0.8321\n",
      "Epoch 00041: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.3331 - accuracy: 0.8296 - val_loss: 0.3493 - val_accuracy: 0.8667\n",
      "Epoch 42/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3094 - accuracy: 0.8571\n",
      "Epoch 00042: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 647us/sample - loss: 0.3209 - accuracy: 0.8408 - val_loss: 0.3386 - val_accuracy: 0.8667\n",
      "Epoch 43/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3046 - accuracy: 0.8643\n",
      "Epoch 00043: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 647us/sample - loss: 0.3279 - accuracy: 0.8547 - val_loss: 0.3937 - val_accuracy: 0.7778\n",
      "Epoch 44/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3997 - accuracy: 0.7964\n",
      "Epoch 00044: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 649us/sample - loss: 0.3864 - accuracy: 0.7989 - val_loss: 0.3503 - val_accuracy: 0.8556\n",
      "Epoch 45/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.3150 - accuracy: 0.8483\n",
      "Epoch 00045: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 641us/sample - loss: 0.3149 - accuracy: 0.8464 - val_loss: 0.3397 - val_accuracy: 0.8667\n",
      "Epoch 46/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.3183 - accuracy: 0.8593\n",
      "Epoch 00046: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.3604 - accuracy: 0.8268 - val_loss: 0.3365 - val_accuracy: 0.8667\n",
      "Epoch 47/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3310 - accuracy: 0.8286\n",
      "Epoch 00047: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.3264 - accuracy: 0.8408 - val_loss: 0.3420 - val_accuracy: 0.8556\n",
      "Epoch 48/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.2965 - accuracy: 0.8559\n",
      "Epoch 00048: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 706us/sample - loss: 0.3003 - accuracy: 0.8520 - val_loss: 0.3268 - val_accuracy: 0.8556\n",
      "Epoch 49/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2723 - accuracy: 0.8690\n",
      "Epoch 00049: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.3092 - accuracy: 0.8547 - val_loss: 0.3511 - val_accuracy: 0.8222\n",
      "Epoch 50/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3094 - accuracy: 0.8429\n",
      "Epoch 00050: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.3032 - accuracy: 0.8575 - val_loss: 0.3548 - val_accuracy: 0.8222\n",
      "Epoch 51/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2872 - accuracy: 0.8714\n",
      "Epoch 00051: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.2810 - accuracy: 0.8799 - val_loss: 0.3011 - val_accuracy: 0.8667\n",
      "Epoch 52/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2811 - accuracy: 0.8750\n",
      "Epoch 00052: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.2969 - accuracy: 0.8575 - val_loss: 0.3057 - val_accuracy: 0.8444\n",
      "Epoch 53/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3464 - accuracy: 0.8179\n",
      "Epoch 00053: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.3288 - accuracy: 0.8352 - val_loss: 0.3078 - val_accuracy: 0.8556\n",
      "Epoch 54/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2894 - accuracy: 0.8571\n",
      "Epoch 00054: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.2961 - accuracy: 0.8492 - val_loss: 0.3128 - val_accuracy: 0.8444\n",
      "Epoch 55/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2961 - accuracy: 0.8500\n",
      "Epoch 00055: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.2915 - accuracy: 0.8547 - val_loss: 0.3091 - val_accuracy: 0.8444\n",
      "Epoch 56/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.3093 - accuracy: 0.8464\n",
      "Epoch 00056: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.2955 - accuracy: 0.8603 - val_loss: 0.2950 - val_accuracy: 0.8556\n",
      "Epoch 57/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2591 - accuracy: 0.8679\n",
      "Epoch 00057: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 649us/sample - loss: 0.2816 - accuracy: 0.8659 - val_loss: 0.3325 - val_accuracy: 0.8333\n",
      "Epoch 58/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2881 - accuracy: 0.8571\n",
      "Epoch 00058: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 645us/sample - loss: 0.2755 - accuracy: 0.8687 - val_loss: 0.3128 - val_accuracy: 0.8333\n",
      "Epoch 59/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2965 - accuracy: 0.8750\n",
      "Epoch 00059: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 649us/sample - loss: 0.2838 - accuracy: 0.8715 - val_loss: 0.2935 - val_accuracy: 0.8444\n",
      "Epoch 60/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2950 - accuracy: 0.8571\n",
      "Epoch 00060: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.3065 - accuracy: 0.8464 - val_loss: 0.2946 - val_accuracy: 0.8556\n",
      "Epoch 61/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2540 - accuracy: 0.8793\n",
      "Epoch 00061: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.2459 - accuracy: 0.8855 - val_loss: 0.3013 - val_accuracy: 0.8333\n",
      "Epoch 62/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2517 - accuracy: 0.8857\n",
      "Epoch 00062: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.2719 - accuracy: 0.8687 - val_loss: 0.3527 - val_accuracy: 0.7889\n",
      "Epoch 63/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.3472 - accuracy: 0.8379\n",
      "Epoch 00063: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 643us/sample - loss: 0.3267 - accuracy: 0.8492 - val_loss: 0.3684 - val_accuracy: 0.7778\n",
      "Epoch 64/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2560 - accuracy: 0.8655\n",
      "Epoch 00064: val_accuracy did not improve from 0.86667\n",
      "358/358 [==============================] - 0s 647us/sample - loss: 0.2661 - accuracy: 0.8631 - val_loss: 0.2817 - val_accuracy: 0.8667\n",
      "Epoch 65/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2869 - accuracy: 0.8414\n",
      "Epoch 00065: val_accuracy improved from 0.86667 to 0.91111, saving model to models/CNN2_dataset_2_slide5_65.h5\n",
      "358/358 [==============================] - 0s 716us/sample - loss: 0.2739 - accuracy: 0.8575 - val_loss: 0.2663 - val_accuracy: 0.9111\n",
      "Epoch 66/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.2532 - accuracy: 0.8815\n",
      "Epoch 00066: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.2891 - accuracy: 0.8575 - val_loss: 0.3243 - val_accuracy: 0.8333\n",
      "Epoch 67/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2833 - accuracy: 0.8786\n",
      "Epoch 00067: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.2798 - accuracy: 0.8631 - val_loss: 0.2673 - val_accuracy: 0.8889\n",
      "Epoch 68/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2234 - accuracy: 0.8786\n",
      "Epoch 00068: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.2471 - accuracy: 0.8715 - val_loss: 0.3127 - val_accuracy: 0.8333\n",
      "Epoch 69/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2629 - accuracy: 0.8750\n",
      "Epoch 00069: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 652us/sample - loss: 0.2788 - accuracy: 0.8603 - val_loss: 0.3279 - val_accuracy: 0.8111\n",
      "Epoch 70/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2934 - accuracy: 0.8750\n",
      "Epoch 00070: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 643us/sample - loss: 0.2795 - accuracy: 0.8687 - val_loss: 0.3106 - val_accuracy: 0.8333\n",
      "Epoch 71/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2593 - accuracy: 0.8828\n",
      "Epoch 00071: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.2608 - accuracy: 0.8827 - val_loss: 0.2790 - val_accuracy: 0.8667\n",
      "Epoch 72/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2676 - accuracy: 0.8750\n",
      "Epoch 00072: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.2417 - accuracy: 0.8939 - val_loss: 0.2646 - val_accuracy: 0.8667\n",
      "Epoch 73/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.2678 - accuracy: 0.8529\n",
      "Epoch 00073: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 735us/sample - loss: 0.2586 - accuracy: 0.8575 - val_loss: 0.2652 - val_accuracy: 0.8667\n",
      "Epoch 74/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2415 - accuracy: 0.8821\n",
      "Epoch 00074: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.2468 - accuracy: 0.8799 - val_loss: 0.2980 - val_accuracy: 0.8333\n",
      "Epoch 75/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.2424 - accuracy: 0.8741\n",
      "Epoch 00075: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 680us/sample - loss: 0.2374 - accuracy: 0.8771 - val_loss: 0.2521 - val_accuracy: 0.8889\n",
      "Epoch 76/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2111 - accuracy: 0.8966\n",
      "Epoch 00076: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 652us/sample - loss: 0.2242 - accuracy: 0.8911 - val_loss: 0.2888 - val_accuracy: 0.8333\n",
      "Epoch 77/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2569 - accuracy: 0.8857\n",
      "Epoch 00077: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.2633 - accuracy: 0.8743 - val_loss: 0.2669 - val_accuracy: 0.8556\n",
      "Epoch 78/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.2451 - accuracy: 0.8704\n",
      "Epoch 00078: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 688us/sample - loss: 0.2424 - accuracy: 0.8743 - val_loss: 0.2763 - val_accuracy: 0.8444\n",
      "Epoch 79/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2284 - accuracy: 0.9036\n",
      "Epoch 00079: val_accuracy improved from 0.91111 to 0.93333, saving model to models/CNN2_dataset_2_slide5_79.h5\n",
      "358/358 [==============================] - 0s 758us/sample - loss: 0.2320 - accuracy: 0.8994 - val_loss: 0.2305 - val_accuracy: 0.9333\n",
      "Epoch 80/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2321 - accuracy: 0.8857\n",
      "Epoch 00080: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 695us/sample - loss: 0.2350 - accuracy: 0.8799 - val_loss: 0.2302 - val_accuracy: 0.9222\n",
      "Epoch 81/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2517 - accuracy: 0.8964\n",
      "Epoch 00081: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.2479 - accuracy: 0.8911 - val_loss: 0.2537 - val_accuracy: 0.8667\n",
      "Epoch 82/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2483 - accuracy: 0.8857\n",
      "Epoch 00082: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.2468 - accuracy: 0.8883 - val_loss: 0.2507 - val_accuracy: 0.8889\n",
      "Epoch 83/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2191 - accuracy: 0.9103\n",
      "Epoch 00083: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.2056 - accuracy: 0.9162 - val_loss: 0.2426 - val_accuracy: 0.9000\n",
      "Epoch 84/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2200 - accuracy: 0.9000\n",
      "Epoch 00084: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 645us/sample - loss: 0.2239 - accuracy: 0.8939 - val_loss: 0.2225 - val_accuracy: 0.8889\n",
      "Epoch 85/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2158 - accuracy: 0.8893\n",
      "Epoch 00085: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 652us/sample - loss: 0.2226 - accuracy: 0.8799 - val_loss: 0.2340 - val_accuracy: 0.9000\n",
      "Epoch 86/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2311 - accuracy: 0.8893\n",
      "Epoch 00086: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.2444 - accuracy: 0.8771 - val_loss: 0.2537 - val_accuracy: 0.8444\n",
      "Epoch 87/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1965 - accuracy: 0.9111\n",
      "Epoch 00087: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.2184 - accuracy: 0.9050 - val_loss: 0.2859 - val_accuracy: 0.8222\n",
      "Epoch 88/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2447 - accuracy: 0.9000\n",
      "Epoch 00088: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.2456 - accuracy: 0.8994 - val_loss: 0.2428 - val_accuracy: 0.8667\n",
      "Epoch 89/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2377 - accuracy: 0.8964\n",
      "Epoch 00089: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 644us/sample - loss: 0.2354 - accuracy: 0.8966 - val_loss: 0.2156 - val_accuracy: 0.9111\n",
      "Epoch 90/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2369 - accuracy: 0.8821\n",
      "Epoch 00090: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.2225 - accuracy: 0.8911 - val_loss: 0.2120 - val_accuracy: 0.9111\n",
      "Epoch 91/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2028 - accuracy: 0.9069\n",
      "Epoch 00091: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.2073 - accuracy: 0.8994 - val_loss: 0.2156 - val_accuracy: 0.8889\n",
      "Epoch 92/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2223 - accuracy: 0.8931\n",
      "Epoch 00092: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.2183 - accuracy: 0.8994 - val_loss: 0.2397 - val_accuracy: 0.8556\n",
      "Epoch 93/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2050 - accuracy: 0.9143\n",
      "Epoch 00093: val_accuracy improved from 0.93333 to 0.94444, saving model to models/CNN2_dataset_2_slide5_93.h5\n",
      "358/358 [==============================] - 0s 708us/sample - loss: 0.2196 - accuracy: 0.9050 - val_loss: 0.1915 - val_accuracy: 0.9444\n",
      "Epoch 94/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.2297 - accuracy: 0.8963\n",
      "Epoch 00094: val_accuracy did not improve from 0.94444\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.2226 - accuracy: 0.9022 - val_loss: 0.2413 - val_accuracy: 0.8667\n",
      "Epoch 95/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2056 - accuracy: 0.9000\n",
      "Epoch 00095: val_accuracy did not improve from 0.94444\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.2019 - accuracy: 0.9022 - val_loss: 0.2562 - val_accuracy: 0.8667\n",
      "Epoch 96/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2205 - accuracy: 0.9143\n",
      "Epoch 00096: val_accuracy did not improve from 0.94444\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.2153 - accuracy: 0.9078 - val_loss: 0.1918 - val_accuracy: 0.9333\n",
      "Epoch 97/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1933 - accuracy: 0.9143\n",
      "Epoch 00097: val_accuracy improved from 0.94444 to 0.95556, saving model to models/CNN2_dataset_2_slide5_97.h5\n",
      "358/358 [==============================] - 0s 712us/sample - loss: 0.1770 - accuracy: 0.9246 - val_loss: 0.1960 - val_accuracy: 0.9556\n",
      "Epoch 98/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2019 - accuracy: 0.9107\n",
      "Epoch 00098: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.2100 - accuracy: 0.9134 - val_loss: 0.1827 - val_accuracy: 0.9333\n",
      "Epoch 99/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.1982 - accuracy: 0.9172\n",
      "Epoch 00099: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 0.1945 - accuracy: 0.9106 - val_loss: 0.2082 - val_accuracy: 0.9000\n",
      "Epoch 100/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2221 - accuracy: 0.9000\n",
      "Epoch 00100: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.2182 - accuracy: 0.9022 - val_loss: 0.1870 - val_accuracy: 0.9000\n",
      "Epoch 101/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2305 - accuracy: 0.8893\n",
      "Epoch 00101: val_accuracy improved from 0.95556 to 0.96667, saving model to models/CNN2_dataset_2_slide5_101.h5\n",
      "358/358 [==============================] - 0s 713us/sample - loss: 0.2174 - accuracy: 0.8966 - val_loss: 0.1910 - val_accuracy: 0.9667\n",
      "Epoch 102/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1930 - accuracy: 0.9071\n",
      "Epoch 00102: val_accuracy did not improve from 0.96667\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.2066 - accuracy: 0.9050 - val_loss: 0.2240 - val_accuracy: 0.8889\n",
      "Epoch 103/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2003 - accuracy: 0.9000\n",
      "Epoch 00103: val_accuracy did not improve from 0.96667\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.2005 - accuracy: 0.9022 - val_loss: 0.2284 - val_accuracy: 0.8556\n",
      "Epoch 104/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.9000\n",
      "Epoch 00104: val_accuracy did not improve from 0.96667\n",
      "358/358 [==============================] - 0s 693us/sample - loss: 0.2218 - accuracy: 0.8994 - val_loss: 0.2341 - val_accuracy: 0.8778\n",
      "Epoch 105/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2328 - accuracy: 0.8857\n",
      "Epoch 00105: val_accuracy did not improve from 0.96667\n",
      "358/358 [==============================] - 0s 652us/sample - loss: 0.2186 - accuracy: 0.8911 - val_loss: 0.2168 - val_accuracy: 0.9000\n",
      "Epoch 106/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2090 - accuracy: 0.9179\n",
      "Epoch 00106: val_accuracy did not improve from 0.96667\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.2056 - accuracy: 0.9134 - val_loss: 0.1701 - val_accuracy: 0.9556\n",
      "Epoch 107/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1748 - accuracy: 0.9321\n",
      "Epoch 00107: val_accuracy did not improve from 0.96667\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.1763 - accuracy: 0.9330 - val_loss: 0.1726 - val_accuracy: 0.9333\n",
      "Epoch 108/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1524 - accuracy: 0.9357\n",
      "Epoch 00108: val_accuracy improved from 0.96667 to 0.97778, saving model to models/CNN2_dataset_2_slide5_108.h5\n",
      "358/358 [==============================] - 0s 720us/sample - loss: 0.1534 - accuracy: 0.9385 - val_loss: 0.1582 - val_accuracy: 0.9778\n",
      "Epoch 109/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1815 - accuracy: 0.9222\n",
      "Epoch 00109: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.1951 - accuracy: 0.9162 - val_loss: 0.2180 - val_accuracy: 0.8778\n",
      "Epoch 110/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.1698 - accuracy: 0.9241\n",
      "Epoch 00110: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.1988 - accuracy: 0.9106 - val_loss: 0.2101 - val_accuracy: 0.8778\n",
      "Epoch 111/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2206 - accuracy: 0.8929\n",
      "Epoch 00111: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.2038 - accuracy: 0.8994 - val_loss: 0.1886 - val_accuracy: 0.9444\n",
      "Epoch 112/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2166 - accuracy: 0.9000\n",
      "Epoch 00112: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.2139 - accuracy: 0.9022 - val_loss: 0.1648 - val_accuracy: 0.9556\n",
      "Epoch 113/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1587 - accuracy: 0.9286\n",
      "Epoch 00113: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1821 - accuracy: 0.9134 - val_loss: 0.1905 - val_accuracy: 0.9444\n",
      "Epoch 114/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1773 - accuracy: 0.9214\n",
      "Epoch 00114: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 649us/sample - loss: 0.1909 - accuracy: 0.9190 - val_loss: 0.1606 - val_accuracy: 0.9444\n",
      "Epoch 115/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.2190 - accuracy: 0.8926\n",
      "Epoch 00115: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.2457 - accuracy: 0.8855 - val_loss: 0.2079 - val_accuracy: 0.8889\n",
      "Epoch 116/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1741 - accuracy: 0.9393\n",
      "Epoch 00116: val_accuracy improved from 0.97778 to 0.98889, saving model to models/CNN2_dataset_2_slide5_116.h5\n",
      "358/358 [==============================] - 0s 717us/sample - loss: 0.1971 - accuracy: 0.9218 - val_loss: 0.1640 - val_accuracy: 0.9889\n",
      "Epoch 117/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.2118 - accuracy: 0.9074\n",
      "Epoch 00117: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 679us/sample - loss: 0.2200 - accuracy: 0.9050 - val_loss: 0.1710 - val_accuracy: 0.9889\n",
      "Epoch 118/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1804 - accuracy: 0.9286\n",
      "Epoch 00118: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1757 - accuracy: 0.9274 - val_loss: 0.1551 - val_accuracy: 0.9889\n",
      "Epoch 119/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1801 - accuracy: 0.9393\n",
      "Epoch 00119: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 644us/sample - loss: 0.1675 - accuracy: 0.9441 - val_loss: 0.1924 - val_accuracy: 0.9222\n",
      "Epoch 120/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.2062 - accuracy: 0.9000\n",
      "Epoch 00120: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.1926 - accuracy: 0.9078 - val_loss: 0.1663 - val_accuracy: 0.9333\n",
      "Epoch 121/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1564 - accuracy: 0.9250\n",
      "Epoch 00121: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.1700 - accuracy: 0.9162 - val_loss: 0.1707 - val_accuracy: 0.9222\n",
      "Epoch 122/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1429 - accuracy: 0.9481\n",
      "Epoch 00122: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.1425 - accuracy: 0.9441 - val_loss: 0.1473 - val_accuracy: 0.9444\n",
      "Epoch 123/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1530 - accuracy: 0.9321\n",
      "Epoch 00123: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.1586 - accuracy: 0.9274 - val_loss: 0.1259 - val_accuracy: 0.9778\n",
      "Epoch 124/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1826 - accuracy: 0.9286\n",
      "Epoch 00124: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.1808 - accuracy: 0.9246 - val_loss: 0.1411 - val_accuracy: 0.9889\n",
      "Epoch 125/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1652 - accuracy: 0.9107\n",
      "Epoch 00125: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.1648 - accuracy: 0.9190 - val_loss: 0.1448 - val_accuracy: 0.9333\n",
      "Epoch 126/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1941 - accuracy: 0.9250\n",
      "Epoch 00126: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.1884 - accuracy: 0.9246 - val_loss: 0.1765 - val_accuracy: 0.9333\n",
      "Epoch 127/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1434 - accuracy: 0.9464\n",
      "Epoch 00127: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1608 - accuracy: 0.9330 - val_loss: 0.1243 - val_accuracy: 0.9778\n",
      "Epoch 128/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2034 - accuracy: 0.9179\n",
      "Epoch 00128: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1899 - accuracy: 0.9190 - val_loss: 0.1371 - val_accuracy: 0.9667\n",
      "Epoch 129/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1919 - accuracy: 0.9171\n",
      "Epoch 00129: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 694us/sample - loss: 0.1888 - accuracy: 0.9190 - val_loss: 0.1501 - val_accuracy: 0.9889\n",
      "Epoch 130/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1800 - accuracy: 0.9370\n",
      "Epoch 00130: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.1763 - accuracy: 0.9358 - val_loss: 0.1812 - val_accuracy: 0.8889\n",
      "Epoch 131/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1811 - accuracy: 0.9179\n",
      "Epoch 00131: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.1747 - accuracy: 0.9190 - val_loss: 0.1432 - val_accuracy: 0.9556\n",
      "Epoch 132/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1898 - accuracy: 0.9400\n",
      "Epoch 00132: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 696us/sample - loss: 0.1880 - accuracy: 0.9413 - val_loss: 0.1482 - val_accuracy: 0.9667\n",
      "Epoch 133/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1805 - accuracy: 0.9370\n",
      "Epoch 00133: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.1634 - accuracy: 0.9413 - val_loss: 0.1666 - val_accuracy: 0.9444\n",
      "Epoch 134/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1658 - accuracy: 0.9429\n",
      "Epoch 00134: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 0.1716 - accuracy: 0.9441 - val_loss: 0.1315 - val_accuracy: 0.9889\n",
      "Epoch 135/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1613 - accuracy: 0.9429\n",
      "Epoch 00135: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 652us/sample - loss: 0.1528 - accuracy: 0.9441 - val_loss: 0.1526 - val_accuracy: 0.9667\n",
      "Epoch 136/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1397 - accuracy: 0.9357\n",
      "Epoch 00136: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1468 - accuracy: 0.9330 - val_loss: 0.1486 - val_accuracy: 0.9444\n",
      "Epoch 137/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1693 - accuracy: 0.9250\n",
      "Epoch 00137: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1611 - accuracy: 0.9274 - val_loss: 0.1230 - val_accuracy: 0.9889\n",
      "Epoch 138/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1516 - accuracy: 0.9444\n",
      "Epoch 00138: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.1439 - accuracy: 0.9497 - val_loss: 0.1274 - val_accuracy: 0.9778\n",
      "Epoch 139/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1479 - accuracy: 0.9429\n",
      "Epoch 00139: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.1446 - accuracy: 0.9385 - val_loss: 0.1336 - val_accuracy: 0.9667\n",
      "Epoch 140/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1426 - accuracy: 0.9407\n",
      "Epoch 00140: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.1427 - accuracy: 0.9441 - val_loss: 0.1138 - val_accuracy: 0.9889\n",
      "Epoch 141/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.1634 - accuracy: 0.9172\n",
      "Epoch 00141: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 649us/sample - loss: 0.1796 - accuracy: 0.9134 - val_loss: 0.1315 - val_accuracy: 0.9889\n",
      "Epoch 142/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1738 - accuracy: 0.9250\n",
      "Epoch 00142: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1719 - accuracy: 0.9246 - val_loss: 0.1426 - val_accuracy: 0.9667\n",
      "Epoch 143/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1311 - accuracy: 0.9571\n",
      "Epoch 00143: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.1558 - accuracy: 0.9497 - val_loss: 0.1371 - val_accuracy: 0.9889\n",
      "Epoch 144/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1796 - accuracy: 0.9296\n",
      "Epoch 00144: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.1821 - accuracy: 0.9274 - val_loss: 0.1285 - val_accuracy: 0.9889\n",
      "Epoch 145/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1788 - accuracy: 0.9111\n",
      "Epoch 00145: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1849 - accuracy: 0.9162 - val_loss: 0.1261 - val_accuracy: 0.9889\n",
      "Epoch 146/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1360 - accuracy: 0.9536\n",
      "Epoch 00146: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.1349 - accuracy: 0.9469 - val_loss: 0.1131 - val_accuracy: 0.9889\n",
      "Epoch 147/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1875 - accuracy: 0.9286\n",
      "Epoch 00147: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.1956 - accuracy: 0.9162 - val_loss: 0.1292 - val_accuracy: 0.9889\n",
      "Epoch 148/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1676 - accuracy: 0.9357\n",
      "Epoch 00148: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.1595 - accuracy: 0.9385 - val_loss: 0.1419 - val_accuracy: 0.9667\n",
      "Epoch 149/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1538 - accuracy: 0.9444\n",
      "Epoch 00149: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.1484 - accuracy: 0.9497 - val_loss: 0.1205 - val_accuracy: 0.9889\n",
      "Epoch 150/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9114\n",
      "Epoch 00150: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 691us/sample - loss: 0.1941 - accuracy: 0.9134 - val_loss: 0.1270 - val_accuracy: 0.9778\n",
      "Epoch 151/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2020 - accuracy: 0.9071\n",
      "Epoch 00151: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.1941 - accuracy: 0.9106 - val_loss: 0.1392 - val_accuracy: 0.9778\n",
      "Epoch 152/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1500 - accuracy: 0.9357\n",
      "Epoch 00152: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.1414 - accuracy: 0.9358 - val_loss: 0.1257 - val_accuracy: 0.9889\n",
      "Epoch 153/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1280 - accuracy: 0.9500\n",
      "Epoch 00153: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.1257 - accuracy: 0.9553 - val_loss: 0.1207 - val_accuracy: 0.9778\n",
      "Epoch 154/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9464\n",
      "Epoch 00154: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1294 - accuracy: 0.9469 - val_loss: 0.1020 - val_accuracy: 0.9889\n",
      "Epoch 155/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1534 - accuracy: 0.9250\n",
      "Epoch 00155: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.1413 - accuracy: 0.9302 - val_loss: 0.1038 - val_accuracy: 0.9889\n",
      "Epoch 156/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.1378 - accuracy: 0.9345\n",
      "Epoch 00156: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 644us/sample - loss: 0.1408 - accuracy: 0.9330 - val_loss: 0.1289 - val_accuracy: 0.9778\n",
      "Epoch 157/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1421 - accuracy: 0.9393\n",
      "Epoch 00157: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 0.1479 - accuracy: 0.9358 - val_loss: 0.1066 - val_accuracy: 0.9889\n",
      "Epoch 158/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1594 - accuracy: 0.9464\n",
      "Epoch 00158: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1544 - accuracy: 0.9469 - val_loss: 0.1323 - val_accuracy: 0.9778\n",
      "Epoch 159/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1533 - accuracy: 0.9500\n",
      "Epoch 00159: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 652us/sample - loss: 0.1582 - accuracy: 0.9441 - val_loss: 0.1352 - val_accuracy: 0.9556\n",
      "Epoch 160/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1427 - accuracy: 0.9500\n",
      "Epoch 00160: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.1483 - accuracy: 0.9330 - val_loss: 0.1045 - val_accuracy: 0.9889\n",
      "Epoch 161/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1357 - accuracy: 0.9500\n",
      "Epoch 00161: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.1337 - accuracy: 0.9497 - val_loss: 0.1189 - val_accuracy: 0.9889\n",
      "Epoch 162/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1399 - accuracy: 0.9286\n",
      "Epoch 00162: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.1500 - accuracy: 0.9302 - val_loss: 0.0968 - val_accuracy: 0.9889\n",
      "Epoch 163/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1496 - accuracy: 0.9321\n",
      "Epoch 00163: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.1471 - accuracy: 0.9330 - val_loss: 0.1190 - val_accuracy: 0.9889\n",
      "Epoch 164/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1436 - accuracy: 0.9429\n",
      "Epoch 00164: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.1430 - accuracy: 0.9441 - val_loss: 0.1129 - val_accuracy: 0.9889\n",
      "Epoch 165/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1470 - accuracy: 0.9393\n",
      "Epoch 00165: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1326 - accuracy: 0.9441 - val_loss: 0.1131 - val_accuracy: 0.9667\n",
      "Epoch 166/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1506 - accuracy: 0.9250\n",
      "Epoch 00166: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.1397 - accuracy: 0.9385 - val_loss: 0.1564 - val_accuracy: 0.9444\n",
      "Epoch 167/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1889 - accuracy: 0.9321\n",
      "Epoch 00167: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.1986 - accuracy: 0.9274 - val_loss: 0.1131 - val_accuracy: 0.9889\n",
      "Epoch 168/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1677 - accuracy: 0.9321\n",
      "Epoch 00168: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.1458 - accuracy: 0.9441 - val_loss: 0.1277 - val_accuracy: 0.9889\n",
      "Epoch 169/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1209 - accuracy: 0.9444\n",
      "Epoch 00169: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 688us/sample - loss: 0.1385 - accuracy: 0.9385 - val_loss: 0.1632 - val_accuracy: 0.9333\n",
      "Epoch 170/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1713 - accuracy: 0.9222\n",
      "Epoch 00170: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 687us/sample - loss: 0.1666 - accuracy: 0.9218 - val_loss: 0.1310 - val_accuracy: 0.9778\n",
      "Epoch 171/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1882 - accuracy: 0.9148\n",
      "Epoch 00171: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.1721 - accuracy: 0.9246 - val_loss: 0.1058 - val_accuracy: 0.9889\n",
      "Epoch 172/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1207 - accuracy: 0.9500\n",
      "Epoch 00172: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1154 - accuracy: 0.9525 - val_loss: 0.0956 - val_accuracy: 0.9889\n",
      "Epoch 173/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1603 - accuracy: 0.9393\n",
      "Epoch 00173: val_accuracy did not improve from 0.98889\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.1469 - accuracy: 0.9441 - val_loss: 0.1018 - val_accuracy: 0.9889\n",
      "Epoch 174/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1013 - accuracy: 0.9607\n",
      "Epoch 00174: val_accuracy improved from 0.98889 to 1.00000, saving model to models/CNN2_dataset_2_slide5_174.h5\n",
      "358/358 [==============================] - 0s 727us/sample - loss: 0.1065 - accuracy: 0.9581 - val_loss: 0.0947 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9400\n",
      "Epoch 00175: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 689us/sample - loss: 0.1338 - accuracy: 0.9385 - val_loss: 0.1134 - val_accuracy: 0.9889\n",
      "Epoch 176/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1273 - accuracy: 0.9500\n",
      "Epoch 00176: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 645us/sample - loss: 0.1228 - accuracy: 0.9497 - val_loss: 0.1477 - val_accuracy: 0.9222\n",
      "Epoch 177/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2073 - accuracy: 0.9250\n",
      "Epoch 00177: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.2024 - accuracy: 0.9190 - val_loss: 0.1096 - val_accuracy: 0.9889\n",
      "Epoch 178/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1612 - accuracy: 0.9321\n",
      "Epoch 00178: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.1588 - accuracy: 0.9330 - val_loss: 0.1116 - val_accuracy: 0.9556\n",
      "Epoch 179/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.2013 - accuracy: 0.9107\n",
      "Epoch 00179: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.1977 - accuracy: 0.9134 - val_loss: 0.1224 - val_accuracy: 0.9667\n",
      "Epoch 180/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1091 - accuracy: 0.9536\n",
      "Epoch 00180: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.1151 - accuracy: 0.9525 - val_loss: 0.1011 - val_accuracy: 0.9889\n",
      "Epoch 181/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1289 - accuracy: 0.9607\n",
      "Epoch 00181: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.1193 - accuracy: 0.9609 - val_loss: 0.0962 - val_accuracy: 0.9889\n",
      "Epoch 182/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1594 - accuracy: 0.9519\n",
      "Epoch 00182: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.1475 - accuracy: 0.9525 - val_loss: 0.0834 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1098 - accuracy: 0.9571\n",
      "Epoch 00183: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1229 - accuracy: 0.9469 - val_loss: 0.0884 - val_accuracy: 0.9889\n",
      "Epoch 184/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1232 - accuracy: 0.9464\n",
      "Epoch 00184: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.1203 - accuracy: 0.9469 - val_loss: 0.1169 - val_accuracy: 0.9444\n",
      "Epoch 185/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1060 - accuracy: 0.9429\n",
      "Epoch 00185: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.1229 - accuracy: 0.9274 - val_loss: 0.1057 - val_accuracy: 0.9667\n",
      "Epoch 186/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1350 - accuracy: 0.9412\n",
      "Epoch 00186: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 699us/sample - loss: 0.1290 - accuracy: 0.9441 - val_loss: 0.0921 - val_accuracy: 0.9889\n",
      "Epoch 187/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1032 - accuracy: 0.9607\n",
      "Epoch 00187: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.1152 - accuracy: 0.9553 - val_loss: 0.0792 - val_accuracy: 0.9889\n",
      "Epoch 188/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1125 - accuracy: 0.9519\n",
      "Epoch 00188: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.1167 - accuracy: 0.9525 - val_loss: 0.0717 - val_accuracy: 0.9889\n",
      "Epoch 189/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0932 - accuracy: 0.9536\n",
      "Epoch 00189: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.0975 - accuracy: 0.9553 - val_loss: 0.0780 - val_accuracy: 0.9889\n",
      "Epoch 190/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1352 - accuracy: 0.9536\n",
      "Epoch 00190: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.1305 - accuracy: 0.9553 - val_loss: 0.0795 - val_accuracy: 0.9889\n",
      "Epoch 191/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1063 - accuracy: 0.9571\n",
      "Epoch 00191: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1107 - accuracy: 0.9581 - val_loss: 0.0740 - val_accuracy: 0.9889\n",
      "Epoch 192/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1186 - accuracy: 0.9464\n",
      "Epoch 00192: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 679us/sample - loss: 0.1188 - accuracy: 0.9413 - val_loss: 0.0990 - val_accuracy: 0.9889\n",
      "Epoch 193/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1317 - accuracy: 0.9500\n",
      "Epoch 00193: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 652us/sample - loss: 0.1240 - accuracy: 0.9497 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1823 - accuracy: 0.9214\n",
      "Epoch 00194: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.1754 - accuracy: 0.9246 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1105 - accuracy: 0.9393\n",
      "Epoch 00195: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1179 - accuracy: 0.9413 - val_loss: 0.0820 - val_accuracy: 0.9889\n",
      "Epoch 196/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1346 - accuracy: 0.9643\n",
      "Epoch 00196: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.1535 - accuracy: 0.9497 - val_loss: 0.1180 - val_accuracy: 0.9556\n",
      "Epoch 197/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1340 - accuracy: 0.9536\n",
      "Epoch 00197: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.1157 - accuracy: 0.9581 - val_loss: 0.0933 - val_accuracy: 0.9889\n",
      "Epoch 198/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1406 - accuracy: 0.9429\n",
      "Epoch 00198: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1306 - accuracy: 0.9469 - val_loss: 0.0884 - val_accuracy: 0.9889\n",
      "Epoch 199/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1097 - accuracy: 0.9519\n",
      "Epoch 00199: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.1060 - accuracy: 0.9581 - val_loss: 0.0913 - val_accuracy: 0.9889\n",
      "Epoch 200/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1083 - accuracy: 0.9607\n",
      "Epoch 00200: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1070 - accuracy: 0.9637 - val_loss: 0.0823 - val_accuracy: 0.9889\n",
      "Epoch 201/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1593 - accuracy: 0.9370\n",
      "Epoch 00201: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.1426 - accuracy: 0.9413 - val_loss: 0.0773 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1124 - accuracy: 0.9630\n",
      "Epoch 00202: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 684us/sample - loss: 0.1104 - accuracy: 0.9609 - val_loss: 0.0920 - val_accuracy: 0.9889\n",
      "Epoch 203/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1507 - accuracy: 0.9321\n",
      "Epoch 00203: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.1495 - accuracy: 0.9274 - val_loss: 0.0969 - val_accuracy: 0.9778\n",
      "Epoch 204/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1067 - accuracy: 0.9607\n",
      "Epoch 00204: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.1127 - accuracy: 0.9581 - val_loss: 0.0765 - val_accuracy: 0.9889\n",
      "Epoch 205/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1373 - accuracy: 0.9393\n",
      "Epoch 00205: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1302 - accuracy: 0.9413 - val_loss: 0.0937 - val_accuracy: 0.9889\n",
      "Epoch 206/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1287 - accuracy: 0.9500\n",
      "Epoch 00206: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1366 - accuracy: 0.9413 - val_loss: 0.0740 - val_accuracy: 0.9889\n",
      "Epoch 207/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1464 - accuracy: 0.9370\n",
      "Epoch 00207: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.1256 - accuracy: 0.9469 - val_loss: 0.0883 - val_accuracy: 0.9889\n",
      "Epoch 208/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1218 - accuracy: 0.9500\n",
      "Epoch 00208: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.1124 - accuracy: 0.9497 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1815 - accuracy: 0.9148\n",
      "Epoch 00209: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 678us/sample - loss: 0.1469 - accuracy: 0.9358 - val_loss: 0.0942 - val_accuracy: 0.9889\n",
      "Epoch 210/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0943 - accuracy: 0.9714\n",
      "Epoch 00210: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0994 - accuracy: 0.9665 - val_loss: 0.0848 - val_accuracy: 0.9889\n",
      "Epoch 211/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1170 - accuracy: 0.9429\n",
      "Epoch 00211: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.1193 - accuracy: 0.9469 - val_loss: 0.0695 - val_accuracy: 0.9889\n",
      "Epoch 212/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1426 - accuracy: 0.9370\n",
      "Epoch 00212: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.1272 - accuracy: 0.9413 - val_loss: 0.1009 - val_accuracy: 0.9778\n",
      "Epoch 213/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1102 - accuracy: 0.9444\n",
      "Epoch 00213: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.1209 - accuracy: 0.9497 - val_loss: 0.0962 - val_accuracy: 0.9778\n",
      "Epoch 214/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0897 - accuracy: 0.9643\n",
      "Epoch 00214: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.1370 - accuracy: 0.9581 - val_loss: 0.1012 - val_accuracy: 0.9778\n",
      "Epoch 215/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0901 - accuracy: 0.9704\n",
      "Epoch 00215: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0912 - accuracy: 0.9693 - val_loss: 0.0968 - val_accuracy: 0.9889\n",
      "Epoch 216/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1008 - accuracy: 0.9667\n",
      "Epoch 00216: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.1123 - accuracy: 0.9581 - val_loss: 0.1136 - val_accuracy: 0.9778\n",
      "Epoch 217/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1256 - accuracy: 0.9370\n",
      "Epoch 00217: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 695us/sample - loss: 0.1297 - accuracy: 0.9358 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1174 - accuracy: 0.9536\n",
      "Epoch 00218: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1062 - accuracy: 0.9581 - val_loss: 0.0900 - val_accuracy: 0.9889\n",
      "Epoch 219/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1231 - accuracy: 0.9393\n",
      "Epoch 00219: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.1093 - accuracy: 0.9469 - val_loss: 0.0801 - val_accuracy: 0.9889\n",
      "Epoch 220/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1089 - accuracy: 0.9643\n",
      "Epoch 00220: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0962 - accuracy: 0.9693 - val_loss: 0.0823 - val_accuracy: 0.9889\n",
      "Epoch 221/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0828 - accuracy: 0.9714\n",
      "Epoch 00221: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0893 - accuracy: 0.9721 - val_loss: 0.1024 - val_accuracy: 0.9667\n",
      "Epoch 222/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1094 - accuracy: 0.9556\n",
      "Epoch 00222: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.1188 - accuracy: 0.9497 - val_loss: 0.0916 - val_accuracy: 0.9889\n",
      "Epoch 223/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0938 - accuracy: 0.9643\n",
      "Epoch 00223: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.1107 - accuracy: 0.9525 - val_loss: 0.0957 - val_accuracy: 0.9778\n",
      "Epoch 224/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1277 - accuracy: 0.9429\n",
      "Epoch 00224: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.1267 - accuracy: 0.9441 - val_loss: 0.0785 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1153 - accuracy: 0.9571\n",
      "Epoch 00225: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.1036 - accuracy: 0.9609 - val_loss: 0.0738 - val_accuracy: 0.9889\n",
      "Epoch 226/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0856 - accuracy: 0.9714\n",
      "Epoch 00226: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0949 - accuracy: 0.9665 - val_loss: 0.0766 - val_accuracy: 0.9889\n",
      "Epoch 227/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0984 - accuracy: 0.9593\n",
      "Epoch 00227: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.0949 - accuracy: 0.9637 - val_loss: 0.0661 - val_accuracy: 0.9889\n",
      "Epoch 228/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1124 - accuracy: 0.9500\n",
      "Epoch 00228: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.1058 - accuracy: 0.9553 - val_loss: 0.0902 - val_accuracy: 0.9889\n",
      "Epoch 229/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0846 - accuracy: 0.9679\n",
      "Epoch 00229: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0954 - accuracy: 0.9637 - val_loss: 0.0769 - val_accuracy: 0.9889\n",
      "Epoch 230/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1147 - accuracy: 0.9429\n",
      "Epoch 00230: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1100 - accuracy: 0.9413 - val_loss: 0.0842 - val_accuracy: 0.9778\n",
      "Epoch 231/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1126 - accuracy: 0.9643\n",
      "Epoch 00231: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.1054 - accuracy: 0.9665 - val_loss: 0.0710 - val_accuracy: 0.9889\n",
      "Epoch 232/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0977 - accuracy: 0.9607\n",
      "Epoch 00232: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1069 - accuracy: 0.9581 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1043 - accuracy: 0.9571\n",
      "Epoch 00233: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0975 - accuracy: 0.9609 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0660 - accuracy: 0.9750\n",
      "Epoch 00234: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.0776 - accuracy: 0.9693 - val_loss: 0.0760 - val_accuracy: 0.9889\n",
      "Epoch 235/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0966 - accuracy: 0.9676\n",
      "Epoch 00235: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 706us/sample - loss: 0.1314 - accuracy: 0.9609 - val_loss: 0.1516 - val_accuracy: 0.9444\n",
      "Epoch 236/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1128 - accuracy: 0.9464\n",
      "Epoch 00236: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.1060 - accuracy: 0.9553 - val_loss: 0.0777 - val_accuracy: 0.9889\n",
      "Epoch 237/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1556 - accuracy: 0.9429\n",
      "Epoch 00237: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.1826 - accuracy: 0.9385 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1587 - accuracy: 0.9429\n",
      "Epoch 00238: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.1406 - accuracy: 0.9469 - val_loss: 0.0864 - val_accuracy: 0.9889\n",
      "Epoch 239/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1156 - accuracy: 0.9429\n",
      "Epoch 00239: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.1202 - accuracy: 0.9385 - val_loss: 0.0785 - val_accuracy: 0.9889\n",
      "Epoch 240/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1052 - accuracy: 0.9714\n",
      "Epoch 00240: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.0998 - accuracy: 0.9665 - val_loss: 0.0692 - val_accuracy: 0.9889\n",
      "Epoch 241/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0649 - accuracy: 0.9815\n",
      "Epoch 00241: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 685us/sample - loss: 0.0662 - accuracy: 0.9777 - val_loss: 0.0690 - val_accuracy: 0.9889\n",
      "Epoch 242/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0587 - accuracy: 0.9857\n",
      "Epoch 00242: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 690us/sample - loss: 0.0588 - accuracy: 0.9832 - val_loss: 0.0806 - val_accuracy: 0.9889\n",
      "Epoch 243/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1342 - accuracy: 0.9500\n",
      "Epoch 00243: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.1223 - accuracy: 0.9553 - val_loss: 0.0569 - val_accuracy: 0.9889\n",
      "Epoch 244/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0929 - accuracy: 0.9704\n",
      "Epoch 00244: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0922 - accuracy: 0.9693 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1268 - accuracy: 0.9481\n",
      "Epoch 00245: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1236 - accuracy: 0.9469 - val_loss: 0.0631 - val_accuracy: 0.9889\n",
      "Epoch 246/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0847 - accuracy: 0.9643\n",
      "Epoch 00246: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0909 - accuracy: 0.9553 - val_loss: 0.0740 - val_accuracy: 0.9889\n",
      "Epoch 247/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0820 - accuracy: 0.9786\n",
      "Epoch 00247: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.0755 - accuracy: 0.9804 - val_loss: 0.0630 - val_accuracy: 0.9889\n",
      "Epoch 248/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0555 - accuracy: 0.9786\n",
      "Epoch 00248: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0583 - accuracy: 0.9804 - val_loss: 0.0623 - val_accuracy: 0.9889\n",
      "Epoch 249/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0753 - accuracy: 0.9704\n",
      "Epoch 00249: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.0742 - accuracy: 0.9749 - val_loss: 0.0457 - val_accuracy: 0.9889\n",
      "Epoch 250/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1672 - accuracy: 0.9286\n",
      "Epoch 00250: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.1678 - accuracy: 0.9274 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0793 - accuracy: 0.9714\n",
      "Epoch 00251: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.0898 - accuracy: 0.9637 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1176 - accuracy: 0.9519\n",
      "Epoch 00252: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.1052 - accuracy: 0.9581 - val_loss: 0.0708 - val_accuracy: 0.9889\n",
      "Epoch 253/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0818 - accuracy: 0.9778\n",
      "Epoch 00253: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0958 - accuracy: 0.9721 - val_loss: 0.0621 - val_accuracy: 0.9889\n",
      "Epoch 254/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0628 - accuracy: 0.9750\n",
      "Epoch 00254: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0584 - accuracy: 0.9804 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 0.9657\n",
      "Epoch 00255: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 722us/sample - loss: 0.0984 - accuracy: 0.9637 - val_loss: 0.0832 - val_accuracy: 0.9667\n",
      "Epoch 256/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1095 - accuracy: 0.9556\n",
      "Epoch 00256: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.1073 - accuracy: 0.9553 - val_loss: 0.0563 - val_accuracy: 0.9889\n",
      "Epoch 257/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0841 - accuracy: 0.9607\n",
      "Epoch 00257: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0793 - accuracy: 0.9665 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1239 - accuracy: 0.9393\n",
      "Epoch 00258: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.1270 - accuracy: 0.9358 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1055 - accuracy: 0.9571\n",
      "Epoch 00259: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.1029 - accuracy: 0.9609 - val_loss: 0.0582 - val_accuracy: 0.9889\n",
      "Epoch 260/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1045 - accuracy: 0.9481\n",
      "Epoch 00260: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.1065 - accuracy: 0.9525 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0731 - accuracy: 0.9714\n",
      "Epoch 00261: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0755 - accuracy: 0.9693 - val_loss: 0.0568 - val_accuracy: 0.9889\n",
      "Epoch 262/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1161 - accuracy: 0.9679\n",
      "Epoch 00262: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1093 - accuracy: 0.9665 - val_loss: 0.0687 - val_accuracy: 0.9889\n",
      "Epoch 263/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1348 - accuracy: 0.9500\n",
      "Epoch 00263: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.1245 - accuracy: 0.9553 - val_loss: 0.0710 - val_accuracy: 0.9889\n",
      "Epoch 264/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0978 - accuracy: 0.9571\n",
      "Epoch 00264: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0840 - accuracy: 0.9637 - val_loss: 0.0684 - val_accuracy: 0.9889\n",
      "Epoch 265/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0999 - accuracy: 0.9607\n",
      "Epoch 00265: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.1004 - accuracy: 0.9581 - val_loss: 0.0646 - val_accuracy: 0.9889\n",
      "Epoch 266/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0726 - accuracy: 0.9714\n",
      "Epoch 00266: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0721 - accuracy: 0.9693 - val_loss: 0.0665 - val_accuracy: 0.9889\n",
      "Epoch 267/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0974 - accuracy: 0.9643\n",
      "Epoch 00267: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.1163 - accuracy: 0.9581 - val_loss: 0.0927 - val_accuracy: 0.9778\n",
      "Epoch 268/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1108 - accuracy: 0.9519\n",
      "Epoch 00268: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.1258 - accuracy: 0.9497 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1123 - accuracy: 0.9464\n",
      "Epoch 00269: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 680us/sample - loss: 0.1142 - accuracy: 0.9469 - val_loss: 0.0723 - val_accuracy: 0.9889\n",
      "Epoch 270/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1598 - accuracy: 0.9464\n",
      "Epoch 00270: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1580 - accuracy: 0.9469 - val_loss: 0.0986 - val_accuracy: 0.9778\n",
      "Epoch 271/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0939 - accuracy: 0.9704\n",
      "Epoch 00271: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0806 - accuracy: 0.9777 - val_loss: 0.0941 - val_accuracy: 0.9778\n",
      "Epoch 272/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1471 - accuracy: 0.9500\n",
      "Epoch 00272: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1369 - accuracy: 0.9553 - val_loss: 0.0710 - val_accuracy: 0.9889\n",
      "Epoch 273/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0830 - accuracy: 0.9607\n",
      "Epoch 00273: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0867 - accuracy: 0.9581 - val_loss: 0.0656 - val_accuracy: 0.9889\n",
      "Epoch 274/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0659 - accuracy: 0.9857\n",
      "Epoch 00274: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 703us/sample - loss: 0.0831 - accuracy: 0.9749 - val_loss: 0.0585 - val_accuracy: 0.9889\n",
      "Epoch 275/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0767 - accuracy: 0.9714\n",
      "Epoch 00275: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0763 - accuracy: 0.9721 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
      "Epoch 276/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0850 - accuracy: 0.9556\n",
      "Epoch 00276: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0963 - accuracy: 0.9581 - val_loss: 0.0654 - val_accuracy: 0.9889\n",
      "Epoch 277/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1120 - accuracy: 0.9536\n",
      "Epoch 00277: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0946 - accuracy: 0.9637 - val_loss: 0.0544 - val_accuracy: 0.9889\n",
      "Epoch 278/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0872 - accuracy: 0.9714\n",
      "Epoch 00278: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0958 - accuracy: 0.9637 - val_loss: 0.0932 - val_accuracy: 0.9778\n",
      "Epoch 279/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1088 - accuracy: 0.9429\n",
      "Epoch 00279: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1016 - accuracy: 0.9469 - val_loss: 0.0760 - val_accuracy: 0.9778\n",
      "Epoch 280/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0893 - accuracy: 0.9607\n",
      "Epoch 00280: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0929 - accuracy: 0.9581 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1091 - accuracy: 0.9607\n",
      "Epoch 00281: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.1014 - accuracy: 0.9637 - val_loss: 0.0541 - val_accuracy: 0.9889\n",
      "Epoch 282/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0833 - accuracy: 0.9607\n",
      "Epoch 00282: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.1026 - accuracy: 0.9469 - val_loss: 0.0633 - val_accuracy: 0.9889\n",
      "Epoch 283/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0995 - accuracy: 0.9500\n",
      "Epoch 00283: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0864 - accuracy: 0.9581 - val_loss: 0.0644 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1014 - accuracy: 0.9481\n",
      "Epoch 00284: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.1080 - accuracy: 0.9441 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1274 - accuracy: 0.9536\n",
      "Epoch 00285: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1179 - accuracy: 0.9553 - val_loss: 0.0590 - val_accuracy: 0.9889\n",
      "Epoch 286/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0820 - accuracy: 0.9704\n",
      "Epoch 00286: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0809 - accuracy: 0.9693 - val_loss: 0.0610 - val_accuracy: 0.9778\n",
      "Epoch 287/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0692 - accuracy: 0.9704\n",
      "Epoch 00287: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0807 - accuracy: 0.9693 - val_loss: 0.0708 - val_accuracy: 0.9889\n",
      "Epoch 288/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1626 - accuracy: 0.9357\n",
      "Epoch 00288: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.1474 - accuracy: 0.9385 - val_loss: 0.0661 - val_accuracy: 0.9889\n",
      "Epoch 289/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0957 - accuracy: 0.9536\n",
      "Epoch 00289: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1000 - accuracy: 0.9497 - val_loss: 0.0642 - val_accuracy: 0.9889\n",
      "Epoch 290/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0968 - accuracy: 0.9643\n",
      "Epoch 00290: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0937 - accuracy: 0.9665 - val_loss: 0.0695 - val_accuracy: 0.9778\n",
      "Epoch 291/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0876 - accuracy: 0.9571\n",
      "Epoch 00291: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1024 - accuracy: 0.9525 - val_loss: 0.0810 - val_accuracy: 0.9889\n",
      "Epoch 292/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1013 - accuracy: 0.9667\n",
      "Epoch 00292: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 702us/sample - loss: 0.0895 - accuracy: 0.9693 - val_loss: 0.0665 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0878 - accuracy: 0.9630\n",
      "Epoch 00293: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 686us/sample - loss: 0.0787 - accuracy: 0.9665 - val_loss: 0.0682 - val_accuracy: 0.9889\n",
      "Epoch 294/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0755 - accuracy: 0.9571\n",
      "Epoch 00294: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0858 - accuracy: 0.9553 - val_loss: 0.0565 - val_accuracy: 0.9889\n",
      "Epoch 295/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0846 - accuracy: 0.9750\n",
      "Epoch 00295: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.0865 - accuracy: 0.9749 - val_loss: 0.0705 - val_accuracy: 0.9889\n",
      "Epoch 296/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0721 - accuracy: 0.9786\n",
      "Epoch 00296: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0658 - accuracy: 0.9804 - val_loss: 0.0695 - val_accuracy: 0.9889\n",
      "Epoch 297/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0927 - accuracy: 0.9704\n",
      "Epoch 00297: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0927 - accuracy: 0.9693 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0701 - accuracy: 0.9714\n",
      "Epoch 00298: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0918 - accuracy: 0.9637 - val_loss: 0.0596 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0917 - accuracy: 0.9630\n",
      "Epoch 00299: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0919 - accuracy: 0.9637 - val_loss: 0.0626 - val_accuracy: 0.9889\n",
      "Epoch 300/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0951 - accuracy: 0.9643\n",
      "Epoch 00300: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.0871 - accuracy: 0.9665 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0567 - accuracy: 0.9786\n",
      "Epoch 00301: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.0697 - accuracy: 0.9749 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0831 - accuracy: 0.9704\n",
      "Epoch 00302: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0757 - accuracy: 0.9721 - val_loss: 0.0693 - val_accuracy: 0.9778\n",
      "Epoch 303/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0914 - accuracy: 0.9704\n",
      "Epoch 00303: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0926 - accuracy: 0.9665 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
      "Epoch 304/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0916 - accuracy: 0.9536\n",
      "Epoch 00304: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.0779 - accuracy: 0.9637 - val_loss: 0.0682 - val_accuracy: 0.9889\n",
      "Epoch 305/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0956 - accuracy: 0.9750\n",
      "Epoch 00305: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0833 - accuracy: 0.9777 - val_loss: 0.0717 - val_accuracy: 0.9778\n",
      "Epoch 306/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1092 - accuracy: 0.9536\n",
      "Epoch 00306: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0972 - accuracy: 0.9553 - val_loss: 0.0505 - val_accuracy: 0.9889\n",
      "Epoch 307/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0816 - accuracy: 0.9607\n",
      "Epoch 00307: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0928 - accuracy: 0.9637 - val_loss: 0.0617 - val_accuracy: 0.9889\n",
      "Epoch 308/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1260 - accuracy: 0.9559\n",
      "Epoch 00308: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 714us/sample - loss: 0.1225 - accuracy: 0.9581 - val_loss: 0.0844 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1089 - accuracy: 0.9593\n",
      "Epoch 00309: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 682us/sample - loss: 0.1060 - accuracy: 0.9581 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1081 - accuracy: 0.9643\n",
      "Epoch 00310: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 681us/sample - loss: 0.1019 - accuracy: 0.9693 - val_loss: 0.0847 - val_accuracy: 0.9667\n",
      "Epoch 311/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0686 - accuracy: 0.9852\n",
      "Epoch 00311: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0680 - accuracy: 0.9832 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1007 - accuracy: 0.9607\n",
      "Epoch 00312: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0975 - accuracy: 0.9637 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0531 - accuracy: 0.9893\n",
      "Epoch 00313: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0658 - accuracy: 0.9832 - val_loss: 0.0996 - val_accuracy: 0.9667\n",
      "Epoch 314/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0965 - accuracy: 0.9607\n",
      "Epoch 00314: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0870 - accuracy: 0.9693 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0736 - accuracy: 0.9679\n",
      "Epoch 00315: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0644 - accuracy: 0.9721 - val_loss: 0.0600 - val_accuracy: 0.9778\n",
      "Epoch 316/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0584 - accuracy: 0.9821\n",
      "Epoch 00316: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.0754 - accuracy: 0.9777 - val_loss: 0.0546 - val_accuracy: 0.9778\n",
      "Epoch 317/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1169 - accuracy: 0.9500\n",
      "Epoch 00317: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.1143 - accuracy: 0.9525 - val_loss: 0.0916 - val_accuracy: 0.9667\n",
      "Epoch 318/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0993 - accuracy: 0.9536\n",
      "Epoch 00318: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0832 - accuracy: 0.9637 - val_loss: 0.0938 - val_accuracy: 0.9556\n",
      "Epoch 319/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0877 - accuracy: 0.9607\n",
      "Epoch 00319: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0846 - accuracy: 0.9581 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0675 - accuracy: 0.9630\n",
      "Epoch 00320: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0766 - accuracy: 0.9609 - val_loss: 0.0622 - val_accuracy: 0.9778\n",
      "Epoch 321/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0494 - accuracy: 0.9786\n",
      "Epoch 00321: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0625 - accuracy: 0.9749 - val_loss: 0.0810 - val_accuracy: 0.9667\n",
      "Epoch 322/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0818 - accuracy: 0.9607\n",
      "Epoch 00322: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 699us/sample - loss: 0.0835 - accuracy: 0.9553 - val_loss: 0.0748 - val_accuracy: 0.9778\n",
      "Epoch 323/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0935 - accuracy: 0.9643\n",
      "Epoch 00323: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0913 - accuracy: 0.9637 - val_loss: 0.0645 - val_accuracy: 0.9889\n",
      "Epoch 324/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0761 - accuracy: 0.9821\n",
      "Epoch 00324: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0912 - accuracy: 0.9749 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1037 - accuracy: 0.9607\n",
      "Epoch 00325: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 0.0981 - accuracy: 0.9637 - val_loss: 0.0826 - val_accuracy: 0.9667\n",
      "Epoch 326/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1042 - accuracy: 0.9571\n",
      "Epoch 00326: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.1051 - accuracy: 0.9525 - val_loss: 0.0616 - val_accuracy: 0.9889\n",
      "Epoch 327/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0710 - accuracy: 0.9679\n",
      "Epoch 00327: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0635 - accuracy: 0.9721 - val_loss: 0.0678 - val_accuracy: 0.9778\n",
      "Epoch 328/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0779 - accuracy: 0.9607\n",
      "Epoch 00328: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0788 - accuracy: 0.9637 - val_loss: 0.0663 - val_accuracy: 0.9778\n",
      "Epoch 329/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1152 - accuracy: 0.9679\n",
      "Epoch 00329: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.1111 - accuracy: 0.9693 - val_loss: 0.1183 - val_accuracy: 0.9667\n",
      "Epoch 330/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0911 - accuracy: 0.9536\n",
      "Epoch 00330: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.0812 - accuracy: 0.9609 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1069 - accuracy: 0.9714\n",
      "Epoch 00331: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.1006 - accuracy: 0.9693 - val_loss: 0.0592 - val_accuracy: 0.9889\n",
      "Epoch 332/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1024 - accuracy: 0.9714\n",
      "Epoch 00332: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0929 - accuracy: 0.9721 - val_loss: 0.0478 - val_accuracy: 0.9889\n",
      "Epoch 333/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0703 - accuracy: 0.9750\n",
      "Epoch 00333: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.0719 - accuracy: 0.9749 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0830 - accuracy: 0.9643\n",
      "Epoch 00334: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.0885 - accuracy: 0.9637 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0898 - accuracy: 0.9556\n",
      "Epoch 00335: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 687us/sample - loss: 0.0845 - accuracy: 0.9609 - val_loss: 0.0469 - val_accuracy: 0.9889\n",
      "Epoch 336/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0729 - accuracy: 0.9679\n",
      "Epoch 00336: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 700us/sample - loss: 0.0733 - accuracy: 0.9693 - val_loss: 0.0630 - val_accuracy: 0.9889\n",
      "Epoch 337/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0989 - accuracy: 0.9607\n",
      "Epoch 00337: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.0992 - accuracy: 0.9665 - val_loss: 0.0757 - val_accuracy: 0.9778\n",
      "Epoch 338/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0712 - accuracy: 0.9679\n",
      "Epoch 00338: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0737 - accuracy: 0.9637 - val_loss: 0.0712 - val_accuracy: 0.9889\n",
      "Epoch 339/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1183 - accuracy: 0.9750\n",
      "Epoch 00339: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.1267 - accuracy: 0.9721 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1158 - accuracy: 0.9500\n",
      "Epoch 00340: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.1118 - accuracy: 0.9525 - val_loss: 0.0436 - val_accuracy: 0.9889\n",
      "Epoch 341/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0705 - accuracy: 0.9714\n",
      "Epoch 00341: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0901 - accuracy: 0.9665 - val_loss: 0.0438 - val_accuracy: 0.9889\n",
      "Epoch 342/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0822 - accuracy: 0.9714\n",
      "Epoch 00342: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0790 - accuracy: 0.9693 - val_loss: 0.0542 - val_accuracy: 0.9889\n",
      "Epoch 343/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0819 - accuracy: 0.9786\n",
      "Epoch 00343: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.0832 - accuracy: 0.9721 - val_loss: 0.0504 - val_accuracy: 0.9889\n",
      "Epoch 344/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0752 - accuracy: 0.9786\n",
      "Epoch 00344: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0756 - accuracy: 0.9777 - val_loss: 0.0552 - val_accuracy: 0.9889\n",
      "Epoch 345/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0766 - accuracy: 0.9786\n",
      "Epoch 00345: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0904 - accuracy: 0.9693 - val_loss: 0.0563 - val_accuracy: 0.9889\n",
      "Epoch 346/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0832 - accuracy: 0.9750\n",
      "Epoch 00346: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0820 - accuracy: 0.9749 - val_loss: 0.0841 - val_accuracy: 0.9889\n",
      "Epoch 347/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1658 - accuracy: 0.9286\n",
      "Epoch 00347: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.1418 - accuracy: 0.9385 - val_loss: 0.0583 - val_accuracy: 0.9889\n",
      "Epoch 348/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0762 - accuracy: 0.9704\n",
      "Epoch 00348: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 683us/sample - loss: 0.0748 - accuracy: 0.9721 - val_loss: 0.0752 - val_accuracy: 0.9889\n",
      "Epoch 349/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0637 - accuracy: 0.9741\n",
      "Epoch 00349: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 708us/sample - loss: 0.0675 - accuracy: 0.9693 - val_loss: 0.0509 - val_accuracy: 0.9889\n",
      "Epoch 350/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0476 - accuracy: 0.9852\n",
      "Epoch 00350: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 681us/sample - loss: 0.0458 - accuracy: 0.9860 - val_loss: 0.0519 - val_accuracy: 0.9889\n",
      "Epoch 351/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0521 - accuracy: 0.9786\n",
      "Epoch 00351: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.0535 - accuracy: 0.9777 - val_loss: 0.0820 - val_accuracy: 0.9778\n",
      "Epoch 352/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0749 - accuracy: 0.9786\n",
      "Epoch 00352: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.0716 - accuracy: 0.9777 - val_loss: 0.0536 - val_accuracy: 0.9889\n",
      "Epoch 353/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0449 - accuracy: 0.9821\n",
      "Epoch 00353: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0493 - accuracy: 0.9777 - val_loss: 0.0428 - val_accuracy: 0.9889\n",
      "Epoch 354/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0519 - accuracy: 0.9778\n",
      "Epoch 00354: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0557 - accuracy: 0.9777 - val_loss: 0.0473 - val_accuracy: 0.9889\n",
      "Epoch 355/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0521 - accuracy: 0.9821\n",
      "Epoch 00355: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0568 - accuracy: 0.9804 - val_loss: 0.0401 - val_accuracy: 0.9889\n",
      "Epoch 356/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0753 - accuracy: 0.9704\n",
      "Epoch 00356: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 687us/sample - loss: 0.0749 - accuracy: 0.9693 - val_loss: 0.0415 - val_accuracy: 0.9889\n",
      "Epoch 357/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0879 - accuracy: 0.9643\n",
      "Epoch 00357: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.0811 - accuracy: 0.9693 - val_loss: 0.0474 - val_accuracy: 0.9889\n",
      "Epoch 358/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0763 - accuracy: 0.9714\n",
      "Epoch 00358: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0804 - accuracy: 0.9693 - val_loss: 0.0660 - val_accuracy: 0.9889\n",
      "Epoch 359/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0948 - accuracy: 0.9607\n",
      "Epoch 00359: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.1006 - accuracy: 0.9609 - val_loss: 0.0567 - val_accuracy: 0.9889\n",
      "Epoch 360/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0773 - accuracy: 0.9750\n",
      "Epoch 00360: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0810 - accuracy: 0.9721 - val_loss: 0.0598 - val_accuracy: 0.9889\n",
      "Epoch 361/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0754 - accuracy: 0.9750\n",
      "Epoch 00361: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 707us/sample - loss: 0.0712 - accuracy: 0.9777 - val_loss: 0.0719 - val_accuracy: 0.9778\n",
      "Epoch 362/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0760 - accuracy: 0.9750\n",
      "Epoch 00362: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 682us/sample - loss: 0.0910 - accuracy: 0.9665 - val_loss: 0.0505 - val_accuracy: 0.9889\n",
      "Epoch 363/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0526 - accuracy: 0.9821\n",
      "Epoch 00363: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0609 - accuracy: 0.9749 - val_loss: 0.0531 - val_accuracy: 0.9889\n",
      "Epoch 364/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0511 - accuracy: 0.9821\n",
      "Epoch 00364: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0634 - accuracy: 0.9749 - val_loss: 0.0629 - val_accuracy: 0.9778\n",
      "Epoch 365/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1065 - accuracy: 0.9571\n",
      "Epoch 00365: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0986 - accuracy: 0.9581 - val_loss: 0.0870 - val_accuracy: 0.9667\n",
      "Epoch 366/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0691 - accuracy: 0.9786\n",
      "Epoch 00366: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0672 - accuracy: 0.9777 - val_loss: 0.0619 - val_accuracy: 0.9778\n",
      "Epoch 367/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0591 - accuracy: 0.9786\n",
      "Epoch 00367: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0570 - accuracy: 0.9804 - val_loss: 0.0409 - val_accuracy: 0.9889\n",
      "Epoch 368/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0645 - accuracy: 0.9750\n",
      "Epoch 00368: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0692 - accuracy: 0.9777 - val_loss: 0.0403 - val_accuracy: 0.9889\n",
      "Epoch 369/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0793 - accuracy: 0.9679\n",
      "Epoch 00369: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0818 - accuracy: 0.9693 - val_loss: 0.0707 - val_accuracy: 0.9889\n",
      "Epoch 370/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0898 - accuracy: 0.9519\n",
      "Epoch 00370: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 680us/sample - loss: 0.0861 - accuracy: 0.9609 - val_loss: 0.0711 - val_accuracy: 0.9889\n",
      "Epoch 371/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0798 - accuracy: 0.9571\n",
      "Epoch 00371: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0777 - accuracy: 0.9609 - val_loss: 0.0480 - val_accuracy: 0.9889\n",
      "Epoch 372/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0455 - accuracy: 0.9857\n",
      "Epoch 00372: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0430 - accuracy: 0.9860 - val_loss: 0.0649 - val_accuracy: 0.9889\n",
      "Epoch 373/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0876 - accuracy: 0.9679\n",
      "Epoch 00373: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0913 - accuracy: 0.9665 - val_loss: 0.0486 - val_accuracy: 0.9889\n",
      "Epoch 374/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0721 - accuracy: 0.9679\n",
      "Epoch 00374: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 712us/sample - loss: 0.0780 - accuracy: 0.9665 - val_loss: 0.0567 - val_accuracy: 0.9889\n",
      "Epoch 375/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0813 - accuracy: 0.9643\n",
      "Epoch 00375: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0750 - accuracy: 0.9693 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0528 - accuracy: 0.9893\n",
      "Epoch 00376: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0494 - accuracy: 0.9860 - val_loss: 0.0769 - val_accuracy: 0.9778\n",
      "Epoch 377/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0702 - accuracy: 0.9750\n",
      "Epoch 00377: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0771 - accuracy: 0.9665 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0770 - accuracy: 0.9643\n",
      "Epoch 00378: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0835 - accuracy: 0.9637 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0953 - accuracy: 0.9750\n",
      "Epoch 00379: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 679us/sample - loss: 0.1221 - accuracy: 0.9693 - val_loss: 0.0659 - val_accuracy: 0.9778\n",
      "Epoch 380/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0907 - accuracy: 0.9714\n",
      "Epoch 00380: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0886 - accuracy: 0.9693 - val_loss: 0.0492 - val_accuracy: 0.9889\n",
      "Epoch 381/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0663 - accuracy: 0.9679\n",
      "Epoch 00381: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0667 - accuracy: 0.9693 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0700 - accuracy: 0.9714\n",
      "Epoch 00382: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.0620 - accuracy: 0.9749 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0793 - accuracy: 0.9571\n",
      "Epoch 00383: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0716 - accuracy: 0.9609 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0693 - accuracy: 0.9821\n",
      "Epoch 00384: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0718 - accuracy: 0.9749 - val_loss: 0.0387 - val_accuracy: 0.9889\n",
      "Epoch 385/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0482 - accuracy: 0.9821\n",
      "Epoch 00385: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0807 - accuracy: 0.9721 - val_loss: 0.0461 - val_accuracy: 0.9889\n",
      "Epoch 386/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1231 - accuracy: 0.9593\n",
      "Epoch 00386: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 705us/sample - loss: 0.1133 - accuracy: 0.9637 - val_loss: 0.0771 - val_accuracy: 0.9778\n",
      "Epoch 387/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0878 - accuracy: 0.9750\n",
      "Epoch 00387: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.1097 - accuracy: 0.9609 - val_loss: 0.0436 - val_accuracy: 0.9889\n",
      "Epoch 388/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0627 - accuracy: 0.9786\n",
      "Epoch 00388: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0596 - accuracy: 0.9804 - val_loss: 0.0459 - val_accuracy: 0.9889\n",
      "Epoch 389/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0762 - accuracy: 0.9750\n",
      "Epoch 00389: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.0695 - accuracy: 0.9777 - val_loss: 0.0617 - val_accuracy: 0.9778\n",
      "Epoch 390/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0655 - accuracy: 0.9750\n",
      "Epoch 00390: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0898 - accuracy: 0.9693 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0681 - accuracy: 0.9750\n",
      "Epoch 00391: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.0615 - accuracy: 0.9749 - val_loss: 0.0470 - val_accuracy: 0.9889\n",
      "Epoch 392/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0617 - accuracy: 0.9821\n",
      "Epoch 00392: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0656 - accuracy: 0.9777 - val_loss: 0.0361 - val_accuracy: 0.9889\n",
      "Epoch 393/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0304 - accuracy: 0.9857\n",
      "Epoch 00393: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.0411 - accuracy: 0.9804 - val_loss: 0.0664 - val_accuracy: 0.9667\n",
      "Epoch 394/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0786 - accuracy: 0.9714\n",
      "Epoch 00394: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 689us/sample - loss: 0.0727 - accuracy: 0.9721 - val_loss: 0.0417 - val_accuracy: 0.9889\n",
      "Epoch 395/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0520 - accuracy: 0.9857\n",
      "Epoch 00395: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.0470 - accuracy: 0.9888 - val_loss: 0.0465 - val_accuracy: 0.9889\n",
      "Epoch 396/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0604 - accuracy: 0.9821\n",
      "Epoch 00396: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 711us/sample - loss: 0.0632 - accuracy: 0.9804 - val_loss: 0.0416 - val_accuracy: 0.9889\n",
      "Epoch 397/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0833 - accuracy: 0.9714\n",
      "Epoch 00397: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 681us/sample - loss: 0.0757 - accuracy: 0.9721 - val_loss: 0.0511 - val_accuracy: 0.9889\n",
      "Epoch 398/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0934 - accuracy: 0.9741\n",
      "Epoch 00398: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 679us/sample - loss: 0.0871 - accuracy: 0.9721 - val_loss: 0.0568 - val_accuracy: 0.9778\n",
      "Epoch 399/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0747 - accuracy: 0.9714\n",
      "Epoch 00399: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0683 - accuracy: 0.9749 - val_loss: 0.0491 - val_accuracy: 0.9889\n",
      "Epoch 400/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0642 - accuracy: 0.9778\n",
      "Epoch 00400: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.0591 - accuracy: 0.9804 - val_loss: 0.0408 - val_accuracy: 0.9889\n",
      "Epoch 401/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0554 - accuracy: 0.9750\n",
      "Epoch 00401: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0549 - accuracy: 0.9777 - val_loss: 0.0436 - val_accuracy: 0.9889\n",
      "Epoch 402/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1680 - accuracy: 0.9500\n",
      "Epoch 00402: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1724 - accuracy: 0.9469 - val_loss: 0.0412 - val_accuracy: 0.9889\n",
      "Epoch 403/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0560 - accuracy: 0.9815\n",
      "Epoch 00403: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.0618 - accuracy: 0.9777 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0708 - accuracy: 0.9714\n",
      "Epoch 00404: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0689 - accuracy: 0.9721 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0464 - accuracy: 0.9750\n",
      "Epoch 00405: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0614 - accuracy: 0.9749 - val_loss: 0.0272 - val_accuracy: 0.9889\n",
      "Epoch 406/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0500 - accuracy: 0.9786\n",
      "Epoch 00406: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0435 - accuracy: 0.9804 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0917 - accuracy: 0.9629\n",
      "Epoch 00407: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 696us/sample - loss: 0.0963 - accuracy: 0.9609 - val_loss: 0.0520 - val_accuracy: 0.9889\n",
      "Epoch 408/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0915 - accuracy: 0.9571\n",
      "Epoch 00408: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0908 - accuracy: 0.9609 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 409/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0630 - accuracy: 0.9786\n",
      "Epoch 00409: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0647 - accuracy: 0.9804 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0771 - accuracy: 0.9643\n",
      "Epoch 00410: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0816 - accuracy: 0.9637 - val_loss: 0.0341 - val_accuracy: 0.9889\n",
      "Epoch 411/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0634 - accuracy: 0.9750\n",
      "Epoch 00411: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.0659 - accuracy: 0.9749 - val_loss: 0.0486 - val_accuracy: 0.9889\n",
      "Epoch 412/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0648 - accuracy: 0.9750\n",
      "Epoch 00412: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0735 - accuracy: 0.9665 - val_loss: 0.0379 - val_accuracy: 0.9889\n",
      "Epoch 413/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0786 - accuracy: 0.9607\n",
      "Epoch 00413: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0767 - accuracy: 0.9609 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0525 - accuracy: 0.9750\n",
      "Epoch 00414: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0567 - accuracy: 0.9777 - val_loss: 0.0525 - val_accuracy: 0.9889\n",
      "Epoch 415/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0515 - accuracy: 0.9857\n",
      "Epoch 00415: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.0494 - accuracy: 0.9860 - val_loss: 0.0543 - val_accuracy: 0.9778\n",
      "Epoch 416/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0467 - accuracy: 0.9786\n",
      "Epoch 00416: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0557 - accuracy: 0.9749 - val_loss: 0.0557 - val_accuracy: 0.9889\n",
      "Epoch 417/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1015 - accuracy: 0.9679\n",
      "Epoch 00417: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0850 - accuracy: 0.9749 - val_loss: 0.0430 - val_accuracy: 0.9889\n",
      "Epoch 418/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9686\n",
      "Epoch 00418: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 704us/sample - loss: 0.0729 - accuracy: 0.9693 - val_loss: 0.0499 - val_accuracy: 0.9889\n",
      "Epoch 419/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0470 - accuracy: 0.9821\n",
      "Epoch 00419: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0974 - accuracy: 0.9643\n",
      "Epoch 00420: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.0929 - accuracy: 0.9693 - val_loss: 0.0544 - val_accuracy: 0.9889\n",
      "Epoch 421/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0562 - accuracy: 0.9857\n",
      "Epoch 00421: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.0631 - accuracy: 0.9804 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0552 - accuracy: 0.9786\n",
      "Epoch 00422: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0578 - accuracy: 0.9749 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0524 - accuracy: 0.9750\n",
      "Epoch 00423: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0474 - accuracy: 0.9777 - val_loss: 0.0378 - val_accuracy: 0.9889\n",
      "Epoch 424/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0495 - accuracy: 0.9893\n",
      "Epoch 00424: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0495 - accuracy: 0.9860 - val_loss: 0.0380 - val_accuracy: 0.9889\n",
      "Epoch 425/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0572 - accuracy: 0.9786\n",
      "Epoch 00425: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0636 - accuracy: 0.9749 - val_loss: 0.0396 - val_accuracy: 0.9889\n",
      "Epoch 426/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0638 - accuracy: 0.9786\n",
      "Epoch 00426: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.0653 - accuracy: 0.9777 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0560 - accuracy: 0.9786\n",
      "Epoch 00427: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 701us/sample - loss: 0.0629 - accuracy: 0.9777 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0445 - accuracy: 0.9893\n",
      "Epoch 00428: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 677us/sample - loss: 0.0419 - accuracy: 0.9888 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0927 - accuracy: 0.9786\n",
      "Epoch 00429: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0756 - accuracy: 0.9832 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0515 - accuracy: 0.9786\n",
      "Epoch 00430: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0427 - accuracy: 0.9832 - val_loss: 0.0314 - val_accuracy: 0.9889\n",
      "Epoch 431/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0425 - accuracy: 0.9750\n",
      "Epoch 00431: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0491 - accuracy: 0.9721 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0578 - accuracy: 0.9750\n",
      "Epoch 00432: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0481 - accuracy: 0.9804 - val_loss: 0.0470 - val_accuracy: 0.9889\n",
      "Epoch 433/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0410 - accuracy: 0.9893\n",
      "Epoch 00433: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0388 - accuracy: 0.9888 - val_loss: 0.0376 - val_accuracy: 0.9889\n",
      "Epoch 434/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0507 - accuracy: 0.9786\n",
      "Epoch 00434: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0560 - accuracy: 0.9721 - val_loss: 0.0347 - val_accuracy: 0.9889\n",
      "Epoch 435/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0614 - accuracy: 0.9786\n",
      "Epoch 00435: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0639 - accuracy: 0.9749 - val_loss: 0.0247 - val_accuracy: 0.9889\n",
      "Epoch 436/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0628 - accuracy: 0.9786\n",
      "Epoch 00436: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 681us/sample - loss: 0.0520 - accuracy: 0.9832 - val_loss: 0.0379 - val_accuracy: 0.9889\n",
      "Epoch 437/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0767 - accuracy: 0.9771\n",
      "Epoch 00437: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 698us/sample - loss: 0.0751 - accuracy: 0.9777 - val_loss: 0.0290 - val_accuracy: 0.9889\n",
      "Epoch 438/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0427 - accuracy: 0.9824\n",
      "Epoch 00438: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 726us/sample - loss: 0.0441 - accuracy: 0.9804 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0471 - accuracy: 0.9889\n",
      "Epoch 00439: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 691us/sample - loss: 0.0426 - accuracy: 0.9916 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0593 - accuracy: 0.9771\n",
      "Epoch 00440: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 691us/sample - loss: 0.0634 - accuracy: 0.9749 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1103 - accuracy: 0.9679\n",
      "Epoch 00441: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.1036 - accuracy: 0.9665 - val_loss: 0.0381 - val_accuracy: 0.9889\n",
      "Epoch 442/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0453 - accuracy: 0.9786\n",
      "Epoch 00442: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0446 - accuracy: 0.9804 - val_loss: 0.0304 - val_accuracy: 0.9889\n",
      "Epoch 443/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0533 - accuracy: 0.9821\n",
      "Epoch 00443: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0699 - accuracy: 0.9777 - val_loss: 0.0652 - val_accuracy: 0.9778\n",
      "Epoch 444/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0647 - accuracy: 0.9750\n",
      "Epoch 00444: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0926 - accuracy: 0.9693 - val_loss: 0.0304 - val_accuracy: 0.9889\n",
      "Epoch 445/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0407 - accuracy: 0.9857\n",
      "Epoch 00445: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0445 - accuracy: 0.9832 - val_loss: 0.0297 - val_accuracy: 0.9889\n",
      "Epoch 446/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0742 - accuracy: 0.9607\n",
      "Epoch 00446: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0959 - accuracy: 0.9581 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0447 - accuracy: 0.9786\n",
      "Epoch 00447: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 680us/sample - loss: 0.0494 - accuracy: 0.9749 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0704 - accuracy: 0.9714\n",
      "Epoch 00448: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0748 - accuracy: 0.9721 - val_loss: 0.0319 - val_accuracy: 0.9889\n",
      "Epoch 449/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0621 - accuracy: 0.9750\n",
      "Epoch 00449: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0726 - accuracy: 0.9721 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0304 - accuracy: 0.9889\n",
      "Epoch 00450: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.0288 - val_accuracy: 0.9889\n",
      "Epoch 451/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0516 - accuracy: 0.9750\n",
      "Epoch 00451: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0517 - accuracy: 0.9777 - val_loss: 0.0416 - val_accuracy: 0.9889\n",
      "Epoch 452/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0753 - accuracy: 0.9714\n",
      "Epoch 00452: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0789 - accuracy: 0.9693 - val_loss: 0.0306 - val_accuracy: 0.9889\n",
      "Epoch 453/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0701 - accuracy: 0.9679\n",
      "Epoch 00453: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0667 - accuracy: 0.9721 - val_loss: 0.0343 - val_accuracy: 0.9889\n",
      "Epoch 454/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0675 - accuracy: 0.9750\n",
      "Epoch 00454: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0705 - accuracy: 0.9721 - val_loss: 0.0483 - val_accuracy: 0.9778\n",
      "Epoch 455/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0257 - accuracy: 0.9893\n",
      "Epoch 00455: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0338 - accuracy: 0.9888 - val_loss: 0.0455 - val_accuracy: 0.9889\n",
      "Epoch 456/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0467 - accuracy: 0.9786\n",
      "Epoch 00456: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 690us/sample - loss: 0.0448 - accuracy: 0.9777 - val_loss: 0.0388 - val_accuracy: 0.9889\n",
      "Epoch 457/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0528 - accuracy: 0.9741\n",
      "Epoch 00457: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 704us/sample - loss: 0.0700 - accuracy: 0.9693 - val_loss: 0.0359 - val_accuracy: 0.9889\n",
      "Epoch 458/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0624 - accuracy: 0.9741\n",
      "Epoch 00458: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0565 - accuracy: 0.9777 - val_loss: 0.0315 - val_accuracy: 0.9889\n",
      "Epoch 459/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0566 - accuracy: 0.9786\n",
      "Epoch 00459: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0590 - accuracy: 0.9804 - val_loss: 0.0312 - val_accuracy: 0.9889\n",
      "Epoch 460/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0548 - accuracy: 0.9821\n",
      "Epoch 00460: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0549 - accuracy: 0.9777 - val_loss: 0.0531 - val_accuracy: 0.9778\n",
      "Epoch 461/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0732 - accuracy: 0.9704\n",
      "Epoch 00461: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 681us/sample - loss: 0.0706 - accuracy: 0.9721 - val_loss: 0.0621 - val_accuracy: 0.9667\n",
      "Epoch 462/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9714\n",
      "Epoch 00462: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 741us/sample - loss: 0.0872 - accuracy: 0.9721 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0443 - accuracy: 0.9800\n",
      "Epoch 00463: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 701us/sample - loss: 0.0444 - accuracy: 0.9804 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0675 - accuracy: 0.9750\n",
      "Epoch 00464: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0682 - accuracy: 0.9749 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0596 - accuracy: 0.9821\n",
      "Epoch 00465: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0633 - accuracy: 0.9804 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0653 - accuracy: 0.9714\n",
      "Epoch 00466: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0724 - accuracy: 0.9693 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0673 - accuracy: 0.9714\n",
      "Epoch 00467: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 704us/sample - loss: 0.0709 - accuracy: 0.9693 - val_loss: 0.0372 - val_accuracy: 0.9889\n",
      "Epoch 468/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0804 - accuracy: 0.9714\n",
      "Epoch 00468: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0675 - accuracy: 0.9777 - val_loss: 0.0609 - val_accuracy: 0.9778\n",
      "Epoch 469/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0539 - accuracy: 0.9857\n",
      "Epoch 00469: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 0.0454 - accuracy: 0.9888 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0747 - accuracy: 0.9643\n",
      "Epoch 00470: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0658 - accuracy: 0.9665 - val_loss: 0.0398 - val_accuracy: 0.9889\n",
      "Epoch 471/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0391 - accuracy: 0.9857\n",
      "Epoch 00471: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0385 - accuracy: 0.9860 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0499 - accuracy: 0.9741\n",
      "Epoch 00472: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 711us/sample - loss: 0.0448 - accuracy: 0.9777 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0948 - accuracy: 0.9679\n",
      "Epoch 00473: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 693us/sample - loss: 0.0829 - accuracy: 0.9721 - val_loss: 0.0500 - val_accuracy: 0.9889\n",
      "Epoch 474/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9800\n",
      "Epoch 00474: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 692us/sample - loss: 0.0499 - accuracy: 0.9804 - val_loss: 0.0575 - val_accuracy: 0.9667\n",
      "Epoch 475/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0813 - accuracy: 0.9750\n",
      "Epoch 00475: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0726 - accuracy: 0.9777 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0957 - accuracy: 0.9607\n",
      "Epoch 00476: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 693us/sample - loss: 0.0933 - accuracy: 0.9609 - val_loss: 0.0341 - val_accuracy: 0.9889\n",
      "Epoch 477/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0365 - accuracy: 0.9889\n",
      "Epoch 00477: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.0834 - accuracy: 0.9721 - val_loss: 0.0368 - val_accuracy: 0.9889\n",
      "Epoch 478/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0698 - accuracy: 0.9821\n",
      "Epoch 00478: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0747 - accuracy: 0.9777 - val_loss: 0.0393 - val_accuracy: 0.9889\n",
      "Epoch 479/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0447 - accuracy: 0.9893\n",
      "Epoch 00479: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.0419 - accuracy: 0.9916 - val_loss: 0.0400 - val_accuracy: 0.9889\n",
      "Epoch 480/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0590 - accuracy: 0.9786\n",
      "Epoch 00480: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0591 - accuracy: 0.9804 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0481 - accuracy: 0.9821\n",
      "Epoch 00481: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0483 - accuracy: 0.9804 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0596 - accuracy: 0.9741\n",
      "Epoch 00482: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 687us/sample - loss: 0.0626 - accuracy: 0.9749 - val_loss: 0.0234 - val_accuracy: 0.9889\n",
      "Epoch 483/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0449 - accuracy: 0.9821\n",
      "Epoch 00483: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.0568 - accuracy: 0.9777 - val_loss: 0.0369 - val_accuracy: 0.9889\n",
      "Epoch 484/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0892 - accuracy: 0.9607\n",
      "Epoch 00484: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0711 - accuracy: 0.9693 - val_loss: 0.0667 - val_accuracy: 0.9556\n",
      "Epoch 485/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0429 - accuracy: 0.9786\n",
      "Epoch 00485: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 709us/sample - loss: 0.0391 - accuracy: 0.9804 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0861 - accuracy: 0.9677\n",
      "Epoch 00486: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 807us/sample - loss: 0.0754 - accuracy: 0.9721 - val_loss: 0.0359 - val_accuracy: 0.9889\n",
      "Epoch 487/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0846 - accuracy: 0.9750\n",
      "Epoch 00487: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 699us/sample - loss: 0.0871 - accuracy: 0.9665 - val_loss: 0.0463 - val_accuracy: 0.9889\n",
      "Epoch 488/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0409 - accuracy: 0.9879\n",
      "Epoch 00488: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 751us/sample - loss: 0.0390 - accuracy: 0.9888 - val_loss: 0.0293 - val_accuracy: 0.9889\n",
      "Epoch 489/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0860 - accuracy: 0.9593\n",
      "Epoch 00489: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 695us/sample - loss: 0.0871 - accuracy: 0.9637 - val_loss: 0.0377 - val_accuracy: 0.9889\n",
      "Epoch 490/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0565 - accuracy: 0.9821\n",
      "Epoch 00490: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 705us/sample - loss: 0.0621 - accuracy: 0.9804 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0439 - accuracy: 0.9821\n",
      "Epoch 00491: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 686us/sample - loss: 0.0401 - accuracy: 0.9832 - val_loss: 0.0290 - val_accuracy: 0.9889\n",
      "Epoch 492/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0701 - accuracy: 0.9714\n",
      "Epoch 00492: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0696 - accuracy: 0.9721 - val_loss: 0.0519 - val_accuracy: 0.9778\n",
      "Epoch 493/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0657 - accuracy: 0.9714\n",
      "Epoch 00493: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0569 - accuracy: 0.9749 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0697 - accuracy: 0.9714\n",
      "Epoch 00494: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.0665 - accuracy: 0.9721 - val_loss: 0.0304 - val_accuracy: 0.9889\n",
      "Epoch 495/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0714 - accuracy: 0.9714\n",
      "Epoch 00495: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0659 - accuracy: 0.9749 - val_loss: 0.0332 - val_accuracy: 0.9889\n",
      "Epoch 496/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0415 - accuracy: 0.9786\n",
      "Epoch 00496: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0474 - accuracy: 0.9749 - val_loss: 0.0215 - val_accuracy: 0.9889\n",
      "Epoch 497/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0444 - accuracy: 0.9889\n",
      "Epoch 00497: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 712us/sample - loss: 0.0472 - accuracy: 0.9888 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0482 - accuracy: 0.9857\n",
      "Epoch 00498: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 701us/sample - loss: 0.0556 - accuracy: 0.9804 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1093 - accuracy: 0.9600\n",
      "Epoch 00499: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 703us/sample - loss: 0.1076 - accuracy: 0.9609 - val_loss: 0.0309 - val_accuracy: 0.9889\n",
      "Epoch 500/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0404 - accuracy: 0.9893\n",
      "Epoch 00500: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0493 - accuracy: 0.9860 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Training completed in time:  0:02:01.015608\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.375\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAJcCAYAAADTmwh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nOzdeZzV8+LH8denaZcWu7oU10xatEioLDeyVfeiSLlRskdlyd5F/US0iCwX4SJRdl1F9sjuWqJURFK6SaFFqpnP74857h1d1VRz5jtz5vV8PM6js3zP+b7nzDHjPZ/P5/sNMUYkSZIkSSrtyiUdQJIkSZKkomDBlSRJkiRlBAuuJEmSJCkjWHAlSZIkSRnBgitJkiRJyggWXEmSJElSRrDgSpKUsBBClRDChBDCjyGER5LOsz4hhFdCCKcV4et9FUJoV1SvJ0mSBVeSVKxSpebnEMLyEMLCEMI/QgjV1tmmdQjhpRDCslTpmxBCaLjONtVDCCNDCF+nXuuL1O3t1rPfEELoG0L4JISwIoTwTQjhkRDCXun8egvpOGBHYNsY4/Fb+mIhhD+FEPJS70vBS6stj7pJOTbpeyRJ0pay4EqSkvDnGGM1oBnQHLjs1wdSJWwy8BRQG9gN+AiYGkLYPbVNReBFoBFwJFAdaAV8D+y7nn3eBPQD+gLbADnAk0CHTQ0fQii/qc/ZiLrArBjj2iLMsiDGWG2dy5tbFnOTcm3O90iSpC1iwZUkJSbGuBB4jvyi+6sbgPtjjDfFGJfFGJfEGAcAbwFXp7Y5GdgVODbGOD3GmBdjXBRj/L8Y48R19xNCyAbOAbrFGF+KMf4SY1wZY3wwxjgktc1vpt+GEHqGEF4vcDuGEM4JIcwGZocQbg8hDFtnP0+FEC5IXa8dQngshPBdCOHLEELf33sPQggDgSuBE1KjnKeGEMqFEAaEEOaGEBaFEO4PIdRIbV8vleXUEMLXwEuFf8f/s89TQggzUiPkc0IIZ67z+NEhhA9DCD+lRl2PLPBw3RDC1NRzJ29gNHZTv0f7hhDeDCH8EEL4NoRwS6ok/zr6fmPqvfgphDAthNA49Vj7EML0VJ75IYT+m/p+SJIyhwVXkpSYEMIfgKOAz1O3qwKtgd9bhzoeOCx1vR3wbIxxeSF3dSjwTYzxnS1LzDHAfkBD4CHyS2kACCHUAg4HHg4hlAMmkD/yXCe1//NCCEes+4IxxquAa4FxqVHWu4GeqUtbYHegGnDLOk89GGgA/M9rFsIioCP5o6qnADeGEPZOfR37AvcDFwE1gYOArwo898TUc3YAKgLrK5Sb+j3KBc4HtiN/pPdQoHfqscNTOXKAGkAX8keCAe4Gzowxbg00ZjMKvyQpc1hwJUlJeDKEsAyYR37Zuip1/zbk/2769nee8y355Qdg2/Vssz6buv36XJcaUf4ZeA2IwIGpx44D3owxLgBaAtvHGAfFGFfHGOcAdwFdC7mfvwIjYoxzUgXxMqDrOtORr44xrkhl+T21U6OhBS9bAcQYn4kxfhHzvUr+lPBfv45TgXtijM+nRl3nxxg/K/C698YYZ6X2O57fjr4XtEnveYzx/RjjWzHGtTHGr4A7yC/xAGuArYE9gRBjnBFj/LbAYw1DCNVjjEtjjP8q7D4lSZnHgitJSsIxqRG3P5FfWn4trkuBPGDn33nOzsDi1PXv17PN+mzq9usz79crMcYIPAx0S911IvBg6npd1imYwOXkH0iqMGoDcwvcnguUX+f589iwBTHGmutcVgCEEI4KIbwVQliSytae/34PdgG+2MDrLixwfSX5o8u/Z5Pe8xBCTgjhnyH/wGM/kT+qvR1AjPEl8kewbwUWhRDuDCFUTz21cyr/3BDCq8V9IC1JUsliwZUkJSY1evgPYFjq9grgTeD3jiTchfyDFgG8ABzx64hkIbwI/CGEsM8GtlkBVC1we6ffi7zO7YeA40IIdcmfuvxY6v55wJfrlMutY4ztC5l3Afkl+Ve7AmuBf28gS6GEECqlcg4Ddowx1gQmAqFA9j9uzmuvY1O/R7cDnwHZMcbq5P9B4NdMxBhvjjG2IH96eA75U6iJMb4bYzya/CnTT5I/qixJKqMsuJKkpI0EDgshNE3dvhToEfJP6bN1CKFWCOEa8tdlDkxt8wD5ReyxEMKeqYMybRtCuDyE8D8lMsY4G7gNeCjkn0KnYgihcgihawjh0tRmHwKdQghVQwh7kD9Vd4NijB+QP6o8GnguxvhD6qF3gGUhhEtC/jlus0IIjUMILQv5njwEnB9C2C3kn0Lp1zW6m3yU5d9REagEfAesDSEcRf4a11/dDZwSQjg09b7WCSHsuRn72aTvEflTkH8Clqf2d/avD4QQWoYQ9gshVCD/DxGrgLzU9/GvIYQaMcY1qefnbUZWSVKGsOBKkhIVY/yO/IMaXZm6/Tr5B07qRP4azrnkn0rogFRRJcb4C/kHMfoMeJ78YvMO+VNa317Prvry32muP5A/DfdY8g8GBXAjsJr8UdL7+O90440Zm8oytsDXlEv+QZyaAV/y3xJco5CveQ/5BXFK6vmrgD6FfO6vaof/PQ9u5xjjMvLfi/HkTwk/EXi6QPZ3SB14CvgReJXfjiYXymZ8j/qnsiwjf73yuAKPVU/dt5T8z8P3wNDUYycBX6WmNZ9F/vplSVIZFfKXEEmSJEmSVLo5gitJkiRJyggWXEmSJElSRrDgSpIkSZIyggVXkiRJkpQRyicdYFMdcsgh8aWXXko6hrTF/v3vf7PjjjsmHUPaIn6OlSn8LCsT+DlWBgkb3+T3lboR3O+//z7pCFKRyM3NTTqCtMX8HCtT+FlWJvBzLJXCgitJkiRJ0u+x4EqSJEmSMoIFV5IkSZKUESy4kiRJkqSMYMGVJEmSJGUEC64kSZIkKSNYcCVJkiRJGcGCK0mSJEnKCBZcSZIkSVJGsOBKkiRJkjKCBVeSJEmSlBEsuJIkSZKkjGDBlSRJkiRlBAuuJEmSJCkjWHAlSZIkSRnBgitJkiRJyggWXEmSJElSRrDgSpIkSZIyggVXkiRJkpQRLLiSJEmSpIxgwZUkSZIkZYS0FdwQwj0hhEUhhE/W83gIIdwcQvg8hPBxCGHvdGWRJEmSJGW+dI7g/gM4cgOPHwVkpy5nALenMYskSZIkKcOVT9cLxxinhBDqbWCTo4H7Y4wReCuEUDOEsHOM8dt0ZZKktHtjFLwyBFYvTzpJsaiddACpiPhZVibwc6yMcfWPm/3UtBXcQqgDzCtw+5vUff9TcEMIZ5A/ysvOO+/MggULiiWglE5LlixJOoLSYKeXr6XcmpVJx5AkSSqTkiy4hRZjvBO4E6Bp06axdm3/PqXM4Gc5A1luJUmSEpNkwZ0P7FLg9h9S90lSZtiC6TWlxYIFC/xDjTKCn2VlAj/HWp96lz7zn+tfDemQYJL/WrNmDSeeeCKPPvoodevWZdiwYXTu3JkQwha9bpKnCXoaODl1NOX9gR9dfytJkiRJmWvt2rUAVKhQgerVqzNo0CBmzJjBcccdt8XlFtI4ghtCeAj4E7BdCOEb4CqgAkCM8e/ARKA98DmwEjglXVkkSZIkScmJMfLQQw9xxRVX8M9//pNGjRpx9913F/l+0nkU5W4beTwC56Rr/5IkSZKk5L3//vv07duXN954g+bNm7N69eq07SvJKcqSJEmSpAx2zjnn0LJlSz7//HNGjx7Nu+++S/PmzdO2PwuuJEmSJKnI/LrOFmC77bbjggsuYNasWZx66qlkZWWldd8WXEmSJElSkZg4cSKNGjXi2WefBWDgwIEMGzaMGjVqFMv+LbiSJEmSpC0yc+ZM2rdvT4cOHQghUKVKlURyWHAlSZIkSZtt8ODBNG7cmKlTpzJ8+HA+/vhjDj744ESypO0oypIkSZKkzJSbmwtAVlYWO+64Iz179mTw4MHssMMOieZyBFeSJEmSVGivv/46LVu25M477wTgtNNO46677kq83IIFV5IkSZJUCPPmzaNbt24ceOCBfPfdd+y0005JR/ofFlxJkiRJ0gaNHj2a+vXr8+STT3LllVfy2WefceyxxyYd63+4BleSJEmS9D9ijKxZs4aKFStSt25dOnTowNChQ6lXr17S0dbLEVxJkiRJ0m989NFHtG3blgEDBgBw2GGH8cgjj5TocgsWXEmSJElSyuLFizn77LPZe++9+eSTT6hfv37SkTaJU5QlSZIkSTz99NP06NGDZcuW0adPH6666ipq1aqVdKxNYsGVJEmSpDLsl19+oVKlSmRnZ9OqVSuGDRtGw4YNk461WSy4kiRJklQGff7551x44YVUrFiRRx55hAYNGjBx4sSkY20RC64kSZIkJeCuKXMY+cIsVqzOLdb9Llu2jMGDB3PjjTdSsWJFBgwYQIyREEKx5kgHC64kSZIkJaC4y+1WFbN488036dSpEwsXLqRnz55ce+217LzzzsWWId0suJIkSZKUgOIst1UrZnFeuxyys6vTrFkzBg4cyL777lts+y8uFlxJkiRJSthXQzqk5XUXLFjApZdeysyZMzn16jcpV64ckyZNSsu+SgLPgytJkiRJGWbVqlVcd9115OTkMG7cOA499FDWrFmTdKy0cwRXkiRJkjLIzJkzad++PXPmzOGYY45h+PDh7L777knHKhYWXEmSJEnKAD///DNVqlShXr16NG7cmDvuuIN27dolHatYOUVZkiRJkkqxJUuW0KdPHxo2bMiKFSuoVKkSTz31VJkrt2DBlSRJkqRSae3atdx2221kZ2dz22230b59e9auXZt0rEQ5RVmSJEmSSpnFixdzyCGHMG3aNNq2bctNN93EXnvtlXSsxDmCK0mSJEmlxIoVKwDYdtttad68OY899hgvvvii5TbFgitJkiRJJdyKFSsYMGAAdevWZf78+YQQuO++++jUqRMhhKTjlRgWXEmSJEkqoWKMPPjgg9SvX5/Bgwdz5JFHkpWVlXSsEss1uJIkSZJUAq1evZpDDz2U119/nRYtWjB+/Hhat26ddKwSzYIrSZIkSSXI8uXLqVatGhUrVqRVq1accsop9OzZk3LlnIC7Mb5DkiRJklQCrF69mmHDhrHLLrvwr3/9C4AbbriBXr16WW4LyXdJkiRJkhL2zDPP0LhxYy666CIOOOAAatSokXSkUskpypIkSZKUsI4dO1K/fn0mTZrEkUcemXScUsuCK0mSJEnFbNmyZb+5PWLECM4991wqVKiQUKLM4BRlSZIkSSomubm53HXXXfzxj3/8zf3nn3++5bYIWHAlSZIkqRhMmTKFffbZhzPOOIP69esnHScjOUVZkiRJkjbRXVPmMPKFWaxYnbtpTzziGuoeAfPSE6vMcwRXkiRJkjbRZpXb9diqYlaRvI4suJIkSZK0yYqy3J7XLqdIXktOUZYkSZKkLfLVkA7/uf7BBx/Qr18/XnvtNZo2bcqoUaM48MADE0xXtjiCK0mSJElF4IYbbqBFixbMmDGDO+64g/fff99yW8wsuJIkSZK0BZYvXw5A69at6du3L7NmzeKMM84gK8u1tcXNgitJkiRJW+Cyyy4D4IADDmDkyJHUqlUr4URllwVXkiRJkjbB7Nmzf3P7iCOOSCiJ1mXBlSRJkqRCGjNmDI0aNfrNfR07dkwojdZlwZUkSZKkDcjLy+OHH34A8tfZnnzyyQkn0vpYcCVJkiRpPd588032228/unfvDsDuu+/O6NGjE06l9bHgSpIkSdI65s+fz0knnUTr1q1ZsGABXbt2JcaYdCxtRPmkA0iSJElSSfLCCy9w9NFHk5ubyxVXXMGll15KtWrVko6lQnAEV5IkSVKZF2Nk8eLFALRs2ZIuXbowffp0rrnmGsttKWLBlSRJklSmTZs2jXbt2tG2bVvWrl1LjRo1uPfee9l9992TjqZNZMGVJEmSVCZ9//33nHPOOTRr1owPPviAs846K+lI2kKuwZUkSZJU5kybNo2DDz6Yn376id69e3P11Vez7bbbJh1LW8iCK0mSJKnMWLRoETvssAMNGjTg+OOPp0+fPjRu3DjpWCoiTlGWJEmSlPHmzJlDp06d2Guvvfjxxx8pX748d9xxh+U2w1hwJUmSJGWs5cuXc/nll9OgQQMmT55Mv379qFSpUtKxlCZOUZYkSZKUkRYuXEiLFi1YsGAB3bt3Z8iQIdSpUyfpWEojC64kSZKkjLJw4UJ22mkndtppJ0488UQ6depEq1atko6lYmDBlSRJkpQRvv32Wy677DLGjx/Pp59+ym677cbQoUM3+XXumjKHkS/MYsXq3DSkVDq5BleSJElSqfbLL79w/fXXk5OTw9ixY+nTp88WnfJnU8rtVhWzNns/KnqO4EqSJEkqtVatWkWzZs2YOXMmf/nLXxg2bBjZ2dlb9JqbUm7Pa5ezRftS0bLgSpIkSSp1FixYQO3atalcuTKnnHIKzZo144gjjijy/Xw1pEORv6bSxynKkiRJkkqNpUuXct5551G3bl2mTp0KwCWXXJKWcqvSxxFcSZIkSSVebm4uo0ePZsCAASxZsoQzzjiDnBynB+u3LLiSJEmSSrQYI4cccghTpkzhoIMO4qabbqJZs2ZJx1IJ5BRlSZIkSSXS/PnziTESQqBHjx6MHz+eV155xXKr9bLgSpIkSSpRVq5cyVVXXcUee+zB2LFjAejVqxfHH388IYSE06kkc4qyJEmSpBIhxsi4ceO46KKL+Oabb+jatSsHHXRQ0rFUijiCK0mSJKlEOOmkk+jWrRvbb789U6ZM4aGHHmKXXXZJOpZKEUdwJUmSJCVm0aJFbL311lSpUoWuXbty8MEH06tXL7KyspKOplLIEVxJkiRJxW716tWMGDGC7Oxshg8fDkDHjh05/fTTLbfabBZcSZIkScVq0qRJNGnShAsvvJA2bdpw/PHHJx1JGcKCK0mSJKnYXH755bRv354YI8888wwTJ06kfv36ScdShnANriRJkqS0+vHHH8nNzWWbbbahU6dObLPNNvTt25eKFSsmHU0ZxhFcSZIkSWmRl5fH3XffTU5ODhdddBEA++yzD/3797fcKi0suJIkSZKK3NSpU9l333057bTT2GOPPTj77LOTjqQywIIrSZIkqUjdfvvtHHDAASxcuJCxY8fy+uuvs88++yQdS2WAa3AlSZIkbbGff/6ZpUuXUrt2bf785z+zcOFCLr74Yrbaaquko6kMcQRXkiRJ0maLMfLYY4/RsGFDunfvToyRP/zhDwwcONByq2LnCK4kSZKkzfLxxx/Tr18/XnnlFfbaay/+9re/EUJIOtZG3TVlDiNfmMWK1blJR1ERs+BKkiRJ2mRPP/00xx57LDVr1uS2227j9NNPp3z50lEvCltut6qYVQxpVJScoixJkiSpUNasWcOXX34JwCGHHMIll1zC7NmzOfvss0tNuQUKXW7Pa5dTDGlUlErPp1CSJElSYl544QX69evHmjVr+PTTT6lWrRrXXntt0rG22FdDOiQdQUXIEVxJkiRJ6/XFF19wzDHHcNhhh7Fq1SqGDh1aqkZrVbb4yZQkSZL0u95//31at25NhQoVuO666zj//POpVKlS0rGk9XIEV5IkSdJ/5OXlMXPmTACaNWvGJZdcwqxZs7j00ksttyrxLLiSJEmSAHj77bdp3bo1rVq1YsmSJWRlZTFo0CBq166ddDSpUCy4kiRJUhn37bff0rNnT/bff3/mzp3LyJEjqVmzZtKxpE3mGlxJkiSpDJs/fz577rknq1ev5pJLLuGKK65g6623TjqWtFksuJIkSVIZE2NkxowZNGzYkDp16nDllVdy7LHHssceeyQdTdoiTlGWJEmSypDp06dzxBFH0LRpU2bNmgXARRddZLlVRrDgSpIkSWXA0qVL6devH02aNOHdd99l+PDh7LbbbknHkoqUU5QlSZKkDLdy5UoaNWrEv//9b84880wGDRrEdtttl3QsqchZcCVJkqQMNW3aNPbaay+qVq3KwIED2XfffWnatGnSsaS0cYqyJEmSlGG++uorjj/+eJo0acLLL78MwOmnn265VcZLa8ENIRwZQpgZQvg8hHDp7zy+awjh5RDCByGEj0MI7dOZR5IkScpkK1as4Morr6RBgwY888wzDBo0iP333z/pWFKxSdsU5RBCFnArcBjwDfBuCOHpGOP0ApsNAMbHGG8PITQEJgL10pVJkiRJylQxRlq3bs3HH39Mt27duP7669lll12SjiUVq3Suwd0X+DzGOAcghPAwcDRQsOBGoHrqeg1gQRrzSJIkSRln2rRpNGzYkBACf/vb39hpp5044IADko4lJSKdBbcOMK/A7W+A/dbZ5mpgcgihD7AV0O73XiiEcAZwBsDOO+/MggX2YJV+S5YsSTqC0qB2getl4WeVn2NlCj/LKo2+++47rr/+eh5++GGGDx/OYYcdRuvWrYGy8TuoqPhelTy1a9fe+EbrkfRRlLsB/4gxDg8htAIeCCE0jjHmFdwoxngncCdA06ZN45Z8wVJJ4mc5s5WV729Z+TqV+fwsq7RYvXo1o0aNYtCgQaxcuZILLriAXr16sWLFCj/HhfbBf675nmWWdBbc+UDBSf9/SN1X0KnAkQAxxjdDCJWB7YBFacwlSZIklVqdO3fmn//8J+3bt2fEiBHUr18fyD/AlFTWpbPgvgtkhxB2I7/YdgVOXGebr4FDgX+EEBoAlYHv0phJkiRJKnVmzpxJnTp1qFatGhdeeCFnn3027dt7ApLfc9eUOYx8YRYrVucmHUUJSNtpgmKMa4FzgeeAGeQfLfnTEMKgEMJfUptdCJweQvgIeAjoGWOM6cokSZIklSY//vgjF154IY0bN2bo0KEA/OlPf7LcbsCmlNutKmalOY2KW1rX4MYYJ5J/6p+C911Z4Pp0oE06M0iSJEmlTW5uLvfeey+XX345ixcv5tRTT6V3795JxyoVNqXcntcuJ81pVNySPsiUJEmSpHX069ePW2+9lTZt2vDss8+y9957Jx2pVPpqSIekI6iYWXAlSZKkEmDevHmUL1+enXfembPOOos2bdrQtWtXQghJR5NKjbStwZUkSZK0cT///DODBg2ifv36XHLJJQA0btyYbt26WW6lTeQIriRJkpSAGCOPPvoo/fv35+uvv+b4449n0KBBSceSSjVHcCVJkqQEDB06lC5dulCrVi1eeeUVxo8fT7169ZKOJZVqjuBKkiRJxWTx4sUsXbqU7OxsevbsSY0aNTjttNPIyvJ0NVJRcARXkiRJSrM1a9Zw8803k52dzamnngrADjvswJlnnmm5lYqQBVeSJElKo8mTJ9O0aVP69etHy5Yt+fvf/550JCljWXAlSZKkNHn44Yc54ogjWL16NU8//TTPPfccDRs2TDqWlLEsuJIkSVIRWrZsGR999BEAxxxzDDfffDOffvopf/7znz3tj5RmFlxJkiSpCOTl5fGPf/yDnJwcjjnmGNauXUvlypXp06cPlSpVSjqeVCZYcCVJkqQt9NZbb7H//vtzyimnULduXcaNG0f58p6wRCpu/lcnSZIkbYE33niDNm3asPPOO3P//ffz17/+lXLlHEeSkuB/eZIkSdImWrVqFW+99RYArVq14tZbb2XWrFmcdNJJllspQf7XJ0mSJBVSjJEnnniChg0bcvjhh7N06VJCCPTu3Ztq1aolHU8q8yy4kiRJUiF88sknHHbYYXTq1ImqVavy+OOPU6tWraRjSSrANbiSJEnSRsydO5fmzZuz9dZbM2rUKM466ywPIiWVQI7gSpIkSb9j7dq1vPrqqwDUrVuX0aNHM3v2bM4991zLrVRCWXAlSZKkdbz88svsvffeHHLIIcyaNQuAHj16sO222yacTNKG+KcnSZIkKeXLL7+kf//+PP7449SrV49HHnmE7OzspGOVGXdNmcPIF2axYnVu0lFUSllwJUmSJGD58uXsvfferF69msGDB3PBBRdQuXLlpGOVKUVZbreqmFUkr6PSxYIrSZKkMivGyAsvvEC7du2oVq0ao0ePZv/996dOnTpJRyuTirLcntcup0heS6WLBVeSJEll0nvvvUffvn158803eeGFFzj00EPp3Llz0rGU8tWQDklHUCnkQaYkSZJUpixcuJBevXrRsmVL5syZwz333EPbtm2TjiWpCDiCK0mSpDIjLy+Pgw46iK+++oqLLrqIAQMGUL169aRjSSoiFlxJkiRltF/X2bZt25by5ctz2223seuuu5KT4xpNKdM4RVmSJEkZa8aMGRx11FEcfvjh3H///QC0a9fOcitlKAuuJEmSMs4PP/zA+eefT5MmTXjrrbe48cYbOemkk5KOJSnNnKIsSZKkjNO5c2defvllTj/9dK655hq23377pCNJKgYWXEmSJGWE1157jb322ouaNWsyZMgQypcvT/PmzZOOJakYOUVZkiRJpdrXX3/NCSecwEEHHcSIESMAaNmypeVWKoMcwZUkSVKptHLlSoYOHcr1119PjJGrrrqKiy++OOlYkhJkwZUkSVKp1KdPH+655x5OOOEEbrjhBnbdddekI0lKmAVXkiRJpcYHH3xArVq1qFevHpdddhk9evTgoIMOSjqWpBLCNbiSJEkq8b777jvOPPNMWrRowVVXXQXAHnvsYbmV9BsWXEmSJJVYa9asYeTIkWRnZ3PPPffQr18/brrppqRjSSqhLLiSJEkqsa677jrOP/989t9/fz7++GNuvPFGatasmXQsSSWUa3AlSZJUosyePZuVK1fStGlTzj33XPbee286dOhACCHpaJJKOEdwJUmSVCL89NNPXHzxxTRq1Ii+ffsCsM0229CxY0fLraRCseBKkiQpUXl5edx7773k5OQwdOhQunfvzrhx45KOJakUcoqyJEmSEjVmzBh69epFq1atmDBhAi1btkw6ktLkrilzGPnCLFaszk06ijKUBVeSJEnFbv78+cyZM4cDDzyQrl27UrVqVTp37uxU5AxX2HK7VcWsYkijTOQUZUmSJBWbVatWMXjwYHJycujRowe5ublUrFiR4447znJbBhS23J7XLqcY0igTOYIrSZKktIsx8sQTT3DhhRfy1Vdf0alTJ4YOHUpWliN1ZdVXQzokHUEZyIIrSUivI7cAACAASURBVJKktJsyZQqdO3emcePGvPDCCxx66KFJR5KUgZyiLEmSpLT4/vvvmTRpEgAHHXQQjz32GB988IHlVlLaWHAlSZJUpNauXcstt9xCdnY2J5xwAj/99BMhBDp16kT58k4glJQ+FlxJkiQVmRdffJFmzZrRp08fmjdvzhtvvEH16tWTjiWpjPBPaJIkSSoSX3zxBYcddhj16tXjiSee4Oijj/bIyJKKlSO4kiRJ2mzLly/nscceA+CPf/wjEyZMYPr06RxzzDGWW0nFzoIrSZKkTZaXl8eYMWOoX78+Xbp0Yc6cOQB06NCBypUrJ5xOUlllwZUkSdImeffdd2nTpg0nnXQSderU4fXXX2f33XdPOpYkuQZXkiRJhffTTz9x6KGHUrVqVe69915OPvlkypVzzERSyeBPI0mSJG3QL7/8wgMPPECMkerVq/PUU08xa9YsevbsabmVVKL4E0mSJEm/K8bI008/TaNGjTj55JN57bXXAGjbtq2n/pFUIllwJUmS9D+mT5/OkUceydFHH03FihV59tlnOeigg5KOJUkb5BpcSZIk/UZubi4dO3ZkyZIljBw5kt69e1OhQoWkY0nSRllwJUmSRG5uLg8++CAnnHAClSpV4qGHHmL33Xdn++23TzqaJBWaBVeSJKmMe/XVV+nXrx8fffQRIQROOukk9ttvv6RjSdImcw2uJElSGTV37ly6dOnCn/70J5YuXcr48ePp3r170rEkabM5gitJklRG9ejRg3feeYeBAwfSv39/qlatmnQkSdoiFlxJkqQyIsbI+PHjOeSQQ9h+++257bbbqFatGrvuumvS0SSpSIQYY9IZNkmV2tlxx5NHJh1Dkn7XV5VP/M/1eqvGJphEkqSS7ashHZKOoJIrbO4TS90a3LzS1cclSZIkrWOrillJR1CGKnUFV5IkSVLptVXFLM5rl5N0DGWoUrsG1ykNKu0WLFhA7dq1k46honb1f6+WhZ9Tfo6VKTLtszxp0iR222039txzT+bNm8fy5ctp0KBB0rGUZpn2OZY2hyO4kiRJGWLWrFl06NCB9u3bM3z4cAB22WUXy62kMsOCK0mSVMr9+OOP9O/fn8aNG/Paa68xbNgwbr311qRjSVKxK7VTlCVJkpRvxIgRjBgxgl69ejF48GB23HHHpCNJUiIsuJIkSaXQ1KlTAWjTpg0XXnghf/nLX2jRokXCqSQpWU5RliRJKkW++eYbTjzxRA444AAGDhwIQPXq1S23koQFV5IkqVT4+eef+b//+z/q16/P448/zoABA3jiiSeSjiVJJYpTlCVJkkqBhx9+mCuvvJLjjjuOoUOHUq9evaQjSVKJY8GVJEkqoT7++GO+/vprOnbsyMknn0z9+vVp3bp10rEkqcRyirIkSVIJs3jxYs4++2yaN29O//79ycvLIysry3IrSRthwZUkSSoh1qxZw80330x2djZ33XUX55xzDm+88Qblyvm/bJJUGE5RliRJKiFef/11+vXrR7t27Rg5ciSNGjVKOpIklSr+OVCSJClBX3zxBQ8++CAAbdu2ZerUqUyePNlyK0mbwYIrSZKUgGXLlnHZZZfRsGFD+vbty/LlywFo3bo1IYSE00lS6WTBlSRJKkZ5eXncf//91K9fnyFDhtC1a1emTZtGtWrVko4mSaWea3AlSZKK0RdffEGvXr1o0aIFTzzxBPvtt1/SkSQpYziCK0mSlGYLFizgtttuAyA7O5s333yTN99803IrSUXMgitJkpQmq1atYsiQIeTk5HD++efz9ddfA9CyZUtP/SNJaeBPVkmSpCIWY+Spp56iUaNGXHbZZbRr147p06ez6667Jh1NkjKaa3AlSZKK2A8//ECPHj2oU6cOkydP5rDDDks6kiSVCY7gSpIkFYElS5YwdOhQ8vLyqFWrFq+88goffvih5VaSipEFV5IkaQusXbuW22+/nZycHC699FLeeecdAJo1a0aFChUSTidJZYsFV5IkaTO98sortGjRgt69e7PXXnvxwQcfsP/++ycdS5LKLNfgSpIkbYa1a9dy2mmnsXbtWh599FE6depECCHpWJJUpjmCK0mSVEgrVqxgyJAhrFy5kvLlyzNhwgRmzJhB586dLbeSVAJYcCVJkjYixsjYsWOpX78+l112GRMnTgSgQYMGVKlSJeF0kqRfWXAlSZI24P333+fAAw/kr3/9KzvttBOvv/46xx13XNKxJEm/wzW4kiRJG9C/f39mz57N3XffTc+ePSlXzvEBSSqpCl1wQwhVY4wr0xlGkiQpaatXr+aWW26ha9eu1K5dm3vvvZdatWpRo0aNpKNJkjZio3+CDCG0DiFMBz5L3W4aQritMC8eQjgyhDAzhPB5COHS9WzTJYQwPYTwaQhh7CallyRJKkLPPPMMjRs35sILL+Thhx8GoF69epZbSSolCjPH5kbgCOB7gBjjR8BBG3tSCCELuBU4CmgIdAshNFxnm2zgMqBNjLERcN4mpZckSSoCn3/+Oe3bt6djx46EEJg4cSIXXHBB0rEkSZuoUItIYozz1rkrtxBP2xf4PMY4J8a4GngYOHqdbU4Hbo0xLk3tZ1Fh8kiSJBWlW2+9lalTpzJ8+HCmTZvGUUcdlXQkSdJmKMwa3HkhhNZADCFUAPoBMwrxvDpAwWL8DbDfOtvkAIQQpgJZwNUxxmfXfaEQwhnAGQAVd9oDgAULFhQiglRyLVmyJOkISoPaBa6XhZ9Tfo5VWuXm5jJu3DiaNGlC48aN6d27N1dccQXbbbcdixcvTjqetFn8maxMUbt27Y1vtB6FKbhnATeRX1jnA5OB3pu9x//dfzbwJ+APwJQQwl4xxh8KbhRjvBO4E6DSztkRtuyLlkoKP8eZrax8f8vK16nM8frrr9OvXz/+9a9/0a9fPw4//HDAz7Iyg59jlXWFmaJcP8b41xjjjjHGHWKM3YEGhXjefGCXArf/kLqvoG+Ap2OMa2KMXwKzyC+8kiRJRWrevHl069aNAw88kEWLFvHQQw9x4403Jh1LklSEClNwRxXyvnW9C2SHEHYLIVQEugJPr7PNk+SP3hJC2I78KctzCvHakiRJm+See+7hySef5Morr+Szzz6ja9euhBCSjiVJKkLrnaIcQmgFtAa2DyEUPIxgdfLXy25QjHFtCOFc4LnU9vfEGD8NIQwC3osxPp167PDUaYhygYtijN9v/pcjSZKUL8bIo48+So0aNTj88MO56KKL6NmzJ3Xr1k06miQpTTa0BrciUC21zdYF7v8JOK4wLx5jnAhMXOe+Kwtcj8AFqYskSVKR+Oijj+jXrx+vvvoqxxxzDIcffjhVq1a13EpShltvwY0xvgq8GkL4R4xxbjFmkiRJ2iyLFy9mwIAB3HXXXdSqVYu///3vnHbaaUnHkiQVk8IcRXllCGEo0Aio/OudMcZD0pZKkiRpM0yaNInRo0fTp08frrrqKmrVqpV0JElSMSpMwX0QGAd0JP+UQT2A79IZSpIkqbAmT57M4sWLOfHEE/nrX//K/vvvT3a2J2WQpLKoMEdR3jbGeDewJsb4aoyxF+DorSRJStTnn3/OX/7yF4444ghGjBhBjJFy5cpZbiWpDCtMwV2T+vfbEEKHEEJzYJs0ZpIkSVqvZcuWcckll9CwYUNefvllrr/+eqZOneopfyRJhZqifE0IoQZwIfnnv60OnJfWVJIkSevx4YcfMnToUHr06MG1117LzjvvnHQkSVIJsdGCG2P8Z+rqj0BbgBBCm3SGkiRJKuitt97i3XffpU+fPhx44IHMmjWLPfbYI+lYkqQSZr1TlEMIWSGEbiGE/iGExqn7OoYQ3gBuKbaEkiSpzFqwYAEnn3wyrVq1YtiwYaxcuRLAcitJ+l0bWoN7N3AasC1wcwhhDDAMuCHG2Lw4wkmSpLJp1apVXHfddeTk5DBu3Dguv/xyPv30U6pWrZp0NElSCbahKcr7AE1ijHkhhMrAQuCPMcbviyeaJEkqq+bPn8/VV19N+/btGT58OLvvvnvSkSRJpcCGRnBXxxjzAGKMq4A5lltJkpQun3zyCQMHDgTgj3/8IzNmzOCJJ56w3EqSCm1DBXfPEMLHqcu0ArenhRA+Lq6AkiQpsy1ZsoQ+ffrQrFkzbrrpJubPnw9gsZUkbbINTVFuUGwpJElSmbN27VruuOMOrrzySn744QfOOussBg0axLbbbpt0NElSKbXeghtjnFucQSRJUtmyfPlyrr76apo0acJNN91EkyZNko4kSSrlNjRFWZIkqUh9+eWX9O/fn9zcXGrWrMl7773HSy+9ZLmVJBUJC64kSUq75cuXM2DAABo0aMDtt9/ORx99BEDdunUJISScTpKUKQpVcEMIVUII9dMdRpIkZZYYI2PGjKF+/foMHjyY4447jlmzZrH33nsnHU2SlIE2WnBDCH8GPgSeTd1uFkJ4Ot3BJElS6bd27VquvfZaateuzdSpUxkzZgx16tRJOpYkKUMVZgT3amBf4AeAGOOHwG5pzCRJkkqxhQsX0q9fP3766ScqVKjA888/z9tvv03r1q2TjiZJynCFKbhrYow/rnNfTEcYSZJUev3yyy8MHTqUnJwcbr/9dl577TUA6tSpQ7lyHvZDkpR+hflt82kI4UQgK4SQHUIYBbyR5lySJKmUiDHyz3/+k8aNG3PxxRdz8MEH88knn9ChQ4eko0mSypjCFNw+QCPgF2As8CNwXjpDSZKk0mXUqFGUL1+eSZMmMWHCBHJycpKOJEkqg8oXYps9Y4xXAFekO4wkSSodfvjhB6655hrOPfdc6tWrxwMPPECtWrWoUKFC0tEkSWVYYUZwh4cQZoQQ/i+E0DjtiSRJUomVm5vLnXfeSXZ2NiNGjOD5558HYIcddrDcSpISt9GCG2NsC7QFvgPuCCFMCyEMSHsySZJUokyZMoV99tmHM888kwYNGvD+++9z+umnJx1LkqT/KNQhDWOMC2OMNwNnkX9O3CvTmkqSJJU4Y8eO5fvvv2fcuHG8+uqrNG/ePOlIkiT9xkYLbgihQQjh6hDCNODXIyj/Ie3JJElSolauXMnVV1/Nm2++CcD111/PZ599RpcuXQghJJxOkqT/VZiDTN0DjAOOiDEuSHMeSZKUsBgj48eP56KLLmLevHkAtGrViho1aiScTJKkDdtowY0xtiqOIJIkKXkffvghffv25bXXXqNZs2Y8+OCDHHjggUnHkiSpUNZbcEMI42OMXVJTk2PBh4AYY2yS9nSSJKlYTZ48mRkzZnDnnXfSq1cvsrKyko4kSVKhbWgEt1/q347FEUSSJBW/NWvWcMstt1C3bl06depEv379OOOMM6hZs2bS0SRJ2mTrPchUjPHb1NXeMca5BS9A7+KJJ0mS0uXZZ5+lSZMmXHDBBTzzzDMAVKpUyXIrSSq1CnOaoMN+576jijqIJEkqHrNnz6Zjx44cddRRrF27lgkTJjB69OikY0mStMU2tAb3bPJHancPIXxc4KGtganpDiZJktLjww8/ZMqUKdxwww307duXSpUqJR1JkqQisaE1uGOBScB1wKUF7l8WY1yS1lSSJKnI5OXlcd999/Hzzz/Tu3dvjjvuONq2bct2222XdDRJkorUhqYoxxjjV8A5wLICF0II26Q/miRJ2lJvvPEG++67L7169eLJJ58kxkgIwXIrScpIGyq4Y1P/vg+8l/r3/QK3JUlSCTV//ny6d+9OmzZt+PbbbxkzZgzPPfccIYSko0mSlDbrnaIcY+yY+ne34osjSZKKwjfffMPjjz/OFVdcwaWXXkq1atWSjiRJUtptaA0uACGENsCHMcYVIYTuwN7AyBjj12lPJ0mSCiXGyBNPPMFHH33EwIED2W+//Zg3bx7bbrtt0tEkSSo2hTlN0O3AyhBCU+BC4AvggbSmkiRJhTZt2jQOPfRQOnfuzFNPPcWqVasALLeSpDKnMAV3bYwxAkcDt8QYbyX/VEGSJClBS5Ys4ZxzzqFZs2Z89NFH3Hrrrbz33ntUrlw56WiSJCVio1OUgWUhhMuAk4ADQwjlgArpjSVJkjZm+fLlPPDAA/Tu3ZuBAweyzTae5ECSVLYVZgT3BOAXoFeMcSHwB2BoWlNJkqTf9eKLL9K7d29ijOy6667MnTuXUaNGWW4lSaIQBTdVah8EaoQQOgKrYoz3pz2ZJEn6jzlz5nDsscfSrl07nn32WRYtWgRArVq1Ek4mSVLJsdGCG0LoArwDHA90Ad4OIRyX7mCSJAlWrFjB5ZdfToMGDXj++ee59tprmT59OjvuuGPS0SRJKnEKswb3CqBljHERQAhhe+AF4NF0BpMkSZCXl8d9993HCSecwHXXXUedOnWSjiRJUolVmDW45X4ttynfF/J5kiRpM7zzzjt0796d1atXs/XWW/Ppp59y//33W24lSdqIwhTVZ0MIz4UQeoYQegLPABPTG0uSpLLn22+/5ZRTTmG//fbjxRdfZPbs2QDUrFkz4WSSJJUOhTnI1EXAHUCT1OXOGOMl6Q4mSVJZsWbNGm644QZycnIYO3Ysl1xyCbNmzaJRo0ZJR5MkqVRZ7xrcEEI2MAz4IzAN6B9jnF9cwSRJKivKlSvHww8/zCGHHMLw4cPZY489ko4kSVKptKER3HuAfwKdgfeBUcWSSJKkMmD69Ol06dKFJUuWkJWVxSuvvMJTTz1luZUkaQtsqOBuHWO8K8Y4M8Y4DKhXTJkkScpYS5cu5bzzzqNJkyZMnjyZjz/+GIDq1asnnEySpNJvQ6cJqhxCaA6E1O0qBW/HGP+V7nCSJGWKGCN33nknV1xxBUuXLuWMM85g0KBBbL/99klHkyQpY2yo4H4LjChwe2GB2xE4JF2hJEnKNCEEJk2aRKNGjbjpppto1qxZ0pEkSco46y24Mca2xRlEkqRMM3fuXC677DKuvvpqcnJyGDNmDFtttRUhhI0/WZIkbbLCnAdXkiRtgpUrV3LVVVex55578uSTT/Lhhx8CUK1aNcutJElpZMGVJKkIPfLII9SvX59BgwZx7LHHMnPmTLp06ZJ0LEmSyoQNrcGVJEmb6I033mD77bfnoYce4oADDkg6jiRJZcpGR3BDvu4hhCtTt3cNIeyb/miSJJV8ixYt4vTTT+fll18G4Nprr+Xdd9+13EqSlIDCTFG+DWgFdEvdXgbcmrZEkiSVAqtXr2bEiBFkZ2fzj3/84z/ns61SpQpZWVkJp5MkqWwqzBTl/WKMe4cQPgCIMS4NIVRMcy5Jkkqs559/nj59+jBz5kyOOuoobrzxRurXr590LEmSyrzCFNw1IYQs8s99SwhheyAvrakkSSrBPvvsM2KMPPPMM7Rv3z7pOJIkKaUwU5RvBp4AdgghDAZeB65NaypJkkqQH3/8kf79+3P//fcDcPbZZzNt2jTLrSRJJcxGR3BjjA+GEN4HDgUCcEyMcUbak0mSlLC8vDzuvfdeLr/8cr777jsuvvhiAMqX9yQEkiSVRBv9DR1C2BVYCUwoeF+M8et0BpMkKUnvvPMOvXv35v3336d169ZMnDiRFi1aJB1LkiRtQGH+BP0M+etvA1AZ2A2YCTRKYy5JkhK1aNEiFi5cyIMPPki3bt0IISQdSZIkbURhpijvVfB2CGFvoHfaEkmSlICff/6Z4cOHU65cOS6//HI6dOjA7NmzqVKlStLRJElSIRXmIFO/EWP8F7BfGrJIklTsYow89thjNGzYkL/97W/MmDGDGCMhBMutJEmlTGHW4F5Q4GY5YG9gQdoSSZJUTD777DN69+7Nyy+/zF577cVLL71E27Ztk44lSZI2U2HW4G5d4Ppa8tfkPpaeOJIkFZ9ffvmFTz/9lNtvv53TTjvNoyNLklTKbfA3eQghC9g6xti/mPJIkpQ2a9as4e9//zuzZs1i1KhRNG3alLlz51K5cuWko0mSpCKw3jW4IYTyMcZcoE0x5pEkKS2ef/55mjVrRt++fZk5cyarV68GsNxKkpRBNnSQqXdS/34YQng6hHBSCKHTr5fiCCdJ0pb65ptvOProozn88MNZtWoVTz75JM899xwVK1ZMOpokSSpihVlsVBn4HjiE/54PNwKPpzGXJElFonz58rz33ntcd911nHfeeY7YSpKUwTZUcHdIHUH5E/5bbH8V05pKkqTNlJeXx5gxY5gwYQLjx49np512Ys6cOVSqVCnpaJIkKc02NEU5C6iWumxd4PqvF0mSSpS3336bVq1a0aNHD77++mu+//57AMutJEllxIZGcL+NMQ4qtiSSJG2mJUuWcN555/HAAw+w0047cd9999G9e3fKldvQ33ElSVKm2dBv/rCBxyRJKjGqVKnC22+/zaWXXsqsWbM4+eSTLbeSJJVBGxrBPbTYUkiStAlijDz99NOMGjWKCRMmUKVKFaZNm+aRkSVJKuPW++ftGOOS4gwiSVJhfPrp/7N333FV1v0fx18XS1REMUlUHKSICi7EHYJ5O1Nz5MI9Uru1nGWlFq5UzIlm5shcKVndejvKXOGqyDTN3BvFlXsCnuv3RzfnJ4IbPIz38/Hg8fBc53u+1+fiXCDv8/1e32sPdevWpUmTJsTExHDq1CkAhVsRERF56BRlERGRNOP27du8/fbblC1blqioKCZPnszOnTspVqyYrUsTERGRNOJx7oMrIiJic1myZGHHjh10796d4cOHkydPHluXJCIiImmMRnBFRCTN2rhxIzVq1ODs2bMYhsH69ev59NNPFW5FREQkWQq4IiKS5hw7dowWLVpQs2ZNTpw4wfHjxwFwdHS0cWUiIiKSlingiohImmGaJh9++CElSpRg1apVjBgxgr1791KpUiVblyYiIiLpgK7BFRGRNMMwDA4fPkzz5s0ZO3Ysnp6eti5JRERE0hGN4IqIiE1t376d4OBgdu/eDcCXX37JwoULFW5FRETkiSngioiITZw9e5Zu3bpRsWJF9u7dS3R0NAAODppcJCIiIk9HAVdERJ678PBwihcvzrx58xgwYAAHDhygfv36ti5LRERE0jl9TC4iIs/d2bNnCQwMZMKECRQvXtzW5YiIiEgGoRFcERFJdfv27aNBgwasWrUKgGHDhrFixQqFWxEREUlRCrgiIpJqLl++TP/+/SldujRbtmzhwoULANjb29u4MhEREcmINEVZRERSxVdffUWfPn24cOECXbt2ZeTIkeTNm9fWZYmIiEgGpoArIiIpyjRNDMPgxo0b+Pj48P333+Pv72/rskRERCQT0BRlERFJESdOnKB169ZMnz4dgC5duhAZGalwKyIiIs9NqgZcwzDqGYax3zCMQ4ZhvPeQds0NwzANwwhIzXpERCTl3bx5k2HDhlGiRAmWLVvGrVu3ALCzs8MwDBtXJyIiIplJqk1RNgzDHpgG1AaigSjDMJabpvnXfe1yAH2AX1KrFhERSR0bN27k/fff58SJE7Rs2ZKwsDAKFy5s67JEREQkk0rNEdxKwCHTNI+YphkLLAZeS6bdCGAscDsVaxERkRRkmibwz2rIbm5ubNy4kSVLlijcioiIiE2l5iJTBYCT9zyOBirf28AwDH+goGmaKw3DeOdBHRmG0R3oDuDkUQyA06dPp3S9Is/VxYsXbV2CpIL89/w7I/6e+vvvvwkLC8PV1ZXBgwfj6+vLihUrsLOzy5DHK5mHfidLRqDzWDKK/PnzP7rRA9hsFWXDMOyACUCnR7U1TfNz4HOALPm8TXi2gxZJK3QeZ2wZ6f2Ni4vj008/JTQ0lOvXr9OvXz/r8WWk45TMTeeyZAQ6jyWzS82AewooeM9jz/9tS5AD8AM2/m8REg9guWEYjU3T/C0V6xIRkScQFRVFx44d2bt3L3Xq1GHSpEmULFnS1mWJiIiIJJGaATcK8DYMw4t/gm1rICThSdM0rwB5Eh4bhrERGKhwKyKSNiTcz9bV1RWA5cuX07BhQ62MLCIiImlWqgVc0zTjDcPoDfwA2ANzTNPcYxjGcOA30zSXp9a+RUTk6V29epVRo0Zx4sQJvvrqK3x8fNizZ4+CrYiIiKR5qXoNrmmaq4BV92378AFtg1OzFhEReTiLxcK8efN4//33OXPmDJ06dSIuLg5HR0eFWxEREUkXbLbIlIiIpB0HDhygXbt2REVFUaVKFZYvX07FihVtXZaIiIjIE1HAFRHJxBKus33hhRe4desW8+fPJyQkBDu71LxNuoiIiEjqUMAVEcmEbt++zYQJE1izZg3r16/nhRdeYNeuXZqKLCIiIumaPqIXEclETNPku+++o1SpUgwePJjcuXNz7do1AIVbERERSfcUcEVEMomzZ89Su3ZtmjVrRvbs2Vm7di3ffvstOXPmtHVpIiIiIilCU5RFRDK4hOts3dzcuHHjBlOnTqVHjx44OOi/ABEREclY9NeNiEgGFR8fz4wZM5gxYwZbt27FxcWFrVu3aiqyiIiIZFiaoiwikgGtX7+e8uXL07t3b/LkycOlS5cAXWcrIiIiGZsCrohIBnLjxg2aN29OrVq1uH79Ot988w3r1q2jYMGCti5NREREJNUp4IqIZAAWiwWAbNmyERcXx8iRI9m7dy/NmjXTqK2IiIhkGgq4IiLpmGmaLFiwgBIlShAdHY1hGCxbtozBgwfj7Oxs6/JEREREnisFXBGRdCoqKorq1avTvn17cubMyZUrVwBdZysiIiKZlwKuiEg6Y7FY6NatG5UqVeLIkSPMmTOHX375BV9fX1uXJiIiImJTCrgiIunE3bt3AbCzs8PR0ZF33nmHAwcO0LlzZ+zs9OtcRERERH8RiYikcaZpsmLFCkqVKkVUVBQAn376KWFhYbi6utq4OhEREZG0QwFXRCQN27dvH/Xr16dRo0bY2dkRFxcH6DpbERERkeQo4IqIpFFDhgyhdOnS/Pzzz0ycOJFdu3ZRrVo1W5clIiIikmY52LoAERH5f3fv3sXOzg7DMMiePTtdunRh5MiRgJNIAgAAIABJREFUuLu727o0ERERkTRPI7giImlEZGQkAQEBfPvttwC8//77zJgxQ+FWRERE5DEp4IqI2NiJEydo1aoVQUFB/P333zg7O9u6JBEREZF0SQFXRMSGpk6dSokSJVi+fDkfffQR+/bt49VXX7V1WSIiIiLpkq7BFRF5zkzTxGKxYG9vT+7cuWnUqBHjxo2jUKFCti5NREREJF3TCK6IyHO0Y8cOgoKCmDhxIgAhISEsWbJE4VZEREQkBSjgiog8B+fPn6dHjx5UqFCBvXv38uKLL9q6JBEREZEMR1OURURSWUREBN27d+fGjRv07duXDz/8kFy5ctm6LBEREZEMRwFXRCSVxMXF4ejoiKenJ1WrVmXChAmULFnS1mWJiIiIZFiaoiwikkr69OkDQLVq1Vi9erXCrYiIiEgqU8AVEUkhV69eTfS4WLFiNqpEREREJHNSwBURSQHr16+nePHiibb179/fRtWIiIiIZE4KuCIizyAuLg4ALy8vSpUqZeNqRERERDI3BVwRkacQHR1Nu3bteO211zBNEy8vL9avX2/rskREREQyNQVcEZEncOvWLUaNGoWPjw9Lly7F39+fu3fv2rosEREREUG3CRIReWx//PEHTZo04dixYzRr1oxPPvkELy8vW5clIiIiIv+jgCsi8gixsbE4OTlRpEgRihYtyuzZs3nllVdsXZaIiIiI3EdTlEVEHuDvv/+mV69eVKpUifj4eHLmzMnatWsVbkVERETSKAVcEZH7xMfHM3XqVLy9vZkxYwaBgYHcuXPH1mWJiIiIyCNoirKIyD1OnjxJ/fr12bNnD7Vq1WLSpEn4+fnZuiwREREReQwawRURAesIbb58+ShatCjffvstP/74o8KtiIiISDqigCsimdr169f54IMP8Pb25vLlyzg4OLBs2TKaNm2KYRi2Lk9EREREnoACrohkShaLhfnz51O8eHFGjx5NcHAwcXFxti5LRERERJ6BrsEVkUzn2rVr1K5dm19++YWKFSvyzTffULVqVVuXJSIiIiLPSAFXRDKN27dv4+zsTI4cOfD19aVnz5506NABOztNZhERERHJCPRXnYhkeHfu3CEsLIyCBQty5MgRAGbPnk2nTp0UbkVEREQyEP1lJyIZlmmaLF++HF9fXwYNGkS1atWwt7e3dVkiIiIikko0RVlEMqS7d+/SqFEjVq9eTcmSJfnhhx+oU6eOrcsSERERkVSkgCsiGcrNmzfJli0b9vb2lC9fnnr16vHmm2/i6Oho69JEREREJJVpirKIZAh3797ls88+o3DhwmzatAmAUaNG8fbbbyvcioiIiGQSCrgiku799NNP+Pv78+abb1KqVCnc3NxsXZKIiIiI2IACroika2+88QbBwcFcvnyZiIgINm7ciJ+fn63LEhEREREbUMAVkXTn5s2bWCwWAMqXL8+wYcPYt28fLVq0wDAMG1cnIiIiIraigCsi6YZpmnz11Vf4+PiwaNEiAP7973/z4YcfkjVrVhtXJyIiIiK2poArIunC77//TmBgICEhIbi7u1O0aFFblyQiIiIiaYwCroikeaGhoQQEBHDgwAFmzpxJVFQUVatWtXVZIiIiIpLGKOCKSJoUGxvLnTt3gH+us+3Xrx8HDx6kW7du2Nvb27g6EREREUmLFHBFJM1ZvXo1ZcqUISwsDIDXXnuN8ePHkzNnThtXJiIiIiJpmQKuiKQZBw4c4NVXX6VBgwaYpknFihVtXZKIiIiIpCMKuCKSJnz++ef4+vqyefNmPvnkE3bv3k29evVsXZaIiIiIpCMOti5ARDKvu3fvcuvWLVxcXAgICKBjx46MGjWKvHnz2ro0EREREUmHNIIrIjaxefNmKlWqxFtvvQWAv78/s2bNUrgVERERkaemgCsiz9XJkycJCQkhMDCQc+fOUbduXVuXJCIiIiIZhKYoi8hzs2zZMkJCQrBYLAwdOpRBgwaRPXt2W5clIiIiIhmEAq6IpCrTNLly5Qq5cuUiICCApk2bMnLkSIoUKWLr0kREREQkg1HAFZFUs2vXLvr06YNpmmzYsIECBQqwYMECW5clIiIiIhmUrsEVkRR34cIF3nzzTcqXL8/u3btp3bo1pmnauiwRERERyeA0gisiKernn3+mfv36XLt2jd69exMaGoqbm5utyxIRERGRTEAjuCKSIi5dugRA6dKlefXVV/njjz+YPHmywq2IiIiIPDcKuCLyTA4fPsxrr71GpUqVuHPnDtmzZ2fBggX4+vraujQRERERyWQUcEXkqVy7do3333+fUqVKsW7dOrp27YphGLYuS0REREQyMV2DKyJP7PDhwwQGBhITE0PHjh35+OOPyZ8/v63LEhEREZFMTgFXRB7b33//zQsvvICXlxcNGzaka9euVK5c2dZliYiIiIgAmqIsIo/h9OnTdOjQAW9vb86fP4+dnR2ff/65wq2IiIiIpCkKuCLyQLdv32bMmDEUL16cJUuW0KNHD7JmzWrrskREREREkqUpyiKSrMuXLxMQEGBdJXn8+PEULVrU1mWJiIiIiDyQAq6IJHL+/Hnc3d3JlSsXr7/+OrVq1aJ27dq2LktERERE5JE0RVlEALh06RJvv/02hQoVYu/evQCMGTNG4VZERERE0g0FXJFMLj4+nunTp+Pt7c20adPo3LkzL774oq3LEhERERF5YpqiLJKJxcfHU7VqVX777TeCg4OZPHkyZcqUsXVZIiIiIiJPRSO4IpnQ2bNnAXBwcKB169YsXbqU9evXK9yKiIiISLqmgCuSidy4cYOhQ4dSuHBhfvzxRwAGDBhA8+bNMQzDxtWJiIiIiDwbTVEWyQRM0+Srr77i3Xff5dSpU4SEhFCyZElblyUiIiIikqIUcEUygaZNm7Js2TL8/f1ZsmQJ1atXt3VJIiIiIiIpTgFXJIM6d+4cL7zwAvb29rz++us0atSIzp07Y2enKxNEREREJGPSX7oiGUxsbCzjx4/H29ub2bNnA9CuXTu6du2qcCsiIiIiGZr+2hXJQFauXImfnx8DBw4kMDCQ4OBgW5ckIiIiIvLcKOCKZBBvvfUWDRs2xM7OjlWrVrFixQqKFy9u67JERERERJ4bXYMrko5dvnwZBwcHXFxcaNy4MV5eXvTu3RsnJydblyYiIiIi8txpBFckHbp79y4zZ86kePHijBw5EoDatWvTv39/hVsRERERybQUcEXSmc2bN1OxYkW6d++Oj48PLVu2tHVJIiIiIiJpggKuSDoSFhZGYGAg58+f56uvviIyMhJ/f39blyUiIiIikiboGlyRNO7mzZvcvHmTPHny8Oqrr3Ljxg0GDRpEtmzZbF2aiIiIiEiaohFckTTKNE0iIiIoWbIkvXv3BsDX15dhw4Yp3IqIiIiIJEMBVyQN2rlzJ8HBwbRq1Qo3NzfefPNNW5ckIiIiIpLmKeCKpDELFy7E39+fPXv28Nlnn7F9+3aCgoJsXZaIiIiISJqngCuSBsTFxXH69GkA6tSpw4ABAzh48CA9evTA3t7extWJiIiIiKQPqRpwDcOoZxjGfsMwDhmG8V4yz/c3DOMvwzB2GYaxzjCMwqlZj0hatGbNGsqWLUvTpk2xWCy4u7szbtw43NzcbF2aiIiIiEi6kmoB1zAMe2AaUB8oBbQxDKPUfc12AAGmaZYBlgJhqVWPSFpz5MgRGjduTN26dYmNjWXIkCEYhmHrskRERERE0q3UvE1QJeCQaZpHAAzDWAy8BvyV0MA0zQ33tP8ZaJeK9YikGRs3bqROnTpkyZKFsWPH0qdPH7JkyWLrskRERERE0rXUDLgFgJP3PI4GKj+kfVdgdXJPGIbRHegO4ORRDMB6vaJIemGxWDh16hQFCxakUKFChISE0KdPH/Lmzcvff/9t6/IkheS/59+Z4ffUxYsXbV2CSIrQuSwZgc5jySjy58//6EYPkJoB97EZhtEOCACSXSrWNM3Pgc8BsuTzNuHZDlrkefv55595++23OXPmDPv27SNbtmx8/PHHOo8zuMzy/maW45SMT+eyZAQ6jyWzS81Fpk4BBe957Pm/bYkYhvEvYDDQ2DTNO6lYj8hzd+rUKdq3b0/VqlWJjo5m1KhRODs727osEREREZEMKTVHcKMAb8MwvPgn2LYGQu5tYBhGeWAGUM80zXOpWIvIc7dv3z4CAgKIi4vjgw8+4P3338fFxcXWZYmIiIiIZFipFnBN04w3DKM38ANgD8wxTXOPYRjDgd9M01wOjANcgK//t3rsCdM0G6dWTSKpzTRNjhw5QtGiRfHx8aFfv3507tyZl156ydaliYiIiIhkeKl6Da5pmquAVfdt+/Cef/8rNfcv8jz9+eef9O3bl19++YUDBw6QL18+RowYYeuyREREREQyjdS8BlckU7h48SK9e/embNmy/P7774wZMwZ3d3dblyUiIiIikumkiVWURdKrixcvUrx4cS5dusSbb77JsGHDeOGFF2xdloiIiIhIpqSAK/IU9u/fj4+PD7lz5+b999+nTp06lC5d2tZliYiIiIhkapqiLPIEjh49SrNmzShVqhQ7d+4EYMCAAQq3IiIiIiJpgAKuyGO4fv06gwcPpmTJkvzwww8MHz4cHx8fW5clIiIiIiL30BRlkUeIi4ujfPnyHDp0iHbt2jFmzBgKFChg67JEREREROQ+CrgiD7B3715KlCiBo6MjH3zwASVKlKBq1aq2LktERERERB5AU5RF7nPmzBk6d+5MqVKlWLFiBQCdO3dWuBURERERSeM0givyP3fu3GHy5MmMGDGCO3fu8M477xAUFGTrskRERERE5DEp4Ir8T506dYiMjKRhw4ZMmDABb29vW5ckIiIiIiJPQFOUJVPbv38/cXFxwD+3+1m9ejX//e9/FW5FRERERNIhBVzJlC5fvky/fv3w8/Nj+vTpADRu3Jh69erZuDIREREREXlamqIsmcrdu3eZPXs2gwcP5u+//+aNN96gTZs2ti5LRERERERSgAKuZCqdOnViwYIF1KhRg8mTJ1OuXDlblyQiIiIiIilEAVcyvOPHj+Pq6oqbmxtvvvkmjRo1okWLFhiGYevSREREREQkBekaXMmwbt68yUcffUSJEiUYMWIEANWqVaNly5YKtyIiIiIiGZBGcCXDMU2TiIgI3nnnHU6ePEmrVq3o27evrcsSEREREZFUpoArGc7QoUMZNWoU5cqVY+HChQQGBtq6JEkNW8Nh4xiIvW7rSkREREQkjVDAlQzh3LlzxMbG4unpSadOnShUqBBdu3bF3t7e1qVJaknr4dbJxdYViIiIiGQ6ugZX0rXY2FgmTpxI8eLFeeuttwAoVqwY3bt3V7jN6NJ6uA1+z9ZViIiIiGQ6GsGVdOv777+nb9++7N+/n3r16jF69GhblyS2EnrF1hWIiIiISBqgEVxJl2bMmEH9+vWxWCysWLGCVatWUaJECVuXJSIiIiIiNqQRXEk3rl69SkxMDD4+PrRs2ZKbN2/Sq1cvnJycbF1axqcFnUREREQkHdAIrqR5FouFOXPm4O3tTevWrTFNEzc3N/r166dw+7yk5XCrxZxERERE5H8UcCVN27p1K5UqVaJr164UK1aMmTNnYhiGrcvKfNJyuNViTiIiIiLyP5qiLGnW6tWradCgAQUKFGDhwoW0adNG4TYt0IJOIiIiIpJGaQRX0pRbt27xxx9/APCvf/2LTz75hH379hESEqJwKyIiIiIiD6WAK2mCaZp88803lCpVinr16nHr1i0cHR0ZMGAALi66xlJERERERB5NAVdsbteuXdSqVYvXX38dFxcXFi5cSNasWW1dloiIiIiIpDO6Bldsavfu3ZQvX55cuXIxbdo0unfvjoODTksREREREXlyGsGV5y4+Pp5ff/0VAD8/PyZPnszBgwf597//rXArIiIiIiJPTQFXnqt169ZRrlw5goKCiImJwTAMevfuTe7cuW1dmoiIiIiIpHMaLpPn4siRIwwYMID//Oc/vPTSS3z11Vd4eHjYuqy0aWs4bByTdu89KyIiIiKSRingSqo7f/48fn5+2NnZ8fHHH9OvXz+cnZ1tXVbalZbDrZNWtBYRERGRtEsBV1KFxWJh69atvPzyy7i7uzN9+nRq165N/vz5bV1a2peWw23we7auQkRERETkgRRwJcX9+uuv9OnTh59//pnff/+d8uXL07FjR1uXlT6FXrF1BSIiIiIi6YYWmZIUExMTQ6dOnahcuTLHjh1j7ty5lC1b1tZliYiIiIhIJqERXEkRsbGxBAQEcOHCBQYNGsTgwYPJkSOHrct6NBsu6KTJ2iIiIiIiKUsBV56aaZr89NNPBAUF4eTkxNSpUyldujTFihWzdWmPTws6iYiIiIhkGJqiLE/lr7/+om7dutSsWZNly5YB0LRp0/QVbiFth1st6CQiIiIi8kQ0gitP5NKlS4SGhjJt2jRy5MjB5MmTefXVV21dVsp4zgs6nT59WqtKi4iIiIikIAVceWymaVK7dm127NhB9+7dGT58OO7u7rYuS0REREREBFDAlcewefNmAgICcHZ2JiwsjNy5c1OuXLkn78iGCzqJiIiIiEjGp2tw5YGOHz9Oy5YtCQwMZMaMGQC88sorTxduIW2HWy3oJCIiIiKS7mkEV5K4efMmY8eOJSwsDMMwGD58ON27d3/2jtNyuNWCTiIi8gQsFgvR0dHcuHHD1qWIWN29e5crV57vmiIiT8rR0ZEXX3wRV1fXVOlfAVeSaN++Pd9++y1t2rRh7NixFCxYMOV38pwXdBIREUlJFy5cwDAMfHx8sLPThDhJG2JjY3FycrJ1GSIPZJomt27d4tSpUwCpEnL1G1kA+P333zl//jwAQ4YMYdOmTSxatCh1wq2IiEg6d/nyZfLmzatwKyLyBAzDIFu2bBQoUIBz586lyj40gpsRPcViTv73/Lt8wj/WpmRRIiIiGcfdu3dxdHS0dRkiIulS1qxZiYuLS5W+9bFjRpSWF3MCLegkIiIZgmEYti5BRCRdSs3fnwq4GVFaD7da0ElERERERFKBpihndPcs5nTgwAEMw8Db25sTJ06we/duXn31VRsWJyIiIiIiknI0gpsJXLlyhYEDB+Ln58e7774LQKFChRRuRURERJ7St99+S5kyZbBYLLYuJcM6fvw4L7zwAjExMY9se/XqVZo2bUrOnDkxDINjx46lfoGp6NixYxiGwebNmx/aLjQ0lGLFij2nqtIHBdwMbvbs2RQvXpwJEybQoUMHPvvsM1uXJCIiIjbUqVMnDMPAMAzs7e3x9PSkQ4cO1tt23Ovw4cN06tSJAgUK4OTkRP78+enYsSOHDx9O0vbmzZuMHDmSMmXKkC1bNnLnzk3lypUJDw/n5s2bz+PQnpv4+HgGDhzIsGHDMvxK2jExMbRs2RJXV1dcXV1p3br1I1e/DQ4Otp5j935lz549UbsDBw5Qt25dsmXLRp48eejZs2eie0sXLlyYVq1aMXTo0EfWOX36dLZt28bmzZuJiYlJ8TuBPCxIFilShJEjR6bo/u4XHR2NYRhs3LgxVfeTEWTsn0ihW7dueHt7ExUVxaxZs8ibN6+tSxIREREbCwwMJCYmhhMnTrBo0SJ27NhBixYtErXZsWMHAQEBREdHs2jRIg4dOsTixYs5ffo0AQEB7Ny509r26tWrVK9enfDwcHr16sXWrVvZvn07AwcOJCIigjVr1jzX44uNjU3V/r/77jtu375N48aNn6mf1K7zWVksFho2bMjRo0f58ccfWbNmDQcOHKBJkyaYpvnA13377bfExMRYv06fPk2BAgVo3bq1tc3169epVasWDg4ObN26lYiICL7//nu6du2aqK9u3bqxYMECLly48NBaDx48iK+vL6VLl8bDwwN7e/unOua0/p7IoyngZjDR0dGJHi9evJhNmzZRoUIFG1UkIiIiaY2TkxMeHh4UKFCAGjVq0L17d7Zt28bVq1cBME2TTp06UbBgQb7//nuCgoIoVKgQNWrUYPXq1Xh6etKpUydryBk8eDD79u3j559/pkePHpQrVw4vLy9atGhBZGQkwcHBD6zl+vXr9O3bl4IFC5IlSxaKFCnCxx9/DDx4mmaxYsUIDQ21PjYMgylTphASEkLOnDlp37491atXp3v37kn2V7JkSYYMGWJ9vHjxYsqVK4ezszNFihShf//+iUYRk7Nw4UIaNmyYKEQdPXqUZs2akT9/frJly0bp0qWZP39+otcFBwfTtWtXhg4dSr58+ShUqBAAhw4donnz5uTKlQs3Nzfq1KnD7t27ra+7dOkS7dq1o1ChQmTNmhUfHx/Gjx//0JCZEtauXcvvv//OggULqFy5MlWqVGH+/Pls27aNn3766YGvy507Nx4eHtavP//8k1OnTtGzZ09rm0WLFnHhwgUWLVpEuXLleOWVV5g2bRpLlizh6NGj1nb+/v7kzZuXpUuXPnB/RYoUYfbs2axfvx7DMKzn27Vr1+jRowfu7u5kyZKFgICARB+2JJxfCxcupEGDBmTPnv2xRosfJS4ujtDQULy8vHB2dsbX15cZM2YkajN58mTKlSuHi4sLHh4etG7d+qFTsRNGpGvWrIlhGBQpUiTR88uWLaNEiRJkz56d4OBgDh48aP0e5MiRg0WLFiVqf+zYMezs7Ni0adMzH29ao0WmMohbt27xySefMGbMGG688/9va6tWrWxYlYiISOZQ5L2VNt3/sTFPv67G6dOnWbp0Kfb29tbAtmvXLnbt2sX8+fNxcEj856KDgwPvvvsuHTp0YPfu3fj5+bFw4ULatm2Ll5dXkv4NwyBXrlzJ7ts0TRo2bMiJEycIDw+nTJkyREdHs3///ic+jmHDhjFs2DBGjBiBxWJhw4YNDBo0iPDwcLJkyQLAr7/+yr59++jQoQMAc+fOpV+/fkyZMoXq1asTHR1N7969OX/+fJJweq+ffvqJcePGJdp2/fp1XnnlFT766CNcXFxYtWoVnTt3xtPTk5o1a1rbRURE0LZtW9atW8fdu3c5e/YsL7/8Mk2bNmXTpk04OTkxdepUgoOD2bdvH+7u7ty5cwc/Pz/69++Pm5sbW7ZsoWfPnuTOnZvOnTs/sM769es/MsCsXr2awMDAZJ/bsmULXl5e+Pj4WLf5+vri6enJ5s2bH/rBxb0+++wzypcvT8WKFRP1XbVqVXLmzGndVqdOHezs7Kz7TVC5cmU2bNiQKCDfKyoqit69exMTE0NERAROTk4AdOnShaioKBYsWEChQoX47LPPaNiwIbt27aJEiRLW1w8aNIixY8cybdq0xzqeR3njjTf4/fffmTFjBt7e3vz666/06NEDBweHRCPUn3zyCUWLFuXMmTMMGDCA1q1bP/CDg99//x1/f3+++eYbqlWrlujDlZiYGKZPn87ChQtxcHCgS5cudOnShU2bNpEjRw5CQkKYOXMmISEh1tfMnj2bEiVKPPC9T88UcNM50zT55ptvGDhwIMePH+f1118Hnu80IBEREUlfNm7ciIuLCxaLhVu3bgEwYMAA6zWSCQHT19c32dcnbN+/fz8eHh5cunSJUqVKPXEd69ev56effiIqKoqAgAAAXnrpJWrUqPHEfTVp0oTevXtbH7u7u9OnTx+WL19unX49b948qlSpQvHixYF/rqscPXo07du3t+576tSpBAUFMWXKFNzc3JLs5/Lly1y+fJkCBQok2l66dGlKly5tffzWW2+xdu1aFi1alCjg5suXj08//dR67W5oaChFihRh+vTp1jZTpkxh1apVLFy4kL59++Lh4cF77/3/bRa9vLyIiopi0aJFDw24s2bNsr6/D3L/cdwrJiYGDw+PJNs9PDwea+GnhD6WL1/O1KlTH9m3o6MjuXPnTtK3p6fnQ4O6u7s7WbNmtc5MgH9GxZcuXcrKlSupW7cu8M+o6aZNmwgLC2POnDnW1/fo0YO2bds+8liOHDmCi4tLku33XmN+9OhR5s2bx19//WUN0V5eXuzfv5/w8HBrwO3Tp4/1NV5eXkybNg1/f39OnTqV7Hvi7u4O/P/o+L3u3LnD/PnzrW3effdd2rRpw+3bt3F2dqZHjx5UqFCBgwcP4u3tzd27d/niiy8YMGDAI485PVLAfVZbw2HjGJvde9YAXgde7wTgisKtiIiIPErlypX58ssvuX37NhEREaxdu/apF8l5lmmy27dvx83NzRpun0WlSpUSPc6VKxeNGzdm/vz5tGjRgri4OBYvXsyIESMAOH/+PMePH6d///4MHDjQ+rqE4zl06FCiEccECYHR2dk50fabN28yfPhw/vvf/xITE0NsbCx37txJFG4BKlSokGhhqqioKLZv354kON26dcs6zdRisRAWFsbixYuJjo7m9u3bxMXFUbhw4Yd+Tx4WXp+XOXPm4OzsnGj08Ek5Ozs/Mqjf76+//gJI8mFJjRo12LZtW6Jt9587D1KwYEHWrVuXZPu9I9m//fYbpmkmOafj4+MTjbpu3LiR0aNH89dff3H58mXratzHjx9/4vctf/781nCb8Ng0Tc6dO0ehQoXw9/cnICCAWbNmMXbsWFavXs2FCxesMxkyGgXcZ2XDcPtITkk/YRIREZGU9yxThG0ha9as1hVh/fz8OHz4MG+99RYzZ84EsI5w/vnnn5QvXz7J6/fs2QOAj48P7u7uuLm5WQNFSkoIgveH6Li4uCRt71+hF6BDhw40bdqU8+fPs2XLFq5fv25d6CghUEyePDlJCIV/Rg2TkydPHgzD4OLFi4m2v/POOyxbtowJEybg4+ND9uzZGTBgAFeuXHlonRaLhVq1aiUZ4QSs03fHjx/P6NGjmThxIuXLlydHjhxMnDiRlSsfPjX+Waco58uXj7Vr1ybZfvbsWfLly/fQfuGfY5s5cyZt27YlR44cSfo+efJkom1xcXFcvHgxSd8XL15MFOBSWnLnTnIcHR2TXUn53mn8CefZq91AAAAgAElEQVTV1q1byZYtW6J2hmEAcOLECRo0aED79u358MMPyZMnD9HR0fzrX/96qkWuEqZk37+fe29h1bNnTz744ANGjhzJrFmzaNasGS+88MIT7ys9UMB9Vmk53Aa/9+h2IiIikumFhoZSsmRJevToQUBAAGXLlsXPz49x48bRpk2bRH/Ax8fHM27cOMqUKUPp0qUxDIOQkBBmz57N4MGDk1yHa5omV69eTXStZYIKFSpw6dIlfvvtt2RHcRNCzenTp63bzp07l+wtjZJTt25dcufOzeLFi9mwYQMNGza0TjvOmzcvBQsWZP/+/bzxxhuP1R/8E3L8/PzYs2cPzZs3t26PjIykbdu2tGzZEvgnXBw4cOCRd7AICAhg7ty5eHp6JhkVvrfvevXq0aVLF+u2hNHdh3nWKcrVq1dn+PDh1qmt8M/I6MmTJ3n55Zcfuf/vv/+e48eP06NHj2T77tOnD1evXsXV1RWAH3/8EYvFQvXq1RO13b17N9WqVXvk/u6VMI0+MjKSBg0aWLdHRkYm+6FNSklY2PXEiRM0bNgw2TZRUVHcunWLSZMmkTVrVuCf2QwPkxBi7969+1R1tW7dmv79+zNjxgxWrlz53Fc2f54UcFNS6JVHt3lKa9asoW/fvuzdu5fatWszadKkp7rWRUREROR+3t7eNGrUiMGDB/PDDz9gGAZz587llVdeoX79+gwdOhQvLy+OHTvGiBEjOHHiBBs2bLCOFI0aNYrIyEiqVKnCiBEjqFy5Mq6uruzcuZOJEyfSv39/mjRpkmS/r7zyCoGBgbRq1YoJEyZQpkwZTp8+zd69e+nWrRtZs2alevXqhIWFUaJECeLj4xk8eLB10ahHcXBwICQkhOnTp3P48OEkK/GOGjWKrl274ubmxmuvvYajoyN79+5l9erVSVa9vVeDBg2SLAbk4+PDsmXLaN68OS4uLkyYMIHTp08/MuD27t2b2bNn89prrzFkyBAKFixIdHQ0q1ev5tVXX6VatWr4+Pgwf/58NmzYQIECBZg3bx6//PJLstcI3+tZpyj/61//wt/fn3bt2hEeHo5pmvTq1YsqVaoQFBRkbVerVi0qVarE6NGjE71+xowZVKxYMdlAGRISwogRIwgJCWHUqFFcvHiRXr160apVq0Qfkly7do3t27czatSoJ6q9aNGitGjRgn//+9/MmDGDwoULM336dP78888kKwqnpGLFitGlSxfeeOMNwsLCqFq1Kjdu3GD79u2cP3+eQYMG4e3tjWEYjB8/nrZt2/LHH38wfPjwh/abJ08eXFxcWLNmDb6+vmTJkuWR7/+9smfPTrt27RgwYABeXl7JzlrIKHSboHRgx44d1K1bl9jYWJYtW8YPP/ygcCsiIiIp6p133mHNmjVs3LgR+Gck6rfffiN//vy0bt2al156iZYtW5IvXz62b9+eKLTkzJmTbdu20atXL8LDw6lSpQr+/v6MGTOGVq1aWRf5uZ9hGKxcuZIGDRrQs2dPfHx8aNeuXaJ7ns6ZMwcXFxeqVatG69at6d69+2NNj03QsWNH9u7dS86cOalfv36i59q3b09ERAQrVqygUqVKVKxYkdDQ0EcGw+7duxMZGZloiu3EiRMpXLgwNWvWpFatWhQoUOB/i38+XN68edm2bRt58uShWbNm+Pj40LZtW44fP249zqFDhxIUFMRrr71G1apVuXTpEm+//fZjfw+elp2dHStWrKBQoULUqlWL2rVrU7RoUZYtW2b9cAPg8OHDSRaGOnXqFCtXrkx29BbAxcWFtWvXEhsbS9WqVXn99depU6cOs2fPTtRu6dKlFClS5LFXbL7XrFmzqFu3Lu3ataNs2bJs2bKFFStWJFpBOTV8/vnn9OvXj1GjRlGqVClq1arFl19+yUsvvQRAmTJlCA8PZ8aMGZQqVYpPPvmESZMmPbRPOzs7pk2bRkREBJ6enk81Ct29e3diY2OfaMZCemSk9v2zUlqWfN5mvo6T0s61LqH3TLdJwRHca9eusXnzZusv4q+//prGjRs/9ieWkvadPn2a/Pnz27oMkWei81gyiic9l/fu3UvJkiVTsSJJ67p27UqOHDkeGUyep9jY2CTXY6ZnFouFsmXLMmTIEN36MgWsWrWKpk2bcvLkSV588UVbl/Oo36PGg554FI3gpjEWi4Uvv/yS4sWL07RpU86dOwdAixYtFG5FRERE0ojRo0fj4eGRaCEfSVmnTp2iU6dOCrfP6ObNmxw7dozQ0FDatm2bJsJtalLATUN++eUXqlatSqdOnShcuDCRkZEZ/gQUERERSY9efPFF3nvvvUS3/JGUVbBgwQx7r9bnKSwsjGLFiuHg4MDYsWNtXU6q009kGnHmzBkCAwM5efIk8+bNY+vWrY99Ty4REREREZHkhIaGEh8fz9atW1P1dktphQKuDd2+fZtvvvkGAA8PD7777jsOHDhA+/bt9WmgiIiIiIjIE1KKsgHTNPnPf/6Dr68vr7/+Ort27QLg1VdfxcXFxcbViYiIiIiIpE8KuM/Znj17qF27Nk2bNsXZ2Zk1a9ZQpkwZW5clIiIiIiKS7jnYuoDM5Pbt2wQHBxMfH8+UKVN48803cXDQWyAiIiIiIpISlK5SWXx8PF9//TWtWrXC2dmZiIgISpcuTZ48eWxdmoiIiIiISIaiKcqpaMOGDfj7+xMSEsLKlSsBqFmzpsKtiIiIiIhIKkh3I7i+xjF+dw6BUFtX8mDHjh1j4MCBfPPNNxQuXJilS5fSsGFDW5clIiIiIink22+/JTQ0lJ07d+ruF6nk+PHj+Pv78+eff5IvX76Htr169SodO3Zk/fr1XL16laNHj1KkSJHnU2gms3HjRmrWrMnJkyfx9PS0dTlJpLufRjssti4heU7/rH5smiaNGzdm9erVjBgxgr1799K8eXMMw7BxgSIiIiLQqVMnDMPAMAzs7e3x9PSkQ4cOnDp1Kknbw4cP06lTJwoUKICTkxP58+enY8eOHD58OEnbmzdvMnLkSMqUKUO2bNnInTs3lStXJjw8nJs3bz6PQ3tu4uPjGThwIMOGDcvw4TYmJoaWLVvi6uqKq6srrVu35ty5cw99TXBwsPUcu/cre/bsidodOHCAunXrki1bNvLkyUPPnj25ceOG9fnChQvTqlUrhg4d+sg6p0+fzrZt29i8eTMxMTEULFjw6Q74AUJDQ63HYWdnR4ECBWjTpg3Hjx9P0f2kB9WqVSMmJob8+fPbupRkZeyfyOfEdHJhZ6563LhxA8MwmDNnDvv372fIkCFkzZrV1uWJiIiIJBIYGEhMTAwnTpxg0aJF7NixgxYtWiRqs2PHDgICAoiOjmbRokUcOnSIxYsXc/r0aQICAti5c6e17dWrV6levTrh4eH06tWLrVu3sn37dgYOHEhERARr1qx5rscXGxubqv1/99133L59m8aNGz9TP6ld57OyWCw0bNiQo0eP8uOPP7JmzRoOHDhAkyZNME3zga/79ttviYmJsX6dPn2aAgUK0Lp1a2ub69evU6tWLRwcHNi6dSsRERF8//33dO3aNVFf3bp1Y8GCBVy4cOGhtR48eBBfX19Kly6Nh4cH9vb2T3XMD3tPihQpQkxMDNHR0cybN4/ffvuNRo0acffu3afaV3rl5OSEh4dH2v1wxzTNdPVVIZ+daX7kaqYVUVFRZrVq1UzADA8Pt3U5ko6cOnXK1iWIPDOdx5JRPOm5/Ndff6VSJamvY8eOZq1atRJtmzJligmYV65cMU3TNC0Wi1mmTBmzdOnSZlxcXKK2cXFxpp+fn1m2bFnTYrGYpmmavXv3Np2dnc0jR44k2Z/FYjEvXbr0wHquXbtm9unTx/T09DSdnJzMwoULm6NGjTJN0zSPHj1qAuamTZsSvaZo0aLmRx99ZH0MmJMnTzbbtGljurq6mi1btjSrVatmvvHGG0n2V6JECXPw4MHWx1999ZVZtmxZM0uWLGbhwoXNfv36mdevX39gvaZpmq+99lqSvo8cOWI2bdrUzJcvn5k1a1bTz8/PnDdvXqI2QUFBZpcuXcwhQ4aYHh4eZt68eU3TNM2DBw+azZo1M3PmzGnmypXLrF27trlr1y7r6y5evGi2bdvWLFiwoOns7GwWL17c/OSTT6zf/wR37tx5aN1P6ocffjABc9++fdZtf/75pwmYGzZseOx+1qxZYwLmr7/+at02Y8YM09nZ2bx8+bJ124oVK0wgyXlUqFAhc/r06Q/sv3DhwiZg/QoKCjJN0zSvXr1qdu/e3cyTJ4/p5ORkVqhQwfzhhx+sr0s4vxYsWGDWr1/fzJYtm/nuu+8mu4+PPvrILFq0aKJtCxYssH5/NmzYYALmmjVrzMDAQDNr1qxmyZIlzVWrViV6zZkzZ8yOHTuaefLkMV1cXMxq1aqZP/30k/X5hH5OnjyZ6HX29vbmF198kajuhQsXmnXq1DGzZs1q+vj4mBs3bjSjo6Otx1KyZEkzMjIyUT/btm0zAwMDTWdnZzNXrlxmmzZtzLNnzyY5zv/85z+mj4+PmS1bNjMoKMg8cODAA2u0WCxmt27dzJdeesl0dnY2vby8zPfff9+8ffv2A98z03zk79Gnzovp7hrctOLs2bN88MEHfPHFF7i7uzN79mw6depk67JERETEFkJz2nj/V576padPn2bp0qXY29tbR7127drFrl27mD9/fpJbGjo4OPDuu+/SoUMHdu/ejZ+fHwsXLqRt27Z4eXkl6d8wDHLlypXsvk3TpGHDhpw4cYLw8HDKlClDdHQ0+/fvf+LjGDZsGMOGDWPEiBFYLBY2bNjAoEGDCA8PJ0uWLAD8+uuv7Nu3jw4dOgAwd+5c+vXrx5QpU6hevTrR0dH07t2b8+fPM3/+/Afu66effmLcuHGJtl2/fp1XXnmFjz76CBcXF1atWkXnzp3x9PSkZs2a1nYRERG0bduWdevWcffuXc6ePcvLL79M06ZN2bRpE05OTkydOpXg4GD27duHu7s7d+7cwc/Pj/79++Pm5saWLVvo2bMnuXPnpnPnzg+ss379+mzatOmh37fVq1cTGBiY7HNbtmzBy8sLHx8f6zZfX188PT3ZvHkzwcHBD+07wWeffUb58uWpWLFior6rVq1Kzpz//7NTp04d7OzsrPtNULlyZTZs2EDPnj2T7T8qKorevXsTExNDREQETk5OAHTp0oWoqCgWLFhAoUKF+Oyzz2jYsCG7du2iRIkS1tcPGjSIsWPHMm3atMc6ngQJMzXj4uKs2wYOHMjYsWMpWrQoH3/8Ma1ateL48eO4ublx69YtatasScmSJVm9ejW5cuViyZIl1K5dm507d1KyZMkn2v/QoUMZP3484eHhDBo0iNatW+Pr60uvXr2YNGkSH3zwASEhIRw5cgRHR0fOnDlDnTp1aNiwIdOmTePKlSv8+9//5vXXXycyMtLab0xMDNOnT2fhwoU4ODjQpUsXunTp8sBzyTRNXnzxRRYtWkTevHnZtWsXPXr0wNHRkWHDhj3RMaUEBdyn1K1bN3744QcGDBjAkCFDEv1wioiIiKRlGzduxMXFBYvFwq1btwAYMGCA9RrJhIDp6+ub7OsTtu/fvx8PDw8uXbpEqVKlnriO9evX89NPPxEVFUVAQAAAL730EjVq1Hjivpo0aULv3r2tj93d3enTpw/Lly+3Tr+eN28eVapUoXjx4sA/11WOHj2a9u3bW/c9depUgoKCmDJlCm5ubkn2c/nyZS5fvkyBAgUSbS9dujSlS5e2Pn7rrbdYu3YtixYtShRw8+XLx6effmqd3hkaGkqRIkWYPn26tc2UKVNYtWoVCxcupG/fvnh4ePDee+9Zn/fy8iIqKopFixY9NODOmjXL+v4+yP3Hca+YmBg8PDySbPfw8CAmJuah/d7bx/Lly5k6deoj+3Z0dCR37txJ+vb09HxoUHd3dydr1qzWqbMAhw4dYunSpaxcuZK6desCMHnyZDZt2kRYWBhz5syxvr5Hjx60bdv2sY4nwYkTJxg7diwFCxbEx8fHOoX6o48+ol69egCMGTOGuXPn8uuvv1K3bl2WLFnC1atXWbJkifWDo8GDB7Nu3TpmzJjBpEmTnqiGt956iyZNmgDwwQcfUKlSJQYOHEjTpk2tffv7+7N//378/PyYNm0arq6uzJ071/ohwPz58ylXrhyRkZHWn7s7d+4wf/583N3dAXj33Xdp06YNt2/fxtnZOUkddnZ2jBo1yvq4SJEiHD58mE8//VQBNy0zTZNVq1ZRrlw5ChQowCeffML48eOtvyBFRERE0ovKlSvz5Zdfcvv2bSIiIli7di0jR458qr7Mh1yL+Sjbt2/Hzc3NGm6fRaVKlRI9zpUrF40bN2b+/Pm0aNGCuLg4Fi9ezIgRIwA4f/48x48fp3///gwcOND6uoTjOXToUKIRxwQJgfH+P/Rv3rzJ8OHD+e9//0tMTAyxsbHcuXMnUbgFqFChQqJrF6Oioti+fTsuLi5J9nPw4EHgn2thw8LCWLx4MdHR0dy+fZu4uDgKFy780O/Jw8Lr8zJnzhycnZ0JCQl56j6cnZ0fGdTv99dffwEk+bCkRo0abNu2LdG2+8+dBzly5EiiD4YqVqzId999h6Ojo7VNuXLlrP/Omzcv9vb2nD17FvjnvT5z5kySGQ137tx5qnV7ypYta/13QrAvU6ZMkm0Ji4Lt2bOHKlWqWMNtQh85c+Zkz5491u9V/vz5reE24bFpmpw7d45ChQolW8vMmTOZNWsWx44d48aNG8THx2Ox2GZxYAXcx7Bv3z769evH999/z8CBAxk3blyiqRoiIiKSyT3DFGFbyJo1K8WKFQPAz8+Pw4cP89ZbbzFz5kwA6wf4f/75J+XLl0/y+j179gDg4+ODu7s7bm5u1kCRkhKC4P0h+t4poQnuX6EXoEOHDjRt2pTz58+zZcsWrl+/bl3oKOGP78mTJycJocADb3+SJ08eDMPg4sWLiba/8847LFu2jAkTJuDj40P27NkZMGAAV64kPjfur9NisVCrVq0kI5yAdYbg+PHjGT16NBMnTqR8+fLkyJGDiRMnsnLlymRrTPCsU5Tz5cvH2rVrk2w/e/bsI2/bA/8c28yZM2nbti05cuRI0vfJkycTbYuLi+PixYtJ+r548WKiwJXSkjt3klOwYEHWrVuHnZ0d+fLlSzaU3hseEyScaxaLhZIlS/Ldd98laZMtWzYg+XP+7t27yYbFe4N1wh1bktv2pEHz/mN4VD9ff/01vXr1YsyYMQQFBeHq6srXX3/N4MGDn2i/KUUB9yEuX77M8OHDCQ8PJ1u2bEyYMCHR1BcRERGRjCA0NJSSJUvSo0cPAgICKFu2LH5+fowbN442bdokug43Pj6ecePGUaZMGUqXLo1hGISEhDB79mwGDx6c5Dpc0zS5evVqspdzVahQgUuXLvHbb78lO4qbEGpOnz5t3Xbu3Llkb2mUnLp165I7d24WL17Mhg0baNiwoXXacd68eSlYsCD79+/njTfeeKz+4J8A4efnx549e2jevLl1e2RkJG3btqVly5bAP2HgwIED5M2b96H9BQQEMHfuXDw9PZOd/pnQd7169ejSpYt1W8Lo7sM86xTl6tWrM3z4cA4ePIi3tzfwz8joyZMnefnllx+5/++//57jx4/To0ePZPvu06cPV69exdXVFYAff/wRi8VC9erVE7XdvXs31apVe+T+7pUwjT4yMpIGDRpYt0dGRib7oc3jcHR0tH4w9DQCAgKYN28erq6uvPjii8m2Sdh++vRp662Odu7c+UwzJRL4+vryxRdfEBsbaw2xf/zxB1euXMHPz++p+034nvbv39+67dixY89a7lNLo2s7pw1Dhw5l0qRJdO7cmYMHD9KvX79En4qIiIiIZATe3t40atTIOuJiGAZz587l+PHj1K9fn8jISE6ePMmmTZto0KABJ06cYO7cudaRnVGjRuHt7U2VKlX4/PPP+eOPPzh69CjfffcdQUFBbNiwIdn9vvLKKwQGBtKqVSuWLVvG0aNH2bJlC7NmzQL+GWmuXr06YWFh/PHHH2zfvp0OHTpYF416FAcHB0JCQpg+fTorV66kY8eOiZ4fNer/2rv/4KrKO4/j7w8hVlsUZ8yaChWoAtllbS0YKLSjlAmNAl1ZLRBEULLMIhWKpS7dstCFbQtYbYva7bpSYKhut0AZF7KwFUoFBMQgKkLkh4OVVsL6Y10WbLEV4bt/3BMmxJBcSHITbj6vmQz3nPuc53zvnS937vc+z3nObB5++GFmz55NRUUF+/btY8WKFbUWZNUNHjyYjRs3nravoKCAlStXsm3bNnbv3s348eNPK8zPZNKkSZw4cYKhQ4eyadMmDhw4wObNm5k+fTrPPPPMqb43bNjA+vXreeWVV5gxYwbl5eX19t2xY0e6du1a519dU2MHDhxIr169GD16NNu2baO8vJw77riDvn370r9//1PtioqKmDZt2oeOf/TRR+ndu3etBeWoUaPIy8tj1KhRvPTSS6xfv56JEydSUlJy2o8k7777Ls8//zxDhgyp9/VWd/XVVzN8+HDuvvtu1qxZw969e7nnnnuoqKhg6tSpZ9VXY6laiG3IkCGsXbuWAwcOUF5ezty5c1mxYgUAXbt2pXPnzsyaNYu9e/eyefNmpkyZcur/WkNMmjSJo0ePMnbsWCoqKti8eTNjxozh+uuvP+MofjoKCgrYtWsXK1eu5NVXX+Whhx7iiSeeaHC858oFbg2bNm1i586dQOrC7O3btzN//vwz/spiZmZmlg2mTp3K2rVr2bBhA5AaXd2+fTsdOnRg5MiRXHXVVYwYMYIrrriC559//rSipX379mzdupWJEyfyox/9iL59+9KrVy/uu+8+SkpKTi3yU5MkVq9ezeDBg5kwYQIFBQWMHj36tHueLlq0iHbt2vG5z32OkSNHMn78+LSmx1a588472bNnD+3bt2fQoEGnPTdmzBiWLVvGqlWr6NOnD71792bWrFn1Xrs6fvz4U0V/lXnz5tG5c2cGDBhAUVERHTt2ZNiwYfXGl5+fz9atW8nLy+PWW2+loKCA22+/nd/+9renXue3vvUt+vfvz9ChQ+nXrx+HDx9m8uTJab8H56pNmzasWrWKTp06UVRUxBe/+EWuvvpqVq5ceVrB9eqrr35oYajKykpWr159xh8L2rVrx7p163j//ffp168fw4YNo7i4mIULF57Wbvny5XTp0iXtFZurW7BgATfeeCOjR4/m2muvZcuWLaxateq0FZQz6cILL2Tjxo0UFhZSWlpK9+7dufXWW9m2bdup66nbtm3L0qVLeeutt+jZsycTJ05k9uzZjXLP2fz8fNauXcvBgwfp3bs3X/rSl7jmmmtYvnx5g/q96667GDNmDKWlpfTs2ZPy8nJmzZrV4HjPlRpjuDuTCjvkxPbx7Rr9WpfXX3+db3zjGyxZsoThw4ezbNmyRu3frKZDhw7RoUOH5g7DrEGcx5YtzjaX9+zZc9a39LDsMm7cOC6++OKzXvm2KVWfepoNTp48ybXXXsuMGTMoKSlp7nCskdXzOXrOQ9atfgS3asW7goICVqxYwcyZM1m8eHFzh2VmZmZmLdjcuXP5+Mc/3mwrxbYGlZWVjB071sWtnZVWv8jUI488wsyZMxkxYgT3339/vcutm5mZmZldfvnlp92b1hrflVdeyb333tvcYdh5plUWuDt27ODIkSP079+fu+++mz59+jTowmozMzMzMzNrfq1qivLbb7/NhAkTuO6665g6dSoRwUUXXeTi1szMzMzMLAu0igL3+PHjPPjgg3Tr1o2FCxcyefJk1qxZ0yjLbZuZmVnrdL4t1Glm1lI05ednq5iiXFZWxpQpUyguLubBBx/0qodmZmbWIDk5ORw/fjyrVqw1M8uU9957j9zc3CbpO2tHcPfv309ZWRkAt9xyC0899RRPPvmki1szMzNrsEsvvZQ333zTK+iamZ2FiODYsWNUVlZy+eWXN8k5sm4E9+jRo8yePZt58+aRn5/PoEGDyM3NZcCAAc0dmpmZmWWJvLw8Dh48yL59+5o7FLNTTpw4QU5OTnOHYVan3Nxc8vPzueSSS5qk/6wpcE+ePMljjz3GtGnTeOONNygtLWXOnDlNNvRtZmZmrVebNm3o1KlTc4dhdppDhw7RoUOH5g7DrFllTYH7wgsvUFpaSt++fSkrK6N3797NHZKZmZmZmZll0Hl9DW5lZSWPP/44AIWFhWzcuJEtW7a4uDUzMzMzM2uFmrTAlXSTpH2S9kv6Zi3Pf0TS0uT5ckld0u17zpw5FBQUMGHCBN555x0AbrjhBtq0Oa9rdjMzMzMzMztHTVYNSsoBfgwMAnoAt0nqUaPZOOBwRHQF5gHfS7f/6dOnU1xczK5du7jssssaK2wzMzMzMzM7TzXlNbh9gP0R8RsASUuAocDuam2GArOSx8uBf5akSOPOv+vWraOoqKhxIzYzMzMzM7PzVlMWuB2B16ttHwQ+e6Y2EfGBpCPAZcD/VG8kaTwwPtn8k/7paAUMbJKgzTIojxq5bnYech5btnAuWzZwHlu2qIiIa87lwPNiFeWImA/MB5C0PSIKmzkkswZzLls2cB5btnAuWzZwHlu2kLT9XI9tyhWZKoErq21/ItlXaxtJbYH2wDtNGJOZmZmZmZllqaYscJ8Dukn6pKQLgJFAWY02ZcCdyeNhwFPpXH9rZmZmZmZmVlOTTVFOrqmdBKwBcoBFEfGypG8D2yOiDFgIPC5pP/C/pIrg+sxvqpjNMsy5bNnAeWzZwrls2cB5bNninHNZHjA1MzMzMzOzbNCUU5TNzMzMzMzMMsYFrpmZmZmZmWWFFlvgSrpJ0j5J+yV9s5bnPyJpafJ8uaQumY/SrG5p5PHXJe2WtFPSryV1bo44zepTXy5Xa/dlSSHJt6mwFiedPJY0IvlcflnSv2c6RrN0pPH9omdrul0AAAeRSURBVJOk9ZJeTL5jDG6OOM3qImmRpLckVZzheUl6OMnznZJ6pdNviyxwJeUAPwYGAT2A2yT1qNFsHHA4IroC84DvZTZKs7qlmccvAoUR8WlgOXB/ZqM0q1+auYyki4F7gPLMRmhWv3TyWFI3YBrw+Yj4S+BrGQ/UrB5pfibPAJZFRE9Si7j+S2ajNEvLYuCmOp4fBHRL/sYDj6TTaYsscIE+wP6I+E1EvA8sAYbWaDMU+GnyeDlQJEkZjNGsPvXmcUSsj4hjyeazpO4XbdbSpPOZDPAdUj82/jGTwZmlKZ08/lvgxxFxGCAi3spwjGbpSCeXA7gkedweOJTB+MzSEhFPk7qTzpkMBR6LlGeBSyVdUV+/LbXA7Qi8Xm37YLKv1jYR8QFwBLgsI9GZpSedPK5uHPDLJo3I7NzUm8vJtKErI2J1JgMzOwvpfCZ3B7pL2iLpWUl1jSyYNZd0cnkWMFrSQeC/gK9mJjSzRnW236WBJrwPrpmlT9JooBDo39yxmJ0tSW2AHwJjmzkUs4ZqS2oq3BdIzah5WtKnIuL/mjUqs7N3G7A4In4gqR/wuKRrIuJkcwdm1tRa6ghuJXBlte1PJPtqbSOpLanpF+9kJDqz9KSTx0gaCEwHbo6IP2UoNrOzUV8uXwxcA2yQdADoC5R5oSlrYdL5TD4IlEXE8Yh4DXiFVMFr1pKkk8vjgGUAEbEVuBDIy0h0Zo0nre/SNbXUAvc5oJukT0q6gNTF8WU12pQBdyaPhwFPRURkMEaz+tSbx5J6Ao+SKm59rZe1VHXmckQciYi8iOgSEV1IXU9+c0Rsb55wzWqVzneLFaRGb5GUR2rK8m8yGaRZGtLJ5d8BRQCS/oJUgft2RqM0a7gy4I5kNeW+wJGI+O/6DmqRU5Qj4gNJk4A1QA6wKCJelvRtYHtElAELSU232E/q4uSRzRex2YelmccPAO2AXyRrpP0uIm5utqDNapFmLpu1aGnm8RqgWNJu4AQwNSI8O8xalDRz+V7gJ5KmkFpwaqwHgqylkfRzUj8q5iXXi88EcgEi4l9JXT8+GNgPHANK0+rXuW5mZmZmZmbZoKVOUTYzMzMzMzM7Ky5wzczMzMzMLCu4wDUzMzMzM7Os4ALXzMzMzMzMsoILXDMzMzMzM8sKLnDNzKzVkHRC0o5qf13qaPv7RjjfYkmvJed6QVK/c+hjgaQeyeN/qPHcMw2NMemn6n2pkPSfki6tp/1nJA1ujHObmZk1Jt8myMzMWg1Jv4+Ido3dto4+FgOrImK5pGLg+xHx6Qb01+CY6utX0k+BVyJidh3txwKFETGpsWMxMzNrCI/gmplZqyWpnaRfJ6OruyQNraXNFZKerjbCeX2yv1jS1uTYX0iqr/B8GuiaHPv1pK8KSV9L9n1M0mpJLyX7S5L9GyQVSroPuCiJ42fJc79P/l0iaUi1mBdLGiYpR9IDkp6TtFPSXWm8LVuBjkk/fZLX+KKkZyQVSLoA+DZQksRSksS+SNK2pO2H3kczM7NMaNvcAZiZmWXQRZJ2JI9fA4YDt0TEUUl5wLOSyuL06U2jgDURMVtSDvDRpO0MYGBE/EHS3wNfJ1X4nclfAbskXQeUAp8FBJRL2ghcBRyKiCEAktpXPzgivilpUkR8ppa+lwIjgNVJAVoEfAUYBxyJiN6SPgJskbQ2Il6rLcDk9RUBC5Nde4HrI+IDSQOBORHxZUn/SLURXElzgKci4m+S6c3bJK2LiD/U8X6YmZk1Ohe4ZmbWmrxXvUCUlAvMkXQDcJLUyGU+8Ea1Y54DFiVtV0TEDkn9gR6kCkaAC0iNfNbmAUkzgLdJFZxFwH9UFX+SngCuB54EfiDpe6SmNW86i9f1S+ChpIi9CXg6It5LpkV/WtKwpF17oBup4r66qsK/I7AH+FW19j+V1A0IIPcM5y8Gbpb0d8n2hUCnpC8zM7OMcYFrZmat2e3AnwHXRcRxSQdIFWenRMTTSQE8BFgs6YfAYeBXEXFbGueYGhHLqzYkFdXWKCJekdQLGAx8V9KvI6KuEeHqx/5R0gbgRqAEWFJ1OuCrEbGmni7ei4jPSPoosAaYCDwMfAdYHxG3JAtybTjD8QK+HBH70onXzMysqfgaXDMza83aA28lxe0AoHPNBpI6A29GxE+ABUAv4Fng85Kqrqn9mKTuaZ5zE/DXkj4q6WPALcAmSR2AYxHxb8ADyXlqOp6MJNdmKampz1WjwZAqVr9SdYyk7sk5axURx4DJwL2S2pJ6fyqTp8dWa/oucHG17TXAV5UMZ0vqeaZzmJmZNSUXuGZm1pr9DCiUtAu4g9Q1pzV9AXhJ0oukRkcfioi3SRV8P5e0k9T05D9P54QR8QKwGNgGlAMLIuJF4FOkrl3dAcwEvlvL4fOBnVWLTNWwFugPrIuI95N9C4DdwAuSKoBHqWf2VhLLTuA24H5gbvLaqx+3HuhRtcgUqZHe3CS2l5NtMzOzjPNtgszMzMzMzCwreATXzMzMzMzMsoILXDMzMzMzM8sKLnDNzMzMzMwsK7jANTMzMzMzs6zgAtfMzMzMzMyyggtcMzMzMzMzywoucM3MzMzMzCwr/D/LgI0E8CtuZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.18      0.67      0.29        24\n",
      "   Pneumonia       0.80      0.31      0.44       104\n",
      "\n",
      "    accuracy                           0.38       128\n",
      "   macro avg       0.49      0.49      0.37       128\n",
      "weighted avg       0.68      0.38      0.41       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  8]\n",
      " [72 32]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
