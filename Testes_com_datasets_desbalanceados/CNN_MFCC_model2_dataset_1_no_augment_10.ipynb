{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 2\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 1 - no_augment_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'no_augment_10'\n",
    "GROUP_TEST = 'no_augment_10'\n",
    "DATASET = 'dataset_1'\n",
    "DURATION = 10\n",
    "SIZE = 431\n",
    "CSV_TRAIN = 'train1.csv'\n",
    "CSV_TEST = 'test1.csv'\n",
    "MODEL_NAME = f'CNN2_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  102  Healthy\n",
       "1  121  Healthy\n",
       "2  123  Healthy\n",
       "3  125  Healthy\n",
       "4  126  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  122  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAEYCAYAAAA57swgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nOy9f7QuWVnf+X2q3nNuNy0K2AhId4RlWlcwOkYZ0MlMFqOoDXHZRpMMuiYicUKcBYkuM8sF4lJHJctRY9REmWGUCBFF1Dj2MK0EnCQmWYOChCCIaIsQum3EBmx+dPc956165o/az65nP7Wr6j33nveec+/9ftZ6u89bP/Z+9s+qW+/+1ldUFYQQQgghhCzRnHUAhBBCCCHk/MObRkIIIYQQsgpvGgkhhBBCyCq8aSSEEEIIIavwppEQQgghhKzCm0ZCCCGEELIKbxoJIYQQQsgqvGkkhFwWIvJeETkSkZvD9v8kIioiTxKRn0nHfNx9/gd37NeLyFvS9vtE5NdE5L91+z9LRH5RRO4XkQdE5O0i8m0i0l7JshJCyPUMbxoJIafBHwP4OvsiIp8L4BHhmB9U1U9yn19Ix34bgB8F8I8BPA7AXwDwkwDuSPs/E8BvAXg/gM9V1U8B8LcAPBXAI/daKkIIIRmhIwwh5HIQkfcC+CkAd6jqf522/TCAjwD4fgBPBvA9AO5R1e8M534KgHsBPE9Vf3Em/Z8F8GhV/ev7KgMhhJB1+KSREHIavAnAJ4vIX0o/GT8HwM/ucN4XA7gBwK8sHPNMAL90+SESQgi5HHjTSAg5Lf4lgG8A8GUA3oXhCaLnfxGRP0+f+9O2TwVwv6puF9L9VAD3nXq0hBBCTsTmrAMghFwz/EsAv4nh5+hXVfb/cPx5GsCHANwsIpuFG8cPAXjC6YVJCCHkUuCTRkLIqaCq78MgiHk2gH+142n/H4CLAL564Zg3Avjay4uOEELI5cKbRkLIafJNAL5EVT+xy8Gq+gCA7wLwEyLy1SLyCBE5EJFnicgPpsO+G8B/IyI/JCKPBwAR+Ysi8rMi8qi9lIIQQsgE/jxNCDk1VPWPLuGcfyIiHwDwnQBeDeBjAH4HwEstTRH5YgxK7HeKyAbAewH8i3QsIYSQKwBfuUMIIYQQQlbhz9OEEEIIIWQV3jQSQgghhJBVeNNICCGEEEJW4U0jIYQQQghZ5UTq6Zs/+Sb9jMc+BhAZNkQRjW33+5aOrYlwfBp23lK6a3Gs5b2UzlKcl0KM6yTsGu+lEtOdy2eXul1jLb1LKeNcPzstlsq9lvdJ2n2XvryU3i59eO17jV3qtxaXxXvS82JeJ+1Xds4u5bzc+HzdLNXTrmPnpG2za9qXElPt+LW62jXvWhwnTfukafjjIrU5Nu6/lL66lO4ubXIp1Pri0vhci+tS+1dkLa/TuN6mPN76R++/X1Ufe3mJXT5f2NykH9Vup2PvxsXXq+rtew7psjjRTeNnPPYx+I8/+G1A2wK9Ap0zcGgaQNyDS+2H/9s2+25IM2zr3faYhp3nt1me7Wa6rWnKPGMslle7mcbn04nxxNgtnaYZ/rb/+xj6cE4sWyPTuul12J7zcYPH6sqXeymuk1BLN7alldO2NzLEV2vXNfw5a+0d07d4Yxlr/Sz2rTl2OS62XdeN51rd1WKtnZvz1XL7LvXp66eW1tyYinXuv7ftUJ5an41xzJXRjrGYfDw+v1rbtW15jpWt66bHGH3lwtJthwuOHbtW7qXtfizFNrAyWny+bubqyfqJtXPtmNq5c/PkXNrAfD9amm99/1uaR+bqys+9a3nX5sg4hubG+FL/m7su1coATMdPvCb4Ptd182PP9sc50qhda+K+HEcPHF4Y07S8av29hu+bsT/N5b8U11qZjLW28cdF/PXb5iLjpHO4i/XGr/3W960HtH8+qh1+dPMZOx37lds/uHnP4Vw2fE8jIYQQQsg+EEAOdnx6PGekeo7gmkZCCCGEkD0gjaC9sd3ps5qWyK0i8m9E5PdE5J0i8i1p+2NE5A0i8ofp/49O20VEflxE7haRt4vIF1xueXjTSAghhBCyDwRoNrLTZwe2AP6Rqj4FwBcBeIGIPAXAiwD8hqreBuA30ncAeBaA29Ln+QBedrnF4U0jIYQQQsg+SD9P7/JZQ1XvU9W3pr8/BuBdAJ4I4A4Ar0yHvRLAV6e/7wDwKh14E4BHicgTLqc4J1vTKFJfyBppBOh3XBhbW9y6JqKJeemKmCIu8C8W+c7E48+ZE2b4xdq7iE+KcxugqYk80oLnRuoLoJcW9s/F4OOMC8ztexQeWAwA4Dfn/NqxnZeoiQNqgiQfT1sRMADlguklUYPl5QVKu/Qlf9zcsdrXy9wIgPTzQqxH29/rVNxk+dlC/Fq5/HiI48/3F6Bsq4jVxUFbHtdrErFgvq1qzTwROKT8a4vm4xicxKbT73aOWnxBRLLWVjkt62/NKJaYO74q1ghiAGvfLISpiAX6vq6orQkusrivmZ5rac8J7IpYVwQ2k3KFYxrr25cgJotprY2zmO6c2MPPFY2U/bY2FtT1GSAJQqSM3Y6ZGytREOljsWRiP7c4u65M2Oe9JEjxaF+WpbO8V4QgTTNmbf22PKjsp1ngaLHOzJFr8U7aYUFEZkQxWT630gdOKuw8Z4js/BQRAG4Wkbe47y9X1ZfPpPskAH8FwG8BeJyq3pd2fQDA49LfTwTwfnfaPWnbfbhEKIQhhBBCCNkHJxHCAPer6lNXkxT5JAC/DOBbVfWj4l5lpKoqInt69xxvGgkhhBBC9kNa03hqyYkcYLhhfLWq/qu0+U9F5Amqel/6+fmDafu9AG51p9+Stl0yV/dzX0IIIYSQc4oI0B42O33W0xIB8NMA3qWqP+J23Qnguenv5wL4Vbf9G5KK+osAPOB+xr4k+KSREEIIIWQvCCS+DP7S+asA/g6A3xWRt6Vt3wHgBwC8VkS+CcD7APzttO8uAM8GcDeABwE873ID4E0jIYQQQsg+EEDa0/lRV1X/w5BilS+tHK8AXnAqmScu76bRWz95CzGgrqz1qro5y62oipyor6LaVuuKT68ErSFJJbim6tyVaCXWVhRzsZw1FW4uQ02hu4OtV83KzZ8W0zCFW021lu20sK6C8+pf215Tc/axDk5Q/96qbE65HRWKRdnDOXP5eyWyqRLn1KBeuer7/5zKeS6dObV4E44pbC+djd0uNmNRZRuV0bU2XrKHy+dUlNZZFR7Uv8V5GOOpqaH9OVFduxSrT8NvL2zj+vo5ts33n5rSuKawLZ4mbNYt+axMUV0bbUl9WdsFpfGa9VssY7RmNAU1Vmwx7dhMUNC37fTtGbV+4onlsfgtm2y76uwuD4L9pLc7LeaZ0G/mrC29Wr9tK1abmG9Pi9esLC2eXVaAFep2V545G8CaVWC8KSmaZ2YcRKV8jbl+W1Oe53LMzKnFWwtmXmQd+1y0Mp17w8SchfA5QAA07emtaTxr+KSREEIIIWQfCE7z5+kzhzeNhBBCCCF7QfikkRBCCCGELCMCNAfrvtJXC7xpJIQQQgjZB/x5GlPrMhMXLC3Gj+IF7cfFzbaotiaoiXkCw0Jjvzg4LgyfW9y+tC3aNEW7paW0loQ7S/tq4ge/Ly74jTHWFqpPxEhapr2LtaNhQotGxkXzE9u/JeuyGZ+uQtCCeZvHnA7KvmNl9CKcOXFAFFwsxVMTPGBm4XWNufTn7MPiYnyzSvPpTCwgK+n4PKplmDlnF3uuQoRRseDzNp5WhphHFGdlUQNGy7S2ndr05UX+qe81oV8UbdI6W0NXf17QsEs7TuJtRnHHLnZq5swgCqhMxSYWqx2frfswxta243m1+gKmc2Qxzk8wxqOAL4thMA7f2KaxHpqmtIPL4/GEogQvHMpjYSGNKD7z8XkhYtUy0aVt4iJfF7Gvm2CpEK34c1IcuiJAsvNyGaK4BdO5tm9GC0xg6GOqQx+z8yaimYMxj1kRn6C4BVgTWAFjvSyWq2YPW7EJzectXIdjfe/Sp05yjbsi8OdpQgghhBCygvBJIyGEEEII2QXZ5VedqwTeNBJCCCGE7AM+aSSEEEIIIWuICNoDPmkkhBBCCCEr8OdpYFAomWAuqxa9qrKi2lxTXdWUUVGdqzoqFP0xUXGr/XRbYf0VlJ6X26bRTs/nG239atTUr2sxRVVg7Ji+7pZU3ZGJatwpQKMyNSqkczvNPI6fszebUzAD86q+QmUcbciibVWFWl7R3nHORgtO3RrV0d7uyn+v5VWjcUrMNZvFiaXiim2dxezxisVorRbPjfH3TakQnqh6o9J24WcabzEat8+pwK0sbTvMC51XZUqaK0LZvEWhKdKjajfG1Os4DCSooou4gyp8qdzal1ZwVj6vwp57A8HSXBLb0ve/OB83/fTvWlq+HLU+n9PsB6WvV2Hnt20svaUgbdeZcvWKwkLQyjfpX5Wx1zZlG5ntplceR4Vwk+a2qGyP7Vh7a0RUzPu3UNSYsx/Nb46I4yKp1X35Y10vvRawNlca3orRYpibp050DakQ+1C0Dq3F3Uip1K/lc1rWwKcFf54mhBBCCCHrCG8aCSGEEELIOrxpJIQQQgghiwzvaeSaRkIIIYQQsgTV0xgEJY1bpG/14Rcx1xbSzy1gnVvU3WsQr2AqgtmFaIO1RC7TTCPHctnC77l02rDoGigto5aY2HXFbZUFv1H84eOo4UUmc2IZW4QOLFuy+fO7rl6X0SayC/tr9W5lKuKpUJR7xlJwzRLShBG70shQhlq5lrB+FOvI95W4oD4KHGIcAIDNdMxEAYwJZ9TlXROz+bz6UD6/vw/t7q3GcpphDOpx+d3HE+eVLv1HmvG82JZW3zY3WZro1gUptfJY2tnS0AnrakKHHE9XlsHmRJGpCCzXTegDVoeAG89h7lwae1H017p8iz7alW0Xx1kNq8vYRnFe9vHV0qwJGj21drIyRStVqyurIj+Ga1asSIKbbMsXxJbWbyImoLFj54Sf3Yw40AtH/b4o5jGRS7R4zPEdu76S6kRd37HtbbDzmx3jFZHZ2nUjUiuHT3My76Z5M863S5a3lke0K/V9/Zzem/FJIyGEEEIIWYQ2goQQQgghZCd400gIIYQQQlYQ/jxNCCGEEEJWuMZ+nr52bn8JIYQQQs4VAmnbnT6rKYm8QkQ+KCLvcNseIyJvEJE/TP9/dNouIvLjInK3iLxdRL7gNEpzsptGDfZRTROUsTJ+vDLUYzZZpto1pZj/9Doq+Zqm/Exi6qcqK5+PV7X6NKoqXZdf7+KxdGbrxcVs6agOH1N2Ldl+eWJZGxk/MU9fFq+s7d0nYmVp22S9VlG3ecusrPTeDh9L18rs62iOuXh6Le2+5tJYsqKy/XPHxHyLftGUx1ibeWoxRfvCmi1azcoyxuP7W7R384p2/4n5eCs0+77LTyGNzKdbi9e3dySPW/u4fuHVnN12WidF+q5uaqp23/+2x2W/svRjXF7JmsdpTX0+M7/YfOZjzeNcx/S88ju+YWEOaZLCNfQ7i9vmxiLvSl6ROG/68Rz7lm8P//84H/iPr2ffXj6/XDdBmWzHxnhtu81LMe9Yb7O2kitzRdNMx3jsv7U3etjY8sdau8W28/Xk++xSe+X4TvBEyl+DLV3fX2tKaauDfL0Isdv+dlMqlH2d29wx109q5YrpzI1DS79xZaj10eKYaIs4M5bPCBPC7PLZgZ8BcHvY9iIAv6GqtwH4jfQdAJ4F4Lb0eT6Al51Gec5PzRJCCCGEXGNI0+z0WUNVfxPAh8PmOwC8Mv39SgBf7ba/SgfeBOBRIvKEyy0L1zQSQgghhOwDOZH39M0i8hb3/eWq+vKVcx6nqvelvz8A4HHp7ycCeL877p607T5cBrxpJIQQQgjZEydQT9+vqk+91HxUVUVkx7VwlwZvGgkhhBBC9sSe1dN/KiJPUNX70s/PH0zb7wVwqzvulrTtsri0m8bGFuC7Bcu9ltZNwHTF5NKC+zkm56QFyDULp12tj6LwwJ+bt/tF+e6YOYHPnBBDKwvB5yzZdiHaQjUu5ontko6ipF3wNl3RFqqWRrQq81hstbqaW2QOjBZuc5aGS3gBQk2AstYvoq2ZnVNrWytDtvFy9dXEdphZjN5XyrmLXWK0qPR5SoPCAs3iskX8wLT/zQmZfNvV7BVrtmTeTg0YpoiJHabLW1x7+8OiyMeLQnxssV8WfcnZJgJDtUwsFiuCCl8fhweu3lx6TTvaz/k8vIgjxuIFBD7P+D2WB9ht9bkXyPg5LgsJwnxdO7eGr+s4nmuCpeGP9XnH5kYbZ1E96oVyXqRRiDFdX/Lj34s2Yn+3NvD5dV3dbrawf3X2mDbv+ljiOJorfhFzrD+zEfV1YXaHB8P/C4tB1+9qFnwTRa773rajBeZcfLUY15ibv5cEi0V+wY44x9W4a7C7rmoPtAf1c84BIgLZrCujL4M7ATwXwA+k//+q2/5CEXkNgKcDeMD9jH3J8EkjIYQQQsiekCWf9ZOl8/MAnoFh7eM9AL4bw83ia0XkmwC8D8DfToffBeDZAO4G8CCA551GDLxpJIQQQgjZB3KiNY2LqOrXzez60sqxCuAFp5KxgzeNhBBCCCF74UTq6XMPbxoJIYQQQvaB4Fy9bPxy4U0jIYQQQsie4JPGifI42It5taJXbMZzTNlmmOpqSWGV1chmhSVTtVRUb5lCbE5lHM+NmBXZ0mLWmspriZoyEJhXPEbbpaai1rO682ryuX/hVO3gnJpx+GP4X7upxzpnB2axSDOm4Y+P6kdvNxbTqikCgaB8xGjrFZWevp/M9S9fjmj1VVU+i1PvVWy40E6VvlVlZlDXxvasffdlKsrTVrZhVD1bHQFJ1V6ph6hg7rqxz9dUxpF2M/ZbO27jFJ/+/DyWulHdmtXnlqdr46gozersdozV1Mn5nH5egR6JimtPVuLOlMHnG+dBf24uT2jTqOKtUZRLkppcx3O8ODO+sSHaaPq814gK+hxDU26LtnS+TLvYKq6pu30e/hzfj00xHssVFcRt/s/I2qvtekXxVgKzYlXXbyT0X7TTeOJcF/udr4e5sda0U+s8IFyfZt5CEVkT9cZ2yNfCpiyvb4famxbmqLbpzPwszfgGjGKczdjhnhNEZCdf6asFPmkkhBBCCNkTpyWEOQ/wppEQQgghZE/w52lCCCGEELKMyPoygasI3jQSQgghhOwJPmnUvlgTPFkMXbUBMvsfd+zMmu+CaPsFJFGDEyLY9yhUiQtzC3HMtrIId8ae0C9OX7PRmtvuLa/8YuJ4TKQPi9ojS4udTZiwlG41zVCXtlh/USQgU7HFXFoxDr/4OVo8emFHIXJZWQiebSFljMPSm8trzmKu1ic0pO8X+8fY/Dm+X0iww4pWh3Fxt8WRv4uzuKxYMw47drO9tHqeiMpcujWrtIn1WxLqbKKAJ9gddiFeL6brLP6u3FcTcWhlzEeLxzjP1PpYbAfbvXXil1xnIcGa0GPO5rA4RqftYOIjf1q0x7NYfd+OMXgRk0+nJiSYxGV1W5lTrUy1MWHpzs1Hvj+37VS0Fm0B1+JrmnIen5vnmtC+NdFEdd7HfF3Y3BqFS30PqI8n7J8IPTZTK0TDxDkmvIuWhfH4Nojyst3owmV+ToQ5KVOcX/x8V7mOdl19bjB8m9Xsb4GxvgvBjY7XGkvTCwo7LI+5s+I8xnSJ8EkjIYQQQsgeoHqaEEIIIYTsBH+eJoQQQgghy1AIQwghhBBCdoJPGgkhhBBCyBpy3T9p9IoyoKK8dMoqr0D1SrOuG8/zVmU1GyGPSFLNrUivfTpZFV1Jt1CryVTdCgxKMV8WX4as3qqc52OpLYQ9LcujmuVe3L/UaaMSuEZWbJ7Arqnvl9P0aXgLw4Og1K71iSUrwLlY1mLYlcIGrKY4Dt+9QnCX+osq+z7UU60t5/pATQFeUyzuYv1Vi1maUeXp95tyObZdh6DInusf4Q0NmmzcvGLYq1dFBtVqVHpOrC1n3rAQ7TH93KF9aWmoQfVsis5C1eqUr5Z3VcWu0zKhkr+vlxr+zQ/2NgmvQs22mjPn76L2tjSiPac09bdcTM63Nw04Zb/lncvZjsfW1OXR6tLH3lb6dbcFtlrvB9Fu0fBv5PDt2cjYD+wNIv46ZOfkPhn6ok/TzwPR0jPXb0rHlOY5LZenH/fddqpynuvXVk4fi13n+m4sZ9OUZQJSO85c732evcyr9deu8RZfHK+1J3Z9X8575+0GTcAnjYQQQgghZA2qpwkhhBBCyBoCvqeREEIIIYSsIcvLtK4yeNNICCGEELInhE8aA7UF5iYQyRZAqNsRxXOAcpG12TVN8ovbZP4RcLSS89tqZQHKBfJzFmHaA4qynHZeXvSt04W6MR3DL+S2+ptbuF4spLY8Q5ptWKxs7Gp96LEF034xu7qF9ba43acRF17P2a3V8rV8jt0C/TnLPy/2mBMk2YLsRsaYaouxfX/bRTxTW5gf827E1Y+zu5oT85iIopZ/TawV+4DP34sz5trXxmXMrzZGvGCmJqjJgouZMsTF9/Fcn64XuQDpvNZt8/m7vmbrh/okKqmVY25hfk3Ah2al/8Et2k/H2BImL/KLgpHqvNKUbWzbctzBYi3m4cvikQbFHFATZNX6QJzbYh5m4WY6iapIy/rCzNzv+4q3jJvjJGIyDaJJaaZjKGoqi7oN7ekt+bQvj419P17rct2tPHWKdWxp+nVxfT/EEvtT7Mdy4PYH0ZL113h9lCZYM3aloGtyfChPze4zjmUvzJoTYflxD5R2hfG+opb3eUFwPuO6RPikkRBCCCFkL8g1pZ6+dm5/CSGEEELOESKAtO1On93Sk9tF5N0icreIvGjP4U/gTSMhhBBCyF5IywJ2+aylJNIC+AkAzwLwFABfJyJP2XMBCnjTSAghhBCyL0R2+6zzNAB3q+p7VPUIwGsA3LHX2ANc00gIIYQQsi9OTz39RADvd9/vAfD000p8F05+07iL3ZRRqFe9otHOr/yG75VQpsyDs5UzJZVXsdUsrGI6c9ui8tarW82WKarWfPlM/eWrw9thmeJwSSVm35fUgDVFpFct1o6p2fQtpT2nPI7K6eq5lXSjYjOmvaRSjkrLtp1XX86lAZQxZ2u3lH9N0RcxVWxNsezzjuramHfbpj4wU4Y5NevERsvlY1ZrNQV6rS/NKaxryvo5pXvMw1ugWR+JtokWZ46rXe5f0kyP8cf5skf7RMs/x+eOsT60izVdVs2msrRtfT4Dhjbqu2AvOaMo9dtjP7L42nbsmw2mdVVrm5hW7alFre94TJ3u+0B8Y4IdF4+p5Tt5cwLq+2rxWjvV5mxPfLtG7DPWbnaNsDrw/WRzUB+bNZV/6+Z130etjmrzVG18xH2+PD49ICml2yHOiH9LBzC+JaJ1bxnwc/9GynOipaHF6dO3+skxpjLGOvXjzOKONr3572b6RpVoydv3w7jK+V6lP4yKTPvRPDeLyFvc95er6sv3ENUlwyeNhBBCCCH7Ynf19P2q+tSF/fcCuNV9vyVtu2LwppEQQgghZF80p+Y9/WYAt4nIkzHcLD4HwNefVuK7wJtGQgghhJB9sGQ8ckJUdSsiLwTwegxr4F6hqu88lcR3hDeNhBBCCCH74hS9p1X1LgB3nVqCJ+TkN43R6sv+rhEXEktT2rkZxQJyOIFCM+yrrQfwC5KjDVSMFSgXj/uFv9GOKC8gbgDtxnNzmVysbTtaQs0JMXz+hs/Tfy9PKM+rCTKisKOWV85zZmF+TTBRtXgzC6pgybX0D6hoX2cLo/2C5ijQUQ39oRn7QRFPs2wHaAvvvfWUCTcmZXPbaqIq1eU+DkyFQl1XWqs1QZRRS0dcPQFje88JqCy9KMKJAgI719fXnGXXHL6tLa9uO23/vCDfC0VS+YGh/hsZf65RHerJCwQslk2anvoujcewoLzN/6nPRWaB5mlbYBvGord5nGufXscyGE0oY7Rb8+llsY87J/b1th2KI16sEPpV36wLAqKAahc70iadF61fgenYi6KbmtWq5ZvjrvTJms1ejDNa1flxEtsOcOIw1w+bfrAT9MdMxDvNtH37puzH3trS2qQmeGrd8UMQKT0tx4LlsUvbVO0ZK8K0iXisMr8aVne5DO2039pxUbTayFinMU/fP+asBmvxzIk1sy1jEMIBKf54/Mq1+CygjSAhhBBCCFnkFH+ePg/wppEQQgghZF+c4s/TZw1vGgkhhBBC9oLgFNXTZw5vGgkhhBBC9oGAP08TQgghhJBlFIBe9z9Pe/s8oK4CNos7U6Oqs28CSkVeVD76CjZ1dM1SLKYTmVM0R+Wfp1AHhwWs0XbO1OBmN+jPi4rXXWzeloix+Po366lamqaanbMIrFn9RYs2oK4eBablXFKRWywTGzcZ7aLM8qtWXz4vr+b15fNq82hdZunEvH1ZYjt61abF57FzvHWk9Uk/PjqU26wcvkw1xWFNoe7tu+Ys5WrWgBGdiWXuHBu/foz4/K2N2jCtdF3oSw0gOu4Dyv6lqI/3XlGooeMbGLQf9nuFpbfa7DpgE9L19m8AcLSdqni7DhCnwLUy57cXyGirlhWlVj6nxm8305j9/mzB6NS/UfHvx+aSIjO2p5HnzWaqRJaZ4+O4i/3Gzo95TBTkQUmbx5a68RoU1zlNnb/e+GtKvB5Y34vzVBf60eStEFIe59sYGK9nscy+/0XsWrZke2hMyrEtx30+zpWr75HHfVVpPPP2hviWB59/zW7S0o9/5/ZK7ehV/LE/5j7i5v7aT7jSjGnYfL5kw3geldM4kY3guYdPGgkhhBBC9gVvGgkhhBBCyBr8eZoQQgghhCwjVE8TQgghhJBduO7V07awWN1idpFywX625XKigGh/ZYtWbbGx3YzXKjguvPWL2/1CWX9+tB+KlnyTPLRMo7bw26dvi4SbkPZc+j7+QnSQ/l8IiWYENHPp1eKrxV4TGMRy2oLpKNKoLciPi7KjkMS2+7gKS8Vgu+bT8nn7do7UFv3HY2timTZaYzVBtNEkq8iK6GuyAB3lYvpITbBS21+1gJxZ+D2Xprf4mhMmVUUSGvplU5a7ZufosbprmtKWLwoapCKGAkL/6lGKQfpyXKmW7Z4TzdAAACAASURBVOf7XhZ0ROFJX1qUFmVfqNfYl7zwx+KuiQEmFm5hDMU6MKHPxMrSxWOiQC96AErx0Vzfj6KlGMOsYGphDp8c288LWrwoQkKdeTGMHTM3Hoq8Ku0Y0/Zl833YjjmO8yem9n4dZsZMKAMw9j+L37dNFE22WBZ25O3unDnbVE/XDUGLmwvsuD6IfsaTRsFltjTVMmaRab/2Y3IpxhommKmVpWadm4+piA3PLcKfpwkhhBBCyAoCCmEIIYQQQsg6yptGQgghhBCyjMwvrboK4U0jIYQQQsieUKqnCSGEEELIInK9O8JUrYCSAsqrR9t4rKmdgnLN28r1Fau8fIxTb00siWo2R84yySzKisOauhJMF1RZ8fiuG9Vxdtz2eKwPIyr4Yl5RPW7nxOOjIq2mRvbKN7/Pl6embGt9nUZVZ4rF2/tF1aIRrcFqFOrBpE5eOm9OtehtyuycqIg21pTLdoxI6CcLx/u0o3K8bYPF2g5qwmhTacrxaPtY9Mmghh0yd+fMqKR9PjktqffbHF9U9aKucI3K3qikjfaJNaJKO78JYaVP+TKYrZ+PL1pUxvloMv6b6ZiK1mreqnAOf+HwbeWVtWZnV3v7QqEoDbFeKnPzSTwmz/PtjOo9tHe08Ixjs/pWB6mPfT/HVefDynYNscSLtrXfnG1mtMmtlWEXJm90SPNAzQIyqvc97QZZ2Wyxzs1BNZvESOyHfu7tU//zxfRtomG8AKlf6HRbjao96UK5Itav1t6Eco6g9zQhhBBCCNmN6/pJIyGEEEII2QkFnzQSQgghhJBFhK/cIYQQQgghK8i1pZ6+tNvfJZEDMNq+2eLY2senFf8227b86Yb0lhb3ztkvrZajnz/XxD19WBTtY8sL8Jvx41la2Cvp/U0TC7Jwvs/f1/1afnOL1mOdq7OKqn38sbncod6icMDKt4s921JfWqqTpWPisXHRu19g78vZuHYUqYs87PxdxDXAbn2z76bHxbr2wrOqAMbOuUSBxC6WlbZQXnUqELHYgOkxsa8W/aSpl7MoswwiBBszNRGPiY/yuJoRO8T+q6GPqOsTc3OOtye0OWIXYl4eE2eY2K8JdZnnxzC3WrpFWjv20xyXhvJ7UYO3lYtzc5iXvGDJ9se26rbTebVppraQnprob+k6FOu4du1Zws8LNeGY9aGYTyxrvAYCdRFMrS5921nf9qK7eIzHxoAdbx8/PuKNjK//zl1za2PN7Bh7Z5s7dw20+rL/z/WdquBRp8fHObuWzzlC05PGXT6Xg4j8LRF5p4j0IvLUsO/FInK3iLxbRL7Cbb89bbtbRF60Sz580kgIIYQQsi+ujHr6HQC+BsD/UWYtTwHwHACfA+DTAbxRRD4r7f4JAF8G4B4AbxaRO1X195Yy4U0jIYQQQsieuBJrGlX1XQAg0xvUOwC8RlUvAvhjEbkbwNPSvrtV9T3pvNekYxdvGq+d1ZmEEEIIIecKGX6i3uED4GYReYv7PP8UAngigPe77/ekbXPbF+GTRkIIIYSQPXGCJ433q+pT53aKyBsBPL6y6yWq+quXEttJ4U0jIYQQQsg+EIHOOeScEFV95iWcdi+AW933W9I2LGyf5eQ3jV6xZHfPUQU7d1c9p4hrZlRzpsrqdVQrRqshbxs2UXlZ+n1pXWXKWADZMi6WwfKuqeeKOpDSXi1asflzawpjn1fcFpWbE2XejArTxxPTXlKXRfXinD1jLZ1o12VWZ75tTQkXVYjAoAj1RKVtoVS3dllQLdYwJaBZt0VbPIulpoCcS3+uPn37+XN9O+yi9JsogCt5N+H4+HaCmgWb7TNqKsla+/uxk2Na6Fs1lXeMR9P3or4qc8WcEtpi9X/ndMKxE9vQfnpMXLXjLfGAwTJQmrH/xPnAtkW7uHj8JF2zE93xAuPn35rlXcTXoVmf1vp8rd/uij/HW+/1/Zhu7gsV5b2EfmK0m1HVHmNesuSzY3axpxu/nKy/2ff4t6mUYzqxH/rvc3HW+lu0pmzCnBmtRGsKZQ39vWlDWfrBErDWF5qZ/mH9d04NndOdsQ2MVoi18RW/z7XLOeAc2AjeCeDnRORHMAhhbgPw2wAEwG0i8mQMN4vPAfD1a4nxSSMhhBBCyJ64EkIYEfkbAP4ZgMcC+H9E5G2q+hWq+k4ReS0GgcsWwAtUtUvnvBDA6zG4jb9CVd+5lg9vGgkhhBBC9sSVsBFU1V8B8Csz+14K4KWV7XcBuOsk+fCmkRBCCCFkL9BGkBBCCCGE7MAZr2k8VU5+02iLmoFy4W3NSkl1ukg5nhNFGl50YItwlxaG2wJ6qdgp5YXSdr5bOG4LkqPgwotP4qLluMDcpzOXRo2and7Ekq2bLqSvpVMTaSzZ8s2JSib599N6n7PIAuZt7SLVePvS+q4Ji+nnBCo1luwCLb0oFIp/L4kZrP7mrLt8Wrlu2rF+ayKlmMaS8MoLVqJ4yJizNfMxd13ZdtoPK7aX+lvs632PqmClRhaloRx3Vr/qBFJzIoQoHohimppCMYrLcv8Mi/VNHNU2ZR/OsYW8lspq6Uo7putFa7GcTaiLyKTfN8vzpv3fC1qy6DCM06UyqJbzvRfV1cQd9rfVmbd9m5SpIqjSSpsviSmieNDSkGZoR/u+FOtSfAdtOS95sUmc73yavk/5Nl2aGydi0prwxF8zmmBlianYM55Xuy75drB6M0vZopyVuKINod8nTSm0ysJSqy8dBKq1OcePk7lr2dI1b+n6dwaoCPpTUk+fB/ikkRBCCCFkT1yJNY1XCt40EkIIIYTsCa5pJIQQQgghq/BJIyGEEEIIWUSpniaEEEIIIbtw/T5pNNuiBnU1YU0J6tVmUZU4d/Md1U9RxTunXC0UmZVGivZ1Ub0aVXSzlk5O/RhVYrtSU+Cuqeuqtn7BBsor1Hb9141XqxteTW0KxNq2aMOY41qw3ovKbU8jU2VlLa05RX20bfSqUWvzJYWir8+l9lhTdYqMdeMVqzWLLmC+rWp1VKiIFZCFul5Sx/o8kFT/Teg7c5aBQL0OYr9upFSgemVrkY/b3khS7TrLsb6f2lwWZXDt7O3HCqs3p2St2qmldHxbtC2gsW7b8H/U5zc7HxjSmLxJQsrzGtcXbFtU4MZyDIUZywuM827Nhm0Nb+UX68+/5SF2q8mbK5oyrqisjcrnuTdB1PpbtIeM49SrivvK9SrO11bHMQ1pxibOSvTQriZItuT7flTMN5Lyt3hSn1b35gK007caxPK2zZiWpWt2f77f+mOsXmJf9sS3l1icGhTmVXW5lG8GiMpsy9uyj/XXuNhie/q0am+TqMV00mveFaafvdm5+uCTRkIIIYSQvSBQ3jQSQgghhJAlFNfzz9OEEEIIIWRneNNICCGEEEJW4U2jYYtPvbXZHLZIN5+T7NTiotbawv9oAxUXncd4Jotkd7DaU7foPm9DKcroK3aFMY6+n7GOCmKVmLct/l2z7otMBEnNdDGwX9A+JwKJdRYXts8tOt9FwLEkiMkL/r2oIFikzZ0/sagKVlJztlb+uIl4y8VR0w/Uzo952fc5eyygUo9S/3sXCkHNzLm7jNFJms1UiODFUH7xPzDWy5KN5pxgZM0y0x87ZDpdMJ9FdwvlrFkz+pg3FXFav4uQpJu2adoMwIkMvBgnCv6SIKM2xmpCHQ31vkbNTq8mlJqzJ4w2dlYus3G1mKJFYewP0TbVC8TmhFtLFoP+e9OU9dptK3aTQbwY+3EWEXXTus7pdkPZ/TUnXkM62+7EXlY/EmKO9TMpuxeB6ZB47D/R8tBsPr0Y1drLKMa31vuwZ6l9YplqaeXxh3q/qlHYEkuYR3WMHSgFNucG4U0jIYQQQghZRgH0et5uZC8d3jQSQgghhOwJPmkkhBBCCCGr8KaREEIIIYSsINCJQcDVC28aCSGEEEL2gALor9snjaZ27ftSfWZKsqYtjy0s+kzlZGqzpExbst+Tpq5qrq0p9QrkfL6M/5+ztfPKQytHile1h4gCm80Yjy/Dkio7q+qcqivH1ZbpFMcHS785ZeScFd+cCrX3irnQTnPMqdE9UTVctXeqKFJzXCn/6Aq4iwI+7vdp+76zFHPEq/kLZfpKOyxZ/eW0gmrYq0azLVk3rdP8d2jbpkWW5y61oyn6rR3M5jDbJboYCmVzxXaz70e7PyuDV8lGtXG095LQr/13+7vD9K0KqlMlrB+vWJhLcl6uvEu2Y40Ax8fD31tdt7yrzVE5bbNP8wrQmTi9itfXj7cEtO81ta4vX5wLo9I4bvf7cp2Ec9p2bGNfb7W3BPj6mX17QuUNAjXr0nhMxM/HphjOeeiohDZalOMxjrlsN+rKmZW+Ll9TR/t8GimyGsqRNti821Ts/Jbe/ND3pYK+750qP4zFWCc1JvWVd0zfeDH3JoS+B9TmnkpeE5vPYG3pY48U6TWYnQ/9sc3CnH4O4M/ThBBCCCFkGb221NPXTkkIIYQQQs4Vw5rGXT6XlYvID4nI74vI20XkV0TkUW7fi0XkbhF5t4h8hdt+e9p2t4i8aJd8eNNICCGEELIHzHt6l89l8gYAf1lVPw/AHwB4MQCIyFMAPAfA5wC4HcBPikgrIi2AnwDwLABPAfB16dhFeNNICCGEELInrsSTRlX916qarPbwJgC3pL/vAPAaVb2oqn8M4G4AT0ufu1X1Pap6BOA16dhFLn1No1+821Qs08zaLC+InRF21AQO3l6o74Ht1u3bwTIrLwy3hcdBwOLz8PGExbQyZ0fkF6Cb1WBxYlMu0N3FhswvYi/y8vZhUuZdE3sUC9T9AuL1EMqF1EFg460UfV5FHv2Yj9VBr1ORS85jQVyyZnnnF6/PldNv71wf8vnE405K1SorWmg5gcmSACPv39FWy+c1Z+9YE/XU8ux1EDosWR/mMdPXjzFxTdPv1ueBsa3bdrpAf2InWlmUv2YZVrN8nKQh00X5fpy1ByGvFZFaLa44Z9gxcyIbf95EEFQRo1g57Jgo4ojCohomcMwWgc0owpg9R9fnuJxOEHfUiLZ8UcBTE9sZ0W7OttVsadumvC607lJoIhxvKeptD4uypf933dCHvR1qH8ayKrA5GNP326M40F9TRUoR2Fxb1ux1o4ViHEI1od3SfJgtAkPMa+fZMVkYtkN/zDE5i9SYb07Xfz9/opMdSmrcLCJvcd9frqovv4Qs/y6AX0h/PxHDTaRxT9oGAO8P25++ljCFMIQQQgghe+IETxHvV9Wnzu0UkTcCeHxl10tU9VfTMS8BsAXw6pPGuQu8aSSEEEII2QMKOTX1tKo+c2m/iHwjgK8E8KWq+THyvQBudYfdkrZhYfssXNNICCGEELInroQQRkRuB/DtAL5KVR90u+4E8BwRuSAiTwZwG4DfBvBmALeJyJNF5BCDWObOtXz4pJEQQgghZB/o7ku8L5N/DuACgDfIsK7zTar6zar6ThF5LYDfw/Cz9QtUhzezi8gLAbweg/LgFar6zrVMeNNICCGEELIH7JU7e89H9S8u7HspgJdWtt8F4K6T5HPym0ZTTxXq1XaqAKwpzQpV7IxFm1dRGlFJBpR2UxO1VDNVdg2BuUOc9VlOx8XUwqm1nM1aoXqbFnFiH9i2o5q0ceq+SFRze/XxEGipzPN55boJCusi/VB/NRvCwsKrW1emxrz8P6dSmVV7iF8EPGfb5ssUVeGxbbKCbqZMHt9esUxRZR+PrzFRDitmLaysPmysTFScOtpL9qEOgLoqH6inY+Q+ZnE6VeOSHZeds4sa2VuB+TRN1dkeLNfjxBquWbYBs/rz84w00zknpm0q441TP2+P6/FkxXCsq7RvbuxZutoDcrB8TNw2t6+m/myD9ajvs9IuK7mNqABusN7f201hrTrWszumDxZ30Vpzzd4RcG9nsHRMZVt59ULvFLhzStmohq4eY6rcprzGqKn5w7iqjQ0bCmZN2IS5bqJmlqG+8iWpNta76VsnvGq83QAHIT7tU3lcmWrj2dt+RrtHNOMbFCzuaLFo54mMbxWIdo/2vWpRuWIJOHl7g451ldOs1Guch84Zl/s6nfMEnzQSQgghhOyJXf5Nd7XAm0ZCCCGEkD2gEHTXkPc0bxoJIYQQQvYEnzQSQgghhJBVroQQ5kpx8pvGwsbK2fT5RcC1hc/Rym9OsFEIF9JC3WbOhw71BfC2WDZbT+1g4hMX4PoFwX7hf2HLNPPPhyQAAQBBSsdbqzWVxc8r/xRR7SEd3EL9ZowrLpheStMWE3sRyJK9mk+nWLheWWBdi7l2XKqHvL9X5BXlUYiwVC9e7BHjqp3vhSfV9HbJK7Ak4PDnxqS1H8pvjXcp/xTdpV/XbAlNSBTfA+Hrp2ZROZe2F4l4q7OcTj8d1+0OU4+15dzwb9v5sQmMtoY1slAtfc9CjhC/j7sLFpoxVt8Xei0FBblfO7FMV7FFrJXD59dWRAA5z2DnaNicvQlCHWnK6sk2jl7A4CwCta8cq4BULPGatj5v1PDXkiyeSQIzL6aJ/bYJVn+5XBLmyZl8vVhxMs9L+f+1+W5JQOb39TodDxZzzHtuv/aj+Kh2/bM0JpaB8bqTBC3+3Cy4svHr2tniiIKqtjLGgWGMe/tWL8IBBlGaHyMm/inEWuGcfP1Cec555sq9cueKwCeNhBBCCCF7QEH1NCGEEEII2QGuaSSEEEIIIat0fNJICCGEEEKWUAh/niaEEEIIIStc10IYbyFWKAX7ZEnlVaw73FnXVLuFrRFyflmNvDGLsn56vFdviZQKPx+TlcPnU42lL5XGZvXmVdkV1Zx6ZV1N6VhTUa+pc7ukNs7qzr5UNtbyq9nLdSjL7a31vIotKviydZ/Lp6uk786Tij2cdp0rv9QV1nPMLQyp2rUFxaePJZZ3LV1ppudcCr5e59ot9oU1az9L09IL6Q71a0pUjHnE/BuBdp1Tc8/028LSsynH2Zip62N9vX4LVaXWx59UYshjuR/6sh/bcbznuG17N61P7Ydxnc+p2HV226m61h9j270S1dut+hi8LZ9PP8YdVbF2TLRnM6rKcSuj2Vluy+OkYvU2+e7G/ZwdYB9kuqa8j5aq0WIvEucYoP6GhHiOn9ft79wmQa1cq7+o/PX90RTn/u0XtXMs3Q4Vm76Q9y4Wrb7sZp9pZeo6ZGn03Hwkrt94y9y2nfY3Xzexv9pxvh3seu/x9pG1a39+04ezw1x7m4VP2+Lz+eT4whsi1qwxzwCuaSSEEEIIIatc3+9pJIQQQgghqyiu55+nCSGEEELIzpzDX8wvGd40EkIIIYTsAVWgv17V08ObzZ1wwYsNoqBiV7HBEmkBr26Px20maCgWV1cWyPqF9WY91bbl92JBeljZe3SUwnbl7bcp7yTO6bpBZJDjmKJdBwkL67Oox4ta4mLx8F2kgWo/CEmAUbBg5THcc/BCkHM8bJe2LRbxa1pUbekbQ2y2mLxBzfJM3TZpKgv87VwfZ9dB0z+7BJVz5oQsccH3nKjEL6yuWb3F735RuRd5+HRbl3+tneasxnw+ZhuY2lxjepZmTUQ1axs3HVO5b8VYvLWlVMaiNOX2mbSlb6ZWg12ov2ibGOvIL1zX9b7vbSdzuFGsUkkvj91Jun25zcQS/pgorvCCOACI489b0uVy+3FpwoUo9hnnk0yH0A9cfHFc+GPm0vVjqhDthPPiHNr3g3ioRiGmqwjiitCG+slzVuznsQ18OoVlYFPuy/NyNx6bz3Nlr/WxMsDp9QJmIWuikWYqnlxrl7zfCWP6bioA8Zad2kOPh+tMHsOiw7kTW9cg6jJ7X2C03u27sn58jNmqEWWd+WMnc2w3te+sYWKZWC92WpgPi7wwHlNYzGZBV1cKL6OVYBxP5wAKYQghhBBCyCq8aSSEEEIIIatQCEMIIYQQQhYZlvVdp2saCSGEEELIjijQXa/qaUFYYB/cWsZVrsguFKNYoqs7f0TxQVw43MjgAmO74+JZv1DWp1l7HOwWAE8X4ZYL4XV7nAUbaDdjuj6rXqEYFuWOopbKvyjiQv7ksqC2eDevTR/jmYplhjw0lLV0iZFCnFLEk9LTDpCKg4g2peOFigLpX0fSBkGQL4svoyt7FuzEf2FJMza39gDaikNGpQxLz/drjii1RdUpf79N/SJ5FUjQV6j2QxlmFvuP4hC/QL4vhSfufC9UUcs/IWin+VQEP7HuC1FUOj7n07ZFLDnmtp3WVajniVtPr9AmuBJ5AVU39JVSdDPn5FERPcx8n/Q1mAgt1LvMjHufbsUJpxqbHSbN6JSRhQnBBUcG0VjuK3mbwws6fAxtOz2mGONhLNREfHEObAToXBtsmlHo4Z09vHCi6gKF+rgz8WGKZyKgC3PpJI2asEkrfX1GXDjGt9Av7LseF/uLOT+XJziKAKPYwosvfL9oomuQE4PNivjcNWJOvOccnjRtlw5DPzEhTBbjNPPOa1H84uIsxtOKZiTObar9GM9s3zExXEVgFq+zXkyJthQ85bKEc4sAk2BzRgx6HhieNO4/HxH5PgB3AOgBfBDAN6rqn4iIAPgxAM8G8GDa/tZ0znMBfGdK4vtV9ZVr+ezo30YIIYQQQk6K6m6fy+SHVPXzVPXzAbwOwHel7c8CcFv6PB/AywBARB4D4LsBPB3A0wB8t4g8ei0T3jQSQgghhOyJXnf7XA6q+lH39SaMz8XvAPAqHXgTgEeJyBMAfAWAN6jqh1X1IwDeAOD2tXy4ppEQQgghZB+czlPEnRCRlwL4BgAPAPjv0+YnAni/O+yetG1u+yJ80kgIIYQQsgcU6b3uO3wA3Cwib3Gf5/u0ROSNIvKOyucOAFDVl6jqrQBeDeCF+ygPnzQSQgghhOyJE3hP36+qT53bqarP3DGdVwO4C8OaxXsB3Or23ZK23QvgGWH7v11L+IQ2glq1xZtgyq8OhXWRSkUR1zlbM9vn1bNtC9x4OKbz8INTJa9XrqGukFPt11XKTnUKANI0o21hBWnbrL41VXNWwAbFWVUNGBYxFMrUoIId6qnJde9Vv1ll1zelisy3U62+gGWFYrZU01Gp6hWRFRXxxB7Pt3lWBi484A5qTCs7MG23QrG+prDOllkVS7EcczPEWzl3SQ08sdeLauWu/uYAkaZoi6iMz6roaIvn7cAkxOxsJ2v5xbiB1G9aLNZfVF8DGNXSHiu7t2AsbD/7aT5RJR4sSL1KevJ2gBxUUsDK2A6CtmLtGFSljZSqa2+FaOk667N0UDlH2Tg1OzwrZyjm5I0NluYui5miLasnvTXB2le7rlR7e9s1ny9Q5l2xjpso6CvnT6waozp6wVow76+90cJj1nuun+Q3NFi5a/lF8bl7c0Du/2gR1beqPXCsC9e6sh+V15GoGHbzTLwOVOYtOThEYflo53qrzKadWh/WLFBr82KcP1w8k7aeuz4svT1D+9Jit5Z3Lck4j+7K2tx/xugprFfcBRG5TVX/MH29A8Dvp7/vBPBCEXkNBtHLA6p6n4i8HsA/duKXLwfw4rV8+KSREEIIIWRP6JVZ1PgDIvLZGF658z4A35y234XhdTt3Y3jlzvNSTB9Or+l5czrue1X1w2uZ8KaREEIIIWRPXIl7RlX92pntCuAFM/teAeAVJ8mHN42EEEIIIXviBGsazz28aSSEEEII2QOn9OLuc8MJbxqlujDWLNHyItq2Iv5IQpNi0XLVDsstdtd+sLyrUIgl8t+jSKQqdrFtzvYv2qTlMm0OpoviJwVvIF1pVaVxnf7cCtiJdSKGOrJ116muvLBEm5lF6TnvbhJvru+ZxcV5oXevo61hOHeycBsAoj2giZ+88MlsIOPi9rjwOljX7WQhBoTF5xWRUaXMhW2VxTVjj2ixFQKVik1etgN0gp1a28XYJfaBaEUp5aLwWZFAiHuVysJx3R4PogbrD2ZbWUvXn2siqRUmgjO/yN/qzTq/LfDP6doBTRbe5PNj3uIs7oBSIODbw4sgfJlMGGNpdB2imkJ1qKucnrNkLNL1/bhtB/s1y8PyjH09zje1+WdmDvZCQN9nC6vLIM6Y9PeQ9kTk4v/v48lzxVTYY2l44YpIMwr4auOv19IeM20rxDJebOXTkdFeT+y4WMdNzY52SmHHCSe+CXNOYcvp68Xys/S6o2SXtzC/mW3tRBDo+qHo9Jgla063TfJ1MojmoqVvJd1aH5mcW4tDpuIx6Zv6vBgFjrW8grDOi2FXhbpnwHXrPU0IIYQQQnZHz7G6+6TwppEQQgghZA9cqVfuXCl400gIIYQQsieu4zWNhBBCCCFkV/pr6FEjbxoJIYQQQvaA4np+0mjWRpupylOimrZDoZbGQanAExkUflWlk6XVJQu2iw/PWyGl/BfVYnMqUF8GFxcAYOOqxnulqU5VbVHh6JWwXr0Z7ZsqFErvRkrhplfhmnqzaivn8vNK9lycdlIfhZo3qv7E6mhq4ZbV2eimqsmmmcbs0i9sz6JCs5bPyjFVOymv6jSS0k6dUj3jldwYVfx5W1d+z2PB25uluhzfFHA8tmPs783Y1ydEJXm025tVjVdUh6kv5KSjLWCtTn3/S+l61WtWs/oyReu0pKos7AabFuKOz2lUldAY6kz7QtUsVu+WtzRAty3P225TOZ3l25xqtVCsV6z+fFjpLQeF+tTsEv2YaTCmZYpef/VoMVrCwR3b+7cVNMN3O29J3ereXoE4nmO7BHZRwFfHn5XZ6hwNgG463zp7Qasrr1yf2I9qD+2waJsaFeB5jtB+nLObFkA31nEucDuK7DW8aUGa0VowXw8OyjrN7Waq3ZRe35VtJOLata8qqnM/sPJvj6cKemCM0dd3fp2A9Q8bd82Qn7pxn/elr/EcO8/nqT2wDXHHtoqqaz/ei/EQ5lnfB4B5i1DP5A0r62/ZOHNU0fFJIyGEEEIIWeMkb0Q77/CmkRBCCCFkDww/T/NJIyGEEEIIWUJpI0gIIYQQQnbgun3SKCKDvV5159TuWMovMQAAHDRJREFUqhAvVBbzim23hbhJZJIFBDIIb4oFstIMQg5UbIPiYm+XZ7SMmiy+j5ZzXvASF1EbLi5N/5TI64GjMKZmB5a+Z2uqFqOAJtnVRVs+UWdJ1feQdnkBe15A7hbLF4vU46J2X4hC4FBp21p+SYwgTTMKlLxQB8hrx7MQxVnwxYX+VSvDBQpbtIoN2eL3bJFYsR+08qu1lbMVqwgEouXj2MZu8X/Fcm0xvhSj9WUTBCxa/TUy7E/CguGEeUFRYfdXocjL2jYLitrBVlArgiQ/hppmXLjfpnaq9TUvIIA7BygX7wNDm9mYjdagNs76HoJNvS/NzWttOwTp+/+mSeI/EwS4eGN/zeKPVMauc0KCJNho3TSsfSnEkQaAF0XUxkGym3TzqGwOyjq1fIN15aLl2oywTPW4atlnaUYr0DgHqSYBhLeJDBao2vfD1yyKTNcBkaENU3zFPOTb1Ys8vLjJt6PfJq3rk+0YSxB45L5uYqUoYvJ9VHugdf1KdbTc9XNTYX3ZQS8+PGw+PESBzyteT/rUb3x71spQE3F6aiLNpi3rEyldf72I/VJCv7Ixv2CRWb2mRIvZWI45MeA5QnHuQros+KSREEIIIWQfKNB3185dI28aCSGEEEL2BF/uTQghhBBCFlHV63dNIyGEEEII2R2+p5EQQgghhKzSX69PGlUVuj2eqrqAUgHWjcrm8eRgcSdSWvUV+fT5HFPMmXpLgoXhoNA2KzGnfvMqORlUndk+zhTa4tRmwcFIt8dZ0SeHzlIJGK2MtK8qvtTsm3K9VNy/khp6SG84XuFcoZINY1RYZyW5zCt9C5Jq0au79biHJMVmVvAuqZOlGQJaWJchbTvUmY42T7mtnCKyUBdmRbKW9eRVx6mOteucLV/FAtHUvoW9pLMHM6uyXsu6cP3EK9Mt3qwCh2urJqgRO2Ci/NQmq8O178cxkdsvWSx6tXlgomQOtmmz7dF1Oe9CBR0Vh1XVdapjVNS2czZfWW2/cUr4OKDceIjpmMLVbADNrnI7HW/jKZW+YP24T3VqCvfc3k15nOFVz8AQh1fS1ogWn5pexpaTacu3FqipeKVuGRnJiuxc4EoMvs+0Zb22TpHe66D43h6HdMKbK4BJn1D3ZgMxO0e4vqle+TvkZRaxtbdLDEVpCus87bpRLR1faOfnva4DNptxzGAz2jfmxIOq2BS729BPgKn6N9ul9hgV69YHnV2gr68QZ7b+THVUtJq3S1x4M4fNk2JxbmSan/ajTSAwjqFYxtpbOwoFOZYV1NIUzTueHxTTZlto2FxQbGtd3++KuspZ+2tqr9O3U6xd77pufLPKOYI/TxNCCCGEkEVUgY7qaUIIIYQQsoZeQ+rp5TdDE0IIIYSQS0JV0e/4OQ1E5B+JiIrIzem7iMiPi8jdIvJ2EfkCd+xzReQP0+e5u6TPJ42EEEIIIXviSj1pFJFbAXw5gP/iNj8LwG3p83QALwPwdBF5DIDvBvBUDMY1vyMid6rqR5byOJmNYCODCMaLWeaObdthkW/vFv77c+LC2URe8AxAj4+HjZXF6BPrQJ+22UDZwnotFz6Ltx6yGOKCcGC06XMCmkm8ceF4100XKDfNKOjBsCC/EEfoIM4QEagXhHRuYXi0VvN5OkFJdG9ygZbxZVFAWijdN05IhGnbJnuwQoAQBAXau4XPqtBk+eXjK8ri66gQLfSjVRgGUYZ226ndmvUp7QfLyWBR5RfxD/mWx+Q2sLpJbVXt1+FfgaW1pZSL+HN7jtZiuk3Hb0YRjk/XhAC1xexmF5j7rW13wgYTeWTRhyXfYrLYPLe3rwdLw4uWQjgTkYKJ0+LifmA6ZvMxmNIepJi6XO6JwCWIciZCHf+3FwxpXxUZ5TENJ8woYjIlkVmmhTR6Lfux9kNiNaHXmGm53QnAchlqTPIOc0IeF0EAsHShmpl/l6w2FV0hUhhC3hZWhIWI0ebvGL8JHN13wM1N6Zyiv9ViTdaY0oTL2OZg7Avb42m5GhmEdVlgloQd+ZoSBHvp/ELYEi365trO9WWRprTWzeXwFov9KKoyTFRSy8tfT/181/fDeVF45UV9qqM4y+ooimLaFtl21I5pXPoWT00wA4xjOpe1HNfqbTXt2hL7cRRUdV1uq6E4Yd46h6KTK/jz9D8F8O0AftVtuwPAq3RQ47xJRB4lIk8A8AwAb1DVDwOAiLwBwO0Afn4pAz5pJIQQQgjZB3oi7+mbReQt7vvLVfXlu5woIncAuFdV/7OUDz6eCOD97vs9advc9kV400gIIYQQsgcUir5beVXQyP2q+tS5nSLyRgCPr+x6CYDvwPDT9F7hTSMhhBBCyD7Q0/OeVtVn1raLyOcCeDIAe8p4C4C3isjTANwL4FZ3+C1p270YfqL22//tWgxUTxNCCCGE7Anzn177XEb6v6uqn6aqT1LVJ2H4qfkLVPUDAO4E8A1JRf1FAB5Q1fsAvB7Al4vIo0Xk0RieUr5+LS8+aSSEEEII2QOKM39P410Ang3gbgAPAngeAKjqh0Xk+wC8OR33vSaKWeJkNoJdj/4Tn0Bz4yMGxZWX6gYFmKAtVUymsLJtTiVdqLe6LqvutOsgBwfZ8g5IilHtIZuDMa/ttkwnCeZMuaUV+zPpG6gej9+DakzadrDG6zpn4bctj/GKVV+uotKSfaEpcy2emsorKLd3VoE5VbIOhSm3T5TQFSs9dSo2q19THibLO/SalbywevFpOyVyzifUGfp+0h7SOgu0pOpUH3uqQ/XHDBnmNDO2T/qJmDTXiaufoS1Gdb2oOuWsjKpmr3iNbdO2pdIzWjxa7JY+Kn3SYpF+Ymdo5VDRQVGf6lSPj9NbCpzS1Kmxh1AGZWG2RMz59WXM4bzxjQFBDexVt3bO8XbMy+zYotK9UHBKqai19jdLtQZlO/RJWd20TvU/8zYBP46PL0J7He0E09xRjK1+eAtAVgA3MuST5pdCnWrUbFKjNZ2Vyyte7Zg2KL7z/OfyqFq3Odx8m+PzKtTtcXm8qX2tOftuolIXe+NATW0PDH0P3URFr912olDX4+OxX2zacRwjKdaL89049u0y9yaD4ryxY0nbpjc/uDptW0yk8dJAmm3Zl7yVZOvbYbw2SUWhn6ncFNhbBYprS7bydP13ezyen/qi+nI3AjSHZR+M/cHGpamVfd8zO9fcl931tmb164n9wdsXFnO7aztnczrO2eObEeyYPA5r87eP1/eJ9CaK/HYIyzvHp/N2p2eFXvmbxvS00f5WAC+YOe4VAF5xkrT5pJEQQgghZC+c3ou7zwO8aSSEEEII2QMKnEQ9fe7hTSMhhBBCyD44RfX0eYA3jYQQQgghe+KMhTCnyiXdNHYf/1hadBwWGHtbvNoC5rCYfGJLhiAQ6Lq00H+0TusffnhI6uAgH9Zvy4XpkhZQjwusKw3WyLBQ284J9k5yeIjm8MKwoPvoqJ7Oxlnfma2WCR7iguJGxvqpLZrvFYoe4i2Tum5cYO4EIfm75eet6KKYBmmBeLRHTOIh9fFvnB1YezQVG7j20uNtYSsIoPzeCCQuZE55+TY2sVGuv2BPWCzOtwXWsd+5dpGwLy70B9LCfB9LXpwthT3cKKDYjjaA6fzR3lEx6eltW4h5+uPjoS0xCn4K6z73HRi1CrV90jQ5FhNpSduOx25T/8vfx8XqOjdeh8oZ8u29pZtrN3V1EtpKUjyyTcIcaSDtdnJuri8b00OBRlFcFBeYgMFENVH0YjZpKV0k20BXWcM4T6IQPTrK9ZNj67pi7EvTAJsNGqu3zWbIp22LBf7DyRVRg7dxaxqgD4KUKGCJlolwfR6YzJNFn5gIwxzxPJsDpCx7tNeTpqnml/M0O70wv+U+m8ZGHNPF8b2zGEx1kK0fU5msTSb9Osx3Q/sd5bzRtoOIz8/lUZBkf1v9uXFk9QATdXlNhRcbBUvPSV/w5xhJiFUIRDTUBQC54QaINOgfenD4vj0e7HuzOKvS3lkEmtIKQr2MF8tY31sRjkwEcwvXBZ+3brvCQrE8pJznLR5fFpvXehPGHo9zSk4tXSNLy8nzdoN2ea/TOW/wSSMhhBBCyB4Y/p3INY2EEEIIIWQFrmkkhBBCCCHL6Im8p889vGkkhBBCCNkD58AR5lThTSMhhBBCyJ7o9Tp90tgfHeHB996D5nA4ze6exZRv8W56SUnm97vt0khWsUnToLl4BGk/ntVH3UMPT1Sduu2qd/JRoSpBndlvu3Jf06CxvDctmoPNoFB15dReczrSttV8ZdNOtk2OERlVvNsOqlpsG+If8zIbsOq/WGYs1QZlYbBsM3Wstx4MCsD+KFj/AUAjaDZjeU3N2PiySjPG2zRoDsp+UihzkerPWytaupVyeoW6bNrcFn5fWXelbZ71q6JOzXrL+oApiO17UsyqVzvadodspYg39rPuoYvoj4/RHByUlmlNU4wd7bqJSjvXyXBQqZxM32XTjjF5C0ZLJylmc/1IWec5ZhnVobrtir7v8/LothvVjbU68kprhD6NQVXZW38I9ebnAd/+Ga+uDWPd0tNeR7V5UvE2Fw5zOfqLR9C+R5+UmbrtpnHMjOc4/xXnpDr2ZctlnbNABIC+H9rTn+/6qC/XJE+vCndvAfDzWlSO+3Satp2UNfeLIdFJvnEszCGNQNIbL9SsYmWce/ObClzf9WkXc5mbR7qLR1Nb0tCnJm+yCPRp3FnZ/fxu/aLxiv9cpqDazQk61Xjb5jnS5tWolvdlbS8c5uvd8Z9/dDjP3k5QuY6pmxOHg/tyeyPz192UttW5iIzXoXgtCeUUN3dlavnMXHv9Wzaa/DaLwd7WvluddBcHdXx/8Sj35ebCYS63+Del1OI4a87ARnCf8EkjIYQQQsgeUChvGgkhhBBCyDp8TyMhhBBCCFlGgW67/AL1qwneNBJCCCGE7AHF1PXpauZEN43aK44/8RAu/skn0B1tsb2YFglv2iQqGa24tO/Rb/vi3GHfcEx7uEF70OTjjfZwg82NF4p0P/HBB/KxNzz6kei3XV6g3B1tBzspt2agOzartjFPaRo0bVzIXAo5ms24aLk7OkZ3tEV7uMHBTTfm/V5g0Wwa9NsezabJi3abzbCYPIsX0oLh/miby54tEJ111iAsGcUjtUXWhYWcs2eq/V2c57abaEjdYvLhu6I7GgQN24cuojvaFiKDZtOiPdwUtobSCDY3jAuSG7dwPQqLDHWL6f0i9d4JYbxYwGKL9e7pt33R/4Ztg8ipPbT6nC62t4X/ud/WrB9DvfddV6SV93uhhrcXA7B96GH0x1vIpsXBJz2iOC/XSxJj9EfHxcJ0H68t1vfbRYY+bH0q16/vO6kPehvFibAkLmrvFf3xcV6En/M6PCgX4m87PPShYcH+Qx/+OLYPHxdt0R0P8fS5/oa/u6Mxvu64T+2RzjnqCsFMd9yju9ij2UShjBRjeuiPG7SHJvRRSCs4vGmYTw5vOsRNj30kLjz6kWjTQvruoYexffgYD3/kYwCAix+7iOOHjnHxow+n70c4frCDHivkINX7saJ7qM/fDx7Zot9qcUx7oUF70CyKBZuDFhceeViKofoeBzcelPNSKGNVhODy2FzYoO80n2dj1/4e8ioFE7avOdgUx0RBRKTZNFUBhLe2tNhMvNBfPBoELCnvzY0XClFYPsfZO9p870VA3cUjbB+86K4Fxzj6xBH6bYftw2kuu7iF9pqvVdqN5e3d3zUhW3fcoz8eBTXtYZvP6Y+7IpZhThja3Pqzdn3eZmxu2EAawcGNw3jdXNhgc8MBLjzyBgDAhU+5CR+950N4+IGH8nkPf/QiHrz/QTz0gUEQ0j3U5f5mtDc2EJdPsxHIgaC9sSnGTXvYoDlI16pWijq3cSPNGHNTE0alc4u5tRFsLpTXLn89rYncbL8Ja4FSiGZz2vahiwCAo489OLTDhUNsHpHuEdryeuuFNOcGCmEIIYQQQsgu8KaREEIIIYSsoNfvexoJIYQQQshuKH+eJoQQQgghq+j4gvZrAd40EkIIIYTshetYPf1f9NPxD7bfj+3hFpubNmgPRjWqKToBoO/6QeXUevVcqbA7vniMrpuqnLvjDkcfGdRSXddhc7DBY570qTi+OKjhPnr/A4P6LCnxmkeMqrvG21I1UqhMTYXr2R5vi5du9n0PvZgUfQcbHD7yEMcXj/HwRx7K8UQLL2lkUOuZDVlScnsFov8OANuLRxMrNVNm965OonqxUBC37axS2uOV1UBSSHolrVNjtkkRfHjDBTQ3NLk+gcE7szvu0F0c1dvaK7YfHsrdb7vcnp4uWczVYvTxz8VXU8LFf7U1mxZt2xbrRtpkGbg1i7teJ3XRdV2y0aoPaG9T6OsdGNXefr9Xwfr2PbhwiPbgAN3xMY6SEtDOy+U3e6xU/lp9Wd+zerbjOlOcu+NrVmNzVn61MgNAe7BB6+q/T33S59W0LW561CMBADc9/pNwcHiA1qnbJansbS5o2gZt26BtTZkuk1jatoGbTnCwab3D4RCLahi7ClWg63psk3q1bYf6eugTg+r04sPHeOD+B/Dwex7M/WJzcICDC4e48ZMHVfsNj78BB4cb3JgU1xdu2ODgsE1ppTI1wGbToEtK2uPjweLOH9P1PbpOEdXTnq7rcfTwFl1n/VLQNILji+M2VUU/sdTUNKeV/daO67tSGd11HfquL+Y3o3jjwMMd+o/3uX9F21Sf5vi9n/S9Ie6+iFv7Hl2aI9uDDQ4uHOYxdfTQw5M+GvOavJkBQLtpcXjDDWjTGyfaTYvDTzvE5qDFwYVBeXtwOKiVN07FO9P1J/XStuMbN0w1Pb5pYfjZ0fqpdcXtcZf7utVfn3b22x7bbZ/66FBnxxe3OD46xsUHh3nhoT95EJ/2pMfhxpsu4MGPDQr+Gx5xiEc88gJuumm45rVJ9dw2MtrrdlrEYf2n68px0nWa8x7mknF/n9tA85tPuq6fjLOmEfS95vbsU38cr4GarotjX/JKbwDQoz7vt2uEzVu+3wLI1/oLj7hheHPBg1sc3fdwzrvfdvk60TTi3on40zgPKDAZw/tARL4HwN8D8Gdp03eo6l1p34sBfBOADsA/VNXXp+23A/gxAC2An1LVH1jLh08aCSGEEEL2gU69u/fIP1XVH/YbROQpAJ4D4HMAfDqAN4rIZ6XdPwHgywDcA+DNInKnqv7eUga8aSSEEEII2Qtn7j19B4DXqOpFAH8sIncDeFrad7eqvgcAROQ16djFm8blN7cSQgghhJBLRrXf6QPgZhF5i/s8/4RZvVBE3i4irxCRR6dtTwTwfnfMPWnb3PZF+KSREEIIIWQPDGtEd1ZP36+qT53bKSJvBPD4yq6XAHgZgO/DsIzy+wD8EwB/92TRrnOim8Y//+A7Pv7LP/6Z7z7tIK5TbgZw/1kHcY3AujxdWJ+nB+vy9GBdni7Xen1+xlkHAACfeOAPXv8fX/eMm3c8fLE9VPWZuyQiIv8ngNelr/cCuNXtviVtw8L2WU76pPHdS3fBZHdE5C2sy9OBdXm6sD5PD9bl6cG6PF1Yn1cGVb39SuQjIk9Q1fvS178B4B3p7zsB/JyI/AgGIcxtAH4bgAC4TUSejOFm8TkAvn4tH/48TQghhBBydfODIvL5GH6efi+Avw8AqvpOEXktBoHLFsALVLUDABF5IYDXY3jlzitU9Z1rmfCmkRBCCCHkKkZV/87CvpcCeGll+10A7jpJPidVT7/8hMeTeViXpwfr8nRhfZ4erMvTg3V5urA+yYkR/7Z3QgghhBBCavA9jYQQQgghZBXeNBJCCCGEkFV2umkUkdtF5N0icreIvGjfQV0rpLeyf1BE3jGz/xki8oCIvC19vutKx3g1IyI3iMhvi8h/FpF3isj/etYxXU2ISCsi/0lEXlfZ940i8meub/5PZxHj1YyIPEpEfklEfl9E3iUiX3zWMZ13ROSzXZ97m4h8VES+NRzDefMyEJFvEZF3pDnzW9fPIGRkVT0tIi0uwdSaAAB+BsA/B/CqhWP+vap+5ZUJ55rjIoAvUdWPi8gBgP8gIr+mqm8668CuEr4FwLsAfPLM/l9Q1RdewXiuNX4MwK+r6t8UkUMAjzjrgM47qvpuAJ8P5GvPvQB+pXIo581LQET+MoC/h8F7+AjAr4vI61T17rONjFwt7PKk8WlIptaqegTATK3JCqr6mwA+fNZxXKvowMfT14P0obJrB0TkFgB/HcBPnXUs1yIi8ikA/hqAnwYAVT1S1T8/26iuOr4UwB+p6vvOOpBriL8E4LdU9UFV3QL4dwC+5oxjIlcRu9w0XpKpNdmZL04/r/6aiHzOWQdztZF+Yn0bgA8CeIOq/tZZx3SV8KMAvh1Av3DM14rI29NPrLcuHEemPBnAnwH4F2kJwE+JyE1nHdRVxnMA/PzMPs6bl8Y7APx3IvKpIvIIAM9GaSVHyCIUwpwtbwXwGar6XwH4ZwD+rzOO56pDVTtV/XwMvplPSz+/kAVE5CsBfFBVf2fhsP8bwJNU9fMAvAHAK69IcNcOGwBfAOBlqvpXAHwCANeD70j6Of+rAPxiZTfnzUtEVd8F4H8D8K8B/DqAtwHozjQoclWxy03jktk1uQxU9aP282p6M/uBiOxqbE4c6ae/fwPgivh8XuX8VQBfJSLvxbDc5EtE5Gf9Aar6IVW9mL7+FIAvvLIhXvXcA+Ae9+T7lzDcRJLdeBaAt6rqn8YdnDcvD1X9aVX9QlX9awA+AuAPzjomcvWwy03jm5FMrdO//p6DwQCbXCYi8ngRkfT30zC0x4fONqqrBxF5rIg8Kv19Iwax1u+fbVTnH1V9sareoqpPwjCe/19V/R/9MSLyBPf1qzAIZsiOqOoHALxfRD47bfpSDN6vZDe+DjM/TXPevDxE5NPS//8ChvWMP3e2EZGriVX1tKpuL8XUmgAi8vMAngHgZhG5B8B3YxBrQFX/dwB/E8D/LCJbAA8BeI7SouckPAHAK5PKsgHwWlWdvD6G7IaIfC+At6jqnQD+oYh8FQaD+w8D+MazjO0q5R8AeHX6x/Z7ADzvjOO5KkhrP78MwN93274Z4Lx5SvyyiHwqgGMAL6BAi5wE2ggSQgghhJBVKIQhhBBCCCGr8KaREEIIIYSswptGQgghhBCyCm8aCSGEEELIKrxpJIQQQgghq/CmkRByaiR7srelzwdE5N7098dF5CfPOj5CCCGXDl+5QwjZCyLyPQA+rqo/fNaxEEIIuXz4pJEQsndE5Bki8rr09/eIyCtF5N+LyPtE5GtE5AdF5HdF5NdF5CAd94Ui8u9E5HdE5PXBpYYQQsgVhjeNhJCz4DMB/P/t3SFOBEEUBND6IRwBj0MACrVILHavhEDjUdwBEgRXgGwQnIAzwCb7EbMCVGPIkOx7clSpSaU76brINFF4l+Spu08zLXxcbovjTZJld58luU1yNVdYAH4xIwjwB+67e11Vq0zzpA/b76skh0mOkpwkedzODO8leZ8hJwBbSiMwh48k6e5NVa2/bQdvMv2XKslrdy/mCgjAT66ngf/oLclBVS2SpKr2q+p45kwAO01pBP6d7v5MskxyXVUvSZ6TnM+bCmC3eXIHAIAhJ40AAAwpjQAADCmNAAAMKY0AAAwpjQAADCmNAAAMKY0AAAx9AbpR2CqiHhztAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['32' '29']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['3' '8']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 40, 431)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_features.shape[1]*train_features.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 40, 431, 1) (61, 2)\n",
      "(11, 40, 431, 1) (11, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 430, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 215, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 215, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 214, 16)       2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 107, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 107, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 106, 8)         520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 53, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 53, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 52, 4)          132       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 26, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 26, 4)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 2,886\n",
      "Trainable params: 2,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "11/11 [==============================] - 1s 91ms/sample - loss: 3.8440 - accuracy: 0.2727\n",
      "Pre-training accuracy: 27.2727%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48 samples, validate on 13 samples\n",
      "Epoch 1/500\n",
      "10/48 [=====>........................] - ETA: 2s - loss: 28.5216 - accuracy: 0.5000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46154, saving model to models/CNN2_dataset_1_no_augment_10_01.h5\n",
      "48/48 [==============================] - 1s 18ms/sample - loss: 19.1316 - accuracy: 0.5208 - val_loss: 0.8497 - val_accuracy: 0.4615\n",
      "Epoch 2/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 13.6613 - accuracy: 0.5000\n",
      "Epoch 00002: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 9.5762 - accuracy: 0.5000 - val_loss: 0.7018 - val_accuracy: 0.4615\n",
      "Epoch 3/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 8.0945 - accuracy: 0.3000\n",
      "Epoch 00003: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 3.8885 - accuracy: 0.5000 - val_loss: 0.7147 - val_accuracy: 0.4615\n",
      "Epoch 4/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 2.0330 - accuracy: 0.5000\n",
      "Epoch 00004: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.9117 - accuracy: 0.5208 - val_loss: 0.7486 - val_accuracy: 0.4615\n",
      "Epoch 5/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 3.2884 - accuracy: 0.3000\n",
      "Epoch 00005: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 2.1659 - accuracy: 0.4167 - val_loss: 0.7740 - val_accuracy: 0.4615\n",
      "Epoch 6/500\n",
      "40/48 [========================>.....] - ETA: 0s - loss: 1.9983 - accuracy: 0.5500\n",
      "Epoch 00006: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 2.0744 - accuracy: 0.4792 - val_loss: 0.7665 - val_accuracy: 0.4615\n",
      "Epoch 7/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.1702 - accuracy: 0.6000\n",
      "Epoch 00007: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 1.2578 - accuracy: 0.6042 - val_loss: 0.7419 - val_accuracy: 0.4615\n",
      "Epoch 8/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9424 - accuracy: 0.5000\n",
      "Epoch 00008: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.5860 - accuracy: 0.4167 - val_loss: 0.7129 - val_accuracy: 0.4615\n",
      "Epoch 9/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9083 - accuracy: 0.7000\n",
      "Epoch 00009: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.0644 - accuracy: 0.5208 - val_loss: 0.6987 - val_accuracy: 0.4615\n",
      "Epoch 10/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.1896 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.1409 - accuracy: 0.5625 - val_loss: 0.6949 - val_accuracy: 0.4615\n",
      "Epoch 11/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8624 - accuracy: 0.5000\n",
      "Epoch 00011: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.2291 - accuracy: 0.5208 - val_loss: 0.6953 - val_accuracy: 0.4615\n",
      "Epoch 12/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4782 - accuracy: 0.7000\n",
      "Epoch 00012: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.1455 - accuracy: 0.5000 - val_loss: 0.6966 - val_accuracy: 0.4615\n",
      "Epoch 13/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.5813 - accuracy: 0.4000\n",
      "Epoch 00013: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.2638 - accuracy: 0.5208 - val_loss: 0.6972 - val_accuracy: 0.4615\n",
      "Epoch 14/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.4765 - accuracy: 0.6000\n",
      "Epoch 00014: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.1800 - accuracy: 0.4583 - val_loss: 0.6981 - val_accuracy: 0.4615\n",
      "Epoch 15/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.3249 - accuracy: 0.4000\n",
      "Epoch 00015: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.1597 - accuracy: 0.5000 - val_loss: 0.6987 - val_accuracy: 0.4615\n",
      "Epoch 16/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.1477 - accuracy: 0.5000\n",
      "Epoch 00016: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.1284 - accuracy: 0.5417 - val_loss: 0.6989 - val_accuracy: 0.4615\n",
      "Epoch 17/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.4071 - accuracy: 0.4000\n",
      "Epoch 00017: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.9956 - accuracy: 0.4583 - val_loss: 0.6992 - val_accuracy: 0.4615\n",
      "Epoch 18/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.5916 - accuracy: 0.3000\n",
      "Epoch 00018: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.1834 - accuracy: 0.4375 - val_loss: 0.6992 - val_accuracy: 0.4615\n",
      "Epoch 19/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0888 - accuracy: 0.5000\n",
      "Epoch 00019: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8262 - accuracy: 0.6042 - val_loss: 0.6991 - val_accuracy: 0.4615\n",
      "Epoch 20/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8422 - accuracy: 0.6000\n",
      "Epoch 00020: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7413 - accuracy: 0.6458 - val_loss: 0.6993 - val_accuracy: 0.4615\n",
      "Epoch 21/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.1597 - accuracy: 0.6000\n",
      "Epoch 00021: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.8835 - accuracy: 0.4792 - val_loss: 0.6991 - val_accuracy: 0.4615\n",
      "Epoch 22/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5290 - accuracy: 0.8000\n",
      "Epoch 00022: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8563 - accuracy: 0.5208 - val_loss: 0.6988 - val_accuracy: 0.4615\n",
      "Epoch 23/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9432 - accuracy: 0.4000\n",
      "Epoch 00023: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.9781 - accuracy: 0.4375 - val_loss: 0.6986 - val_accuracy: 0.4615\n",
      "Epoch 24/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.1341 - accuracy: 0.4000\n",
      "Epoch 00024: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8729 - accuracy: 0.4583 - val_loss: 0.6983 - val_accuracy: 0.4615\n",
      "Epoch 25/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5569 - accuracy: 0.7000\n",
      "Epoch 00025: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8554 - accuracy: 0.5417 - val_loss: 0.6982 - val_accuracy: 0.4615\n",
      "Epoch 26/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.1096 - accuracy: 0.2000\n",
      "Epoch 00026: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.9180 - accuracy: 0.5000 - val_loss: 0.6979 - val_accuracy: 0.4615\n",
      "Epoch 27/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0129 - accuracy: 0.4000\n",
      "Epoch 00027: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.9390 - accuracy: 0.4792 - val_loss: 0.6974 - val_accuracy: 0.4615\n",
      "Epoch 28/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.4596 - accuracy: 0.3000\n",
      "Epoch 00028: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.9269 - accuracy: 0.4583 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 29/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8188 - accuracy: 0.5000\n",
      "Epoch 00029: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8100 - accuracy: 0.5417 - val_loss: 0.6981 - val_accuracy: 0.4615\n",
      "Epoch 30/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5966 - accuracy: 0.6000\n",
      "Epoch 00030: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7852 - accuracy: 0.4167 - val_loss: 0.6982 - val_accuracy: 0.4615\n",
      "Epoch 31/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7724 - accuracy: 0.6000\n",
      "Epoch 00031: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7325 - accuracy: 0.5625 - val_loss: 0.6983 - val_accuracy: 0.4615\n",
      "Epoch 32/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7472 - accuracy: 0.6000\n",
      "Epoch 00032: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7329 - accuracy: 0.5417 - val_loss: 0.6984 - val_accuracy: 0.4615\n",
      "Epoch 33/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5710 - accuracy: 0.6000\n",
      "Epoch 00033: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7886 - accuracy: 0.4792 - val_loss: 0.6985 - val_accuracy: 0.4615\n",
      "Epoch 34/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8696 - accuracy: 0.4000\n",
      "Epoch 00034: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7764 - accuracy: 0.5208 - val_loss: 0.6986 - val_accuracy: 0.4615\n",
      "Epoch 35/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6942 - accuracy: 0.6000\n",
      "Epoch 00035: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8103 - accuracy: 0.5417 - val_loss: 0.6990 - val_accuracy: 0.4615\n",
      "Epoch 36/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8870 - accuracy: 0.5000\n",
      "Epoch 00036: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7023 - accuracy: 0.5833 - val_loss: 0.6988 - val_accuracy: 0.4615\n",
      "Epoch 37/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8730 - accuracy: 0.5000\n",
      "Epoch 00037: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8327 - accuracy: 0.5208 - val_loss: 0.6990 - val_accuracy: 0.4615\n",
      "Epoch 38/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6923 - accuracy: 0.6000\n",
      "Epoch 00038: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7510 - accuracy: 0.5000 - val_loss: 0.6988 - val_accuracy: 0.4615\n",
      "Epoch 39/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8908 - accuracy: 0.1000\n",
      "Epoch 00039: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7983 - accuracy: 0.4583 - val_loss: 0.6986 - val_accuracy: 0.4615\n",
      "Epoch 40/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6438 - accuracy: 0.6000\n",
      "Epoch 00040: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6994 - accuracy: 0.6250 - val_loss: 0.6987 - val_accuracy: 0.4615\n",
      "Epoch 41/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6820 - accuracy: 0.7000\n",
      "Epoch 00041: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7503 - accuracy: 0.5000 - val_loss: 0.6989 - val_accuracy: 0.4615\n",
      "Epoch 42/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7580 - accuracy: 0.4000\n",
      "Epoch 00042: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7160 - accuracy: 0.5208 - val_loss: 0.6991 - val_accuracy: 0.4615\n",
      "Epoch 43/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6792 - accuracy: 0.6000\n",
      "Epoch 00043: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8074 - accuracy: 0.4792 - val_loss: 0.6993 - val_accuracy: 0.4615\n",
      "Epoch 44/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6924 - accuracy: 0.6000\n",
      "Epoch 00044: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7734 - accuracy: 0.4375 - val_loss: 0.6994 - val_accuracy: 0.4615\n",
      "Epoch 45/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8953 - accuracy: 0.3000\n",
      "Epoch 00045: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6945 - accuracy: 0.5833 - val_loss: 0.6995 - val_accuracy: 0.4615\n",
      "Epoch 46/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5960 - accuracy: 0.7000\n",
      "Epoch 00046: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7094 - accuracy: 0.5000 - val_loss: 0.6997 - val_accuracy: 0.4615\n",
      "Epoch 47/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6606 - accuracy: 0.5000\n",
      "Epoch 00047: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7054 - accuracy: 0.5208 - val_loss: 0.6997 - val_accuracy: 0.4615\n",
      "Epoch 48/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8730 - accuracy: 0.6000\n",
      "Epoch 00048: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7569 - accuracy: 0.5000 - val_loss: 0.6995 - val_accuracy: 0.4615\n",
      "Epoch 49/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6150 - accuracy: 0.6000\n",
      "Epoch 00049: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7703 - accuracy: 0.4375 - val_loss: 0.6990 - val_accuracy: 0.4615\n",
      "Epoch 50/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6724 - accuracy: 0.7000\n",
      "Epoch 00050: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8193 - accuracy: 0.4583 - val_loss: 0.6986 - val_accuracy: 0.4615\n",
      "Epoch 51/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6170 - accuracy: 0.7000\n",
      "Epoch 00051: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7638 - accuracy: 0.5208 - val_loss: 0.6983 - val_accuracy: 0.4615\n",
      "Epoch 52/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8493 - accuracy: 0.3000\n",
      "Epoch 00052: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7879 - accuracy: 0.4375 - val_loss: 0.6981 - val_accuracy: 0.4615\n",
      "Epoch 53/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6219 - accuracy: 0.8000\n",
      "Epoch 00053: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7106 - accuracy: 0.6250 - val_loss: 0.6979 - val_accuracy: 0.4615\n",
      "Epoch 54/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6218 - accuracy: 0.7000\n",
      "Epoch 00054: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6526 - accuracy: 0.5833 - val_loss: 0.6976 - val_accuracy: 0.4615\n",
      "Epoch 55/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6429 - accuracy: 0.6000\n",
      "Epoch 00055: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7076 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.4615\n",
      "Epoch 56/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7249 - accuracy: 0.6000\n",
      "Epoch 00056: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6816 - accuracy: 0.6250 - val_loss: 0.6975 - val_accuracy: 0.4615\n",
      "Epoch 57/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6116 - accuracy: 0.6000\n",
      "Epoch 00057: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8020 - accuracy: 0.3958 - val_loss: 0.6975 - val_accuracy: 0.4615\n",
      "Epoch 58/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7822 - accuracy: 0.4000\n",
      "Epoch 00058: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7896 - accuracy: 0.5000 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 59/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5644 - accuracy: 0.8000\n",
      "Epoch 00059: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6924 - accuracy: 0.5833 - val_loss: 0.6979 - val_accuracy: 0.4615\n",
      "Epoch 60/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8215 - accuracy: 0.4000\n",
      "Epoch 00060: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7439 - accuracy: 0.5417 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 61/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7474 - accuracy: 0.6000\n",
      "Epoch 00061: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6934 - accuracy: 0.5833 - val_loss: 0.6976 - val_accuracy: 0.4615\n",
      "Epoch 62/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7580 - accuracy: 0.4000\n",
      "Epoch 00062: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6812 - accuracy: 0.6042 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 63/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7551 - accuracy: 0.4000\n",
      "Epoch 00063: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6813 - accuracy: 0.5417 - val_loss: 0.6979 - val_accuracy: 0.4615\n",
      "Epoch 64/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7184 - accuracy: 0.6000\n",
      "Epoch 00064: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6400 - accuracy: 0.6250 - val_loss: 0.6981 - val_accuracy: 0.4615\n",
      "Epoch 65/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8401 - accuracy: 0.5000\n",
      "Epoch 00065: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7365 - accuracy: 0.5417 - val_loss: 0.6982 - val_accuracy: 0.4615\n",
      "Epoch 66/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6382 - accuracy: 0.7000\n",
      "Epoch 00066: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6666 - accuracy: 0.6042 - val_loss: 0.6982 - val_accuracy: 0.4615\n",
      "Epoch 67/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8176 - accuracy: 0.3000\n",
      "Epoch 00067: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7277 - accuracy: 0.4583 - val_loss: 0.6979 - val_accuracy: 0.4615\n",
      "Epoch 68/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7290 - accuracy: 0.5000\n",
      "Epoch 00068: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7194 - accuracy: 0.6042 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 69/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7686 - accuracy: 0.6000\n",
      "Epoch 00069: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7162 - accuracy: 0.5417 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 70/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7329 - accuracy: 0.6000\n",
      "Epoch 00070: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7210 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.4615\n",
      "Epoch 71/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6238 - accuracy: 0.5000\n",
      "Epoch 00071: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6556 - accuracy: 0.5417 - val_loss: 0.6975 - val_accuracy: 0.4615\n",
      "Epoch 72/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6292 - accuracy: 0.7000\n",
      "Epoch 00072: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7319 - accuracy: 0.4792 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 73/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6310 - accuracy: 0.6000\n",
      "Epoch 00073: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7434 - accuracy: 0.5625 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 74/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9236 - accuracy: 0.2000\n",
      "Epoch 00074: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7531 - accuracy: 0.4792 - val_loss: 0.6978 - val_accuracy: 0.4615\n",
      "Epoch 75/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9209 - accuracy: 0.4000\n",
      "Epoch 00075: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7330 - accuracy: 0.5833 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 76/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6748 - accuracy: 0.5000\n",
      "Epoch 00076: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7466 - accuracy: 0.4792 - val_loss: 0.6978 - val_accuracy: 0.4615\n",
      "Epoch 77/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4895 - accuracy: 1.0000\n",
      "Epoch 00077: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5630 - accuracy: 0.8542 - val_loss: 0.6979 - val_accuracy: 0.4615\n",
      "Epoch 78/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7497 - accuracy: 0.5000\n",
      "Epoch 00078: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7313 - accuracy: 0.5417 - val_loss: 0.6979 - val_accuracy: 0.4615\n",
      "Epoch 79/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6099 - accuracy: 0.7000\n",
      "Epoch 00079: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6506 - accuracy: 0.5833 - val_loss: 0.6980 - val_accuracy: 0.4615\n",
      "Epoch 80/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6013 - accuracy: 0.8000\n",
      "Epoch 00080: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6542 - accuracy: 0.6458 - val_loss: 0.6981 - val_accuracy: 0.4615\n",
      "Epoch 81/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6416 - accuracy: 0.7000\n",
      "Epoch 00081: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6830 - accuracy: 0.5625 - val_loss: 0.6977 - val_accuracy: 0.4615\n",
      "Epoch 82/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5885 - accuracy: 0.7000\n",
      "Epoch 00082: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6075 - accuracy: 0.7083 - val_loss: 0.6975 - val_accuracy: 0.4615\n",
      "Epoch 83/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5798 - accuracy: 0.6000\n",
      "Epoch 00083: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6717 - accuracy: 0.5417 - val_loss: 0.6971 - val_accuracy: 0.4615\n",
      "Epoch 84/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7276 - accuracy: 0.4000\n",
      "Epoch 00084: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7114 - accuracy: 0.5208 - val_loss: 0.6968 - val_accuracy: 0.4615\n",
      "Epoch 85/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6364 - accuracy: 0.7000\n",
      "Epoch 00085: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6978 - accuracy: 0.5000 - val_loss: 0.6964 - val_accuracy: 0.4615\n",
      "Epoch 86/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5237 - accuracy: 0.8000\n",
      "Epoch 00086: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6462 - accuracy: 0.6042 - val_loss: 0.6959 - val_accuracy: 0.4615\n",
      "Epoch 87/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6246 - accuracy: 0.6000\n",
      "Epoch 00087: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6646 - accuracy: 0.5833 - val_loss: 0.6954 - val_accuracy: 0.4615\n",
      "Epoch 88/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6111 - accuracy: 0.6000\n",
      "Epoch 00088: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6490 - accuracy: 0.5833 - val_loss: 0.6953 - val_accuracy: 0.4615\n",
      "Epoch 89/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7664 - accuracy: 0.6000\n",
      "Epoch 00089: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7259 - accuracy: 0.5625 - val_loss: 0.6954 - val_accuracy: 0.4615\n",
      "Epoch 90/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7593 - accuracy: 0.4000\n",
      "Epoch 00090: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7344 - accuracy: 0.5208 - val_loss: 0.6958 - val_accuracy: 0.4615\n",
      "Epoch 91/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6936 - accuracy: 0.6000\n",
      "Epoch 00091: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6054 - accuracy: 0.6875 - val_loss: 0.6959 - val_accuracy: 0.4615\n",
      "Epoch 92/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6494 - accuracy: 0.6000\n",
      "Epoch 00092: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6669 - accuracy: 0.5417 - val_loss: 0.6966 - val_accuracy: 0.4615\n",
      "Epoch 93/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7242 - accuracy: 0.6000\n",
      "Epoch 00093: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6886 - accuracy: 0.5625 - val_loss: 0.6972 - val_accuracy: 0.4615\n",
      "Epoch 94/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6350 - accuracy: 0.6000\n",
      "Epoch 00094: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6604 - accuracy: 0.6250 - val_loss: 0.6969 - val_accuracy: 0.4615\n",
      "Epoch 95/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7713 - accuracy: 0.4000\n",
      "Epoch 00095: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7289 - accuracy: 0.4375 - val_loss: 0.6964 - val_accuracy: 0.4615\n",
      "Epoch 96/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7662 - accuracy: 0.4000\n",
      "Epoch 00096: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6923 - accuracy: 0.5208 - val_loss: 0.6963 - val_accuracy: 0.4615\n",
      "Epoch 97/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6156 - accuracy: 0.6000\n",
      "Epoch 00097: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6666 - accuracy: 0.6250 - val_loss: 0.6956 - val_accuracy: 0.4615\n",
      "Epoch 98/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5848 - accuracy: 0.7000\n",
      "Epoch 00098: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6661 - accuracy: 0.6458 - val_loss: 0.6952 - val_accuracy: 0.4615\n",
      "Epoch 99/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7276 - accuracy: 0.3000\n",
      "Epoch 00099: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6779 - accuracy: 0.5000 - val_loss: 0.6946 - val_accuracy: 0.4615\n",
      "Epoch 100/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6181 - accuracy: 0.6000\n",
      "Epoch 00100: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6607 - accuracy: 0.5833 - val_loss: 0.6944 - val_accuracy: 0.4615\n",
      "Epoch 101/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7236 - accuracy: 0.6000\n",
      "Epoch 00101: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6992 - accuracy: 0.5208 - val_loss: 0.6947 - val_accuracy: 0.4615\n",
      "Epoch 102/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4752 - accuracy: 1.0000\n",
      "Epoch 00102: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6230 - accuracy: 0.6458 - val_loss: 0.6949 - val_accuracy: 0.4615\n",
      "Epoch 103/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5319 - accuracy: 0.7000\n",
      "Epoch 00103: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6126 - accuracy: 0.5833 - val_loss: 0.6949 - val_accuracy: 0.4615\n",
      "Epoch 104/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6691 - accuracy: 0.5000\n",
      "Epoch 00104: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7069 - accuracy: 0.5417 - val_loss: 0.6945 - val_accuracy: 0.4615\n",
      "Epoch 105/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6790 - accuracy: 0.6000\n",
      "Epoch 00105: val_accuracy did not improve from 0.46154\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7050 - accuracy: 0.5417 - val_loss: 0.6941 - val_accuracy: 0.4615\n",
      "Epoch 106/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7065 - accuracy: 0.4000\n",
      "Epoch 00106: val_accuracy improved from 0.46154 to 0.53846, saving model to models/CNN2_dataset_1_no_augment_10_106.h5\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6213 - accuracy: 0.6250 - val_loss: 0.6925 - val_accuracy: 0.5385\n",
      "Epoch 107/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6648 - accuracy: 0.6000\n",
      "Epoch 00107: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6547 - accuracy: 0.6042 - val_loss: 0.6912 - val_accuracy: 0.5385\n",
      "Epoch 108/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6468 - accuracy: 0.5000\n",
      "Epoch 00108: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6394 - accuracy: 0.5833 - val_loss: 0.6914 - val_accuracy: 0.5385\n",
      "Epoch 109/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5943 - accuracy: 0.7000\n",
      "Epoch 00109: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6669 - accuracy: 0.6458 - val_loss: 0.6922 - val_accuracy: 0.5385\n",
      "Epoch 110/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6679 - accuracy: 0.6000\n",
      "Epoch 00110: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6748 - accuracy: 0.5208 - val_loss: 0.6932 - val_accuracy: 0.5385\n",
      "Epoch 111/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7480 - accuracy: 0.6000\n",
      "Epoch 00111: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6500 - accuracy: 0.6458 - val_loss: 0.6944 - val_accuracy: 0.4615\n",
      "Epoch 112/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6376 - accuracy: 0.6000\n",
      "Epoch 00112: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6412 - accuracy: 0.6667 - val_loss: 0.6951 - val_accuracy: 0.4615\n",
      "Epoch 113/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6220 - accuracy: 0.7000\n",
      "Epoch 00113: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6260 - accuracy: 0.6458 - val_loss: 0.6953 - val_accuracy: 0.4615\n",
      "Epoch 114/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5406 - accuracy: 0.8000\n",
      "Epoch 00114: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6874 - accuracy: 0.5625 - val_loss: 0.6959 - val_accuracy: 0.4615\n",
      "Epoch 115/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5635 - accuracy: 0.9000\n",
      "Epoch 00115: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6486 - accuracy: 0.6042 - val_loss: 0.6955 - val_accuracy: 0.4615\n",
      "Epoch 116/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7508 - accuracy: 0.4000\n",
      "Epoch 00116: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6500 - accuracy: 0.6250 - val_loss: 0.6952 - val_accuracy: 0.4615\n",
      "Epoch 117/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8779 - accuracy: 0.5000\n",
      "Epoch 00117: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6782 - accuracy: 0.6875 - val_loss: 0.6949 - val_accuracy: 0.4615\n",
      "Epoch 118/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6930 - accuracy: 0.6000\n",
      "Epoch 00118: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6450 - accuracy: 0.6458 - val_loss: 0.6942 - val_accuracy: 0.4615\n",
      "Epoch 119/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5938 - accuracy: 0.7000\n",
      "Epoch 00119: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5954 - accuracy: 0.7500 - val_loss: 0.6935 - val_accuracy: 0.4615\n",
      "Epoch 120/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7451 - accuracy: 0.4000\n",
      "Epoch 00120: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6596 - accuracy: 0.6042 - val_loss: 0.6924 - val_accuracy: 0.4615\n",
      "Epoch 121/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7219 - accuracy: 0.5000\n",
      "Epoch 00121: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6135 - accuracy: 0.7083 - val_loss: 0.6919 - val_accuracy: 0.4615\n",
      "Epoch 122/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6509 - accuracy: 0.6000\n",
      "Epoch 00122: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6234 - accuracy: 0.7083 - val_loss: 0.6904 - val_accuracy: 0.4615\n",
      "Epoch 123/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7806 - accuracy: 0.5000\n",
      "Epoch 00123: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6700 - accuracy: 0.6042 - val_loss: 0.6885 - val_accuracy: 0.5385\n",
      "Epoch 124/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5805 - accuracy: 0.7000\n",
      "Epoch 00124: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6167 - accuracy: 0.6458 - val_loss: 0.6855 - val_accuracy: 0.5385\n",
      "Epoch 125/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8138 - accuracy: 0.3000\n",
      "Epoch 00125: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6830 - val_accuracy: 0.5385\n",
      "Epoch 126/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7573 - accuracy: 0.5000\n",
      "Epoch 00126: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6025 - accuracy: 0.6875 - val_loss: 0.6844 - val_accuracy: 0.5385\n",
      "Epoch 127/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6425 - accuracy: 0.6000\n",
      "Epoch 00127: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5860 - accuracy: 0.7500 - val_loss: 0.6858 - val_accuracy: 0.5385\n",
      "Epoch 128/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5816 - accuracy: 0.6000\n",
      "Epoch 00128: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6237 - accuracy: 0.6667 - val_loss: 0.6870 - val_accuracy: 0.4615\n",
      "Epoch 129/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5856 - accuracy: 0.7000\n",
      "Epoch 00129: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5294 - accuracy: 0.7917 - val_loss: 0.6874 - val_accuracy: 0.4615\n",
      "Epoch 130/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5734 - accuracy: 0.7000\n",
      "Epoch 00130: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6182 - accuracy: 0.6667 - val_loss: 0.6851 - val_accuracy: 0.4615\n",
      "Epoch 131/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6841 - accuracy: 0.6000\n",
      "Epoch 00131: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6317 - accuracy: 0.6250 - val_loss: 0.6837 - val_accuracy: 0.5385\n",
      "Epoch 132/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5679 - accuracy: 0.8000\n",
      "Epoch 00132: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6205 - accuracy: 0.6458 - val_loss: 0.6828 - val_accuracy: 0.5385\n",
      "Epoch 133/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5576 - accuracy: 0.6000\n",
      "Epoch 00133: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5835 - accuracy: 0.7083 - val_loss: 0.6832 - val_accuracy: 0.5385\n",
      "Epoch 134/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7276 - accuracy: 0.3000\n",
      "Epoch 00134: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6328 - accuracy: 0.5833 - val_loss: 0.6821 - val_accuracy: 0.5385\n",
      "Epoch 135/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7318 - accuracy: 0.5000\n",
      "Epoch 00135: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6760 - accuracy: 0.5625 - val_loss: 0.6831 - val_accuracy: 0.5385\n",
      "Epoch 136/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4776 - accuracy: 0.7000\n",
      "Epoch 00136: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5318 - accuracy: 0.7917 - val_loss: 0.6783 - val_accuracy: 0.5385\n",
      "Epoch 137/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5941 - accuracy: 0.6000\n",
      "Epoch 00137: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.5714 - accuracy: 0.7083 - val_loss: 0.6713 - val_accuracy: 0.5385\n",
      "Epoch 138/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6347 - accuracy: 0.7000\n",
      "Epoch 00138: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6163 - accuracy: 0.7083 - val_loss: 0.6659 - val_accuracy: 0.5385\n",
      "Epoch 139/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6463 - accuracy: 0.5000\n",
      "Epoch 00139: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.6168 - accuracy: 0.6458 - val_loss: 0.6621 - val_accuracy: 0.5385\n",
      "Epoch 140/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6163 - accuracy: 0.6000\n",
      "Epoch 00140: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.5822 - accuracy: 0.6667 - val_loss: 0.6601 - val_accuracy: 0.5385\n",
      "Epoch 141/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7346 - accuracy: 0.5000\n",
      "Epoch 00141: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6149 - accuracy: 0.6458 - val_loss: 0.6516 - val_accuracy: 0.5385\n",
      "Epoch 142/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5342 - accuracy: 0.7000\n",
      "Epoch 00142: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5499 - accuracy: 0.7292 - val_loss: 0.6511 - val_accuracy: 0.5385\n",
      "Epoch 143/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5238 - accuracy: 0.6000\n",
      "Epoch 00143: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6363 - accuracy: 0.5625 - val_loss: 0.6555 - val_accuracy: 0.5385\n",
      "Epoch 144/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4475 - accuracy: 0.9000\n",
      "Epoch 00144: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5310 - accuracy: 0.8125 - val_loss: 0.6616 - val_accuracy: 0.5385\n",
      "Epoch 145/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5178 - accuracy: 0.7000\n",
      "Epoch 00145: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.5387 - accuracy: 0.6875 - val_loss: 0.6574 - val_accuracy: 0.5385\n",
      "Epoch 146/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6639 - accuracy: 0.6000\n",
      "Epoch 00146: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5474 - accuracy: 0.7292 - val_loss: 0.6462 - val_accuracy: 0.5385\n",
      "Epoch 147/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5160 - accuracy: 0.8000\n",
      "Epoch 00147: val_accuracy improved from 0.53846 to 0.61538, saving model to models/CNN2_dataset_1_no_augment_10_147.h5\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.5278 - accuracy: 0.7292 - val_loss: 0.6425 - val_accuracy: 0.6154\n",
      "Epoch 148/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5481 - accuracy: 0.6000\n",
      "Epoch 00148: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5389 - accuracy: 0.7083 - val_loss: 0.6578 - val_accuracy: 0.5385\n",
      "Epoch 149/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4661 - accuracy: 0.7000\n",
      "Epoch 00149: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5074 - accuracy: 0.7708 - val_loss: 0.6591 - val_accuracy: 0.5385\n",
      "Epoch 150/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5043 - accuracy: 0.9000\n",
      "Epoch 00150: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5965 - accuracy: 0.6875 - val_loss: 0.6497 - val_accuracy: 0.5385\n",
      "Epoch 151/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4916 - accuracy: 0.6000\n",
      "Epoch 00151: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5024 - accuracy: 0.7083 - val_loss: 0.6378 - val_accuracy: 0.5385\n",
      "Epoch 152/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4951 - accuracy: 0.8000\n",
      "Epoch 00152: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5527 - accuracy: 0.7500 - val_loss: 0.6397 - val_accuracy: 0.5385\n",
      "Epoch 153/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3955 - accuracy: 0.8000\n",
      "Epoch 00153: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5089 - accuracy: 0.7083 - val_loss: 0.6359 - val_accuracy: 0.5385\n",
      "Epoch 154/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4770 - accuracy: 0.9000\n",
      "Epoch 00154: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.5116 - accuracy: 0.7708 - val_loss: 0.6291 - val_accuracy: 0.6154\n",
      "Epoch 155/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3387 - accuracy: 1.0000\n",
      "Epoch 00155: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5025 - accuracy: 0.7708 - val_loss: 0.6162 - val_accuracy: 0.6154\n",
      "Epoch 156/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2914 - accuracy: 1.0000\n",
      "Epoch 00156: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5026 - accuracy: 0.7917 - val_loss: 0.6168 - val_accuracy: 0.6154\n",
      "Epoch 157/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3833 - accuracy: 0.9000\n",
      "Epoch 00157: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.5280 - accuracy: 0.7500 - val_loss: 0.6197 - val_accuracy: 0.6154\n",
      "Epoch 158/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5498 - accuracy: 0.7000\n",
      "Epoch 00158: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.5058 - accuracy: 0.7500 - val_loss: 0.6377 - val_accuracy: 0.5385\n",
      "Epoch 159/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6554 - accuracy: 0.7000\n",
      "Epoch 00159: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4835 - accuracy: 0.7917 - val_loss: 0.6212 - val_accuracy: 0.6154\n",
      "Epoch 160/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4023 - accuracy: 0.9000\n",
      "Epoch 00160: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4196 - accuracy: 0.8333 - val_loss: 0.6066 - val_accuracy: 0.6154\n",
      "Epoch 161/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3553 - accuracy: 0.9000\n",
      "Epoch 00161: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4519 - accuracy: 0.8125 - val_loss: 0.5907 - val_accuracy: 0.6154\n",
      "Epoch 162/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5241 - accuracy: 0.6000\n",
      "Epoch 00162: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4567 - accuracy: 0.7708 - val_loss: 0.5982 - val_accuracy: 0.6154\n",
      "Epoch 163/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4839 - accuracy: 0.9000\n",
      "Epoch 00163: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4607 - accuracy: 0.8333 - val_loss: 0.5973 - val_accuracy: 0.6154\n",
      "Epoch 164/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4406 - accuracy: 0.9000\n",
      "Epoch 00164: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4630 - accuracy: 0.7917 - val_loss: 0.6119 - val_accuracy: 0.6154\n",
      "Epoch 165/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3860 - accuracy: 0.7000\n",
      "Epoch 00165: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4809 - accuracy: 0.7708 - val_loss: 0.6206 - val_accuracy: 0.6154\n",
      "Epoch 166/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5648 - accuracy: 0.7000\n",
      "Epoch 00166: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.4809 - accuracy: 0.7917 - val_loss: 0.6012 - val_accuracy: 0.6154\n",
      "Epoch 167/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3868 - accuracy: 0.9000\n",
      "Epoch 00167: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4786 - accuracy: 0.7500 - val_loss: 0.5861 - val_accuracy: 0.6154\n",
      "Epoch 168/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6552 - accuracy: 0.6000\n",
      "Epoch 00168: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4988 - accuracy: 0.7708 - val_loss: 0.6007 - val_accuracy: 0.6154\n",
      "Epoch 169/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4747 - accuracy: 0.8000\n",
      "Epoch 00169: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4437 - accuracy: 0.7917 - val_loss: 0.5878 - val_accuracy: 0.6154\n",
      "Epoch 170/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5243 - accuracy: 0.8000\n",
      "Epoch 00170: val_accuracy did not improve from 0.61538\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4688 - accuracy: 0.7917 - val_loss: 0.5709 - val_accuracy: 0.6154\n",
      "Epoch 171/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5475 - accuracy: 0.6000\n",
      "Epoch 00171: val_accuracy improved from 0.61538 to 0.84615, saving model to models/CNN2_dataset_1_no_augment_10_171.h5\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.4381 - accuracy: 0.7083 - val_loss: 0.5542 - val_accuracy: 0.8462\n",
      "Epoch 172/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4525 - accuracy: 0.8000\n",
      "Epoch 00172: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4094 - accuracy: 0.8750 - val_loss: 0.5416 - val_accuracy: 0.8462\n",
      "Epoch 173/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5348 - accuracy: 0.7000\n",
      "Epoch 00173: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4827 - accuracy: 0.7708 - val_loss: 0.5431 - val_accuracy: 0.8462\n",
      "Epoch 174/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4838 - accuracy: 0.7000\n",
      "Epoch 00174: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.5654 - val_accuracy: 0.6923\n",
      "Epoch 175/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3831 - accuracy: 0.9000\n",
      "Epoch 00175: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3228 - accuracy: 0.8750 - val_loss: 0.5657 - val_accuracy: 0.6923\n",
      "Epoch 176/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5214 - accuracy: 0.9000\n",
      "Epoch 00176: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4686 - accuracy: 0.8125 - val_loss: 0.5485 - val_accuracy: 0.7692\n",
      "Epoch 177/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4775 - accuracy: 0.8000\n",
      "Epoch 00177: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3875 - accuracy: 0.8542 - val_loss: 0.5621 - val_accuracy: 0.6923\n",
      "Epoch 178/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4625 - accuracy: 0.8000\n",
      "Epoch 00178: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.4508 - accuracy: 0.7708 - val_loss: 0.5865 - val_accuracy: 0.6154\n",
      "Epoch 179/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3423 - accuracy: 0.8000\n",
      "Epoch 00179: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4390 - accuracy: 0.7500 - val_loss: 0.6181 - val_accuracy: 0.6154\n",
      "Epoch 180/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6472 - accuracy: 0.7000\n",
      "Epoch 00180: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4495 - accuracy: 0.7917 - val_loss: 0.5720 - val_accuracy: 0.6923\n",
      "Epoch 181/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4827 - accuracy: 0.8000\n",
      "Epoch 00181: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3386 - accuracy: 0.9167 - val_loss: 0.5445 - val_accuracy: 0.7692\n",
      "Epoch 182/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2765 - accuracy: 0.9000\n",
      "Epoch 00182: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3697 - accuracy: 0.8542 - val_loss: 0.5612 - val_accuracy: 0.7692\n",
      "Epoch 183/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5336 - accuracy: 0.7000\n",
      "Epoch 00183: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4370 - accuracy: 0.7917 - val_loss: 0.5781 - val_accuracy: 0.6154\n",
      "Epoch 184/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4457 - accuracy: 0.8000\n",
      "Epoch 00184: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4001 - accuracy: 0.9167 - val_loss: 0.6061 - val_accuracy: 0.5385\n",
      "Epoch 185/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3037 - accuracy: 0.9000\n",
      "Epoch 00185: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3611 - accuracy: 0.8125 - val_loss: 0.5804 - val_accuracy: 0.6154\n",
      "Epoch 186/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2350 - accuracy: 0.9000\n",
      "Epoch 00186: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3673 - accuracy: 0.8750 - val_loss: 0.5374 - val_accuracy: 0.8462\n",
      "Epoch 187/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1415 - accuracy: 0.9000\n",
      "Epoch 00187: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2493 - accuracy: 0.9375 - val_loss: 0.5336 - val_accuracy: 0.8462\n",
      "Epoch 188/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5508 - accuracy: 0.6000\n",
      "Epoch 00188: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3357 - accuracy: 0.8333 - val_loss: 0.5644 - val_accuracy: 0.6923\n",
      "Epoch 189/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6313 - accuracy: 0.9000\n",
      "Epoch 00189: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3986 - accuracy: 0.8333 - val_loss: 0.5623 - val_accuracy: 0.7692\n",
      "Epoch 190/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0918 - accuracy: 1.0000\n",
      "Epoch 00190: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.4117 - accuracy: 0.7917 - val_loss: 0.5561 - val_accuracy: 0.7692\n",
      "Epoch 191/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3806 - accuracy: 0.8000\n",
      "Epoch 00191: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3254 - accuracy: 0.8333 - val_loss: 0.5179 - val_accuracy: 0.8462\n",
      "Epoch 192/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5698 - accuracy: 0.8000\n",
      "Epoch 00192: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4215 - accuracy: 0.8542 - val_loss: 0.5417 - val_accuracy: 0.7692\n",
      "Epoch 193/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4577 - accuracy: 0.8000\n",
      "Epoch 00193: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3667 - accuracy: 0.8333 - val_loss: 0.4896 - val_accuracy: 0.8462\n",
      "Epoch 194/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5503 - accuracy: 0.7000\n",
      "Epoch 00194: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3440 - accuracy: 0.8542 - val_loss: 0.5520 - val_accuracy: 0.7692\n",
      "Epoch 195/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3111 - accuracy: 0.9000\n",
      "Epoch 00195: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2722 - accuracy: 0.9375 - val_loss: 0.5574 - val_accuracy: 0.7692\n",
      "Epoch 196/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4401 - accuracy: 0.8000\n",
      "Epoch 00196: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2916 - accuracy: 0.8750 - val_loss: 0.5122 - val_accuracy: 0.8462\n",
      "Epoch 197/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3902 - accuracy: 0.9000\n",
      "Epoch 00197: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3355 - accuracy: 0.8750 - val_loss: 0.5060 - val_accuracy: 0.8462\n",
      "Epoch 198/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4293 - accuracy: 0.8000\n",
      "Epoch 00198: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3279 - accuracy: 0.8750 - val_loss: 0.5023 - val_accuracy: 0.8462\n",
      "Epoch 199/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2576 - accuracy: 0.8000\n",
      "Epoch 00199: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2821 - accuracy: 0.8542 - val_loss: 0.4956 - val_accuracy: 0.8462\n",
      "Epoch 200/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5923 - accuracy: 0.7000\n",
      "Epoch 00200: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3174 - accuracy: 0.8542 - val_loss: 0.5556 - val_accuracy: 0.6923\n",
      "Epoch 201/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4169 - accuracy: 0.7000\n",
      "Epoch 00201: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2593 - accuracy: 0.8750 - val_loss: 0.5081 - val_accuracy: 0.8462\n",
      "Epoch 202/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2495 - accuracy: 0.9000\n",
      "Epoch 00202: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3283 - accuracy: 0.8750 - val_loss: 0.4526 - val_accuracy: 0.8462\n",
      "Epoch 203/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3637 - accuracy: 0.9000\n",
      "Epoch 00203: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2942 - accuracy: 0.8750 - val_loss: 0.4803 - val_accuracy: 0.8462\n",
      "Epoch 204/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1755 - accuracy: 1.0000\n",
      "Epoch 00204: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2952 - accuracy: 0.9375 - val_loss: 0.5369 - val_accuracy: 0.7692\n",
      "Epoch 205/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2060 - accuracy: 0.9000\n",
      "Epoch 00205: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2683 - accuracy: 0.8958 - val_loss: 0.4438 - val_accuracy: 0.8462\n",
      "Epoch 206/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2008 - accuracy: 1.0000\n",
      "Epoch 00206: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3094 - accuracy: 0.8958 - val_loss: 0.4290 - val_accuracy: 0.8462\n",
      "Epoch 207/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6258 - accuracy: 0.8000\n",
      "Epoch 00207: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3611 - accuracy: 0.8333 - val_loss: 0.4788 - val_accuracy: 0.8462\n",
      "Epoch 208/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3477 - accuracy: 0.8000\n",
      "Epoch 00208: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3693 - accuracy: 0.8750 - val_loss: 0.5013 - val_accuracy: 0.7692\n",
      "Epoch 209/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3140 - accuracy: 0.9000\n",
      "Epoch 00209: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3417 - accuracy: 0.8542 - val_loss: 0.4538 - val_accuracy: 0.8462\n",
      "Epoch 210/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3011 - accuracy: 0.9000\n",
      "Epoch 00210: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3158 - accuracy: 0.8542 - val_loss: 0.3942 - val_accuracy: 0.8462\n",
      "Epoch 211/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3977 - accuracy: 0.9000\n",
      "Epoch 00211: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3403 - accuracy: 0.8958 - val_loss: 0.4313 - val_accuracy: 0.8462\n",
      "Epoch 212/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4820 - accuracy: 0.8000\n",
      "Epoch 00212: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4034 - accuracy: 0.7708 - val_loss: 0.5250 - val_accuracy: 0.7692\n",
      "Epoch 213/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2037 - accuracy: 0.9000\n",
      "Epoch 00213: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2719 - accuracy: 0.8750 - val_loss: 0.4450 - val_accuracy: 0.8462\n",
      "Epoch 214/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4628 - accuracy: 0.7000\n",
      "Epoch 00214: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2857 - accuracy: 0.8958 - val_loss: 0.4392 - val_accuracy: 0.8462\n",
      "Epoch 215/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7152 - accuracy: 0.7000\n",
      "Epoch 00215: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3228 - accuracy: 0.8958 - val_loss: 0.4953 - val_accuracy: 0.8462\n",
      "Epoch 216/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1904 - accuracy: 1.0000\n",
      "Epoch 00216: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2778 - accuracy: 0.8750 - val_loss: 0.4735 - val_accuracy: 0.8462\n",
      "Epoch 217/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1692 - accuracy: 0.9000\n",
      "Epoch 00217: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3536 - accuracy: 0.8333 - val_loss: 0.4149 - val_accuracy: 0.8462\n",
      "Epoch 218/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1069 - accuracy: 1.0000\n",
      "Epoch 00218: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2562 - accuracy: 0.9167 - val_loss: 0.3904 - val_accuracy: 0.8462\n",
      "Epoch 219/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8701 - accuracy: 0.6000\n",
      "Epoch 00219: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3357 - accuracy: 0.8750 - val_loss: 0.4575 - val_accuracy: 0.8462\n",
      "Epoch 220/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3279 - accuracy: 0.9000\n",
      "Epoch 00220: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3743 - accuracy: 0.8750 - val_loss: 0.4881 - val_accuracy: 0.8462\n",
      "Epoch 221/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3580 - accuracy: 0.9000\n",
      "Epoch 00221: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3590 - accuracy: 0.8542 - val_loss: 0.4451 - val_accuracy: 0.8462\n",
      "Epoch 222/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3456 - accuracy: 0.8000\n",
      "Epoch 00222: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2906 - accuracy: 0.8542 - val_loss: 0.4644 - val_accuracy: 0.8462\n",
      "Epoch 223/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2072 - accuracy: 1.0000\n",
      "Epoch 00223: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3104 - accuracy: 0.8333 - val_loss: 0.5107 - val_accuracy: 0.8462\n",
      "Epoch 224/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4577 - accuracy: 0.7000\n",
      "Epoch 00224: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2113 - accuracy: 0.8958 - val_loss: 0.4183 - val_accuracy: 0.8462\n",
      "Epoch 225/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4470 - accuracy: 0.8000\n",
      "Epoch 00225: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2641 - accuracy: 0.9167 - val_loss: 0.3956 - val_accuracy: 0.8462\n",
      "Epoch 226/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2713 - accuracy: 0.9000\n",
      "Epoch 00226: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2762 - accuracy: 0.8958 - val_loss: 0.4503 - val_accuracy: 0.8462\n",
      "Epoch 227/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1600 - accuracy: 0.9000\n",
      "Epoch 00227: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2497 - accuracy: 0.9375 - val_loss: 0.5131 - val_accuracy: 0.8462\n",
      "Epoch 228/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1193 - accuracy: 1.0000\n",
      "Epoch 00228: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2200 - accuracy: 0.8958 - val_loss: 0.4814 - val_accuracy: 0.8462\n",
      "Epoch 229/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0787 - accuracy: 1.0000\n",
      "Epoch 00229: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1983 - accuracy: 0.9583 - val_loss: 0.4339 - val_accuracy: 0.8462\n",
      "Epoch 230/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2995 - accuracy: 0.8000\n",
      "Epoch 00230: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2952 - accuracy: 0.8542 - val_loss: 0.4364 - val_accuracy: 0.8462\n",
      "Epoch 231/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2588 - accuracy: 0.8000\n",
      "Epoch 00231: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.2709 - accuracy: 0.8958 - val_loss: 0.4994 - val_accuracy: 0.8462\n",
      "Epoch 232/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3355 - accuracy: 0.9000\n",
      "Epoch 00232: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.2629 - accuracy: 0.8958 - val_loss: 0.5328 - val_accuracy: 0.8462\n",
      "Epoch 233/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2183 - accuracy: 0.9000\n",
      "Epoch 00233: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2184 - accuracy: 0.9167 - val_loss: 0.5288 - val_accuracy: 0.8462\n",
      "Epoch 234/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1210 - accuracy: 1.0000\n",
      "Epoch 00234: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2539 - accuracy: 0.8958 - val_loss: 0.4693 - val_accuracy: 0.8462\n",
      "Epoch 235/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5660 - accuracy: 0.8000\n",
      "Epoch 00235: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3669 - accuracy: 0.8750 - val_loss: 0.4963 - val_accuracy: 0.8462\n",
      "Epoch 236/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3653 - accuracy: 0.8000\n",
      "Epoch 00236: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.3485 - accuracy: 0.8750 - val_loss: 0.6066 - val_accuracy: 0.6154\n",
      "Epoch 237/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1704 - accuracy: 1.0000\n",
      "Epoch 00237: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2037 - accuracy: 0.9583 - val_loss: 0.5450 - val_accuracy: 0.8462\n",
      "Epoch 238/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3744 - accuracy: 0.8000\n",
      "Epoch 00238: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3041 - accuracy: 0.8958 - val_loss: 0.4533 - val_accuracy: 0.8462\n",
      "Epoch 239/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3249 - accuracy: 0.8000\n",
      "Epoch 00239: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2892 - accuracy: 0.8333 - val_loss: 0.4659 - val_accuracy: 0.8462\n",
      "Epoch 240/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1448 - accuracy: 0.9000\n",
      "Epoch 00240: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2025 - accuracy: 0.8958 - val_loss: 0.4449 - val_accuracy: 0.8462\n",
      "Epoch 241/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1930 - accuracy: 1.0000\n",
      "Epoch 00241: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3584 - accuracy: 0.8750 - val_loss: 0.5153 - val_accuracy: 0.8462\n",
      "Epoch 242/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1111 - accuracy: 0.9000\n",
      "Epoch 00242: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2351 - accuracy: 0.8958 - val_loss: 0.4763 - val_accuracy: 0.8462\n",
      "Epoch 243/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1820 - accuracy: 1.0000\n",
      "Epoch 00243: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2988 - accuracy: 0.8750 - val_loss: 0.4418 - val_accuracy: 0.8462\n",
      "Epoch 244/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2263 - accuracy: 0.9000\n",
      "Epoch 00244: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2547 - accuracy: 0.8958 - val_loss: 0.4461 - val_accuracy: 0.8462\n",
      "Epoch 245/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4888 - accuracy: 0.7000\n",
      "Epoch 00245: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3429 - accuracy: 0.8333 - val_loss: 0.5256 - val_accuracy: 0.8462\n",
      "Epoch 246/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2789 - accuracy: 0.8000\n",
      "Epoch 00246: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2563 - accuracy: 0.8750 - val_loss: 0.4973 - val_accuracy: 0.8462\n",
      "Epoch 247/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0968 - accuracy: 1.0000\n",
      "Epoch 00247: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1885 - accuracy: 0.9583 - val_loss: 0.4943 - val_accuracy: 0.8462\n",
      "Epoch 248/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2552 - accuracy: 0.9000\n",
      "Epoch 00248: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2800 - accuracy: 0.8750 - val_loss: 0.4715 - val_accuracy: 0.8462\n",
      "Epoch 249/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1335 - accuracy: 1.0000\n",
      "Epoch 00249: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1976 - accuracy: 0.9167 - val_loss: 0.4516 - val_accuracy: 0.8462\n",
      "Epoch 250/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2708 - accuracy: 0.9000\n",
      "Epoch 00250: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2547 - accuracy: 0.8958 - val_loss: 0.4327 - val_accuracy: 0.8462\n",
      "Epoch 251/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2986 - accuracy: 0.8000\n",
      "Epoch 00251: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2154 - accuracy: 0.8750 - val_loss: 0.4622 - val_accuracy: 0.8462\n",
      "Epoch 252/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2702 - accuracy: 1.0000\n",
      "Epoch 00252: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2630 - accuracy: 0.9167 - val_loss: 0.4395 - val_accuracy: 0.8462\n",
      "Epoch 253/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2566 - accuracy: 0.8000\n",
      "Epoch 00253: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1645 - accuracy: 0.9375 - val_loss: 0.4468 - val_accuracy: 0.8462\n",
      "Epoch 254/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1447 - accuracy: 1.0000\n",
      "Epoch 00254: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2019 - accuracy: 0.9583 - val_loss: 0.4828 - val_accuracy: 0.8462\n",
      "Epoch 255/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1790 - accuracy: 0.9000\n",
      "Epoch 00255: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1565 - accuracy: 0.9583 - val_loss: 0.4742 - val_accuracy: 0.8462\n",
      "Epoch 256/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3596 - accuracy: 0.7000\n",
      "Epoch 00256: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2237 - accuracy: 0.8958 - val_loss: 0.4407 - val_accuracy: 0.8462\n",
      "Epoch 257/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1899 - accuracy: 0.9000\n",
      "Epoch 00257: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2335 - accuracy: 0.8958 - val_loss: 0.4296 - val_accuracy: 0.8462\n",
      "Epoch 258/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1590 - accuracy: 0.9000\n",
      "Epoch 00258: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2637 - accuracy: 0.8750 - val_loss: 0.5068 - val_accuracy: 0.8462\n",
      "Epoch 259/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1191 - accuracy: 1.0000\n",
      "Epoch 00259: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2721 - accuracy: 0.8750 - val_loss: 0.5072 - val_accuracy: 0.8462\n",
      "Epoch 260/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2690 - accuracy: 0.9000\n",
      "Epoch 00260: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1695 - accuracy: 0.9375 - val_loss: 0.4045 - val_accuracy: 0.8462\n",
      "Epoch 261/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3337 - accuracy: 0.9000\n",
      "Epoch 00261: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2071 - accuracy: 0.8958 - val_loss: 0.4577 - val_accuracy: 0.8462\n",
      "Epoch 262/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2291 - accuracy: 0.9000\n",
      "Epoch 00262: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1706 - accuracy: 0.9375 - val_loss: 0.5264 - val_accuracy: 0.8462\n",
      "Epoch 263/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4311 - accuracy: 0.8000\n",
      "Epoch 00263: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2291 - accuracy: 0.9167 - val_loss: 0.5235 - val_accuracy: 0.8462\n",
      "Epoch 264/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1465 - accuracy: 0.9000\n",
      "Epoch 00264: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2937 - accuracy: 0.8750 - val_loss: 0.4782 - val_accuracy: 0.8462\n",
      "Epoch 265/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1223 - accuracy: 1.0000\n",
      "Epoch 00265: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2469 - accuracy: 0.9167 - val_loss: 0.4255 - val_accuracy: 0.8462\n",
      "Epoch 266/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1102 - accuracy: 1.0000\n",
      "Epoch 00266: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1771 - accuracy: 0.9583 - val_loss: 0.4477 - val_accuracy: 0.8462\n",
      "Epoch 267/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4136 - accuracy: 0.8000\n",
      "Epoch 00267: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2316 - accuracy: 0.9167 - val_loss: 0.4293 - val_accuracy: 0.8462\n",
      "Epoch 268/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1891 - accuracy: 0.9000\n",
      "Epoch 00268: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2266 - accuracy: 0.9167 - val_loss: 0.4379 - val_accuracy: 0.8462\n",
      "Epoch 269/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2332 - accuracy: 0.9000\n",
      "Epoch 00269: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2299 - accuracy: 0.9167 - val_loss: 0.4086 - val_accuracy: 0.8462\n",
      "Epoch 270/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5485 - accuracy: 0.7000\n",
      "Epoch 00270: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.3037 - accuracy: 0.8333 - val_loss: 0.3551 - val_accuracy: 0.8462\n",
      "Epoch 271/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2013 - accuracy: 0.9000\n",
      "Epoch 00271: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2267 - accuracy: 0.8958 - val_loss: 0.4307 - val_accuracy: 0.8462\n",
      "Epoch 272/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2780 - accuracy: 0.9000\n",
      "Epoch 00272: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3065 - accuracy: 0.8125 - val_loss: 0.5126 - val_accuracy: 0.8462\n",
      "Epoch 273/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0606 - accuracy: 1.0000\n",
      "Epoch 00273: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3554 - accuracy: 0.8958 - val_loss: 0.3347 - val_accuracy: 0.8462\n",
      "Epoch 274/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2561 - accuracy: 0.9000\n",
      "Epoch 00274: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3728 - accuracy: 0.8125 - val_loss: 0.3783 - val_accuracy: 0.8462\n",
      "Epoch 275/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1688 - accuracy: 0.9000\n",
      "Epoch 00275: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2046 - accuracy: 0.8958 - val_loss: 0.4777 - val_accuracy: 0.8462\n",
      "Epoch 276/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3821 - accuracy: 0.9000\n",
      "Epoch 00276: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.2402 - accuracy: 0.8958 - val_loss: 0.4748 - val_accuracy: 0.8462\n",
      "Epoch 277/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1555 - accuracy: 1.0000\n",
      "Epoch 00277: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1799 - accuracy: 0.9583 - val_loss: 0.3801 - val_accuracy: 0.8462\n",
      "Epoch 278/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2211 - accuracy: 1.0000\n",
      "Epoch 00278: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2553 - accuracy: 0.8958 - val_loss: 0.3492 - val_accuracy: 0.8462\n",
      "Epoch 279/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0973 - accuracy: 0.9000\n",
      "Epoch 00279: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1351 - accuracy: 0.9375 - val_loss: 0.4112 - val_accuracy: 0.8462\n",
      "Epoch 280/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4694 - accuracy: 0.9000\n",
      "Epoch 00280: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2055 - accuracy: 0.9583 - val_loss: 0.4403 - val_accuracy: 0.8462\n",
      "Epoch 281/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1628 - accuracy: 0.9000\n",
      "Epoch 00281: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2587 - accuracy: 0.8125 - val_loss: 0.4433 - val_accuracy: 0.8462\n",
      "Epoch 282/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2135 - accuracy: 0.9000\n",
      "Epoch 00282: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1055 - accuracy: 0.9792 - val_loss: 0.4122 - val_accuracy: 0.8462\n",
      "Epoch 283/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1022 - accuracy: 1.0000\n",
      "Epoch 00283: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1262 - accuracy: 0.9792 - val_loss: 0.4032 - val_accuracy: 0.8462\n",
      "Epoch 284/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1004 - accuracy: 1.0000\n",
      "Epoch 00284: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2013 - accuracy: 0.9167 - val_loss: 0.3749 - val_accuracy: 0.8462\n",
      "Epoch 285/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1114 - accuracy: 1.0000\n",
      "Epoch 00285: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2328 - accuracy: 0.9167 - val_loss: 0.4123 - val_accuracy: 0.8462\n",
      "Epoch 286/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2167 - accuracy: 0.9000\n",
      "Epoch 00286: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1629 - accuracy: 0.9375 - val_loss: 0.4708 - val_accuracy: 0.8462\n",
      "Epoch 287/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1251 - accuracy: 1.0000\n",
      "Epoch 00287: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1868 - accuracy: 0.9167 - val_loss: 0.4182 - val_accuracy: 0.8462\n",
      "Epoch 288/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2544 - accuracy: 0.8000\n",
      "Epoch 00288: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2614 - accuracy: 0.8750 - val_loss: 0.3592 - val_accuracy: 0.8462\n",
      "Epoch 289/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1240 - accuracy: 0.9000\n",
      "Epoch 00289: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2080 - accuracy: 0.9167 - val_loss: 0.3925 - val_accuracy: 0.8462\n",
      "Epoch 290/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1408 - accuracy: 1.0000\n",
      "Epoch 00290: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1421 - accuracy: 0.9583 - val_loss: 0.4307 - val_accuracy: 0.8462\n",
      "Epoch 291/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1530 - accuracy: 0.9000\n",
      "Epoch 00291: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1957 - accuracy: 0.9167 - val_loss: 0.4452 - val_accuracy: 0.8462\n",
      "Epoch 292/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1386 - accuracy: 1.0000\n",
      "Epoch 00292: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1615 - accuracy: 0.9583 - val_loss: 0.4097 - val_accuracy: 0.8462\n",
      "Epoch 293/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 00293: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1894 - accuracy: 0.9583 - val_loss: 0.3812 - val_accuracy: 0.8462\n",
      "Epoch 294/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1596 - accuracy: 0.9000\n",
      "Epoch 00294: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1980 - accuracy: 0.8958 - val_loss: 0.3738 - val_accuracy: 0.8462\n",
      "Epoch 295/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2132 - accuracy: 0.9000\n",
      "Epoch 00295: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1428 - accuracy: 0.9167 - val_loss: 0.4697 - val_accuracy: 0.8462\n",
      "Epoch 296/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1293 - accuracy: 1.0000\n",
      "Epoch 00296: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1600 - accuracy: 0.9583 - val_loss: 0.4643 - val_accuracy: 0.8462\n",
      "Epoch 297/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3322 - accuracy: 0.9000\n",
      "Epoch 00297: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2027 - accuracy: 0.8958 - val_loss: 0.4004 - val_accuracy: 0.8462\n",
      "Epoch 298/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1102 - accuracy: 1.0000\n",
      "Epoch 00298: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1594 - accuracy: 0.9167 - val_loss: 0.3650 - val_accuracy: 0.8462\n",
      "Epoch 299/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3273 - accuracy: 0.9000\n",
      "Epoch 00299: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3884 - accuracy: 0.8333 - val_loss: 0.4090 - val_accuracy: 0.8462\n",
      "Epoch 300/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1430 - accuracy: 0.9000\n",
      "Epoch 00300: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2222 - accuracy: 0.8750 - val_loss: 0.5829 - val_accuracy: 0.8462\n",
      "Epoch 301/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1338 - accuracy: 1.0000\n",
      "Epoch 00301: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2352 - accuracy: 0.8542 - val_loss: 0.5930 - val_accuracy: 0.8462\n",
      "Epoch 302/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1484 - accuracy: 0.9000\n",
      "Epoch 00302: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1988 - accuracy: 0.9167 - val_loss: 0.4008 - val_accuracy: 0.8462\n",
      "Epoch 303/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2572 - accuracy: 0.8000\n",
      "Epoch 00303: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2834 - accuracy: 0.8333 - val_loss: 0.4338 - val_accuracy: 0.8462\n",
      "Epoch 304/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5624 - accuracy: 0.9000\n",
      "Epoch 00304: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3309 - accuracy: 0.8958 - val_loss: 0.6025 - val_accuracy: 0.8462\n",
      "Epoch 305/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2367 - accuracy: 0.9000\n",
      "Epoch 00305: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2687 - accuracy: 0.9167 - val_loss: 0.5145 - val_accuracy: 0.8462\n",
      "Epoch 306/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1740 - accuracy: 0.9000\n",
      "Epoch 00306: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1228 - accuracy: 0.9583 - val_loss: 0.3748 - val_accuracy: 0.8462\n",
      "Epoch 307/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0884 - accuracy: 1.0000\n",
      "Epoch 00307: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2175 - accuracy: 0.9167 - val_loss: 0.4054 - val_accuracy: 0.8462\n",
      "Epoch 308/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 00308: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1309 - accuracy: 0.9583 - val_loss: 0.5245 - val_accuracy: 0.8462\n",
      "Epoch 309/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1125 - accuracy: 1.0000\n",
      "Epoch 00309: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3296 - accuracy: 0.9167 - val_loss: 0.4450 - val_accuracy: 0.8462\n",
      "Epoch 310/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2225 - accuracy: 0.9000\n",
      "Epoch 00310: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1842 - accuracy: 0.8958 - val_loss: 0.3785 - val_accuracy: 0.8462\n",
      "Epoch 311/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1314 - accuracy: 1.0000\n",
      "Epoch 00311: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1355 - accuracy: 0.9792 - val_loss: 0.3590 - val_accuracy: 0.8462\n",
      "Epoch 312/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1185 - accuracy: 1.0000\n",
      "Epoch 00312: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1577 - accuracy: 0.9167 - val_loss: 0.4109 - val_accuracy: 0.8462\n",
      "Epoch 313/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1951 - accuracy: 0.8000\n",
      "Epoch 00313: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2142 - accuracy: 0.8958 - val_loss: 0.4353 - val_accuracy: 0.8462\n",
      "Epoch 314/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2383 - accuracy: 0.8000\n",
      "Epoch 00314: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1907 - accuracy: 0.9167 - val_loss: 0.3370 - val_accuracy: 0.8462\n",
      "Epoch 315/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4628 - accuracy: 0.9000\n",
      "Epoch 00315: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3203 - accuracy: 0.8542 - val_loss: 0.4350 - val_accuracy: 0.8462\n",
      "Epoch 316/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2223 - accuracy: 0.8000\n",
      "Epoch 00316: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2042 - accuracy: 0.8750 - val_loss: 0.4866 - val_accuracy: 0.8462\n",
      "Epoch 317/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1433 - accuracy: 1.0000\n",
      "Epoch 00317: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1872 - accuracy: 0.9167 - val_loss: 0.4050 - val_accuracy: 0.8462\n",
      "Epoch 318/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2531 - accuracy: 0.8000\n",
      "Epoch 00318: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2240 - accuracy: 0.8958 - val_loss: 0.3865 - val_accuracy: 0.8462\n",
      "Epoch 319/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1825 - accuracy: 1.0000\n",
      "Epoch 00319: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1808 - accuracy: 0.9583 - val_loss: 0.4182 - val_accuracy: 0.8462\n",
      "Epoch 320/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3204 - accuracy: 0.8000\n",
      "Epoch 00320: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2776 - accuracy: 0.8333 - val_loss: 0.4895 - val_accuracy: 0.8462\n",
      "Epoch 321/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1075 - accuracy: 1.0000\n",
      "Epoch 00321: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3128 - accuracy: 0.8750 - val_loss: 0.3889 - val_accuracy: 0.8462\n",
      "Epoch 322/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2430 - accuracy: 0.8000\n",
      "Epoch 00322: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2472 - accuracy: 0.8750 - val_loss: 0.3879 - val_accuracy: 0.8462\n",
      "Epoch 323/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0676 - accuracy: 1.0000\n",
      "Epoch 00323: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1661 - accuracy: 0.9375 - val_loss: 0.4133 - val_accuracy: 0.8462\n",
      "Epoch 324/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1700 - accuracy: 1.0000\n",
      "Epoch 00324: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1209 - accuracy: 0.9583 - val_loss: 0.4130 - val_accuracy: 0.8462\n",
      "Epoch 325/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0422 - accuracy: 1.0000\n",
      "Epoch 00325: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2880 - accuracy: 0.8750 - val_loss: 0.4619 - val_accuracy: 0.8462\n",
      "Epoch 326/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0361 - accuracy: 1.0000\n",
      "Epoch 00326: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2234 - accuracy: 0.8958 - val_loss: 0.4166 - val_accuracy: 0.8462\n",
      "Epoch 327/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0712 - accuracy: 1.0000\n",
      "Epoch 00327: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2321 - accuracy: 0.9375 - val_loss: 0.3962 - val_accuracy: 0.8462\n",
      "Epoch 328/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3336 - accuracy: 0.8000\n",
      "Epoch 00328: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1392 - accuracy: 0.9583 - val_loss: 0.3767 - val_accuracy: 0.8462\n",
      "Epoch 329/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2204 - accuracy: 0.9000\n",
      "Epoch 00329: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1917 - accuracy: 0.9375 - val_loss: 0.3784 - val_accuracy: 0.8462\n",
      "Epoch 330/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0934 - accuracy: 1.0000\n",
      "Epoch 00330: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1398 - accuracy: 0.9583 - val_loss: 0.3787 - val_accuracy: 0.8462\n",
      "Epoch 331/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1641 - accuracy: 1.0000\n",
      "Epoch 00331: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2047 - accuracy: 0.9583 - val_loss: 0.3948 - val_accuracy: 0.8462\n",
      "Epoch 332/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1917 - accuracy: 0.9000\n",
      "Epoch 00332: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2466 - accuracy: 0.9167 - val_loss: 0.3790 - val_accuracy: 0.8462\n",
      "Epoch 333/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2664 - accuracy: 0.8000\n",
      "Epoch 00333: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1310 - accuracy: 0.9167 - val_loss: 0.3588 - val_accuracy: 0.8462\n",
      "Epoch 334/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1236 - accuracy: 1.0000\n",
      "Epoch 00334: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1573 - accuracy: 0.9375 - val_loss: 0.3419 - val_accuracy: 0.8462\n",
      "Epoch 335/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 00335: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2229 - accuracy: 0.9375 - val_loss: 0.3542 - val_accuracy: 0.8462\n",
      "Epoch 336/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1899 - accuracy: 0.9000\n",
      "Epoch 00336: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1736 - accuracy: 0.9167 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
      "Epoch 337/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0634 - accuracy: 1.0000\n",
      "Epoch 00337: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2281 - accuracy: 0.9583 - val_loss: 0.3395 - val_accuracy: 0.8462\n",
      "Epoch 338/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3639 - accuracy: 0.7000\n",
      "Epoch 00338: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1616 - accuracy: 0.8958 - val_loss: 0.3649 - val_accuracy: 0.8462\n",
      "Epoch 339/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2401 - accuracy: 0.9000\n",
      "Epoch 00339: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1637 - accuracy: 0.9167 - val_loss: 0.3923 - val_accuracy: 0.8462\n",
      "Epoch 340/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1570 - accuracy: 0.9000\n",
      "Epoch 00340: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1439 - accuracy: 0.9375 - val_loss: 0.3668 - val_accuracy: 0.8462\n",
      "Epoch 341/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3131 - accuracy: 0.8000\n",
      "Epoch 00341: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1886 - accuracy: 0.8958 - val_loss: 0.3765 - val_accuracy: 0.8462\n",
      "Epoch 342/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1407 - accuracy: 1.0000\n",
      "Epoch 00342: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1973 - accuracy: 0.9167 - val_loss: 0.3867 - val_accuracy: 0.8462\n",
      "Epoch 343/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1347 - accuracy: 1.0000\n",
      "Epoch 00343: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1169 - accuracy: 0.9583 - val_loss: 0.4304 - val_accuracy: 0.8462\n",
      "Epoch 344/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1241 - accuracy: 0.9000\n",
      "Epoch 00344: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1419 - accuracy: 0.9375 - val_loss: 0.5147 - val_accuracy: 0.8462\n",
      "Epoch 345/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4807 - accuracy: 0.6000\n",
      "Epoch 00345: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1777 - accuracy: 0.8958 - val_loss: 0.3690 - val_accuracy: 0.8462\n",
      "Epoch 346/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1098 - accuracy: 1.0000\n",
      "Epoch 00346: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1461 - accuracy: 0.9583 - val_loss: 0.2742 - val_accuracy: 0.8462\n",
      "Epoch 347/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3987 - accuracy: 0.8000\n",
      "Epoch 00347: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2316 - accuracy: 0.9167 - val_loss: 0.3192 - val_accuracy: 0.8462\n",
      "Epoch 348/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2742 - accuracy: 0.8000\n",
      "Epoch 00348: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1924 - accuracy: 0.9167 - val_loss: 0.4146 - val_accuracy: 0.8462\n",
      "Epoch 349/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1773 - accuracy: 1.0000\n",
      "Epoch 00349: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1762 - accuracy: 0.9167 - val_loss: 0.4101 - val_accuracy: 0.8462\n",
      "Epoch 350/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 00350: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1584 - accuracy: 0.9375 - val_loss: 0.3640 - val_accuracy: 0.8462\n",
      "Epoch 351/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1399 - accuracy: 0.9000\n",
      "Epoch 00351: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1054 - accuracy: 0.9375 - val_loss: 0.3806 - val_accuracy: 0.8462\n",
      "Epoch 352/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0600 - accuracy: 1.0000\n",
      "Epoch 00352: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1072 - accuracy: 0.9792 - val_loss: 0.3974 - val_accuracy: 0.8462\n",
      "Epoch 353/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1560 - accuracy: 0.9000\n",
      "Epoch 00353: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1054 - accuracy: 0.9583 - val_loss: 0.3675 - val_accuracy: 0.8462\n",
      "Epoch 354/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0490 - accuracy: 1.0000\n",
      "Epoch 00354: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0820 - accuracy: 0.9583 - val_loss: 0.4129 - val_accuracy: 0.8462\n",
      "Epoch 355/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1505 - accuracy: 0.9000\n",
      "Epoch 00355: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1581 - accuracy: 0.9167 - val_loss: 0.3431 - val_accuracy: 0.8462\n",
      "Epoch 356/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0802 - accuracy: 1.0000\n",
      "Epoch 00356: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1256 - accuracy: 0.9583 - val_loss: 0.3419 - val_accuracy: 0.8462\n",
      "Epoch 357/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3699 - accuracy: 0.9000\n",
      "Epoch 00357: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2195 - accuracy: 0.8958 - val_loss: 0.4675 - val_accuracy: 0.8462\n",
      "Epoch 358/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2200 - accuracy: 0.9000\n",
      "Epoch 00358: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1462 - accuracy: 0.9375 - val_loss: 0.6140 - val_accuracy: 0.8462\n",
      "Epoch 359/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2464 - accuracy: 0.9000\n",
      "Epoch 00359: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2806 - accuracy: 0.8542 - val_loss: 0.4298 - val_accuracy: 0.8462\n",
      "Epoch 360/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1653 - accuracy: 1.0000\n",
      "Epoch 00360: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1179 - accuracy: 0.9792 - val_loss: 0.3175 - val_accuracy: 0.8462\n",
      "Epoch 361/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1504 - accuracy: 0.9000\n",
      "Epoch 00361: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1447 - accuracy: 0.9375 - val_loss: 0.3951 - val_accuracy: 0.8462\n",
      "Epoch 362/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1310 - accuracy: 1.0000\n",
      "Epoch 00362: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1610 - accuracy: 0.9167 - val_loss: 0.4876 - val_accuracy: 0.8462\n",
      "Epoch 363/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1651 - accuracy: 1.0000\n",
      "Epoch 00363: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1669 - accuracy: 0.9167 - val_loss: 0.4349 - val_accuracy: 0.8462\n",
      "Epoch 364/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2721 - accuracy: 0.8000\n",
      "Epoch 00364: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1657 - accuracy: 0.9167 - val_loss: 0.2942 - val_accuracy: 0.8462\n",
      "Epoch 365/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0540 - accuracy: 1.0000\n",
      "Epoch 00365: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1840 - accuracy: 0.9375 - val_loss: 0.3389 - val_accuracy: 0.8462\n",
      "Epoch 366/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0504 - accuracy: 1.0000\n",
      "Epoch 00366: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1632 - accuracy: 0.9167 - val_loss: 0.4203 - val_accuracy: 0.8462\n",
      "Epoch 367/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1971 - accuracy: 0.9000\n",
      "Epoch 00367: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1441 - accuracy: 0.9167 - val_loss: 0.4010 - val_accuracy: 0.8462\n",
      "Epoch 368/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2385 - accuracy: 0.8000\n",
      "Epoch 00368: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2721 - accuracy: 0.8542 - val_loss: 0.3952 - val_accuracy: 0.8462\n",
      "Epoch 369/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0561 - accuracy: 1.0000\n",
      "Epoch 00369: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2647 - accuracy: 0.8750 - val_loss: 0.2796 - val_accuracy: 0.8462\n",
      "Epoch 370/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3529 - accuracy: 0.8000\n",
      "Epoch 00370: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1720 - accuracy: 0.9167 - val_loss: 0.3735 - val_accuracy: 0.8462\n",
      "Epoch 371/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1520 - accuracy: 1.0000\n",
      "Epoch 00371: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1140 - accuracy: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.8462\n",
      "Epoch 372/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1033 - accuracy: 0.9000\n",
      "Epoch 00372: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1912 - accuracy: 0.9375 - val_loss: 0.4104 - val_accuracy: 0.8462\n",
      "Epoch 373/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1550 - accuracy: 0.9000\n",
      "Epoch 00373: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1566 - accuracy: 0.9167 - val_loss: 0.3639 - val_accuracy: 0.8462\n",
      "Epoch 374/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2094 - accuracy: 0.9000\n",
      "Epoch 00374: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1594 - accuracy: 0.9375 - val_loss: 0.3064 - val_accuracy: 0.8462\n",
      "Epoch 375/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0747 - accuracy: 1.0000\n",
      "Epoch 00375: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1918 - accuracy: 0.9167 - val_loss: 0.3433 - val_accuracy: 0.8462\n",
      "Epoch 376/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0465 - accuracy: 1.0000\n",
      "Epoch 00376: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1092 - accuracy: 0.9583 - val_loss: 0.3683 - val_accuracy: 0.8462\n",
      "Epoch 377/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0383 - accuracy: 1.0000\n",
      "Epoch 00377: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1839 - accuracy: 0.8958 - val_loss: 0.4575 - val_accuracy: 0.8462\n",
      "Epoch 378/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2876 - accuracy: 0.7000\n",
      "Epoch 00378: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1396 - accuracy: 0.9167 - val_loss: 0.4407 - val_accuracy: 0.8462\n",
      "Epoch 379/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3206 - accuracy: 0.9000\n",
      "Epoch 00379: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1147 - accuracy: 0.9792 - val_loss: 0.3448 - val_accuracy: 0.8462\n",
      "Epoch 380/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0870 - accuracy: 1.0000\n",
      "Epoch 00380: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.3257 - val_accuracy: 0.8462\n",
      "Epoch 381/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0764 - accuracy: 1.0000\n",
      "Epoch 00381: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0979 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.8462\n",
      "Epoch 382/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 00382: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1541 - accuracy: 0.9375 - val_loss: 0.3395 - val_accuracy: 0.8462\n",
      "Epoch 383/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 00383: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0915 - accuracy: 0.9583 - val_loss: 0.3463 - val_accuracy: 0.8462\n",
      "Epoch 384/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2850 - accuracy: 0.8000\n",
      "Epoch 00384: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1978 - accuracy: 0.8958 - val_loss: 0.4113 - val_accuracy: 0.8462\n",
      "Epoch 385/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4892 - accuracy: 0.8000\n",
      "Epoch 00385: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1901 - accuracy: 0.9375 - val_loss: 0.3909 - val_accuracy: 0.8462\n",
      "Epoch 386/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 00386: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0983 - accuracy: 0.9792 - val_loss: 0.3365 - val_accuracy: 0.8462\n",
      "Epoch 387/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0545 - accuracy: 1.0000\n",
      "Epoch 00387: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0877 - accuracy: 0.9792 - val_loss: 0.3162 - val_accuracy: 0.8462\n",
      "Epoch 388/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1159 - accuracy: 1.0000\n",
      "Epoch 00388: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0961 - accuracy: 0.9792 - val_loss: 0.3322 - val_accuracy: 0.8462\n",
      "Epoch 389/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0810 - accuracy: 1.0000\n",
      "Epoch 00389: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0890 - accuracy: 0.9792 - val_loss: 0.3553 - val_accuracy: 0.8462\n",
      "Epoch 390/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1041 - accuracy: 1.0000\n",
      "Epoch 00390: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2062 - accuracy: 0.9375 - val_loss: 0.4109 - val_accuracy: 0.8462\n",
      "Epoch 391/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2619 - accuracy: 0.9000\n",
      "Epoch 00391: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0994 - accuracy: 0.9792 - val_loss: 0.3545 - val_accuracy: 0.8462\n",
      "Epoch 392/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2410 - accuracy: 0.9000\n",
      "Epoch 00392: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1497 - accuracy: 0.9583 - val_loss: 0.2990 - val_accuracy: 0.8462\n",
      "Epoch 393/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1336 - accuracy: 1.0000\n",
      "Epoch 00393: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1012 - accuracy: 0.9583 - val_loss: 0.3297 - val_accuracy: 0.8462\n",
      "Epoch 394/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0807 - accuracy: 1.0000\n",
      "Epoch 00394: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0911 - accuracy: 0.9792 - val_loss: 0.4079 - val_accuracy: 0.8462\n",
      "Epoch 395/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0569 - accuracy: 1.0000\n",
      "Epoch 00395: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1585 - accuracy: 0.9375 - val_loss: 0.3787 - val_accuracy: 0.8462\n",
      "Epoch 396/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1867 - accuracy: 0.9000\n",
      "Epoch 00396: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1409 - accuracy: 0.9583 - val_loss: 0.3681 - val_accuracy: 0.8462\n",
      "Epoch 397/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1201 - accuracy: 0.9000\n",
      "Epoch 00397: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1478 - accuracy: 0.9375 - val_loss: 0.3284 - val_accuracy: 0.8462\n",
      "Epoch 398/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0907 - accuracy: 1.0000\n",
      "Epoch 00398: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2184 - accuracy: 0.9167 - val_loss: 0.4169 - val_accuracy: 0.8462\n",
      "Epoch 399/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0704 - accuracy: 1.0000\n",
      "Epoch 00399: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1627 - accuracy: 0.9375 - val_loss: 0.3849 - val_accuracy: 0.8462\n",
      "Epoch 400/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2213 - accuracy: 0.8000\n",
      "Epoch 00400: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1817 - accuracy: 0.8958 - val_loss: 0.3016 - val_accuracy: 0.8462\n",
      "Epoch 401/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 00401: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1861 - accuracy: 0.9375 - val_loss: 0.3141 - val_accuracy: 0.8462\n",
      "Epoch 402/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0836 - accuracy: 1.0000\n",
      "Epoch 00402: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1889 - accuracy: 0.9375 - val_loss: 0.3585 - val_accuracy: 0.8462\n",
      "Epoch 403/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1094 - accuracy: 0.9000\n",
      "Epoch 00403: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1904 - accuracy: 0.8958 - val_loss: 0.3104 - val_accuracy: 0.8462\n",
      "Epoch 404/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0699 - accuracy: 1.0000\n",
      "Epoch 00404: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1941 - accuracy: 0.9167 - val_loss: 0.3351 - val_accuracy: 0.8462\n",
      "Epoch 405/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3058 - accuracy: 0.8000\n",
      "Epoch 00405: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1956 - accuracy: 0.9167 - val_loss: 0.4011 - val_accuracy: 0.8462\n",
      "Epoch 406/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 00406: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1661 - accuracy: 0.9583 - val_loss: 0.2716 - val_accuracy: 0.8462\n",
      "Epoch 407/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1480 - accuracy: 0.9000\n",
      "Epoch 00407: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1727 - accuracy: 0.9375 - val_loss: 0.2318 - val_accuracy: 0.8462\n",
      "Epoch 408/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0900 - accuracy: 1.0000\n",
      "Epoch 00408: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1545 - accuracy: 0.9583 - val_loss: 0.2978 - val_accuracy: 0.8462\n",
      "Epoch 409/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0718 - accuracy: 1.0000\n",
      "Epoch 00409: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1165 - accuracy: 0.9583 - val_loss: 0.3436 - val_accuracy: 0.8462\n",
      "Epoch 410/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1016 - accuracy: 0.9000\n",
      "Epoch 00410: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1021 - accuracy: 0.9583 - val_loss: 0.3784 - val_accuracy: 0.8462\n",
      "Epoch 411/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1400 - accuracy: 0.9000\n",
      "Epoch 00411: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1489 - accuracy: 0.9375 - val_loss: 0.3215 - val_accuracy: 0.8462\n",
      "Epoch 412/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2594 - accuracy: 0.8000\n",
      "Epoch 00412: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1319 - accuracy: 0.9167 - val_loss: 0.2671 - val_accuracy: 0.8462\n",
      "Epoch 413/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0577 - accuracy: 1.0000\n",
      "Epoch 00413: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2526 - accuracy: 0.9375 - val_loss: 0.3090 - val_accuracy: 0.8462\n",
      "Epoch 414/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2876 - accuracy: 0.9000\n",
      "Epoch 00414: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1680 - accuracy: 0.9375 - val_loss: 0.3755 - val_accuracy: 0.8462\n",
      "Epoch 415/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0880 - accuracy: 1.0000\n",
      "Epoch 00415: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1121 - accuracy: 0.9792 - val_loss: 0.2845 - val_accuracy: 0.8462\n",
      "Epoch 416/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0542 - accuracy: 1.0000\n",
      "Epoch 00416: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1283 - accuracy: 0.9583 - val_loss: 0.2552 - val_accuracy: 0.8462\n",
      "Epoch 417/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1687 - accuracy: 1.0000\n",
      "Epoch 00417: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1206 - accuracy: 0.9792 - val_loss: 0.3202 - val_accuracy: 0.8462\n",
      "Epoch 418/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1318 - accuracy: 0.9000\n",
      "Epoch 00418: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0824 - accuracy: 0.9792 - val_loss: 0.3377 - val_accuracy: 0.8462\n",
      "Epoch 419/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2050 - accuracy: 0.9000\n",
      "Epoch 00419: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2179 - accuracy: 0.8958 - val_loss: 0.3725 - val_accuracy: 0.8462\n",
      "Epoch 420/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0566 - accuracy: 1.0000\n",
      "Epoch 00420: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1869 - accuracy: 0.9375 - val_loss: 0.3044 - val_accuracy: 0.8462\n",
      "Epoch 421/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2370 - accuracy: 0.9000\n",
      "Epoch 00421: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2059 - accuracy: 0.9375 - val_loss: 0.2737 - val_accuracy: 0.8462\n",
      "Epoch 422/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 00422: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2102 - accuracy: 0.9375 - val_loss: 0.4860 - val_accuracy: 0.8462\n",
      "Epoch 423/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0735 - accuracy: 1.0000\n",
      "Epoch 00423: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2194 - accuracy: 0.9375 - val_loss: 0.3846 - val_accuracy: 0.8462\n",
      "Epoch 424/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1760 - accuracy: 1.0000\n",
      "Epoch 00424: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1117 - accuracy: 0.9792 - val_loss: 0.2185 - val_accuracy: 0.8462\n",
      "Epoch 425/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2064 - accuracy: 0.9000\n",
      "Epoch 00425: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1583 - accuracy: 0.9167 - val_loss: 0.2327 - val_accuracy: 0.8462\n",
      "Epoch 426/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3438 - accuracy: 0.8000\n",
      "Epoch 00426: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1746 - accuracy: 0.9167 - val_loss: 0.3614 - val_accuracy: 0.8462\n",
      "Epoch 427/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0953 - accuracy: 1.0000\n",
      "Epoch 00427: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0923 - accuracy: 0.9792 - val_loss: 0.4039 - val_accuracy: 0.8462\n",
      "Epoch 428/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0804 - accuracy: 1.0000\n",
      "Epoch 00428: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1271 - accuracy: 0.9375 - val_loss: 0.3497 - val_accuracy: 0.8462\n",
      "Epoch 429/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2777 - accuracy: 0.9000\n",
      "Epoch 00429: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1398 - accuracy: 0.9583 - val_loss: 0.2729 - val_accuracy: 0.8462\n",
      "Epoch 430/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1465 - accuracy: 0.9000\n",
      "Epoch 00430: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1070 - accuracy: 0.9375 - val_loss: 0.2067 - val_accuracy: 0.8462\n",
      "Epoch 431/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0732 - accuracy: 1.0000\n",
      "Epoch 00431: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1176 - accuracy: 0.9375 - val_loss: 0.2956 - val_accuracy: 0.8462\n",
      "Epoch 432/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0521 - accuracy: 1.0000\n",
      "Epoch 00432: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2666 - accuracy: 0.8750 - val_loss: 0.3618 - val_accuracy: 0.8462\n",
      "Epoch 433/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0596 - accuracy: 1.0000\n",
      "Epoch 00433: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1194 - accuracy: 0.9375 - val_loss: 0.3010 - val_accuracy: 0.8462\n",
      "Epoch 434/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1761 - accuracy: 0.9000\n",
      "Epoch 00434: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1346 - accuracy: 0.9583 - val_loss: 0.2730 - val_accuracy: 0.8462\n",
      "Epoch 435/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1202 - accuracy: 0.9000\n",
      "Epoch 00435: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0886 - accuracy: 0.9583 - val_loss: 0.3260 - val_accuracy: 0.8462\n",
      "Epoch 436/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 00436: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1944 - accuracy: 0.9792 - val_loss: 0.3419 - val_accuracy: 0.8462\n",
      "Epoch 437/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0533 - accuracy: 1.0000\n",
      "Epoch 00437: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0928 - accuracy: 0.9792 - val_loss: 0.2433 - val_accuracy: 0.8462\n",
      "Epoch 438/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0954 - accuracy: 1.0000\n",
      "Epoch 00438: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1066 - accuracy: 0.9583 - val_loss: 0.2590 - val_accuracy: 0.8462\n",
      "Epoch 439/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 00439: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1550 - accuracy: 0.9167 - val_loss: 0.3257 - val_accuracy: 0.8462\n",
      "Epoch 440/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4960 - accuracy: 0.9000\n",
      "Epoch 00440: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2131 - accuracy: 0.9583 - val_loss: 0.3369 - val_accuracy: 0.8462\n",
      "Epoch 441/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0407 - accuracy: 1.0000\n",
      "Epoch 00441: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.2539 - val_accuracy: 0.8462\n",
      "Epoch 442/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1805 - accuracy: 0.9000\n",
      "Epoch 00442: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1825 - accuracy: 0.8958 - val_loss: 0.3180 - val_accuracy: 0.8462\n",
      "Epoch 443/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1210 - accuracy: 1.0000\n",
      "Epoch 00443: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1026 - accuracy: 0.9583 - val_loss: 0.3632 - val_accuracy: 0.8462\n",
      "Epoch 444/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0575 - accuracy: 1.0000\n",
      "Epoch 00444: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0907 - accuracy: 0.9583 - val_loss: 0.2928 - val_accuracy: 0.8462\n",
      "Epoch 445/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 00445: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1870 - accuracy: 0.8958 - val_loss: 0.3064 - val_accuracy: 0.8462\n",
      "Epoch 446/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1023 - accuracy: 1.0000\n",
      "Epoch 00446: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0874 - accuracy: 0.9792 - val_loss: 0.5073 - val_accuracy: 0.8462\n",
      "Epoch 447/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1530 - accuracy: 0.9000\n",
      "Epoch 00447: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1802 - accuracy: 0.8958 - val_loss: 0.4382 - val_accuracy: 0.8462\n",
      "Epoch 448/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 00448: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1075 - accuracy: 0.9792 - val_loss: 0.2555 - val_accuracy: 0.8462\n",
      "Epoch 449/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1945 - accuracy: 1.0000\n",
      "Epoch 00449: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1205 - accuracy: 0.9583 - val_loss: 0.2519 - val_accuracy: 0.8462\n",
      "Epoch 450/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1379 - accuracy: 0.9000\n",
      "Epoch 00450: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1804 - accuracy: 0.9167 - val_loss: 0.3474 - val_accuracy: 0.8462\n",
      "Epoch 451/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0186 - accuracy: 1.0000\n",
      "Epoch 00451: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1600 - accuracy: 0.9167 - val_loss: 0.2877 - val_accuracy: 0.8462\n",
      "Epoch 452/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0958 - accuracy: 0.9000\n",
      "Epoch 00452: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1345 - accuracy: 0.9167 - val_loss: 0.2373 - val_accuracy: 0.8462\n",
      "Epoch 453/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0867 - accuracy: 1.0000\n",
      "Epoch 00453: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0764 - accuracy: 0.9792 - val_loss: 0.2668 - val_accuracy: 0.8462\n",
      "Epoch 454/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1827 - accuracy: 1.0000\n",
      "Epoch 00454: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1164 - accuracy: 0.9792 - val_loss: 0.3335 - val_accuracy: 0.8462\n",
      "Epoch 455/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0560 - accuracy: 1.0000\n",
      "Epoch 00455: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1376 - accuracy: 0.9375 - val_loss: 0.3669 - val_accuracy: 0.8462\n",
      "Epoch 456/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 00456: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1175 - accuracy: 0.9792 - val_loss: 0.2553 - val_accuracy: 0.8462\n",
      "Epoch 457/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 00457: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0751 - accuracy: 0.9792 - val_loss: 0.2103 - val_accuracy: 0.8462\n",
      "Epoch 458/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1336 - accuracy: 0.9000\n",
      "Epoch 00458: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1714 - accuracy: 0.9167 - val_loss: 0.3218 - val_accuracy: 0.8462\n",
      "Epoch 459/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1963 - accuracy: 0.9000\n",
      "Epoch 00459: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1484 - accuracy: 0.9583 - val_loss: 0.4200 - val_accuracy: 0.8462\n",
      "Epoch 460/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2310 - accuracy: 0.8000\n",
      "Epoch 00460: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1416 - accuracy: 0.9167 - val_loss: 0.2689 - val_accuracy: 0.8462\n",
      "Epoch 461/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2426 - accuracy: 0.8000\n",
      "Epoch 00461: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2573 - accuracy: 0.8542 - val_loss: 0.2013 - val_accuracy: 0.8462\n",
      "Epoch 462/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1819 - accuracy: 0.8000\n",
      "Epoch 00462: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0878 - accuracy: 0.9583 - val_loss: 0.3805 - val_accuracy: 0.8462\n",
      "Epoch 463/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 00463: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1050 - accuracy: 0.9375 - val_loss: 0.3611 - val_accuracy: 0.8462\n",
      "Epoch 464/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1431 - accuracy: 0.9000\n",
      "Epoch 00464: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1063 - accuracy: 0.9375 - val_loss: 0.2528 - val_accuracy: 0.8462\n",
      "Epoch 465/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3369 - accuracy: 0.9000\n",
      "Epoch 00465: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1189 - accuracy: 0.9792 - val_loss: 0.2141 - val_accuracy: 0.8462\n",
      "Epoch 466/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1536 - accuracy: 0.9000\n",
      "Epoch 00466: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0874 - accuracy: 0.9583 - val_loss: 0.2715 - val_accuracy: 0.8462\n",
      "Epoch 467/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0999 - accuracy: 1.0000\n",
      "Epoch 00467: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1070 - accuracy: 0.9583 - val_loss: 0.2558 - val_accuracy: 0.8462\n",
      "Epoch 468/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0770 - accuracy: 1.0000\n",
      "Epoch 00468: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1269 - accuracy: 0.9583 - val_loss: 0.2726 - val_accuracy: 0.8462\n",
      "Epoch 469/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0341 - accuracy: 1.0000\n",
      "Epoch 00469: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0644 - accuracy: 0.9792 - val_loss: 0.3109 - val_accuracy: 0.8462\n",
      "Epoch 470/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0888 - accuracy: 1.0000\n",
      "Epoch 00470: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2367 - accuracy: 0.9167 - val_loss: 0.3594 - val_accuracy: 0.8462\n",
      "Epoch 471/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1592 - accuracy: 0.9000\n",
      "Epoch 00471: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1686 - accuracy: 0.9583 - val_loss: 0.2861 - val_accuracy: 0.8462\n",
      "Epoch 472/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1359 - accuracy: 0.9000\n",
      "Epoch 00472: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1846 - accuracy: 0.9375 - val_loss: 0.2263 - val_accuracy: 0.8462\n",
      "Epoch 473/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1618 - accuracy: 0.9000\n",
      "Epoch 00473: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1588 - accuracy: 0.9583 - val_loss: 0.2848 - val_accuracy: 0.8462\n",
      "Epoch 474/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 00474: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1455 - accuracy: 0.8958 - val_loss: 0.2740 - val_accuracy: 0.8462\n",
      "Epoch 475/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0890 - accuracy: 0.9000\n",
      "Epoch 00475: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0545 - accuracy: 0.9792 - val_loss: 0.2734 - val_accuracy: 0.8462\n",
      "Epoch 476/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2133 - accuracy: 0.9000\n",
      "Epoch 00476: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1327 - accuracy: 0.9167 - val_loss: 0.3135 - val_accuracy: 0.8462\n",
      "Epoch 477/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4266 - accuracy: 0.9000\n",
      "Epoch 00477: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1794 - accuracy: 0.9167 - val_loss: 0.1590 - val_accuracy: 0.8462\n",
      "Epoch 478/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 00478: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4199 - accuracy: 0.8333 - val_loss: 0.1400 - val_accuracy: 0.8462\n",
      "Epoch 479/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1571 - accuracy: 0.9000\n",
      "Epoch 00479: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1081 - accuracy: 0.9375 - val_loss: 0.3932 - val_accuracy: 0.8462\n",
      "Epoch 480/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2217 - accuracy: 0.9000\n",
      "Epoch 00480: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3324 - accuracy: 0.9167 - val_loss: 0.4168 - val_accuracy: 0.8462\n",
      "Epoch 481/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2423 - accuracy: 0.9000\n",
      "Epoch 00481: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1466 - accuracy: 0.9375 - val_loss: 0.2161 - val_accuracy: 0.8462\n",
      "Epoch 482/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0432 - accuracy: 1.0000\n",
      "Epoch 00482: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1073 - accuracy: 0.9375 - val_loss: 0.1571 - val_accuracy: 0.8462\n",
      "Epoch 483/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1707 - accuracy: 0.9000\n",
      "Epoch 00483: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1734 - accuracy: 0.9583 - val_loss: 0.2688 - val_accuracy: 0.8462\n",
      "Epoch 484/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0686 - accuracy: 1.0000\n",
      "Epoch 00484: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0980 - accuracy: 0.9583 - val_loss: 0.3994 - val_accuracy: 0.8462\n",
      "Epoch 485/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2016 - accuracy: 0.9000\n",
      "Epoch 00485: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0856 - accuracy: 0.9792 - val_loss: 0.3804 - val_accuracy: 0.8462\n",
      "Epoch 486/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 00486: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1581 - accuracy: 0.9375 - val_loss: 0.2523 - val_accuracy: 0.8462\n",
      "Epoch 487/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0889 - accuracy: 1.0000\n",
      "Epoch 00487: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0845 - accuracy: 0.9792 - val_loss: 0.2279 - val_accuracy: 0.8462\n",
      "Epoch 488/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1549 - accuracy: 0.9000\n",
      "Epoch 00488: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0899 - accuracy: 0.9375 - val_loss: 0.3307 - val_accuracy: 0.8462\n",
      "Epoch 489/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0445 - accuracy: 1.0000\n",
      "Epoch 00489: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1518 - accuracy: 0.9375 - val_loss: 0.2785 - val_accuracy: 0.8462\n",
      "Epoch 490/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1333 - accuracy: 0.9000\n",
      "Epoch 00490: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0895 - accuracy: 0.9583 - val_loss: 0.1927 - val_accuracy: 0.8462\n",
      "Epoch 491/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 00491: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1190 - accuracy: 0.9375 - val_loss: 0.2439 - val_accuracy: 0.8462\n",
      "Epoch 492/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0551 - accuracy: 1.0000\n",
      "Epoch 00492: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1460 - accuracy: 0.9375 - val_loss: 0.3482 - val_accuracy: 0.8462\n",
      "Epoch 493/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0917 - accuracy: 0.9000\n",
      "Epoch 00493: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1420 - accuracy: 0.9167 - val_loss: 0.3126 - val_accuracy: 0.8462\n",
      "Epoch 494/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0501 - accuracy: 1.0000\n",
      "Epoch 00494: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1367 - accuracy: 0.9583 - val_loss: 0.2928 - val_accuracy: 0.8462\n",
      "Epoch 495/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2379 - accuracy: 0.8000\n",
      "Epoch 00495: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1396 - accuracy: 0.9375 - val_loss: 0.2708 - val_accuracy: 0.8462\n",
      "Epoch 496/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2329 - accuracy: 0.8000\n",
      "Epoch 00496: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0853 - accuracy: 0.9583 - val_loss: 0.2408 - val_accuracy: 0.8462\n",
      "Epoch 497/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 00497: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0893 - accuracy: 0.9792 - val_loss: 0.2784 - val_accuracy: 0.8462\n",
      "Epoch 498/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0470 - accuracy: 1.0000\n",
      "Epoch 00498: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.8462\n",
      "Epoch 499/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 00499: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1230 - accuracy: 0.9583 - val_loss: 0.3294 - val_accuracy: 0.8462\n",
      "Epoch 500/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0913 - accuracy: 1.0000\n",
      "Epoch 00500: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.0721 - accuracy: 0.9792 - val_loss: 0.2746 - val_accuracy: 0.8462\n",
      "Training completed in time:  0:00:33.419432\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.875\n",
      "Testing Accuracy:  0.6363636\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.40      0.67      0.50         3\n",
      "   Pneumonia       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.64        11\n",
      "   macro avg       0.62      0.65      0.61        11\n",
      "weighted avg       0.72      0.64      0.66        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [3 5]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
