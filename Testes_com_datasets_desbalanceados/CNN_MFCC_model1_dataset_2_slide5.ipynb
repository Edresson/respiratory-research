{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 1\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 2 - slide5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'slide5'\n",
    "GROUP_TEST = 'slide5'\n",
    "DATASET = 'dataset_2'\n",
    "DURATION = 5\n",
    "SIZE = 216\n",
    "CSV_TRAIN = 'train2.csv'\n",
    "CSV_TEST = 'test2.csv'\n",
    "MODEL_NAME = f'CNN1_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  123  Healthy\n",
       "1  125  Healthy\n",
       "2  126  Healthy\n",
       "3  127  Healthy\n",
       "4  136  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  896  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['256' '192']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['24' '104']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAHwCAYAAABkJOM0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3de7xtZV0v/s9XMbVA0NgSIIoXPIoexdqSohml5eXYMfop4SlF80Se4yUvpzLrZFmWnmNaXovSxDIVFQqTzEveMm+gKIKapJggAt7hKCrw/f0xx4LpYq291372nnutBe/36zVfa85njPHM75hrrLk+85nPHLO6OwAAwI673noXAAAAm5UwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYhmuJqvqzqvrf613HZldVZ1XVketdx86oqndW1X/fwW2uOn6q6siqOm8Bdd2wqs6uqv13dd+72qIeg2uLqnpCVT1nveuAjUCYhk2gqs6tqm9V1SVV9bWq+teqemxVXfU33N2P7e7fX88616qq9q+ql1XVBdM+fbKqfq+qfmDB9/u7VfU321qnu+/U3e8c7P8hVXVGVX2jqr5UVf9cVbceKnZBpsfgu1V16dzl13fT8XNcknd39wVTLa+oqq6qw+fqu11V7dQXIEz72FX1ozuwTVfV7XbmfjeKqnpUVf3LKsveWVWXTb/3L1XVSdPf49PnjofLquqKudtnTdvOP0Z/keQXqurmu2u/YKMSpmHz+Jnu3ivJrZI8O8lvJHnZ+pa046rqZknel+TGSe457dNPJdknyW3Xs7adMYWMVyZ5apK9k9w6yYuTXLGeda3itd2959zl/+ym+31skr9e1vaVJH+wq+6gqirJI6d+H7mr+t2oqmqPgc0e3917Jrldkj2TPLe7/3DpeMjs9/S+uePjTss76O7LkvxjrgOPMWyPMA2bTHd/vbtPSfLzSY6tqjsnV43y/cF0fd+q+odpFPsrVfWepVHsqjqgqt5QVRdX1Wer6olLfVfV4VX1vmm7C6rqRVX1fdOyqqrnV9VF08jrmXP3fcOqem5V/UdVXThNGbjxKrvwlCSXJPnF7j532qfPd/evdvfHpv6OqKoPVdXXp59HzNV4blXdb+72VaPNVXXwNHp27FTLl6rqt6ZlD0jy9CQ/P422fXSl4ub7n/o+sapeOY2gn1VVW1fZr8OSfLa7394zl3T3G7r7P+Yeoz+pqi9Mlz+pqhtOy64xkjg/Cjj9bl9cVW+a6vhAVd12bt2fqtno/ter6kVJapUaVzV//KywbHvHzGnTMXFhVT1vlT5umeQ2ST6wbNEJSe5SVT++jfs+ZTqOz6mqX97OrvxYkv2TPDHJMUvH79TX7arqXdPj9KWqeu3U/u5plY9Ox8bPz23z1OmYv6CqHj3X/oqqeklV/eO0zXur6oem3+tXp9/H3ebWf1pV/fv0+zu7qo5abQe2c6wcWVXnVdVvVNUXk/zVdh6PVXX315L8XWbH7oh3Jvkvo/cP1xbCNGxS3f3BJOdlFh6We+q0bEuS/TILkV2zQP3GJB9NcmCS+yZ5UlXdf9ruiiRPTrJvkntOy//ntOynk9wnye0zG3k9OsmXp2XPntoPy2y068Akv7NK6fdLclJ3X7nSwpqNXL8pyQuS/GCS5yV5U1X94OqPxjXcO8l/mur/naq6Y3e/Ockf5upR2buusa//muQ1mY2cn5LkRaus9+Ekd5hecPxEVe25bPlvJblHZo/RXZMcnuS3d2Cfjknye0lumuScJM9KZi+ckpw09bVvkn9Pcq8d6Heb1nDM/GmSP+3um2T2zsKJq3T1n5N8prsvX9b+zcx+L89aZbvXZHYsH5DkoUn+sKp+chslHzvVu1THz8wt+/0kb8nsMbxFkhcmSXffZ1p+1+nYeO10+4cyO9YPTPKYJC+uqpvO9Xd0rn7cv53ZOy4fnm6/PrNjd8m/Z/a3undmv8e/qdXnjm/vWPmhJDfL7F2q41Z/KLZt+pv6ucyOpxGfmOqD6zRhGja3L2T2T3W572Y2Oner7v5ud7+nuzvJ3ZNs6e5ndvd3uvszmc19PCZJuvv07n5/d18+jRr/eZIfn+tzryR3SFLd/YnuvqCqKrN/6E/u7q909yWZhaNjVqn5B5NcsI19+i9JPt3dfz3V8eokn8z3hqLt+b3u/lZ3fzSzELgz//D/pbtP7e4rMpuisGJf02N5ZGbB68QkX5pGL5dC9S8keWZ3X9TdF2cWqB6xA3Wc3N0fnMLoq3L1aOKDkpzV3a/v7u8m+ZMkX9xOX0fX7N2HpcsB21h3m8dMZsfF7apq3+6+tLvfv0o/+2T2jsRK/jzJLavqgfONVXVQZi8MfqO7L+vuM5L8ZVaZWlBV35/kYUn+dnosXr9s3e9mFkAPmPpbcV7xsvWfOf0NnZrk0sxepC05efqbuSzJyUku6+5XTsfKa5NcNTLd3a/r7i9095VTWP90ZiF5Jds7Vq5M8ozu/nZ3f2s7+7CSF1TV15N8KbPg/4SBPpLZ73PvwW3hWkOYhs3twMzmhi73fzMbbXpLVX2mqp42td8qyQHzQSqzUev9kqSqbl+z6SFfrKpvZBaK902S7v7nzEZlX5zkoqo6vqpuktno9/cnOX2uzzdP7Sv5cmZBfzUHJPncsrbPTfu6VvNh8puZzQsdtbyvG9Uq81SnFyJHd/eWzEYh75PZKGNyzf363NQ2WsfSPh2Q5PNzNfT87VWc2N37zF2+sI11t3nMZDZie/skn6zZlJwHr9LPVzN7MXYN3f3tzEaNl38A8oAkSy/QlmzrWDgqyeVJTp1uvyrJA6tq6Vj89cymwHywZlN2fmmVfpZ8edlI+vJj6cK5699a4fZV61bVI2v24dSlx/DOmf62VrC9Y+XiKcCPemJ3753kLrl6lH7EXkm+vhN1wLWCMA2bVFXdPbNQcY3RtWm+7lO7+zaZTVN4SlXdN7OQ9dllQWqv7n7QtOlLMxsFPmR62/7pmZt/290v6O4fSXJoZgHq1zIb3fpWkjvN9bn39EGmlbwtyVE1dyaSZb6QWYCbd8sk50/X/19m4X3JD63Sz0p26iwRO6K7P5TZ9Is7T03L9+uWU1uybJ+qakf26YIkB81tW/O3d4FtHjPd/enufniSmyd5TpLX18pnZflYkluv9kIks7m/+2Q27WDJF5LcrKrmQ/j8sbDcsZkF2P+Y5hO/LskNkvy3qdYvdvcvd/cBSX4lyUtqN5zBo6puldlo/uOT/GB375Pk41l9bvu2jpVkFx3H3X1mZh/+fPF03OyoO2b2zg9cpwnTsMlU1U2m0b/XJPmb6R/i8nUePH3YqjIbObois7eGP5jkkunDSzeuqutX1Z2nYJ7MRpq+keTSqrpDkv8x1+fdq+pHq+oGmYW/y5JcOc19/oskz6/pNFlVdeDcnNrlnpfkJklOmELG0vrPq6q7ZDaqePuq+m9Vtcf0YbBDk/zDtP0ZmX2w7AY1+zDgQ3fg4bswycHbCPLDqureVfXLc4/BHTJ7IbM07eHVSX67qrZM85x/J8nSafo+muROVXVYVd0oye/uwF2/adr256ag+sTs2AuM7dnmMVNVv1hVW6bj4GvTNteYD9/d52X2bsmKUxumEeBnZHaWmqW2zyf51yR/VFU3mo6Px+Tqx+0qVbU0n/vBmU2BWZpv/JxMUz2q6mFVtTQK+9XMQulSrRdm9gHJRfiB6b4unup4dK5+kbWSbR0ra1XTY3bVZZX1TsjsXYb/uoP9J7MpYP84sB1cqwjTsHm8saouyWyk8LcyC6WPXmXdQzIbAb40sw9FvaS73zHN5VwKG5/NbFT5L3P1vMf/ldko3iWZBeTXzvV5k6ntq5m97fzlzKaTJLMAdE6S90/TQ96W751bepXu/kqSIzKbj/qBaZ/enlnoP6e7vzzV+NTpPn49yYO7+0tTF/87sw+6fTWzuaR/u+ojdk2vm35+uao+vAPbrcXXMgskZ1bVpZlNdTk5ydJp5/4gyWmZjdCemdkH1f4gSbr735I8M7PH7dNZ4d2G1UyPy8My+xDolzP73b9353fnqv63d8w8IMlZ0z7/aZJjtjGP98+z7Xnir84159M/PMnBmY3MnpzZXOG3rbDtI5Kc0d1vmUagv9jdX8zsg6x3qdmZZ+6e2TF3aWYfJv3VaQ54MnsBc8I0DePobdS4w7r77CR/nNnf4oWZfRhzW7+jVY+VHXBEZu8YXXVZ6V2B7v5OZr+3HfrCpymcPyizMA7XaTWbXgcAi1Wz07t9JMl9e/riFjanqnpCkoO6+9fXuxZYb8I0AAAMMs0DAAAGCdMAADBImAYAgEHCNAAADFrt5Pmbwr777tsHH3zwepcBAMC13Omnn/6l6Rtuv8emDtMHH3xwTjvttPUuAwCAa7mq+txK7aZ5AADAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMGiP9S5gs3r+W/9tvUsANpkn/9Tt17sEAHYxI9MAADBImAYAgEHCNAAADBKmAQBgkDANAACDFhamq+qgqnpHVZ1dVWdV1a9O7b9bVedX1RnT5UFz2/xmVZ1TVZ+qqvsvqjYAANgVFnlqvMuTPLW7P1xVeyU5vareOi17fnc/d37lqjo0yTFJ7pTkgCRvq6rbd/cVC6wRAACGLWxkursv6O4PT9cvSfKJJAduY5OHJHlNd3+7uz+b5Jwkhy+qPgAA2Fm7Zc50VR2c5G5JPjA1Pb6qPlZVL6+qm05tByb5/Nxm52WF8F1Vx1XVaVV12sUXX7zAqgEAYNsWHqaras8kb0jypO7+RpKXJrltksOSXJDkj3ekv+4+vru3dvfWLVu27PJ6AQBgrRYapqvqBpkF6Vd190lJ0t0XdvcV3X1lkr/I1VM5zk9y0Nzmt5jaAABgQ1rk2TwqycuSfKK7nzfXvv/cakcl+fh0/ZQkx1TVDavq1kkOSfLBRdUHAAA7a5Fn87hXkkckObOqzpjanp7k4VV1WJJOcm6SX0mS7j6rqk5McnZmZwJ5nDN5AACwkS0sTHf3vySpFRaduo1tnpXkWYuqCQAAdiXfgAgAAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGDQwsJ0VR1UVe+oqrOr6qyq+tWp/WZV9daq+vT086ZTe1XVC6rqnKr6WFX98KJqAwCAXWGRI9OXJ3lqdx+a5B5JHldVhyZ5WpK3d/chSd4+3U6SByY5ZLocl+SlC6wNAAB22sLCdHdf0N0fnq5fkuQTSQ5M8pAkJ0yrnZDkZ6frD0nyyp55f5J9qmr/RdUHAAA7a7fMma6qg5PcLckHkuzX3RdMi76YZL/p+oFJPj+32XlT2/K+jquq06rqtIsvvnhhNQMAwPYsPExX1Z5J3pDkSd39jfll3d1Jekf66+7ju3trd2/dsmXLLqwUAAB2zELDdFXdILMg/aruPmlqvnBp+sb086Kp/fwkB81tfoupDQAANqRFns2jkrwsySe6+3lzi05Jcux0/dgkfz/X/sjprB73SPL1uekgAACw4eyxwL7vleQRSc6sqjOmtqcneXaSE6vqMUk+l+ToadmpSR6U5Jwk30zy6AXWBgAAO21hYbq7/yVJrbL4vius30ket6h6AABgV/MNiAAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAoEV+aQsArOr5b/239S4B2GSe/FO3X+8SrsHINAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMGhhYbqqXl5VF1XVx+fafreqzq+qM6bLg+aW/WZVnVNVn6qq+y+qLgAA2FUWOTL9iiQPWKH9+d192HQ5NUmq6tAkxyS507TNS6rq+gusDQAAdtrCwnR3vzvJV9a4+kOSvKa7v93dn01yTpLDF1UbAADsCusxZ/rxVfWxaRrITae2A5N8fm6d86Y2AADYsHZ3mH5pktsmOSzJBUn+eEc7qKrjquq0qjrt4osv3tX1AQDAmu3WMN3dF3b3Fd19ZZK/yNVTOc5PctDcqreY2lbq4/ju3trdW7ds2bLYggEAYBt2a5iuqv3nbh6VZOlMH6ckOaaqblhVt05ySJIP7s7aAABgR+2xqI6r6tVJjkyyb1Wdl+QZSY6sqsOSdJJzk/xKknT3WVV1YpKzk1ye5HHdfcWiagMAgF1hYWG6ux++QvPLtrH+s5I8a1H1AADAruYbEAEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQWsK01V1r7W0AQDAdclaR6ZfuMY2AAC4ztjmNyBW1T2THJFkS1U9ZW7RTZJcf5GFAQDARre9rxP/viR7TuvtNdf+jSQPXVRRAACwGWwzTHf3u5K8q6pe0d2f2001AQDAprC9keklN6yq45McPL9Nd//kIooCAIDNYK1h+nVJ/izJXya5YnHlAADA5rHWMH15d790oZUAAMAms9ZT472xqv5nVe1fVTdbuiy0MgAA2ODWOjJ97PTz1+baOsltdm05AACweawpTHf3rRddCAAAbDZrCtNV9ciV2rv7lbu2HAAA2DzWOs3j7nPXb5Tkvkk+nESYBgDgOmut0zyeMH+7qvZJ8pqFVAQAAJvEWs/msdz/S2IeNQAA12lrnTP9xszO3pEk109yxyQnLqooAADYDNY6Z/q5c9cvT/K57j5vAfUAAMCmsaZpHt39riSfTLJXkpsm+c4iiwIAgM1gTWG6qo5O8sEkD0tydJIPVNVDF1kYAABsdGud5vFbSe7e3RclSVVtSfK2JK9fVGEAALDRrfVsHtdbCtKTL+/AtgAAcK201pHpN1fVPyV59XT755OcupiSAABgc9hmmK6q2yXZr7t/rap+Lsm9p0XvS/KqRRcHAAAb2fZGpv8kyW8mSXeflOSkJKmq/zwt+5mFVgcAABvY9uY979fdZy5vnNoOXkhFAACwSWwvTO+zjWU33pWFAADAZrO9MH1aVf3y8saq+u9JTl9MSQAAsDlsb870k5KcXFW/kKvD89Yk35fkqEUWBgAAG902w3R3X5jkiKr6iSR3nprf1N3/vPDKAABgg1vTeaa7+x1J3rHgWgAAYFPxLYYAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAxaWJiuqpdX1UVV9fG5tptV1Vur6tPTz5tO7VVVL6iqc6rqY1X1w4uqCwAAdpVFjky/IskDlrU9Lcnbu/uQJG+fbifJA5McMl2OS/LSBdYFAAC7xMLCdHe/O8lXljU/JMkJ0/UTkvzsXPsre+b9Sfapqv0XVRsAAOwKu3vO9H7dfcF0/YtJ9puuH5jk83PrnTe1AQDAhrVuH0Ds7k7SO7pdVR1XVadV1WkXX3zxAioDAIC12d1h+sKl6RvTz4um9vOTHDS33i2mtmvo7uO7e2t3b92yZctCiwUAgG3Z3WH6lCTHTtePTfL3c+2PnM7qcY8kX5+bDgIAABvSHovquKpeneTIJPtW1XlJnpHk2UlOrKrHJPlckqOn1U9N8qAk5yT5ZpJHL6ouAADYVRYWprv74assuu8K63aSxy2qFgAAWATfgAgAAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGDQHutxp1V1bpJLklyR5PLu3lpVN0vy2iQHJzk3ydHd/dX1qA8AANZiPUemf6K7D+vurdPtpyV5e3cfkuTt020AANiwNtI0j4ckOWG6fkKSn13HWgAAYLvWK0x3krdU1elVddzUtl93XzBd/2KS/danNAAAWJt1mTOd5N7dfX5V3TzJW6vqk/MLu7urqlfacArfxyXJLW95y8VXCgAAq1iXkenuPn/6eVGSk5McnuTCqto/SaafF62y7fHdvbW7t27ZsmV3lQwAANew28N0Vf1AVe21dD3JTyf5eJJTkhw7rXZskr/f3bUBAMCOWI9pHvslObmqlu7/b7v7zVX1oSQnVtVjknwuydHrUBsAAKzZbg/T3f2ZJHddof3LSe67u+sBAIBRG+nUeAAAsKkI0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMCgDRemq+oBVfWpqjqnqp623vUAAMBqNlSYrqrrJ3lxkgcmOTTJw6vq0PWtCgAAVrahwnSSw5Oc092f6e7vJHlNkoesc00AALCijRamD0zy+bnb501tAACw4eyx3gXsqKo6Lslx081Lq+pT61kPrGDfJF9a7yLYeJ6y3gXA5uF5lBWt8/PorVZq3Ghh+vwkB83dvsXUdpXuPj7J8buzKNgRVXVad29d7zoANivPo2wmG22ax4eSHFJVt66q70tyTJJT1rkmAABY0YYame7uy6vq8Un+Kcn1k7y8u89a57IAAGBFGypMJ0l3n5rk1PWuA3aCaUgAO8fzKJtGdfd61wAAAJvSRpszDQAAm4YwDZOqunTZ7UdV1YsG+zqyqv5h7voRc8teUVUP3blqAXavqrqiqs6oqo9X1euq6vvXu6a1qKqtVfWC9a6Day9hGhbvyCRHbG8lgA3uW919WHffOcl3kjx2vQtai+4+rbufuN51cO0lTMMaVNWWqnpDVX1outxraj+8qt5XVR+pqn+tqv+0bLuDM/uH8+RpROfHpkX3mdb/zNIodVW9sqp+dm7bV1XVQ3bLDgLsmPckud30zts7q+r1VfXJ6XmrkqSqfqSq3lVVp1fVP1XV/lP7O6tq63R936o6d7r+qKr6u6p6a1WdW1WPr6qnTM+v76+qm03rHTbd/lhVnVxVN53r9zlV9cGq+rel59tl7xRu8zkbRgjTcLUbT4H3jKo6I8kz55b9aZLnd/fdk/x/Sf5yav9kkh/r7rsl+Z0kfzjfYXefm+TPpm0P6+73TIv2T3LvJA9O8uyp7WVJHpUkVbV3ZqPZb9qlewiwk6pqjyQPTHLm1HS3JE9KcmiS2yS5V1XdIMkLkzy0u38kycuTPGsN3d85yc8lufu0/jen59f3JXnktM4rk/xGd99lquEZc9vv0d2HT/XMty/Z5nM2jNhwp0twWIsAAARoSURBVMaDdfSt7j5s6UZVPSrJ0jdw3S/JodOAS5LcpKr2TLJ3khOq6pAkneQGa7yvv+vuK5OcXVX7JUl3v6uqXlJVWzIL7G/o7st3dqcAdpEbTwMNyWxk+mWZvej/YHeflyTT8oOTfC2zYPzW6Xnz+kkuWMN9vKO7L0lySVV9Pckbp/Yzk9xlGmjYp7vfNbWfkOR1c9ufNP08fapjudHnbFiVMA1rc70k9+juy+Ybpw8ovqO7j5qmdLxzjf19e76bueuvTPKLmX3756NHiwVYgO8ZcEiSKSjPP59dkVm2qCRndfc9V+jn8lz9zviNli2b7+vKudtXZm2ZZWn9pTqW+/2MPWfDqkzzgLV5S5InLN2oqqV/KHsnOX+6/qhVtr0kyV5rvJ9XZPb2ZLr77B0tEmCD+FSSLVV1zySpqhtU1Z2mZecm+ZHp+g6d2ai7v57kq3OfP3lEkndtY5Pl1vKcDTtEmIa1eWKSrdMHXs7O1Z9i/z9J/qiqPpLVR03emOSoZR9AXFF3X5jkE0n+ahfVDbDbdfd3MgvKz6mqjyY5I1ef1ei5Sf7H9Ly570D3xyb5v1X1sSSH5Xs/37I9a3nOhh3iGxBhA5nO23pmkh+eRmAAgA3MyDRsEFV1v8xGpV8oSAPA5mBkGgAABhmZBgCAQcI0AAAMEqYBAGCQMA2wCVTVFdPpFc+qqo9W1VOr6nrTsq1V9YL1rhHgusgHEAE2gaq6tLv3nK7fPMnfJnlvdz9jfSsDuG4zMg2wyXT3RUmOS/L4mjmyqv4hSarqx6cR7DOq6iNVtdfU/mtV9aHpi4d+b6mvqvq7qjp9GvE+bmq7flW9oqo+XlVnVtWTp/bbVtWbp/XfU1V32P17D7Cx+PYfgE2ouz9TVddPcvNli/5Xksd193uras8kl1XVTyc5JMnhSSrJKVV1n+5+d5Jf6u6vVNWNk3yoqt6Q5OAkB3b3nZOkqvaZ+j4+yWO7+9NV9aNJXpLkJxe8qwAbmjANcO3y3iTPq6pXJTmpu8+bwvRPJ/nItM6emYXrdyd5YlUdNbUfNLV/KsltquqFSd6U5C1TMD8iyeuqaum+brg7dghgIxOmATahqrpNkiuSXJTkjkvt3f3sqnpTkgcleW9V3T+z0eg/6u4/X9bHkUnul+Se3f3Nqnpnkht191er6q5J7p/ksUmOTvKkJF/r7sMWvnMAm4g50wCbTFVtSfJnSV7Uyz5FXlW37e4zu/s5ST6U5A5J/inJL02jy6mqA6cPMe6d5KtTkL5DkntMy/dNcr3ufkOS307yw939jSSfraqHTevUFLgBrtOMTANsDjeuqjOS3CDJ5Un+OsnzVljvSVX1E0muTHJWkn/s7m9X1R2TvG+aonFpkl9M8uYkj62qT2Q2teP9Ux8HJvmrpVPvJfnN6ecvJHlpVf32VMdrknx01+4mwObi1HgAADDINA8AABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg/5/V8W0gG4zvqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 40, 216)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 40, 216, 1) (448, 2)\n",
      "(128, 40, 216, 1) (128, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 215, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 106, 32)       2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 52, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 25, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 43,570\n",
      "Trainable params: 43,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "128/128 [==============================] - 1s 7ms/sample - loss: 8.8340 - accuracy: 0.1875\n",
      "Pre-training accuracy: 18.7500%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358 samples, validate on 90 samples\n",
      "Epoch 1/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 3.9792 - accuracy: 0.5484\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65556, saving model to models/CNN1_dataset_2_slide5_01.h5\n",
      "358/358 [==============================] - 1s 3ms/sample - loss: 3.5616 - accuracy: 0.5726 - val_loss: 0.5905 - val_accuracy: 0.6556\n",
      "Epoch 2/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.6025 - accuracy: 0.7118\n",
      "Epoch 00002: val_accuracy improved from 0.65556 to 0.70000, saving model to models/CNN1_dataset_2_slide5_02.h5\n",
      "358/358 [==============================] - 0s 799us/sample - loss: 0.6083 - accuracy: 0.7095 - val_loss: 0.4786 - val_accuracy: 0.7000\n",
      "Epoch 3/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.4755 - accuracy: 0.7633\n",
      "Epoch 00003: val_accuracy improved from 0.70000 to 0.74444, saving model to models/CNN1_dataset_2_slide5_03.h5\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.4579 - accuracy: 0.7737 - val_loss: 0.5485 - val_accuracy: 0.7444\n",
      "Epoch 4/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.4532 - accuracy: 0.8067\n",
      "Epoch 00004: val_accuracy did not improve from 0.74444\n",
      "358/358 [==============================] - 0s 603us/sample - loss: 0.4196 - accuracy: 0.8212 - val_loss: 0.6624 - val_accuracy: 0.6333\n",
      "Epoch 5/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.4940 - accuracy: 0.7700\n",
      "Epoch 00005: val_accuracy did not improve from 0.74444\n",
      "358/358 [==============================] - 0s 624us/sample - loss: 0.4855 - accuracy: 0.7765 - val_loss: 0.6651 - val_accuracy: 0.5667\n",
      "Epoch 6/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.3829 - accuracy: 0.8000\n",
      "Epoch 00006: val_accuracy did not improve from 0.74444\n",
      "358/358 [==============================] - 0s 600us/sample - loss: 0.3644 - accuracy: 0.8184 - val_loss: 0.6414 - val_accuracy: 0.5667\n",
      "Epoch 7/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.3119 - accuracy: 0.8667\n",
      "Epoch 00007: val_accuracy improved from 0.74444 to 0.75556, saving model to models/CNN1_dataset_2_slide5_07.h5\n",
      "358/358 [==============================] - 0s 710us/sample - loss: 0.3312 - accuracy: 0.8547 - val_loss: 0.4837 - val_accuracy: 0.7556\n",
      "Epoch 8/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.3018 - accuracy: 0.8529\n",
      "Epoch 00008: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 757us/sample - loss: 0.3002 - accuracy: 0.8520 - val_loss: 0.7027 - val_accuracy: 0.5222\n",
      "Epoch 9/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.3121 - accuracy: 0.8486\n",
      "Epoch 00009: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 699us/sample - loss: 0.3204 - accuracy: 0.8464 - val_loss: 0.5590 - val_accuracy: 0.6667\n",
      "Epoch 10/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2433 - accuracy: 0.8966\n",
      "Epoch 00010: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 629us/sample - loss: 0.2446 - accuracy: 0.8883 - val_loss: 0.6069 - val_accuracy: 0.5444\n",
      "Epoch 11/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2716 - accuracy: 0.8733\n",
      "Epoch 00011: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 630us/sample - loss: 0.2588 - accuracy: 0.8827 - val_loss: 0.6142 - val_accuracy: 0.6444\n",
      "Epoch 12/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2367 - accuracy: 0.9069\n",
      "Epoch 00012: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.2226 - accuracy: 0.9134 - val_loss: 0.6670 - val_accuracy: 0.6222\n",
      "Epoch 13/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.3105 - accuracy: 0.8600\n",
      "Epoch 00013: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 719us/sample - loss: 0.3085 - accuracy: 0.8603 - val_loss: 0.7017 - val_accuracy: 0.5333\n",
      "Epoch 14/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.2215 - accuracy: 0.9000\n",
      "Epoch 00014: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 742us/sample - loss: 0.2273 - accuracy: 0.8966 - val_loss: 0.6378 - val_accuracy: 0.5444\n",
      "Epoch 15/500\n",
      "260/358 [====================>.........] - ETA: 0s - loss: 0.2381 - accuracy: 0.9000\n",
      "Epoch 00015: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 693us/sample - loss: 0.2432 - accuracy: 0.8939 - val_loss: 0.4269 - val_accuracy: 0.7222\n",
      "Epoch 16/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.1990 - accuracy: 0.9000\n",
      "Epoch 00016: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 636us/sample - loss: 0.2010 - accuracy: 0.8994 - val_loss: 0.4401 - val_accuracy: 0.7444\n",
      "Epoch 17/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.2157 - accuracy: 0.9138\n",
      "Epoch 00017: val_accuracy did not improve from 0.75556\n",
      "358/358 [==============================] - 0s 634us/sample - loss: 0.2171 - accuracy: 0.9162 - val_loss: 0.4816 - val_accuracy: 0.6889\n",
      "Epoch 18/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9114\n",
      "Epoch 00018: val_accuracy improved from 0.75556 to 0.84444, saving model to models/CNN1_dataset_2_slide5_18.h5\n",
      "358/358 [==============================] - 0s 796us/sample - loss: 0.2203 - accuracy: 0.9078 - val_loss: 0.3241 - val_accuracy: 0.8444\n",
      "Epoch 19/500\n",
      "260/358 [====================>.........] - ETA: 0s - loss: 0.1445 - accuracy: 0.9462\n",
      "Epoch 00019: val_accuracy did not improve from 0.84444\n",
      "358/358 [==============================] - 0s 704us/sample - loss: 0.1424 - accuracy: 0.9413 - val_loss: 0.5055 - val_accuracy: 0.6778\n",
      "Epoch 20/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1503 - accuracy: 0.9286\n",
      "Epoch 00020: val_accuracy improved from 0.84444 to 0.85556, saving model to models/CNN1_dataset_2_slide5_20.h5\n",
      "358/358 [==============================] - 0s 801us/sample - loss: 0.1504 - accuracy: 0.9302 - val_loss: 0.3009 - val_accuracy: 0.8556\n",
      "Epoch 21/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.1183 - accuracy: 0.9531\n",
      "Epoch 00021: val_accuracy did not improve from 0.85556\n",
      "358/358 [==============================] - 0s 762us/sample - loss: 0.1167 - accuracy: 0.9525 - val_loss: 0.3433 - val_accuracy: 0.8222\n",
      "Epoch 22/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1580 - accuracy: 0.9324\n",
      "Epoch 00022: val_accuracy did not improve from 0.85556\n",
      "358/358 [==============================] - 0s 729us/sample - loss: 0.1553 - accuracy: 0.9330 - val_loss: 0.5914 - val_accuracy: 0.6444\n",
      "Epoch 23/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1782 - accuracy: 0.9314\n",
      "Epoch 00023: val_accuracy did not improve from 0.85556\n",
      "358/358 [==============================] - 0s 711us/sample - loss: 0.1747 - accuracy: 0.9330 - val_loss: 0.2973 - val_accuracy: 0.8222\n",
      "Epoch 24/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1192 - accuracy: 0.9533\n",
      "Epoch 00024: val_accuracy did not improve from 0.85556\n",
      "358/358 [==============================] - 0s 627us/sample - loss: 0.1178 - accuracy: 0.9525 - val_loss: 0.4307 - val_accuracy: 0.7778\n",
      "Epoch 25/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1529 - accuracy: 0.9464\n",
      "Epoch 00025: val_accuracy did not improve from 0.85556\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.1534 - accuracy: 0.9385 - val_loss: 0.3365 - val_accuracy: 0.8222\n",
      "Epoch 26/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1137 - accuracy: 0.9618\n",
      "Epoch 00026: val_accuracy did not improve from 0.85556\n",
      "358/358 [==============================] - 0s 718us/sample - loss: 0.1104 - accuracy: 0.9637 - val_loss: 0.4181 - val_accuracy: 0.7444\n",
      "Epoch 27/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1035 - accuracy: 0.9676\n",
      "Epoch 00027: val_accuracy did not improve from 0.85556\n",
      "358/358 [==============================] - 0s 738us/sample - loss: 0.1016 - accuracy: 0.9693 - val_loss: 0.3693 - val_accuracy: 0.8000\n",
      "Epoch 28/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1785 - accuracy: 0.9324\n",
      "Epoch 00028: val_accuracy did not improve from 0.85556\n",
      "358/358 [==============================] - 0s 730us/sample - loss: 0.1730 - accuracy: 0.9358 - val_loss: 0.4844 - val_accuracy: 0.7000\n",
      "Epoch 29/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1551 - accuracy: 0.9429\n",
      "Epoch 00029: val_accuracy improved from 0.85556 to 0.87778, saving model to models/CNN1_dataset_2_slide5_29.h5\n",
      "358/358 [==============================] - 0s 760us/sample - loss: 0.1350 - accuracy: 0.9497 - val_loss: 0.2355 - val_accuracy: 0.8778\n",
      "Epoch 30/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0985 - accuracy: 0.9636\n",
      "Epoch 00030: val_accuracy improved from 0.87778 to 0.92222, saving model to models/CNN1_dataset_2_slide5_30.h5\n",
      "358/358 [==============================] - 0s 835us/sample - loss: 0.0945 - accuracy: 0.9665 - val_loss: 0.1724 - val_accuracy: 0.9222\n",
      "Epoch 31/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1084 - accuracy: 0.9471\n",
      "Epoch 00031: val_accuracy did not improve from 0.92222\n",
      "358/358 [==============================] - 0s 718us/sample - loss: 0.1146 - accuracy: 0.9441 - val_loss: 0.4422 - val_accuracy: 0.7444\n",
      "Epoch 32/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.1188 - accuracy: 0.9483\n",
      "Epoch 00032: val_accuracy did not improve from 0.92222\n",
      "358/358 [==============================] - 0s 645us/sample - loss: 0.1155 - accuracy: 0.9469 - val_loss: 0.2534 - val_accuracy: 0.8778\n",
      "Epoch 33/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9600\n",
      "Epoch 00033: val_accuracy did not improve from 0.92222\n",
      "358/358 [==============================] - 0s 707us/sample - loss: 0.0820 - accuracy: 0.9609 - val_loss: 0.2350 - val_accuracy: 0.9111\n",
      "Epoch 34/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0860 - accuracy: 0.9576\n",
      "Epoch 00034: val_accuracy improved from 0.92222 to 0.96667, saving model to models/CNN1_dataset_2_slide5_34.h5\n",
      "358/358 [==============================] - 0s 837us/sample - loss: 0.0809 - accuracy: 0.9609 - val_loss: 0.1080 - val_accuracy: 0.9667\n",
      "Epoch 35/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0883 - accuracy: 0.9588\n",
      "Epoch 00035: val_accuracy did not improve from 0.96667\n",
      "358/358 [==============================] - 0s 732us/sample - loss: 0.0877 - accuracy: 0.9581 - val_loss: 0.1224 - val_accuracy: 0.9556\n",
      "Epoch 36/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0672 - accuracy: 0.9778\n",
      "Epoch 00036: val_accuracy improved from 0.96667 to 0.97778, saving model to models/CNN1_dataset_2_slide5_36.h5\n",
      "358/358 [==============================] - 0s 765us/sample - loss: 0.0681 - accuracy: 0.9777 - val_loss: 0.1103 - val_accuracy: 0.9778\n",
      "Epoch 37/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0619 - accuracy: 0.9765\n",
      "Epoch 00037: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 715us/sample - loss: 0.0592 - accuracy: 0.9777 - val_loss: 0.1107 - val_accuracy: 0.9778\n",
      "Epoch 38/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0540 - accuracy: 0.9818\n",
      "Epoch 00038: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 740us/sample - loss: 0.0509 - accuracy: 0.9832 - val_loss: 0.0807 - val_accuracy: 0.9778\n",
      "Epoch 39/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0339 - accuracy: 0.9909\n",
      "Epoch 00039: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 754us/sample - loss: 0.0321 - accuracy: 0.9916 - val_loss: 0.0774 - val_accuracy: 0.9778\n",
      "Epoch 40/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0646 - accuracy: 0.9735\n",
      "Epoch 00040: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 732us/sample - loss: 0.0646 - accuracy: 0.9749 - val_loss: 0.1043 - val_accuracy: 0.9556\n",
      "Epoch 41/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0450 - accuracy: 0.9765\n",
      "Epoch 00041: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 713us/sample - loss: 0.0447 - accuracy: 0.9777 - val_loss: 0.1968 - val_accuracy: 0.8667\n",
      "Epoch 42/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0604 - accuracy: 0.9750\n",
      "Epoch 00042: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 752us/sample - loss: 0.0566 - accuracy: 0.9777 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
      "Epoch 43/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0292 - accuracy: 0.9882\n",
      "Epoch 00043: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 714us/sample - loss: 0.0282 - accuracy: 0.9888 - val_loss: 0.1635 - val_accuracy: 0.8889\n",
      "Epoch 44/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0551 - accuracy: 0.9765\n",
      "Epoch 00044: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 729us/sample - loss: 0.0523 - accuracy: 0.9777 - val_loss: 0.1401 - val_accuracy: 0.9111\n",
      "Epoch 45/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9743\n",
      "Epoch 00045: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 701us/sample - loss: 0.0767 - accuracy: 0.9721 - val_loss: 0.1038 - val_accuracy: 0.9778\n",
      "Epoch 46/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9800\n",
      "Epoch 00046: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 706us/sample - loss: 0.0428 - accuracy: 0.9804 - val_loss: 0.1393 - val_accuracy: 0.9000\n",
      "Epoch 47/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0423 - accuracy: 0.9821\n",
      "Epoch 00047: val_accuracy improved from 0.97778 to 1.00000, saving model to models/CNN1_dataset_2_slide5_47.h5\n",
      "358/358 [==============================] - 0s 708us/sample - loss: 0.0506 - accuracy: 0.9804 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0470 - accuracy: 0.9821\n",
      "Epoch 00048: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 644us/sample - loss: 0.0483 - accuracy: 0.9832 - val_loss: 0.0481 - val_accuracy: 0.9889\n",
      "Epoch 49/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1005 - accuracy: 0.9676\n",
      "Epoch 00049: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 730us/sample - loss: 0.0961 - accuracy: 0.9693 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0682 - accuracy: 0.9719\n",
      "Epoch 00050: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 749us/sample - loss: 0.0625 - accuracy: 0.9749 - val_loss: 0.0870 - val_accuracy: 0.9667\n",
      "Epoch 51/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0318 - accuracy: 0.9875\n",
      "Epoch 00051: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 791us/sample - loss: 0.0329 - accuracy: 0.9860 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0724 - accuracy: 0.9676\n",
      "Epoch 00052: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 728us/sample - loss: 0.0717 - accuracy: 0.9693 - val_loss: 0.0651 - val_accuracy: 0.9778\n",
      "Epoch 53/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0502 - accuracy: 0.9844\n",
      "Epoch 00053: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 737us/sample - loss: 0.0474 - accuracy: 0.9860 - val_loss: 0.1131 - val_accuracy: 0.9222\n",
      "Epoch 54/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0356 - accuracy: 0.9857\n",
      "Epoch 00054: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 702us/sample - loss: 0.0348 - accuracy: 0.9860 - val_loss: 0.0676 - val_accuracy: 0.9667\n",
      "Epoch 55/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0979 - accuracy: 0.9543\n",
      "Epoch 00055: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 701us/sample - loss: 0.1147 - accuracy: 0.9497 - val_loss: 0.1099 - val_accuracy: 0.9222\n",
      "Epoch 56/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0915 - accuracy: 0.9750\n",
      "Epoch 00056: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.0884 - accuracy: 0.9721 - val_loss: 0.1313 - val_accuracy: 0.9444\n",
      "Epoch 57/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0396 - accuracy: 0.9857\n",
      "Epoch 00057: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0448 - accuracy: 0.9804 - val_loss: 0.0663 - val_accuracy: 0.9889\n",
      "Epoch 58/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0337 - accuracy: 0.9857\n",
      "Epoch 00058: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 682us/sample - loss: 0.0349 - accuracy: 0.9832 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9857\n",
      "Epoch 00059: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 712us/sample - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.0633 - val_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0262 - accuracy: 0.9971\n",
      "Epoch 00060: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 712us/sample - loss: 0.0363 - accuracy: 0.9944 - val_loss: 0.0616 - val_accuracy: 0.9667\n",
      "Epoch 61/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0338 - accuracy: 0.9912\n",
      "Epoch 00061: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 719us/sample - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0195 - accuracy: 0.9963\n",
      "Epoch 00062: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 720us/sample - loss: 0.0198 - accuracy: 0.9944 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0403 - accuracy: 0.9853\n",
      "Epoch 00063: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 695us/sample - loss: 0.0385 - accuracy: 0.9860 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9943\n",
      "Epoch 00064: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 673us/sample - loss: 0.0222 - accuracy: 0.9944 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 65/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9943\n",
      "Epoch 00065: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 714us/sample - loss: 0.0271 - accuracy: 0.9944 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9857\n",
      "Epoch 00066: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 694us/sample - loss: 0.0300 - accuracy: 0.9860 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1016 - accuracy: 0.9714\n",
      "Epoch 00067: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 638us/sample - loss: 0.0980 - accuracy: 0.9721 - val_loss: 0.1660 - val_accuracy: 0.8778\n",
      "Epoch 68/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0394 - accuracy: 0.9926\n",
      "Epoch 00068: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0327 - accuracy: 0.9944 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 69/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0142 - accuracy: 0.9963\n",
      "Epoch 00069: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 702us/sample - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0481 - accuracy: 0.9848\n",
      "Epoch 00070: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 739us/sample - loss: 0.0752 - accuracy: 0.9777 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 71/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.9800\n",
      "Epoch 00071: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 702us/sample - loss: 0.0534 - accuracy: 0.9777 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1249 - accuracy: 0.9559\n",
      "Epoch 00072: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 722us/sample - loss: 0.1192 - accuracy: 0.9581 - val_loss: 0.1175 - val_accuracy: 0.9444\n",
      "Epoch 73/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9829\n",
      "Epoch 00073: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 740us/sample - loss: 0.0356 - accuracy: 0.9832 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0436 - accuracy: 0.9815\n",
      "Epoch 00074: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 682us/sample - loss: 0.0434 - accuracy: 0.9804 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0231 - accuracy: 0.9926\n",
      "Epoch 00075: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 708us/sample - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0197 - accuracy: 0.9909\n",
      "Epoch 00076: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 743us/sample - loss: 0.0187 - accuracy: 0.9916 - val_loss: 0.0614 - val_accuracy: 0.9889\n",
      "Epoch 77/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9771\n",
      "Epoch 00077: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.0520 - accuracy: 0.9777 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0247 - accuracy: 0.9912\n",
      "Epoch 00078: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 728us/sample - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 79/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0270 - accuracy: 0.9882\n",
      "Epoch 00079: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 717us/sample - loss: 0.0274 - accuracy: 0.9888 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9800\n",
      "Epoch 00080: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 695us/sample - loss: 0.0312 - accuracy: 0.9804 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0369 - accuracy: 0.9871\n",
      "Epoch 00081: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 596us/sample - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.0609 - val_accuracy: 0.9778\n",
      "Epoch 82/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0360 - accuracy: 0.9828\n",
      "Epoch 00082: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 635us/sample - loss: 0.0375 - accuracy: 0.9832 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0174 - accuracy: 0.9931\n",
      "Epoch 00083: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 608us/sample - loss: 0.0186 - accuracy: 0.9916 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0235 - accuracy: 0.9897\n",
      "Epoch 00084: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 614us/sample - loss: 0.0246 - accuracy: 0.9888 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0154 - accuracy: 0.9931\n",
      "Epoch 00085: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0318 - accuracy: 0.9897\n",
      "Epoch 00086: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 709us/sample - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 00087: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 644us/sample - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0410 - val_accuracy: 0.9889\n",
      "Epoch 88/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0622 - accuracy: 0.9828\n",
      "Epoch 00088: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0659 - accuracy: 0.9777 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0185 - accuracy: 0.9966\n",
      "Epoch 00089: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 621us/sample - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0303 - accuracy: 0.9862\n",
      "Epoch 00090: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 627us/sample - loss: 0.0258 - accuracy: 0.9888 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0133 - accuracy: 0.9966\n",
      "Epoch 00091: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0163 - accuracy: 0.9916 - val_loss: 0.0445 - val_accuracy: 0.9778\n",
      "Epoch 92/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0149 - accuracy: 0.9966\n",
      "Epoch 00092: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 633us/sample - loss: 0.0255 - accuracy: 0.9944 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 00093: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 613us/sample - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0475 - accuracy: 0.9793\n",
      "Epoch 00094: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 614us/sample - loss: 0.0469 - accuracy: 0.9804 - val_loss: 0.0518 - val_accuracy: 0.9889\n",
      "Epoch 95/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0283 - accuracy: 0.9933\n",
      "Epoch 00095: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 604us/sample - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 00096: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 612us/sample - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0270 - accuracy: 0.9931\n",
      "Epoch 00097: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 612us/sample - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0357 - accuracy: 0.9828\n",
      "Epoch 00098: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 613us/sample - loss: 0.0297 - accuracy: 0.9860 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 00099: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 619us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0068 - accuracy: 0.9964\n",
      "Epoch 00100: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.0097 - accuracy: 0.9944 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0116 - accuracy: 0.9931\n",
      "Epoch 00101: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 649us/sample - loss: 0.0103 - accuracy: 0.9944 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 00102: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 618us/sample - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 00103: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 629us/sample - loss: 0.0061 - accuracy: 0.9972 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0325 - accuracy: 0.9862\n",
      "Epoch 00104: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 607us/sample - loss: 0.0366 - accuracy: 0.9832 - val_loss: 0.0484 - val_accuracy: 0.9889\n",
      "Epoch 105/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0366 - accuracy: 0.9828\n",
      "Epoch 00105: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 616us/sample - loss: 0.0322 - accuracy: 0.9860 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 00106: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 624us/sample - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0181 - accuracy: 0.9966\n",
      "Epoch 00107: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 613us/sample - loss: 0.0173 - accuracy: 0.9972 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0166 - accuracy: 0.9966\n",
      "Epoch 00108: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 625us/sample - loss: 0.0163 - accuracy: 0.9972 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0108 - accuracy: 0.9967\n",
      "Epoch 00109: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 615us/sample - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 00110: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0360 - accuracy: 0.9916 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 00111: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 613us/sample - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.0599 - val_accuracy: 0.9667\n",
      "Epoch 112/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0226 - accuracy: 0.9897\n",
      "Epoch 00112: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 617us/sample - loss: 0.0297 - accuracy: 0.9888 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0144 - accuracy: 0.9931\n",
      "Epoch 00113: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 615us/sample - loss: 0.0177 - accuracy: 0.9916 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0387 - accuracy: 0.9862\n",
      "Epoch 00114: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 616us/sample - loss: 0.0379 - accuracy: 0.9860 - val_loss: 0.0470 - val_accuracy: 0.9778\n",
      "Epoch 115/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0146 - accuracy: 0.9931\n",
      "Epoch 00115: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 614us/sample - loss: 0.0169 - accuracy: 0.9916 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0182 - accuracy: 0.9966\n",
      "Epoch 00116: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 625us/sample - loss: 0.0211 - accuracy: 0.9916 - val_loss: 0.0448 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0460 - accuracy: 0.9828\n",
      "Epoch 00117: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0377 - accuracy: 0.9860 - val_loss: 0.0354 - val_accuracy: 0.9889\n",
      "Epoch 118/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.1041 - accuracy: 0.9621\n",
      "Epoch 00118: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 633us/sample - loss: 0.0874 - accuracy: 0.9693 - val_loss: 0.0834 - val_accuracy: 0.9444\n",
      "Epoch 119/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0580 - accuracy: 0.9828\n",
      "Epoch 00119: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0622 - accuracy: 0.9804 - val_loss: 0.1732 - val_accuracy: 0.9000\n",
      "Epoch 120/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0181 - accuracy: 0.9931\n",
      "Epoch 00120: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 616us/sample - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0450 - accuracy: 0.9862\n",
      "Epoch 00121: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0384 - accuracy: 0.9888 - val_loss: 0.0392 - val_accuracy: 0.9889\n",
      "Epoch 122/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00122: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9889\n",
      "Epoch 123/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0574 - accuracy: 0.9759\n",
      "Epoch 00123: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0472 - accuracy: 0.9804 - val_loss: 0.0446 - val_accuracy: 0.9889\n",
      "Epoch 124/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0151 - accuracy: 0.9931\n",
      "Epoch 00124: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0129 - accuracy: 0.9944 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0143 - accuracy: 0.9931\n",
      "Epoch 00125: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 619us/sample - loss: 0.0119 - accuracy: 0.9944 - val_loss: 0.0186 - val_accuracy: 0.9889\n",
      "Epoch 126/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 00126: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 619us/sample - loss: 0.0119 - accuracy: 0.9944 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0170 - accuracy: 0.9929\n",
      "Epoch 00127: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 635us/sample - loss: 0.0145 - accuracy: 0.9944 - val_loss: 0.0796 - val_accuracy: 0.9778\n",
      "Epoch 128/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0134 - accuracy: 0.9931\n",
      "Epoch 00128: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0119 - accuracy: 0.9944 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 129/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0174 - accuracy: 0.9897\n",
      "Epoch 00129: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 617us/sample - loss: 0.0155 - accuracy: 0.9916 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0177 - accuracy: 0.9931\n",
      "Epoch 00130: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 629us/sample - loss: 0.0167 - accuracy: 0.9916 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 00131: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 618us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0080 - accuracy: 0.9966\n",
      "Epoch 00132: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 625us/sample - loss: 0.0066 - accuracy: 0.9972 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0403 - accuracy: 0.9862\n",
      "Epoch 00133: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 619us/sample - loss: 0.0344 - accuracy: 0.9888 - val_loss: 0.0439 - val_accuracy: 0.9778\n",
      "Epoch 134/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0286 - accuracy: 0.9931\n",
      "Epoch 00134: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0249 - accuracy: 0.9944 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0216 - accuracy: 0.9931\n",
      "Epoch 00135: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 611us/sample - loss: 0.0330 - accuracy: 0.9916 - val_loss: 0.6315 - val_accuracy: 0.8889\n",
      "Epoch 136/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0668 - accuracy: 0.9897\n",
      "Epoch 00136: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 620us/sample - loss: 0.0575 - accuracy: 0.9888 - val_loss: 0.0513 - val_accuracy: 0.9667\n",
      "Epoch 137/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 00137: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0236 - accuracy: 0.9909\n",
      "Epoch 00138: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 763us/sample - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.0701 - val_accuracy: 0.9556\n",
      "Epoch 139/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0300 - accuracy: 0.9862\n",
      "Epoch 00139: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 634us/sample - loss: 0.0251 - accuracy: 0.9888 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0450 - accuracy: 0.9750\n",
      "Epoch 00140: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0412 - accuracy: 0.9749 - val_loss: 0.0904 - val_accuracy: 0.9444\n",
      "Epoch 141/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0103 - accuracy: 0.9966\n",
      "Epoch 00141: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 630us/sample - loss: 0.0101 - accuracy: 0.9972 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00142: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 627us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000  \n",
      "Epoch 00143: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 632us/sample - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0228 - accuracy: 0.9897\n",
      "Epoch 00144: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 625us/sample - loss: 0.0204 - accuracy: 0.9916 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0170 - accuracy: 0.9931\n",
      "Epoch 00145: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0139 - accuracy: 0.9944 - val_loss: 0.0391 - val_accuracy: 0.9667\n",
      "Epoch 146/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0115 - accuracy: 0.9964\n",
      "Epoch 00146: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 628us/sample - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0131 - accuracy: 0.9931\n",
      "Epoch 00147: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0110 - accuracy: 0.9944 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 148/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 00148: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 636us/sample - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 00149: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0232 - accuracy: 0.9931\n",
      "Epoch 00150: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 625us/sample - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 00151: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 619us/sample - loss: 0.0061 - accuracy: 0.9972 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000  \n",
      "Epoch 00152: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0070 - accuracy: 0.9966\n",
      "Epoch 00153: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 642us/sample - loss: 0.0081 - accuracy: 0.9944 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000  \n",
      "Epoch 00154: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 633us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0092 - accuracy: 0.9931\n",
      "Epoch 00155: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0095 - accuracy: 0.9944 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 00156: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00157: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 627us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0086 - accuracy: 0.9966\n",
      "Epoch 00158: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0138 - accuracy: 0.9916 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0099 - accuracy: 0.9966    \n",
      "Epoch 00159: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 628us/sample - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0331 - accuracy: 0.9862\n",
      "Epoch 00160: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0270 - accuracy: 0.9888 - val_loss: 0.0639 - val_accuracy: 0.9667\n",
      "Epoch 161/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1156 - accuracy: 0.9786\n",
      "Epoch 00161: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.1006 - accuracy: 0.9749 - val_loss: 0.0487 - val_accuracy: 0.9889\n",
      "Epoch 162/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0930 - accuracy: 0.9655\n",
      "Epoch 00162: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 629us/sample - loss: 0.0794 - accuracy: 0.9693 - val_loss: 0.0204 - val_accuracy: 0.9889\n",
      "Epoch 163/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0199 - accuracy: 0.9931\n",
      "Epoch 00163: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 620us/sample - loss: 0.0194 - accuracy: 0.9916 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0170 - accuracy: 0.9900\n",
      "Epoch 00164: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 625us/sample - loss: 0.0188 - accuracy: 0.9916 - val_loss: 0.0220 - val_accuracy: 0.9889\n",
      "Epoch 165/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0179 - accuracy: 0.9931\n",
      "Epoch 00165: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0120 - accuracy: 0.9966\n",
      "Epoch 00166: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 617us/sample - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0280 - accuracy: 0.9897\n",
      "Epoch 00167: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0524 - val_accuracy: 0.9889\n",
      "Epoch 168/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0261 - accuracy: 0.9862\n",
      "Epoch 00168: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 618us/sample - loss: 0.0284 - accuracy: 0.9832 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0214 - accuracy: 0.9931\n",
      "Epoch 00169: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 630us/sample - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0095 - accuracy: 0.9966\n",
      "Epoch 00170: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 621us/sample - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0365 - accuracy: 0.9867\n",
      "Epoch 00171: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 621us/sample - loss: 0.0353 - accuracy: 0.9888 - val_loss: 0.0178 - val_accuracy: 0.9889\n",
      "Epoch 172/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 00172: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 00173: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 00174: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 618us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00175: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 621us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 00176: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 638us/sample - loss: 0.0054 - accuracy: 0.9972 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00177: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 618us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00178: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 620us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00179: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 639us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
      "Epoch 00180: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 00181: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0159 - accuracy: 0.9931  \n",
      "Epoch 00182: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 625us/sample - loss: 0.0186 - accuracy: 0.9888 - val_loss: 0.0646 - val_accuracy: 0.9556\n",
      "Epoch 183/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0346 - accuracy: 0.9862\n",
      "Epoch 00183: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 637us/sample - loss: 0.0766 - accuracy: 0.9721 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0577 - accuracy: 0.9786\n",
      "Epoch 00184: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.0453 - accuracy: 0.9832 - val_loss: 0.0460 - val_accuracy: 0.9667\n",
      "Epoch 185/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0111 - accuracy: 0.9964\n",
      "Epoch 00185: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.0631 - val_accuracy: 0.9556\n",
      "Epoch 186/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00186: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 638us/sample - loss: 9.9098e-04 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 00187: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 640us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 00188: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 00189: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 745us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 00190: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 689us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9889\n",
      "Epoch 191/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0059 - accuracy: 0.9963\n",
      "Epoch 00191: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 680us/sample - loss: 0.0055 - accuracy: 0.9972 - val_loss: 0.0785 - val_accuracy: 0.9444\n",
      "Epoch 192/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9971\n",
      "Epoch 00192: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 694us/sample - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 00193: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0075 - accuracy: 0.9963\n",
      "Epoch 00194: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0061 - accuracy: 0.9972 - val_loss: 0.0303 - val_accuracy: 0.9889\n",
      "Epoch 195/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00195: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 00196: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 707us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 7.9869e-04 - accuracy: 1.0000\n",
      "Epoch 00197: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 706us/sample - loss: 7.8342e-04 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0109 - accuracy: 0.9971\n",
      "Epoch 00198: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 720us/sample - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 8.9158e-04 - accuracy: 1.0000\n",
      "Epoch 00199: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 685us/sample - loss: 7.1533e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0500 - accuracy: 0.9818\n",
      "Epoch 00200: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 733us/sample - loss: 0.0612 - accuracy: 0.9804 - val_loss: 0.1648 - val_accuracy: 0.9444\n",
      "Epoch 201/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0393 - accuracy: 0.9778\n",
      "Epoch 00201: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 695us/sample - loss: 0.0491 - accuracy: 0.9804 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.1236 - accuracy: 0.9667\n",
      "Epoch 00202: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0965 - accuracy: 0.9749 - val_loss: 0.0660 - val_accuracy: 0.9778\n",
      "Epoch 203/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0170 - accuracy: 0.9964\n",
      "Epoch 00203: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.0271 - accuracy: 0.9944 - val_loss: 0.1676 - val_accuracy: 0.9556\n",
      "Epoch 204/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0356 - accuracy: 0.9893\n",
      "Epoch 00204: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.0299 - accuracy: 0.9916 - val_loss: 0.0167 - val_accuracy: 0.9889\n",
      "Epoch 205/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0067 - accuracy: 0.9963\n",
      "Epoch 00205: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 0.0113 - accuracy: 0.9944 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0222 - accuracy: 0.9857\n",
      "Epoch 00206: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 633us/sample - loss: 0.0180 - accuracy: 0.9888 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00207: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 666us/sample - loss: 9.4400e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 9.1423e-04 - accuracy: 1.0000\n",
      "Epoch 00208: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 7.8068e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00209: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 685us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 7.4135e-04 - accuracy: 1.0000\n",
      "Epoch 00210: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 5.9060e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00211: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0119 - accuracy: 0.9933\n",
      "Epoch 00212: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.0301 - accuracy: 0.9888 - val_loss: 0.0166 - val_accuracy: 0.9889\n",
      "Epoch 213/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0233 - accuracy: 0.9926\n",
      "Epoch 00213: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 696us/sample - loss: 0.0206 - accuracy: 0.9916 - val_loss: 0.0394 - val_accuracy: 0.9889\n",
      "Epoch 214/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9886\n",
      "Epoch 00214: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 710us/sample - loss: 0.0176 - accuracy: 0.9888 - val_loss: 0.0521 - val_accuracy: 0.9778\n",
      "Epoch 215/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9914\n",
      "Epoch 00215: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 713us/sample - loss: 0.0147 - accuracy: 0.9916 - val_loss: 0.0256 - val_accuracy: 0.9889\n",
      "Epoch 216/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0169 - accuracy: 0.9893\n",
      "Epoch 00216: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 678us/sample - loss: 0.0196 - accuracy: 0.9888 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 00217: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 694us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9556\n",
      "Epoch 218/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000  \n",
      "Epoch 00218: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0351 - val_accuracy: 0.9889\n",
      "Epoch 219/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00219: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00220: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00221: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0117 - accuracy: 0.9935\n",
      "Epoch 00222: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 608us/sample - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0039 - accuracy: 0.9966    \n",
      "Epoch 00223: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 631us/sample - loss: 0.0032 - accuracy: 0.9972 - val_loss: 0.0317 - val_accuracy: 0.9889\n",
      "Epoch 224/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 00224: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 597us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9889\n",
      "Epoch 225/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 4.5767e-04 - accuracy: 1.0000\n",
      "Epoch 00225: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 596us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0123 - accuracy: 0.9903\n",
      "Epoch 00226: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 604us/sample - loss: 0.0107 - accuracy: 0.9916 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00227: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 0.9889\n",
      "Epoch 228/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0259 - accuracy: 0.9929  \n",
      "Epoch 00228: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0312 - val_accuracy: 0.9889\n",
      "Epoch 229/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0132 - accuracy: 0.9968\n",
      "Epoch 00229: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 583us/sample - loss: 0.0117 - accuracy: 0.9972 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000  \n",
      "Epoch 00230: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 588us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00231: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 612us/sample - loss: 0.0045 - accuracy: 0.9972 - val_loss: 0.0126 - val_accuracy: 0.9889\n",
      "Epoch 232/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0974 - accuracy: 0.9742\n",
      "Epoch 00232: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 582us/sample - loss: 0.0870 - accuracy: 0.9777 - val_loss: 0.0436 - val_accuracy: 0.9778\n",
      "Epoch 233/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0326 - accuracy: 0.9871\n",
      "Epoch 00233: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 605us/sample - loss: 0.0297 - accuracy: 0.9888 - val_loss: 0.1485 - val_accuracy: 0.9222\n",
      "Epoch 234/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0205 - accuracy: 0.9903\n",
      "Epoch 00234: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 599us/sample - loss: 0.0195 - accuracy: 0.9916 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00235: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 592us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0053 - accuracy: 0.9968  \n",
      "Epoch 00236: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 583us/sample - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00237: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 610us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0053 - accuracy: 0.9968\n",
      "Epoch 00238: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 600us/sample - loss: 0.0046 - accuracy: 0.9972 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00239: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 597us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 00240: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 620us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  \n",
      "Epoch 00241: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 606us/sample - loss: 9.5332e-04 - accuracy: 1.0000 - val_loss: 9.7297e-04 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 4.6716e-04 - accuracy: 1.0000\n",
      "Epoch 00242: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 609us/sample - loss: 4.8472e-04 - accuracy: 1.0000 - val_loss: 8.7247e-04 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 4.6198e-04 - accuracy: 1.0000\n",
      "Epoch 00243: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 600us/sample - loss: 4.0258e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 2.5369e-04 - accuracy: 1.0000\n",
      "Epoch 00244: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 607us/sample - loss: 4.0196e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00245: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 580us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9889\n",
      "Epoch 246/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00246: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 592us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 6.1185e-04 - accuracy: 1.0000\n",
      "Epoch 00247: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 6.2578e-04 - accuracy: 1.0000 - val_loss: 7.8954e-04 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 4.2818e-04 - accuracy: 1.0000\n",
      "Epoch 00248: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 591us/sample - loss: 0.0029 - accuracy: 0.9972 - val_loss: 5.9664e-04 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9800\n",
      "Epoch 00249: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 614us/sample - loss: 0.0582 - accuracy: 0.9721 - val_loss: 0.1280 - val_accuracy: 0.9667\n",
      "Epoch 250/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0673 - accuracy: 0.9688\n",
      "Epoch 00250: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 578us/sample - loss: 0.0602 - accuracy: 0.9721 - val_loss: 0.0369 - val_accuracy: 0.9778\n",
      "Epoch 251/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0382 - accuracy: 0.9935\n",
      "Epoch 00251: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 621us/sample - loss: 0.0417 - accuracy: 0.9916 - val_loss: 0.1149 - val_accuracy: 0.9667\n",
      "Epoch 252/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0371 - accuracy: 0.9806\n",
      "Epoch 00252: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 601us/sample - loss: 0.0324 - accuracy: 0.9832 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0347 - accuracy: 0.9867\n",
      "Epoch 00253: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 607us/sample - loss: 0.0292 - accuracy: 0.9888 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00254: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 590us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0040 - accuracy: 0.9967    \n",
      "Epoch 00255: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 607us/sample - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00256: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 595us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0082 - accuracy: 0.9937\n",
      "Epoch 00257: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 577us/sample - loss: 0.0074 - accuracy: 0.9944 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0093 - accuracy: 0.9964\n",
      "Epoch 00258: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 684us/sample - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0241 - val_accuracy: 0.9889\n",
      "Epoch 259/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 5.6206e-04 - accuracy: 1.0000\n",
      "Epoch 00259: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 738us/sample - loss: 5.7527e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 1.8631e-04 - accuracy: 1.0000\n",
      "Epoch 00260: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 6.1148e-04 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 00261: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 737us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000  \n",
      "Epoch 00262: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 724us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9889\n",
      "Epoch 263/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 00263: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 619us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0060 - accuracy: 0.9968  \n",
      "Epoch 00264: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 593us/sample - loss: 0.0053 - accuracy: 0.9972 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000  \n",
      "Epoch 00265: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 629us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0145 - accuracy: 0.9964  \n",
      "Epoch 00266: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0050 - accuracy: 0.9964\n",
      "Epoch 00267: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 678us/sample - loss: 0.0054 - accuracy: 0.9972 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9943\n",
      "Epoch 00268: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 716us/sample - loss: 0.0086 - accuracy: 0.9944 - val_loss: 0.0274 - val_accuracy: 0.9889\n",
      "Epoch 269/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0098 - accuracy: 0.9968\n",
      "Epoch 00269: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 598us/sample - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 5.4629e-04 - accuracy: 1.0000\n",
      "Epoch 00270: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 642us/sample - loss: 5.6919e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2002 - accuracy: 0.9581\n",
      "Epoch 00271: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 624us/sample - loss: 0.4365 - accuracy: 0.9385 - val_loss: 0.0793 - val_accuracy: 0.9667\n",
      "Epoch 272/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1756 - accuracy: 0.9571\n",
      "Epoch 00272: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 635us/sample - loss: 0.1625 - accuracy: 0.9553 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0257 - accuracy: 0.9897\n",
      "Epoch 00273: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 646us/sample - loss: 0.0218 - accuracy: 0.9916 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0074 - accuracy: 0.9967\n",
      "Epoch 00274: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 618us/sample - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000  \n",
      "Epoch 00275: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 604us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0065 - accuracy: 0.9968\n",
      "Epoch 00276: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 618us/sample - loss: 0.0057 - accuracy: 0.9972 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0072 - accuracy: 0.9964\n",
      "Epoch 00277: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0309 - accuracy: 0.9839\n",
      "Epoch 00278: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 627us/sample - loss: 0.0268 - accuracy: 0.9860 - val_loss: 0.0510 - val_accuracy: 0.9667\n",
      "Epoch 279/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0090 - accuracy: 0.9966\n",
      "Epoch 00279: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 684us/sample - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0094 - accuracy: 0.9893\n",
      "Epoch 00280: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.0079 - accuracy: 0.9916 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00281: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 594us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 8.3283e-04 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 8.0939e-04 - accuracy: 1.0000\n",
      "Epoch 00282: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 604us/sample - loss: 6.8361e-04 - accuracy: 1.0000 - val_loss: 9.3702e-04 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000  \n",
      "Epoch 00283: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 9.0617e-04 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
      "Epoch 00284: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.7269e-04 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00285: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 616us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.8430e-04 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 3.1463e-04 - accuracy: 1.0000\n",
      "Epoch 00286: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 596us/sample - loss: 3.1213e-04 - accuracy: 1.0000 - val_loss: 2.3642e-04 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 8.9448e-05 - accuracy: 1.0000\n",
      "Epoch 00287: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 610us/sample - loss: 8.6830e-05 - accuracy: 1.0000 - val_loss: 2.4764e-04 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00288: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 697us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0272 - accuracy: 0.9926    \n",
      "Epoch 00289: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 690us/sample - loss: 0.0210 - accuracy: 0.9944 - val_loss: 0.0597 - val_accuracy: 0.9889\n",
      "Epoch 290/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0107 - accuracy: 0.9963\n",
      "Epoch 00290: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0043 - accuracy: 0.9968\n",
      "Epoch 00291: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 590us/sample - loss: 0.0038 - accuracy: 0.9972 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 6.5859e-04 - accuracy: 1.0000\n",
      "Epoch 00292: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 605us/sample - loss: 9.1904e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0051 - accuracy: 0.9968\n",
      "Epoch 00293: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 584us/sample - loss: 0.0044 - accuracy: 0.9972 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 8.5591e-04 - accuracy: 1.0000\n",
      "Epoch 00294: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 582us/sample - loss: 7.9451e-04 - accuracy: 1.0000 - val_loss: 1.8498e-04 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0451 - accuracy: 0.9935  \n",
      "Epoch 00295: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 589us/sample - loss: 0.0394 - accuracy: 0.9944 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 00296: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 605us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9889\n",
      "Epoch 297/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00297: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 632us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00298: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 597us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0068 - accuracy: 0.9968  \n",
      "Epoch 00299: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 586us/sample - loss: 0.0062 - accuracy: 0.9972 - val_loss: 7.1829e-04 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 9.0949e-04 - accuracy: 1.0000\n",
      "Epoch 00300: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 601us/sample - loss: 8.4806e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000  \n",
      "Epoch 00301: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 634us/sample - loss: 9.8939e-04 - accuracy: 1.0000 - val_loss: 7.5586e-04 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 4.2326e-04 - accuracy: 1.0000\n",
      "Epoch 00302: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 614us/sample - loss: 3.9942e-04 - accuracy: 1.0000 - val_loss: 5.9432e-04 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0165 - accuracy: 0.9935    \n",
      "Epoch 00303: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 601us/sample - loss: 0.0371 - accuracy: 0.9888 - val_loss: 0.0369 - val_accuracy: 0.9778\n",
      "Epoch 304/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0270 - accuracy: 0.9867\n",
      "Epoch 00304: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0330 - accuracy: 0.9804 - val_loss: 0.0224 - val_accuracy: 0.9889\n",
      "Epoch 305/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00305: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9889\n",
      "Epoch 306/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0132 - accuracy: 0.9929\n",
      "Epoch 00306: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0105 - accuracy: 0.9944 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 00307: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00308: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 8.8879e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00309: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 693us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 9.4437e-04 - accuracy: 1.0000\n",
      "Epoch 00310: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 679us/sample - loss: 7.5585e-04 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 3.6952e-04 - accuracy: 1.0000\n",
      "Epoch 00311: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 684us/sample - loss: 3.0961e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 5.8361e-04 - accuracy: 1.0000\n",
      "Epoch 00312: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 4.6104e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 5.6566e-04 - accuracy: 1.0000\n",
      "Epoch 00313: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 4.8510e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 2.5270e-04 - accuracy: 1.0000\n",
      "Epoch 00314: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 680us/sample - loss: 2.1901e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 1.1234e-04 - accuracy: 1.0000\n",
      "Epoch 00315: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 669us/sample - loss: 1.1867e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 4.2557e-04 - accuracy: 1.0000\n",
      "Epoch 00316: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 763us/sample - loss: 4.0887e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000  \n",
      "Epoch 00317: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.7261e-04 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 3.5714e-04 - accuracy: 1.0000\n",
      "Epoch 00318: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 691us/sample - loss: 0.0026 - accuracy: 0.9972 - val_loss: 9.0309e-04 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 8.7567e-04 - accuracy: 1.0000\n",
      "Epoch 00319: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 672us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.3726e-04 - accuracy: 1.0000\n",
      "Epoch 00320: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 1.1415e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000  \n",
      "Epoch 00321: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 9.4463e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00322: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0141 - accuracy: 0.9893  \n",
      "Epoch 00323: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 0.0219 - accuracy: 0.9888 - val_loss: 0.0610 - val_accuracy: 0.9556\n",
      "Epoch 324/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0193 - accuracy: 0.9964\n",
      "Epoch 00324: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0159 - accuracy: 0.9972 - val_loss: 0.0184 - val_accuracy: 0.9889\n",
      "Epoch 325/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00325: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 685us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0154 - accuracy: 0.9893  \n",
      "Epoch 00326: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 694us/sample - loss: 0.0274 - accuracy: 0.9832 - val_loss: 0.0196 - val_accuracy: 0.9889\n",
      "Epoch 327/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 00327: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 670us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0036 - accuracy: 0.9964  \n",
      "Epoch 00328: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 687us/sample - loss: 0.0072 - accuracy: 0.9944 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0037 - accuracy: 0.9964    \n",
      "Epoch 00329: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 689us/sample - loss: 0.0030 - accuracy: 0.9972 - val_loss: 0.0370 - val_accuracy: 0.9889\n",
      "Epoch 330/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 00330: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 718us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 00331: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 675us/sample - loss: 0.0208 - accuracy: 0.9972 - val_loss: 0.0268 - val_accuracy: 0.9889\n",
      "Epoch 332/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9800\n",
      "Epoch 00332: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 719us/sample - loss: 0.0590 - accuracy: 0.9804 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
      "Epoch 333/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0136 - accuracy: 0.9931    \n",
      "Epoch 00333: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 656us/sample - loss: 0.0164 - accuracy: 0.9916 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 00334: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 9.3746e-04 - accuracy: 1.0000\n",
      "Epoch 00335: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 678us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 5.4321e-04 - accuracy: 1.0000\n",
      "Epoch 00336: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 5.0766e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 00337: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 649us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00338: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 658us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0098 - accuracy: 0.9931\n",
      "Epoch 00339: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.0173 - accuracy: 0.9888 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0081 - accuracy: 0.9967\n",
      "Epoch 00340: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0419 - val_accuracy: 0.9889\n",
      "Epoch 341/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0143 - accuracy: 0.9929\n",
      "Epoch 00341: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 0.0145 - accuracy: 0.9916 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 7.5880e-04 - accuracy: 1.0000\n",
      "Epoch 00342: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0223 - accuracy: 0.9929\n",
      "Epoch 00343: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 9.8719e-04 - accuracy: 1.0000\n",
      "Epoch 00344: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000    \n",
      "Epoch 00345: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 7.3613e-04 - accuracy: 1.0000\n",
      "Epoch 00346: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 653us/sample - loss: 9.7675e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00347: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 645us/sample - loss: 9.1519e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 9.4636e-04 - accuracy: 1.0000\n",
      "Epoch 00348: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 725us/sample - loss: 9.4468e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 5.7221e-04 - accuracy: 1.0000\n",
      "Epoch 00349: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 644us/sample - loss: 5.4490e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 6.8098e-04 - accuracy: 1.0000\n",
      "Epoch 00350: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 645us/sample - loss: 6.0525e-04 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
      "Epoch 00351: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 668us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 2.4248e-04 - accuracy: 1.0000\n",
      "Epoch 00352: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 1.8731e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 5.9117e-05 - accuracy: 1.0000\n",
      "Epoch 00353: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 690us/sample - loss: 8.3203e-05 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 9.9667e-05 - accuracy: 1.0000\n",
      "Epoch 00354: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 682us/sample - loss: 8.6142e-05 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 3.4302e-05 - accuracy: 1.0000\n",
      "Epoch 00355: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 643us/sample - loss: 3.2240e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 5.0152e-04 - accuracy: 1.0000\n",
      "Epoch 00356: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 637us/sample - loss: 4.7225e-04 - accuracy: 1.0000 - val_loss: 6.5725e-04 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 8.7460e-04 - accuracy: 1.0000\n",
      "Epoch 00357: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 632us/sample - loss: 9.1334e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 7.5885e-04 - accuracy: 1.0000\n",
      "Epoch 00358: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 615us/sample - loss: 6.4512e-04 - accuracy: 1.0000 - val_loss: 7.5246e-04 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.4184e-04 - accuracy: 1.0000\n",
      "Epoch 00359: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 678us/sample - loss: 2.0483e-04 - accuracy: 1.0000 - val_loss: 6.4966e-04 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 2.0740e-04 - accuracy: 1.0000\n",
      "Epoch 00360: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 649us/sample - loss: 1.7701e-04 - accuracy: 1.0000 - val_loss: 8.4334e-04 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 6.9297e-05 - accuracy: 1.0000\n",
      "Epoch 00361: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 684us/sample - loss: 6.7750e-05 - accuracy: 1.0000 - val_loss: 8.6510e-04 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 9.4117e-05 - accuracy: 1.0000\n",
      "Epoch 00362: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 7.5944e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 3.4271e-05 - accuracy: 1.0000\n",
      "Epoch 00363: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 3.6455e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 2.2369e-04 - accuracy: 1.0000\n",
      "Epoch 00364: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 657us/sample - loss: 1.8361e-04 - accuracy: 1.0000 - val_loss: 8.5131e-04 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 3.9102e-05 - accuracy: 1.0000\n",
      "Epoch 00365: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 5.2639e-05 - accuracy: 1.0000 - val_loss: 8.3221e-04 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 1.7934e-04 - accuracy: 1.0000\n",
      "Epoch 00366: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 637us/sample - loss: 1.5576e-04 - accuracy: 1.0000 - val_loss: 7.1226e-04 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.6180e-04 - accuracy: 1.0000\n",
      "Epoch 00367: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 667us/sample - loss: 1.2823e-04 - accuracy: 1.0000 - val_loss: 4.1445e-04 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 3.3732e-04 - accuracy: 1.0000\n",
      "Epoch 00368: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 644us/sample - loss: 2.8351e-04 - accuracy: 1.0000 - val_loss: 7.7879e-04 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 7.6873e-04 - accuracy: 1.0000\n",
      "Epoch 00369: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 651us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000  \n",
      "Epoch 00370: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 654us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9889\n",
      "Epoch 371/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.1542 - accuracy: 0.9679\n",
      "Epoch 00371: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 0.1333 - accuracy: 0.9693 - val_loss: 0.1325 - val_accuracy: 0.9444\n",
      "Epoch 372/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0377 - accuracy: 0.9893\n",
      "Epoch 00372: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.0587 - accuracy: 0.9777 - val_loss: 0.0284 - val_accuracy: 0.9778\n",
      "Epoch 373/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0204 - accuracy: 0.9893\n",
      "Epoch 00373: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 0.0165 - accuracy: 0.9916 - val_loss: 0.0142 - val_accuracy: 0.9889\n",
      "Epoch 374/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00374: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 632us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 1.4721e-04 - accuracy: 1.0000\n",
      "Epoch 00375: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 1.7634e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000  \n",
      "Epoch 00376: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0172 - val_accuracy: 0.9889\n",
      "Epoch 377/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 5.7226e-04 - accuracy: 1.0000\n",
      "Epoch 00377: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 5.4892e-04 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9889\n",
      "Epoch 378/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00378: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 676us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 0.9889\n",
      "Epoch 379/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 3.2484e-04 - accuracy: 1.0000\n",
      "Epoch 00379: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 640us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9889\n",
      "Epoch 380/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 3.4012e-04 - accuracy: 1.0000\n",
      "Epoch 00380: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 660us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 0.9889\n",
      "Epoch 381/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000    \n",
      "Epoch 00381: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9889\n",
      "Epoch 382/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.9832e-04 - accuracy: 1.0000\n",
      "Epoch 00382: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 655us/sample - loss: 2.8802e-04 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9889\n",
      "Epoch 383/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000  \n",
      "Epoch 00383: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.5673e-04 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 3.7088e-04 - accuracy: 1.0000\n",
      "Epoch 00384: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 638us/sample - loss: 3.0641e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 2.2116e-04 - accuracy: 1.0000\n",
      "Epoch 00385: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 2.0649e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 3.6158e-04 - accuracy: 1.0000\n",
      "Epoch 00386: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 740us/sample - loss: 3.5409e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 1.4669e-04 - accuracy: 1.0000\n",
      "Epoch 00387: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 650us/sample - loss: 1.2877e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0035 - accuracy: 0.9964    \n",
      "Epoch 00388: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 659us/sample - loss: 0.0049 - accuracy: 0.9944 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 00389: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 679us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 4.2326e-04 - accuracy: 1.0000\n",
      "Epoch 00390: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 664us/sample - loss: 3.3957e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 4.6307e-04 - accuracy: 1.0000\n",
      "Epoch 00391: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 696us/sample - loss: 4.4784e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.5402e-04 - accuracy: 1.0000\n",
      "Epoch 00392: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 1.6417e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 6.2265e-05 - accuracy: 1.0000\n",
      "Epoch 00393: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 661us/sample - loss: 1.7480e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 2.9970e-04 - accuracy: 1.0000\n",
      "Epoch 00394: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 647us/sample - loss: 2.5458e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 2.0489e-04 - accuracy: 1.0000\n",
      "Epoch 00395: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 665us/sample - loss: 4.8084e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 8.2466e-04 - accuracy: 1.0000\n",
      "Epoch 00396: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 709us/sample - loss: 8.0624e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 2.9308e-04 - accuracy: 1.0000\n",
      "Epoch 00397: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 648us/sample - loss: 2.3617e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 2.2053e-04 - accuracy: 1.0000\n",
      "Epoch 00398: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 733us/sample - loss: 2.1288e-04 - accuracy: 1.0000 - val_loss: 7.9558e-04 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 3.4149e-04 - accuracy: 1.0000\n",
      "Epoch 00399: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 785us/sample - loss: 3.1493e-04 - accuracy: 1.0000 - val_loss: 5.6498e-04 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 1.2364e-04 - accuracy: 1.0000\n",
      "Epoch 00400: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 737us/sample - loss: 1.2141e-04 - accuracy: 1.0000 - val_loss: 5.5635e-04 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 2.9393e-05 - accuracy: 1.0000\n",
      "Epoch 00401: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 771us/sample - loss: 3.1002e-05 - accuracy: 1.0000 - val_loss: 5.1938e-04 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 8.5841e-05 - accuracy: 1.0000\n",
      "Epoch 00402: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 731us/sample - loss: 8.3923e-05 - accuracy: 1.0000 - val_loss: 4.9585e-04 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "270/358 [=====================>........] - ETA: 0s - loss: 1.4035e-05 - accuracy: 1.0000\n",
      "Epoch 00403: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 3.8947e-05 - accuracy: 1.0000 - val_loss: 4.8878e-04 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 5.1644e-05 - accuracy: 1.0000\n",
      "Epoch 00404: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 671us/sample - loss: 5.4077e-05 - accuracy: 1.0000 - val_loss: 4.4959e-04 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 1.9017e-04 - accuracy: 1.0000\n",
      "Epoch 00405: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 674us/sample - loss: 2.1365e-04 - accuracy: 1.0000 - val_loss: 4.9455e-04 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 4.3692e-05 - accuracy: 1.0000\n",
      "Epoch 00406: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 631us/sample - loss: 4.0273e-05 - accuracy: 1.0000 - val_loss: 5.2502e-04 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.1294e-04 - accuracy: 1.0000\n",
      "Epoch 00407: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 600us/sample - loss: 9.8840e-05 - accuracy: 1.0000 - val_loss: 4.7089e-04 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 5.3441e-04 - accuracy: 1.0000\n",
      "Epoch 00408: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 592us/sample - loss: 4.8029e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.4468e-04 - accuracy: 1.0000\n",
      "Epoch 00409: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 597us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0267 - accuracy: 0.9903\n",
      "Epoch 00410: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 588us/sample - loss: 0.0232 - accuracy: 0.9916 - val_loss: 0.1077 - val_accuracy: 0.9333\n",
      "Epoch 411/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0679 - accuracy: 0.9710\n",
      "Epoch 00411: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 590us/sample - loss: 0.0868 - accuracy: 0.9721 - val_loss: 0.0551 - val_accuracy: 0.9778\n",
      "Epoch 412/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0262 - accuracy: 0.9935\n",
      "Epoch 00412: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 590us/sample - loss: 0.0672 - accuracy: 0.9832 - val_loss: 0.0653 - val_accuracy: 0.9444\n",
      "Epoch 413/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1195 - accuracy: 0.9742\n",
      "Epoch 00413: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 588us/sample - loss: 0.1278 - accuracy: 0.9693 - val_loss: 0.0777 - val_accuracy: 0.9333\n",
      "Epoch 414/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0440 - accuracy: 0.9871\n",
      "Epoch 00414: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 581us/sample - loss: 0.0389 - accuracy: 0.9888 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0212 - accuracy: 0.9871\n",
      "Epoch 00415: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 578us/sample - loss: 0.0184 - accuracy: 0.9888 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000  \n",
      "Epoch 00416: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 591us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 00417: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 580us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000  \n",
      "Epoch 00418: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 597us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 5.1550e-04 - accuracy: 1.0000\n",
      "Epoch 00419: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 590us/sample - loss: 4.7636e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 5.0248e-04 - accuracy: 1.0000\n",
      "Epoch 00420: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 588us/sample - loss: 4.3563e-04 - accuracy: 1.0000 - val_loss: 8.6857e-04 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 6.3117e-04 - accuracy: 1.0000\n",
      "Epoch 00421: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 603us/sample - loss: 5.7755e-04 - accuracy: 1.0000 - val_loss: 3.6177e-04 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0049 - accuracy: 0.9968    \n",
      "Epoch 00422: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 579us/sample - loss: 0.0052 - accuracy: 0.9972 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9971\n",
      "Epoch 00423: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 704us/sample - loss: 0.0037 - accuracy: 0.9972 - val_loss: 0.0627 - val_accuracy: 0.9444\n",
      "Epoch 424/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00424: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 637us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 3.1595e-04 - accuracy: 1.0000\n",
      "Epoch 00425: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 603us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0225 - accuracy: 0.9935  \n",
      "Epoch 00426: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 587us/sample - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0113 - accuracy: 0.9968\n",
      "Epoch 00427: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 590us/sample - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0045 - accuracy: 0.9968\n",
      "Epoch 00428: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 592us/sample - loss: 0.0043 - accuracy: 0.9972 - val_loss: 8.5012e-04 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    \n",
      "Epoch 00429: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 581us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.2550e-04 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 2.4002e-04 - accuracy: 1.0000\n",
      "Epoch 00430: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 590us/sample - loss: 2.0817e-04 - accuracy: 1.0000 - val_loss: 4.3316e-04 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 4.7989e-04 - accuracy: 1.0000\n",
      "Epoch 00431: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 600us/sample - loss: 4.0797e-04 - accuracy: 1.0000 - val_loss: 4.0826e-04 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 4.3123e-04 - accuracy: 1.0000\n",
      "Epoch 00432: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 578us/sample - loss: 3.9035e-04 - accuracy: 1.0000 - val_loss: 2.2591e-04 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 2.8169e-04 - accuracy: 1.0000\n",
      "Epoch 00433: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 589us/sample - loss: 2.4572e-04 - accuracy: 1.0000 - val_loss: 2.0354e-04 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 9.8208e-04 - accuracy: 1.0000\n",
      "Epoch 00434: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 597us/sample - loss: 8.6673e-04 - accuracy: 1.0000 - val_loss: 4.3650e-04 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 6.1386e-04 - accuracy: 1.0000\n",
      "Epoch 00435: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 584us/sample - loss: 5.3382e-04 - accuracy: 1.0000 - val_loss: 1.0495e-04 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 2.0589e-04 - accuracy: 1.0000\n",
      "Epoch 00436: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 582us/sample - loss: 1.8373e-04 - accuracy: 1.0000 - val_loss: 9.6532e-05 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 3.9990e-04 - accuracy: 1.0000\n",
      "Epoch 00437: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 579us/sample - loss: 4.3455e-04 - accuracy: 1.0000 - val_loss: 1.0481e-04 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.1764e-04 - accuracy: 1.0000\n",
      "Epoch 00438: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 584us/sample - loss: 1.6749e-04 - accuracy: 1.0000 - val_loss: 7.7531e-05 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 3.1319e-05 - accuracy: 1.0000\n",
      "Epoch 00439: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 595us/sample - loss: 3.5020e-05 - accuracy: 1.0000 - val_loss: 6.8571e-05 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.7436e-04 - accuracy: 1.0000\n",
      "Epoch 00440: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 585us/sample - loss: 1.5230e-04 - accuracy: 1.0000 - val_loss: 6.9028e-05 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 8.4912e-05 - accuracy: 1.0000\n",
      "Epoch 00441: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 582us/sample - loss: 7.7797e-05 - accuracy: 1.0000 - val_loss: 5.5582e-05 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 8.4005e-05 - accuracy: 1.0000\n",
      "Epoch 00442: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 581us/sample - loss: 1.2104e-04 - accuracy: 1.0000 - val_loss: 5.8832e-05 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000  \n",
      "Epoch 00443: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 591us/sample - loss: 0.0303 - accuracy: 0.9972 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0074 - accuracy: 0.9968\n",
      "Epoch 00444: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 592us/sample - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0082 - accuracy: 0.9968  \n",
      "Epoch 00445: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 587us/sample - loss: 0.0072 - accuracy: 0.9972 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 7.3344e-04 - accuracy: 1.0000\n",
      "Epoch 00446: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 580us/sample - loss: 6.5535e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 5.0675e-04 - accuracy: 1.0000\n",
      "Epoch 00447: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 593us/sample - loss: 7.1652e-04 - accuracy: 1.0000 - val_loss: 8.4987e-04 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 2.4139e-04 - accuracy: 1.0000\n",
      "Epoch 00448: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 595us/sample - loss: 3.1295e-04 - accuracy: 1.0000 - val_loss: 3.8729e-04 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000  \n",
      "Epoch 00449: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 593us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.1058e-04 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 5.1225e-04 - accuracy: 1.0000\n",
      "Epoch 00450: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 582us/sample - loss: 4.5908e-04 - accuracy: 1.0000 - val_loss: 2.4964e-04 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.3086e-04 - accuracy: 1.0000\n",
      "Epoch 00451: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 578us/sample - loss: 1.2178e-04 - accuracy: 1.0000 - val_loss: 4.8561e-04 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.8398e-04 - accuracy: 1.0000\n",
      "Epoch 00452: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 585us/sample - loss: 0.0022 - accuracy: 0.9972 - val_loss: 4.0776e-04 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0227 - accuracy: 0.9900\n",
      "Epoch 00453: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 623us/sample - loss: 0.0221 - accuracy: 0.9888 - val_loss: 0.0258 - val_accuracy: 0.9889\n",
      "Epoch 454/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00454: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 602us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 4.1897e-04 - accuracy: 1.0000\n",
      "Epoch 00455: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 584us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 00456: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 596us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.3547e-04 - accuracy: 1.0000\n",
      "Epoch 00457: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 583us/sample - loss: 1.2178e-04 - accuracy: 1.0000 - val_loss: 5.4480e-04 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 4.3163e-05 - accuracy: 1.0000\n",
      "Epoch 00458: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 593us/sample - loss: 4.7179e-05 - accuracy: 1.0000 - val_loss: 4.5200e-04 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 4.8387e-05 - accuracy: 1.0000\n",
      "Epoch 00459: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 617us/sample - loss: 2.4770e-04 - accuracy: 1.0000 - val_loss: 3.6185e-04 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.6418e-04 - accuracy: 1.0000\n",
      "Epoch 00460: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 601us/sample - loss: 1.5086e-04 - accuracy: 1.0000 - val_loss: 2.2006e-04 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 4.5627e-05 - accuracy: 1.0000\n",
      "Epoch 00461: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 4.0255e-05 - accuracy: 1.0000 - val_loss: 1.9055e-04 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 4.9491e-05 - accuracy: 1.0000\n",
      "Epoch 00462: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 622us/sample - loss: 5.9375e-04 - accuracy: 1.0000 - val_loss: 1.8791e-04 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 5.9439e-05 - accuracy: 1.0000\n",
      "Epoch 00463: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 5.3533e-05 - accuracy: 1.0000 - val_loss: 6.2041e-04 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 7.2295e-05 - accuracy: 1.0000\n",
      "Epoch 00464: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 619us/sample - loss: 6.7471e-05 - accuracy: 1.0000 - val_loss: 5.4252e-04 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 5.6299e-04 - accuracy: 1.0000\n",
      "Epoch 00465: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 605us/sample - loss: 5.5061e-04 - accuracy: 1.0000 - val_loss: 3.4650e-04 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 5.7937e-05 - accuracy: 1.0000\n",
      "Epoch 00466: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 644us/sample - loss: 5.5159e-05 - accuracy: 1.0000 - val_loss: 2.5803e-04 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 6.8141e-05 - accuracy: 1.0000\n",
      "Epoch 00467: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 619us/sample - loss: 8.6583e-04 - accuracy: 1.0000 - val_loss: 1.7202e-04 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0169 - accuracy: 0.9912  \n",
      "Epoch 00468: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 716us/sample - loss: 0.0161 - accuracy: 0.9916 - val_loss: 0.0269 - val_accuracy: 0.9889\n",
      "Epoch 469/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0561 - accuracy: 0.9821\n",
      "Epoch 00469: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 663us/sample - loss: 0.0452 - accuracy: 0.9860 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "280/358 [======================>.......] - ETA: 0s - loss: 0.0104 - accuracy: 0.9964\n",
      "Epoch 00470: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 662us/sample - loss: 0.0106 - accuracy: 0.9944 - val_loss: 7.7606e-04 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0492 - accuracy: 0.9900  \n",
      "Epoch 00471: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 610us/sample - loss: 0.0422 - accuracy: 0.9916 - val_loss: 0.2649 - val_accuracy: 0.8556\n",
      "Epoch 472/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0352 - accuracy: 0.9839\n",
      "Epoch 00472: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 592us/sample - loss: 0.0315 - accuracy: 0.9860 - val_loss: 1.2751e-04 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0347 - accuracy: 0.9871\n",
      "Epoch 00473: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 578us/sample - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.2170 - val_accuracy: 0.9556\n",
      "Epoch 474/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1098 - accuracy: 0.9742\n",
      "Epoch 00474: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 582us/sample - loss: 0.0955 - accuracy: 0.9777 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1776 - accuracy: 0.9710\n",
      "Epoch 00475: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 595us/sample - loss: 0.1555 - accuracy: 0.9749 - val_loss: 0.0589 - val_accuracy: 0.9889\n",
      "Epoch 476/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0777 - accuracy: 0.9806\n",
      "Epoch 00476: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 580us/sample - loss: 0.0691 - accuracy: 0.9832 - val_loss: 0.0366 - val_accuracy: 0.9889\n",
      "Epoch 477/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0453 - accuracy: 0.9774\n",
      "Epoch 00477: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 587us/sample - loss: 0.0418 - accuracy: 0.9804 - val_loss: 0.0420 - val_accuracy: 0.9889\n",
      "Epoch 478/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0078 - accuracy: 0.9968\n",
      "Epoch 00478: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 584us/sample - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.0275 - val_accuracy: 0.9889\n",
      "Epoch 479/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0090 - accuracy: 0.9968\n",
      "Epoch 00479: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 583us/sample - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0276 - val_accuracy: 0.9889\n",
      "Epoch 480/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0118 - accuracy: 0.9968\n",
      "Epoch 00480: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 590us/sample - loss: 0.0102 - accuracy: 0.9972 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0064 - accuracy: 0.9968  \n",
      "Epoch 00481: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 594us/sample - loss: 0.0058 - accuracy: 0.9972 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 00482: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 601us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 5.0012e-04 - accuracy: 1.0000\n",
      "Epoch 00483: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 632us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 8.4502e-04 - accuracy: 1.0000\n",
      "Epoch 00484: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 641us/sample - loss: 7.0597e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 0.0061 - accuracy: 0.9966  \n",
      "Epoch 00485: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 626us/sample - loss: 0.0106 - accuracy: 0.9916 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0153 - accuracy: 0.9935\n",
      "Epoch 00486: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 603us/sample - loss: 0.0146 - accuracy: 0.9944 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00487: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 608us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 8.4352e-04 - accuracy: 1.0000\n",
      "Epoch 00488: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 603us/sample - loss: 7.4447e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 1.2338e-04 - accuracy: 1.0000\n",
      "Epoch 00489: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 603us/sample - loss: 1.1832e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 2.9921e-04 - accuracy: 1.0000\n",
      "Epoch 00490: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 597us/sample - loss: 2.7097e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0120 - accuracy: 0.9935\n",
      "Epoch 00491: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 585us/sample - loss: 0.0104 - accuracy: 0.9944 - val_loss: 0.0105 - val_accuracy: 0.9889\n",
      "Epoch 492/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000    \n",
      "Epoch 00492: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 599us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00493: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 589us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 6.7372e-04 - accuracy: 1.0000\n",
      "Epoch 00494: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 581us/sample - loss: 8.1895e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 8.0740e-04 - accuracy: 1.0000\n",
      "Epoch 00495: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 598us/sample - loss: 8.1536e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 2.3436e-04 - accuracy: 1.0000\n",
      "Epoch 00496: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 605us/sample - loss: 2.1283e-04 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 7.5665e-04 - accuracy: 1.0000\n",
      "Epoch 00497: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 598us/sample - loss: 6.7635e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 9.4330e-05 - accuracy: 1.0000\n",
      "Epoch 00498: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 608us/sample - loss: 8.0815e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "290/358 [=======================>......] - ETA: 0s - loss: 4.3778e-04 - accuracy: 1.0000\n",
      "Epoch 00499: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 640us/sample - loss: 5.3152e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 9.1776e-05 - accuracy: 1.0000\n",
      "Epoch 00500: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 605us/sample - loss: 7.8127e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Training completed in time:  0:01:56.755215\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deXwV1dnA8d9zswJhJ6wBAcEFFEHibivoa11qq61at7rUrVqrtYtbrUsXW+1mi7YuVauorVYsilarKCJQEQmLyCYisgQSCAnZt7s87x8zSW7uvQkBMrkh83w/5nNnzpw78wwm97nnnJk5oqoYY4zxr0CyAzDGGJNclgiMMcbnLBEYY4zPWSIwxhifs0RgjDE+Z4nAGGN8zhKBMW0gIiNFREUktQ11rxCRBfu6H2M6iiUC0+WIyEYRqReRATHly9wP4ZHJicyYzskSgemqvgAualgRkcOB7skLx5jOyxKB6aqeBS6LWr8cmB5dQUR6i8h0ESkSkU0i8jMRCbjbUkTk9yKyU0Q2AF9N8N4nRaRARLaKyK9EJGVPgxSRoSIyS0RKRGS9iFwTte1oEckTkXIR2S4if3TLM0XkOREpFpFSEVksIoP29NjGNLBEYLqqD4FeInKo+wF9IfBcTJ2HgN7AaOAknMTxHXfbNcBZwCQgFzgv5r1PAyFgjFvnK8DVexHnC0A+MNQ9xq9F5GR325+BP6tqL+BA4F9u+eVu3MOB/sB1QM1eHNsYwBKB6doaWgWnAmuArQ0bopLDHapaoaobgT8Al7pVvgX8SVW3qGoJ8Juo9w4CzgRuVtUqVd0BPOjur81EZDhwAnCbqtaq6nLgCZpaMkFgjIgMUNVKVf0wqrw/MEZVw6q6RFXL9+TYxkSzRGC6smeBi4EriOkWAgYAacCmqLJNwDB3eSiwJWZbgwPc9xa4XTOlwGPAwD2MbyhQoqoVLcRwFXAQsNbt/jkr6rzeAl4QkW0i8lsRSdvDYxvTyBKB6bJUdRPOoPGZwL9jNu/E+WZ9QFTZCJpaDQU4XS/R2xpsAeqAAarax/3pparj9zDEbUA/EemZKAZV/UxVL8JJMA8AM0Skh6oGVfXnqjoOOB6nC+syjNlLlghMV3cVcLKqVkUXqmoYp8/9PhHpKSIHAD+iaRzhX8BNIpIjIn2B26PeWwC8DfxBRHqJSEBEDhSRk/YkMFXdAnwA/MYdAJ7gxvscgIh8W0SyVTUClLpvi4jIVBE53O3eKsdJaJE9ObYx0SwRmC5NVT9X1bwWNt8IVAEbgAXAP4Cn3G1/w+l++RhYSnyL4jIgHVgN7AJmAEP2IsSLgJE4rYOZwD2q+o677XRglYhU4gwcX6iqNcBg93jlOGMf7+N0FxmzV8QmpjHGGH+zFoExxvicJQJjjPE5SwTGGONzlgiMMcbn9rtH4Q4YMEBHjhyZ7DCMMWa/smTJkp2qmp1o236XCEaOHEleXktXAxpjjElERDa1tM26howxxucsERhjjM9ZIjDGGJ/b78YIEgkGg+Tn51NbW5vsUDyXmZlJTk4OaWn2sEljTPvoEokgPz+fnj17MnLkSEQk2eF4RlUpLi4mPz+fUaNGJTscY0wX0SW6hmpra+nfv3+XTgIAIkL//v190fIxxnScLpEIgC6fBBr45TyNMR2nyySC3akNhiksqyUYtse2G2NMNF8lgh0VtYQj7f/Y7eLiYiZOnMjEiRMZPHgww4YNa1yvr69v9b15eXncdNNN7R6TMca0lWeDxSKSCcwDMtzjzFDVe2LqXAH8jqbpAR9W1Se8iskr/fv3Z/ny5QDce++9ZGVl8ZOf/KRxeygUIjU18T91bm4uubm5HRKnMcYk4mWLoA5nisAjgInA6SJybIJ6L6rqRPfHsyTQ0LPeUdPwXHHFFVx33XUcc8wx3HrrrXz00Uccd9xxTJo0ieOPP55PP/0UgLlz53LWWc6c5Pfeey9XXnklU6ZMYfTo0UybNq2DojXG+JlnLQJ1pj6rdFfT3B/PP4d//toqVm8rjysPR5TaYJhu6SkE9nDAddzQXtzztT2dl9y5rPWDDz4gJSWF8vJy5s+fT2pqKu+88w4//elPefnll+Pes3btWt577z0qKio4+OCDuf766+2eAWOMpzy9j8CdXHsJMAb4i6ouSlDtXBH5MrAO+KE7oXfsfq4FrgUYMWKEhxG3r/PPP5+UlBQAysrKuPzyy/nss88QEYLBYML3fPWrXyUjI4OMjAwGDhzI9u3bycnJ6ciwjTE+42kiUNUwMFFE+gAzReQwVV0ZVeU14J+qWici3wWeAU5OsJ/HgccBcnNzW21VtPTNvawmyKbiKsYOzKJbesfcR9ejR4/G5bvuuoupU6cyc+ZMNm7cyJQpUxK+JyMjo3E5JSWFUCjkdZjGGJ/rkKuGVLUUeA84Paa8WFXr3NUngMkdEU8ylJWVMWzYMACefvrp5AZjjDFRPEsEIpLttgQQkW7AqcDamDpDola/DqzxKp5ku/XWW7njjjuYNGmSfcs3xnQq4ozperBjkQk4XT0pOAnnX6r6CxH5BZCnqrNE5Dc4CSAElADXq+raFneK0zUUOzHNmjVrOPTQQ1uNp7wmyMbiKsYMzKJ7B3UNeaUt52uMMdFEZImqJrxW3curhlYAkxKU3x21fAdwh1cxGGOM2T3f3FlsjDEmMUsExhjjc5YIjDHG5/yXCDrqGRPGGLOf8E8icJ8qYXnAGGOa27+vo9wDXk7nUlxczCmnnAJAYWEhKSkpZGdnA/DRRx+Rnp7e6vvnzp1Leno6xx9/vIdRGmNMYr5JBF7a3WOod2fu3LlkZWVZIjDGJIV/uoY62JIlSzjppJOYPHkyp512GgUFBQBMmzaNcePGMWHCBC688EI2btzIo48+yoMPPsjEiROZP39+kiM3xvhN12sRvHk7FH4SV9wtEmF0MEJmegrs6by/gw+HM+5vc3VV5cYbb+TVV18lOzubF198kTvvvJOnnnqK+++/ny+++IKMjAxKS0vp06cP11133R63Iowxpr10vUTQCdTV1bFy5UpOPfVUAMLhMEOGOI9VmjBhApdccgnnnHMO55xzTjLDNMYYoCsmgha+udfWBtmws4rR2VlkZXh72qrK+PHjWbhwYdy2//znP8ybN4/XXnuN++67j08+iW+9GGNMR7IxAg9kZGRQVFTUmAiCwSCrVq0iEomwZcsWpk6dygMPPEBZWRmVlZX07NmTioqKJEdtjPEr/yWCDriRIBAIMGPGDG677TaOOOIIJk6cyAcffEA4HObb3/42hx9+OJMmTeKmm26iT58+fO1rX2PmzJk2WGyMSYqu1zXUoo6Zvv7ee+9tXJ43b17c9gULFsSVHXTQQaxYscLLsIwxpkX+aRF4eUeZMcbsx/yTCIwxxiTUZRLB7mZa65iOIe95NaOcMca/ukQiyMzMpLi4uMt/SKoqxcXFZGZmJjsUY0wX4tlgsYhkAvOADPc4M1T1npg6GcB0YDJQDFygqhv39Fg5OTnk5+dTVFTUYp26UISiijrCJelkpqXs6SE6jczMTHJycpIdhjGmC/HyqqE64GRVrRSRNGCBiLypqh9G1bkK2KWqY0TkQuAB4II9PVBaWhqjRo1qtc6STSVc8/xCnrnyaCYdlL2nhzDGmC7Ls64hdVS6q2nuT2zfzdnAM+7yDOAUkT19EFBbSUNc3uzeGGP2U56OEYhIiogsB3YAs1V1UUyVYcAWAFUNAWVA/wT7uVZE8kQkr7Xun9Zj2au3GWNMl+dpIlDVsKpOBHKAo0XksL3cz+OqmququQ0Tvux1TPv0bmOM6Xo65KohVS0F3gNOj9m0FRgOICKpQG+cQeN219ggsExgjDHNeJYIRCRbRPq4y92AU4G1MdVmAZe7y+cBc9SjTvyGoQe1TGCMMc14edXQEOAZEUnBSTj/UtXXReQXQJ6qzgKeBJ4VkfVACXChV8E03lBmecAYY5rxLBGo6gpgUoLyu6OWa4HzvYohWsNgsSUCY4xprkvcWdwW0nD5aJLjMMaYzsY/iaCxRWCpwBhjovkmETSwNGCMMc35JhHYGIExxiTmn0TQZR5EbYwx7cs/icBaBMYYk5D/EkFywzDGmE7HP4mg8emjSQ7EGGM6Gf8kgsYWgWUCY4yJ5p9E4L5ai8AYY5rzTyKwMQJjjEnIN4nAZigzxpjEfJMIbIYyY4xJzD+JwH21BoExxjTnn0RgE9MYY0xC/kkE7qu1CIwxpjn/JAIbIzDGmIR8kwgaWIvAGGOa800isBnKjDEmMc8SgYgMF5H3RGS1iKwSkR8kqDNFRMpEZLn7c3eifbVPPM6r3UdgjDHNeTZ5PRACfqyqS0WkJ7BERGar6uqYevNV9SwP42jG0oAxxjTnWYtAVQtUdam7XAGsAYZ5dbzdEZuXxhhjEuqQMQIRGQlMAhYl2HyciHwsIm+KyPgW3n+tiOSJSF5RUdHexgDYfQTGGBPL80QgIlnAy8DNqloes3kpcICqHgE8BLySaB+q+riq5qpqbnZ29t7F0bivvXq7McZ0WZ4mAhFJw0kCz6vqv2O3q2q5qla6y28AaSIywJtY3GN6sXNjjNmPeXnVkABPAmtU9Y8t1Bns1kNEjnbjKfYkHpuhzBhjEvLyqqETgEuBT0RkuVv2U2AEgKo+CpwHXC8iIaAGuFA9ur7TZigzxpjEPEsEqrqApq75luo8DDzsVQzRbIzAGGMS882dxdgYgTHGJOSbRCCNmcBSgTHGRPNPIrAWgTHGJOSfROC+WoPAGGOa808iEJu83hhjEvFPInBfLQ0YY0xz/kkENlZsjDEJ+ScR2MQ0xhiTkG8SATYxjTHGJOSbRGCT1xtjTGK+SQTGGGMS800isPsIjDEmMf8kApuhzBhjEvJPInBfrUVgjDHN+ScR2LOGjDEmIf8kApuhzBhjEvJPIrAZyowxJiHfJIIG1iIwxpjmfJMI7IYyY4xJzLNEICLDReQ9EVktIqtE5AcJ6oiITBOR9SKyQkSO9Cwe7DHUxhiTiGeT1wMh4MequlREegJLRGS2qq6OqnMGMNb9OQZ4xH1td/b0UWOMScyzFoGqFqjqUne5AlgDDIupdjYwXR0fAn1EZIgX8dh8BMYYk1iHjBGIyEhgErAoZtMwYEvUej7xyQIRuVZE8kQkr6ioaG9jAKxFYIwxsTxPBCKSBbwM3Kyq5XuzD1V9XFVzVTU3Ozt77+Jo2Je1CYwxphlPE4GIpOEkgedV9d8JqmwFhket57hlHsTivFqLwBhjmvPyqiEBngTWqOofW6g2C7jMvXroWKBMVQs8igewMQJjjInVpquGRKQHUKOqERE5CDgEeFNVg6287QTgUuATEVnulv0UGAGgqo8CbwBnAuuBauA7e3UWe8KaBMYY00xbLx+dB3xJRPoCbwOLgQuAS1p6g6ouoKlrvqU6CtzQxhj2mYi1CIwxJlZbu4ZEVauBbwJ/VdXzgfHeheUNwRoExhgTq82JQESOw2kB/MctS/EmJO+IiF01ZIwxMdqaCG4G7gBmquoqERkNvOddWN6wFoExxsRr0xiBqr4PvA8gIgFgp6re5GVgxhhjOkabWgQi8g8R6eVePbQSWC0it3gbWvuzwWJjjInX1q6hce5dwecAbwKjcC4N3a8IYl1DxhgTo62JIM29S/gcYJZ7/8D+95Eq9ogJY4yJ1dZE8BiwEegBzBORA4C9em5QMgnsj+nLGGM81dbB4mnAtKiiTSIy1ZuQvGNjBMYYE6+tg8W9ReSPDY+CFpE/4LQO9ivOGIGlAmOMidbWrqGngArgW+5POfB3r4LyiojdR2CMMbHa+qyhA1X13Kj1n0c9SG6/IVjXkDHGxGpri6BGRE5sWBGRE4Aab0LyjohdPmqMMbHa2iK4DpguIr3d9V3A5d6E5B2nRWCZwBhjorX1qqGPgSNEpJe7Xi4iNwMrvAyu3dkYgTHGxNmjGcpUtTxq3uEfeRCPp1qdHMEYY3xqX6aq3O8+V50xAmsSGGNMtH1JBPvdJ6rdUGaMMfFaHSMQkQoSf3YK0M2TiDxk8xEYY0y8VlsEqtpTVXsl+OmpqrtLIk+JyA4RWdnC9ikiUiYiy92fu/flRNrCZigzxph4bb18dG88DTwMTG+lznxVPcvDGJqxFoExxsTblzGCVqnqPKDEq/3vDRsjMMaYeJ4lgjY6TkQ+FpE3RWR8S5VE5NqGB94VFRXtw+HszmJjjImVzESwFDhAVY8AHgJeaamiqj6uqrmqmpudnb3XBxSbkMAYY+IkLRG4N6dVustv4MyCNsDLY9oYgTHGxEtaIhCRwSLOd3QROdqNpThZ8RhjjF95dtWQiPwTmAIMEJF84B4gDUBVHwXOA64XkRDOk0wvVI9v+7X5CIwxJp5niUBVL9rN9odxLi/tMILdR2CMMbGSfdVQh7IWgTHGxPNXIsCuGTLGmFj+SgQ2Q5kxxsTxVSIAm6HMGGNi+SoRiPUNGWNMHN8lAssDxhjTnL8SATZDmTHGxPJXIrAWgTHGxPFXIsDuIzDGmFj+SgQi1iIwxpgY/koEYGMExhgTw1eJABsjMMaYOL5KBDYvjTHGxPNXIhB7+qgxxsTyVyLArhoyxphY/koE9hhqY4yJ469EYBPTGGNMHH8lAmsRGGNMHM8SgYg8JSI7RGRlC9tFRKaJyHoRWSEiR3oVizHGmJZ52SJ4Gji9le1nAGPdn2uBRzyMpZE1CIwxpjnPEoGqzgNKWqlyNjBdHR8CfURkiFfxgM1QZowxiSRzjGAYsCVqPd8tiyMi14pInojkFRUV7fUBBbA2gTHGNLdfDBar6uOqmququdnZ2Xu9HxssNsaYeMlMBFuB4VHrOW6ZZ2w+AmOMiZfMRDALuMy9euhYoExVC7w8oM1QZowx8VK92rGI/BOYAgwQkXzgHiANQFUfBd4AzgTWA9XAd7yKpSkmaxEYY0wszxKBql60m+0K3ODV8ROxZw0ZY0y8/WKwuN3YDGXGGBPHV4nAZigzxph4/koEkuwIjDGm8/FXIsDGCIwxJpa/EoHNUGaMMXH8lQiwFoExxsTyVyKwR0wYY0wcfyUCm6HMGGPi+CoRYC0CY4yJ46tEINgjJowxJpa/EkF0JgiH4B8XwuZFEInArJtg84fJDM8YY5LCX4kgeoygYhusexNeuhy2LoGlz8Ar1yc3QGOMSQLPHjrXGYnAsOAm+NdjMGSCUxiuh7WvO8upmckLzhhjksRXiQBgas1sWP2K8wMQqm/qEirf5owm27MojDE+4q+uIYE+kZLmhcEqKPgYJAC1pVC1MznB7S8WPQ7/uCDZURhj2pG/EgFCn/AuCEQ1hDQCoRoYc6qzXluWnOD2F2/eAuv+m+wojDHtyD+JYOsSriv9AweEvoDsQ5tvyz4UJnzLWa4rbyrfvgo+fLTjYjTGmCTwTyKo2M6JlW/RR8tg4CHNtx33Pcga5CzXVzaVP3IC/Pc2uwvNGNOl+ScR9BzUtNx/bPNtw3IhI8tZrotKBA2XmobrPQ3NGGOSydNEICKni8inIrJeRG5PsP0KESkSkeXuz9WeBZM1uHEx1KNpmak/g4GHQnpPZ72uIv69wWrPwjLGmGTz7PJREUkB/gKcCuQDi0Vklqqujqn6oqp+36s4GmUNbFysyBpJ34aVk25xXjPcRFCfKBHUQLe+8eV+FolAwD8NSmO6Mi//ko8G1qvqBlWtB14AzvbweK1LSWtcLO42Mn57dNfQtmXw0OSmbcEab2PbH0WCyY7AGNNOvEwEw4AtUev5blmsc0VkhYjMEJHhiXYkIteKSJ6I5BUVFe1zYHe+tS2+MK27cy9B/mJ4fAoUr2/a1pAIFj0O69/Z5+N3CWFLBMZ0Fclu278GjFTVCcBs4JlElVT1cVXNVdXc7OzsvT5YzYDDKdB+LPqihNuC18BJUcMWIpCe1fS4iWihWuf1zVvguXP3+vhdirUIjOkyvEwEW4Hob/g5blkjVS1W1Tp39QlgMh4qv/RtTqibBsCL4akw9Y7mFdK6JX5jsLr5N+CtS2KuLvKhcCjZERhj2omXiWAxMFZERolIOnAhMCu6gogMiVr9OrDGw3gY1Ls7kdZOuXJ74vIZV8GuTU3rfzsZZnynfYPb30QsEeyra6bnMe5uu0vbJJ9niUBVQ8D3gbdwPuD/paqrROQXIvJ1t9pNIrJKRD4GbgKu8CqeBkcM7wNAemqCU590aeI3Ve2Ah2MaK5s+aOfI9jPWNbTPZq/eTnV9ONlhGOPtGIGqvqGqB6nqgap6n1t2t6rOcpfvUNXxqnqEqk5V1bVexgMw/cqjOeWQgdSHItSFYv4Iz34Yvv1y23bk98FSv5+/MV1IsgeLO1zvbmn83zjnLuPiygR3DLf1fgG/d434/fyN6UJ8lwgAsrMyANhWmuD+gLYmAvV5k95aBO0mErFnWZnk8mUimHxAX1IDwuw1CQaHW0sEk6/wLKb9jo0RtJva2C5KYzqYLxNB3x7pnDh2AI+9v4G/zl2PRj9dNKN34jeN/BL0HJJ4mx9F7MOrvdiAsUk2XyYCgK9NGArAb//7KdvKajnxgTm8vCTfeX7OV34V/4YrXof0Hh0cZSdmXUPtpsYSgUky3yaCU8c3PZZ60YZi8nfVcMuMj52C42+Eo66GQ7/mrI+e6rymde/gKDsx6xpqN7VBSwQmuXw3eX2DXplpLLhtKic+8B4v5eUD0GzM7qt/cF7rqyAl3VmObRH4+Qmc1iJoNzWWCLq2wpVQvRNGT0l2JC3y6aeYY2hv55ESCzcUN5YVltU2r5Teo+nJpbGJoGqHl+F1bnb5aLuxMYIu7tETYHryHrzcFr5OBIGAcPiw5oPD33psYcuX88V2DX3wkEeR7QesRdBurEVgks3XiQBg5veOp3e3prkKNpdUM/qnb/D0/76Ir9xnRNPy8GOg4OMOiLATib66yloE7abWWgT+8PiUTvsFyveJIDUlwPu3TGHeLVP5+xVHNZbnbdoVX7nvqKblHtlQtbP59jm/gg1zvQm0M4i+ZNQSQbuxFoFPbFsG5QnmQukEfJ8IAPp0T2dE/+58+aBsfnnOYUwa0YeNxVUAvPlJAet3ONNXLt8W9ejprIFQFTVJTjgI837X6fsCWxSshbX/ab1O9JVCnfSbTaNgTfMWTCcTfe+KjRH4SCf9u7FEECUlIFx67AFMGNabdYWVLN5YwvXPL+XcRxayqbiK7z6bx6qMic4ENj2yobq46VtyRUHTjl67ec8PXlsO9/aGpdPb52T21Ft3wAsXO99aWhLdCuisl4/+/mD4z4/hvsGwNOE8R51CKGocyu4j8I/3V35BKBxJdhhxLBEkMKJ/D+rDEc5/dCEAZTVBTvrdXLaX13Fu1a3U/mSTkwhQqC5x3lQaNSvnkr/De7+BghXxOw/VJ74rt8x9//+mte/JtNW25c5ra/Mzhzt5iyAShspCWPyEs77qlX3f5+/GwLPf3Pf9xKgPNX0YlNd2wn9Lj1RXV7JrV0myw0iaR95ezjMLN+2+YgezRJDAaVE3m8WqDcFrKwooDLuT3c/5hdMFUZbfvOL798NTpzWtRyJEgnVEfn8wvPjt+B3XuGMSgRQAlnw4t2P/YOrK3deKlut09jGC2rLm6y3NOLcnqorg83dbrxOqgz8dDsv/CfXVbdptMOpbYUlVgqfgdlHbfn8iff88avcV90EwHOH0P83jndUtTDSVRD2oobiybvcVO5glggRy+nZn9g+/DMBXxsUnhVtmrODm19xZN5dOh9+Ogm1L43cUrKasOuj0B//7GgL3DSRQWwKfvhFf150dTSXArl0lTP7v2Xz+2MXtdk671ZAAakpbrtMOYwTrd1SwtrB8r967WzUxA/ypmfu2v1Ab/2DL8qF0M7xyHTxxSpveEt0i2FXtn0QwJuJcjRf06kF77/6Sov89y9rCCm7/d4IWeUeLNO8G6kFtpxwTskTQgrGDerL4zv/jsUsns/oXp3HukTkcNCiL7J7OI6yXR0bzSvpZrB54lvMBtOjRxvfqQU5LIJI1hEvun84n02+BlTOaHyBmzuOKYudqgsKKEPkbnBk7x9cu8er04gSr3W/TtVGJIFTfvKXTbIwg5Awuv3rDHh3ntD/N5/Q/zd/jfvG4ezsiEagqbl4Wm8R03/pit27e0LaK0Qlox+o2vaU+HKE7tfSj3Fctggb5hR59W5//e4bOuYksqumZ0QkenBBs3kLMklryd7Wt1diRLBG0IrtnBiJC9/RU/vCtI3j7hyfx8nXHM/N7x3PI8EHcXH4xZ26+mF39JgFQPMJJAH/rdSOPRs6Bqh38SKcz4Yu/xe989SuQn9f4zbqsyGlhlFbVMu3ldwD3f059FVQUOu8J1UFF0x9QMBzhpbwtezf4FPWhWVxSTFrEuaNaoz/UXv8hPDi+adwguhWQ95QzuLzsOSfGtgjVcTwfA8obnxTstnqD1R+9y5fveYFtK+c7VzeB0yX3u9HNu4NqY1oEsS2EaHl/h39c0Opx//ra/Gaxtyj66rE2qg9FuDt1Oq+k30VpW7oKQvWtj9/sjaqdTf+eLt21idD8P3l+xdX2rQnu09lXUf8+eRnXc24kwXzQxZ/HdyF6KSYR9KGSzSWWCPZ7I/p3Z9KIvrxw7bG886Mvc+iQXkwpuIGr63/MsesuYWTtP/j1gnLyw30JaJiTU5Y3vrdcu3NX8Apn5dUbnG6EXw6Al69GtzvfJPtKBSPEeXRFBvXw66Hwh4PJW5fvfDD/4aDGAern/reen85Yyqa/XwnLnmPH8v+y9d8/c/4gopukpZthydNNf/SbF8EDB8DKl2Htf9g5t6k1U7Z1HavnzWBrwVZY8YJTWOJ+My7fGrXPqAGvXRvb9G9XPe9hnk2/n++k/JeV28qcxDLrJtjeyrfocIhxb3yTBSnXMXTGWfDhX53yRY85r0XrGqtGqpt/8IdiWwzgJN83b4fXb4Z1/3U+GFqQVR/1Ad/Kh31taWFczLsTDCuHBTYyIlDEAVXujYll+TD77sTdbs9+A+4/YLf7bbNIBH53YNx41a4nvkHqu/dQUfBZU2E41PrYUVsPGWxq+ezctnGf9xcn6sq9TAkysmZV8+3hIDx0JDz/rfY/dgs2Fjb/vbk17UVydwy8fdYAABDESURBVL7KluLKFt6RHJ4mAhE5XUQ+FZH1InJ7gu0ZIvKiu32RiIz0Mp72lJmWwpiBPZlx3XGMHz2cdyKTCUY9w2+TNo0tzAh/mcNrn2BC3RMsG3wedwSvYnZ4MtPTL3QqfPISw4veB2Cw7OKutOfijpf7j/Gw/HkAKv90FDXPX8rX557ByoyrODB/Jrx6AwNfuYBhKx6C+wazc9pJVJbvgtpySp6/Gl77AbueuRgiYea95XZTzbgSXriYg1f8tvE4fT57mXFzrmLtY5c3fSvcuc75RvzM1xL+WwR3bnASzV+OhVA9lXUhPvoifqC7csWrAHwv9VXWbSuGzQth6TNU/uMKZi5ax2/eXBO/8+L1zdfzF7sHdb9Vrfo3rHXGXEqKmz/7qXJX8z/CzzfnO8l30SNNheud1heLn2zcDytfhvwljNSobrHKlp8rtaNwS7P1vJVuYotE4j9At6+C9e+Qui2PUeJ8cE2tn4uqoq//CP73Z/ji/fiDbFoA4TqoKaUuFOao+97h2YUbGzeXlRaz7ldHseOBI2Hd2y3G2qjETYDrZ7N4Ywl121bB306mX5VT/vmqvMaq4Ve/D7/JaVOCa01ZcdMH9Y78L5zfrw8fgaJPncJ9bYW4LeelKRPY3uswRkU2N392WOEnzuuWD9u8y7yNJSxZtTY+ttoyIqVbE7+poUpVOQ8+Ff+3/Ou0Jwk/+03nC1StR+Nle0jUoyagiKQA64BTgXxgMXCRqq6OqvM9YIKqXiciFwLfUNVW2+u5ubmal5fXWpUOV1BWw/XPLeXW0w7m0Xkb2FlRx98um0zvze+QVbCQRyu/ROqgQ/hiZxXnTs5hU3EV76zewbZdlYwtmEWEAEXah6EZdfxcH6Y0aww9+w/h041bGEEhyyJjyaCewwIb6SPx3TDbtQ9rIgcwJaX5Iy+K0oaSHWzbnYxvDryKM3Y8CcCSyFgmBz5rse574SOYGnWsyrR+ZAWdD/6tvY9kWvFRhBVuHbSE0OCJVKf1pUx6M3n5z1gcOZijAp8m3O+HkUMZfMz5DDn0WOqrK+kpNYSLN5Ay5+eNdTSQRuSIi0lZ1vwegeAZf2TZB29zdJnTHbAsMoZDZDNTU6fz8nfGM2zIUJ66/wauDL7Q/KCDDqPksCvo9+5PAPjs4OsY+6nTQvpch9KfMvpIFdsOOJv+J32XFCIERhxLIDXN+UPetoyVC9/isPx/sn3giQzasYDvhm7hpuu/z7C3rqHP5rdh6p1Q+Anhsq2kbGs+7lMnGYQjQPbBdN/pDG4uGX45h13+IBmpzhVk1JbB/c7jTWoO/gZLD/0Jc176Kz9InUn6afdSPeFyNsx5mtyltzXut+rMh+lxyClO6zCtG/Qa2vzfK286aa/f6NTVDHpI8+6pd7Mv5ZSLb6F0Qx59XrsSgP9knUvx2PO57NRjIKMXBKugbCsMPBREEv4/jbZl+RyGv/INAFbqgRw86UTSlj8D3fqik6+ElTOQyZfDl34MQEVFGVlajfQc3Kb9hz5+idSZV/PLEU9yU//F9F72KI/kPMDVF11AWmYWkQ8fITD7LgCu7Pt3jjz0IL57yjjSUhJ/H45ElK/f+TCvZ/yMguPuZshpP27cVvBALkNqPqP21q2kZ/YgEIiPL//xb5Gz7a248sKUIQwOO0kxnNEbveZ9ls15kU8yjuSyr55MefE2ti2fzfjxE5GMntBjgPPvLdJ4VeHeEJElqpqbcJuHieA44F5VPc1dvwNAVX8TVectt85CEUkFCoFsbSWozpgIooXCERRa/OWKVhcK8+zCTWT3zGBgz0yOGdWPgND4Sx8KR3hywRekpwaYkNOH8UN7Ub1hEaEZ1zA/PI6/1ZzMNwcW8nnWZD7eWMDTqb/h5YP/yLqyAEOqP+Xssuc4NLCZOeGJvDLidnptmcOvAo/HxTF72A0ce+nPyXj+HIo2r+WUut9xZ9rzXJryTsK4lx83jfvml/FS6l2tnl+B9mOINLUMyqQXpVd9SNbSR+m97K+kaojq1L50D7XSl+/aOPh0puWP4Y+pDzeWrY0M55BA82/jVZpB6g0Lqdy6hv6vXhL3Ifdu4HheHHAjgfxFHBzYwg9TXwZgaWQMqYSZEGjedz1z1L3s2rKaK0P/aiyr1G7USiYDcOKu0zSKpB85dyyl7qFjyKjMp1bTyJTdX1m1YsLPGLriYQbQfKB7p/YmJKmESKEvFfSg5fGBndqLAVJORIVZkeM4J+WDuDo1ZBImgCKECdCH5i2VxZGDOCqwjirNIJTSjd6RVq4ec4UJkILTBVlPKlV0J4tqiulNxO1saPxDVuhHGWmEWHzgDUz8/DG6ST27tCfdpZYMmv6tSqQ3aRoiU2tJkzBhAtSTTpBUQpJKkFSUQOO+FUERekQq6SOVLDh3CSf23kn19Asbf7dqyCCFMOk0b9VUaQaVgV5RrXlBRZx9K2RHiugmTpdWMb0Jk0KQFIbhtDZLNIs6ySAiaXHnPEITfwl75isf88ZrM3g2/dekS9svmqgnlU9GXc3kyx9o83uiJSsRnAecrqpXu+uXAseo6vej6qx06+S765+7dXbG7Ota4FqAESNGTN60qfPdkNEZlNcG6ZXpPECvLhRmc3E13QJBNpdFyB3Zj9SAIBXbCJVuI61XNuzaBIMPh+79nB1EImwtrWJNYTX/N24QumMN4t47sKikB71T6zmkZx0MPpywQkrhx2xPy+HjpR8weWg3svoNJpSSyaoVyxjcPcwnPb9EZnUBmYEIVVtXccwJ/0fvQe6D+1SdbpKB49CSDWwPdSO1rpS5awvJLFmHduvDzhrIqf2UlGGTOPkrZ7N4Ywkb5/+T3sGd6ICxBIcezYGl/2NucBy9S1cxoGwl3XKO4EtnXeocYsVLFKxewKfFQVJFyUiB8d/6OT36DmRHRS3/nL+aMYVv0DNUwrrh5xMKZHDI5hcoGX4qR4ZXsK66B0edeSVFlXUsz1tAoHQT6VpHTvly6uqDhALppAaEtHA13Q+awrgzvouWfMGyN58ipWoHwezDWB0agpZtQSWNrDTYkXMqh/ZLYXDhHD7fXsaUC25mV1k5/1v4P0b3ijD6gBGUfvQCJTsLSdUQREJEwmGqe40k+7Rb+SBvCWN2vktWjx4sGnQBo3fMZmjJIuqCYRj7FWoP+jqhTYvYtmMnvcvWUh3oQY/QLjLDFQRQUokQEAVJofTQixnZvxsVlZWU9j2c/B27OHZkTw5JLWTJwnfZUVJO30AVw/p2p+/oSSzYWElKXTlSWUhaqJqwKtUpPekRriCVIN0jVYQljcyI020nAoLg/kcokMn2kV/j1NPPYe6Kz1my+jPKu+WQHoBApJ5u9cUcW/g8qkpY0kjv3oud2otudTtJ0SCpGiRVQ6RoEPej2nlVRQQikooMGsdRF92FiFBbVcayf/2aQLiOYG0VgXA9mw7+Dikl6zm4eyVZkXJ2FG4lUFtCQMOAIg0ZoGHfad0YcthJbF+/jNraWlIlTBoR0tLTqQz0JiNcTn1dHRKuJyCKqDaeL4FUDph0Cn3qCgikZUC3fjDsSEJDc1m1rZzMtBS2LX4VLfyEboPG0qt+OwU7igiHQ+T3OIxM6kgNVZEeriI9VEl6pIaeB32ZY89IcB9SG+z3iSBaZ28RGGNMZ9RaIvBysHgrMDxqPcctS1jH7RrqDSS41MMYY4xXvEwEi4GxIjJKRNKBC4FZMXVmAZe7y+cBc1obHzDGGNP+PLv1TlVDIvJ94C0gBXhKVVeJyC+APFWdBTwJPCsi64ESnGRhjDGmA3l6D7aqvgG8EVN2d9RyLXC+lzEYY4xpnd1ZbIwxPmeJwBhjfM4SgTHG+JwlAmOM8TnPbijziogUAXt7a/EAoMWb1booO2d/sHP2h3055wNUNTvRhv0uEewLEclr6c66rsrO2R/snP3Bq3O2riFjjPE5SwTGGONzfksE8c9g7vrsnP3BztkfPDlnX40RGGOMiee3FoExxpgYlgiMMcbnfJMIROR0EflURNaLyO3Jjqe9iMhTIrLDneSnoayfiMwWkc/c175uuYjINPffYIWIHJm8yPeeiAwXkfdEZLWIrBKRH7jlXfa8RSRTRD4SkY/dc/65Wz5KRBa55/ai+8h3RCTDXV/vbh+ZzPj3loikiMgyEXndXe/S5wsgIhtF5BMRWS4ieW6Zp7/bvkgEIpIC/AU4AxgHXCQi45IbVbt5Gjg9pux24F1VHQu8666Dc/5j3Z9rgUc6KMb2FgJ+rKrjgGOBG9z/n135vOuAk1X1CGAicLqIHAs8ADyoqmOAXcBVbv2rgF1u+YNuvf3RD4A1Uetd/XwbTFXViVH3DHj7u62qXf4HOA54K2r9DuCOZMfVjuc3ElgZtf4pMMRdHgJ86i4/BlyUqN7+/AO8Cpzql/MGugNLgWNw7jJNdcsbf89x5gE5zl1OdetJsmPfw/PMcT/0TgZex5kKuMueb9R5bwQGxJR5+rvtixYBMAzYErWe75Z1VYNUtcBdLgQGuctd7t/B7QKYBCyii5+3202yHNgBzAY+B0pVNeRWiT6vxnN2t5cB/Ts24n32J+BWIOKu96drn28DBd4WkSUicq1b5unvtqcT05jkU1UVkS55jbCIZAEvAzerarmING7riuetqmFgooj0AWYChyQ5JM+IyFnADlVdIiJTkh1PBztRVbeKyEBgtoisjd7oxe+2X1oEW4HhUes5bllXtV1EhgC4rzvc8i7z7yAiaThJ4HlV/bdb3OXPG0BVS4H3cLpG+ohIwxe66PNqPGd3e2+guIND3RcnAF8XkY3ACzjdQ3+m655vI1Xd6r7uwEn4R+Px77ZfEsFiYKx7xUE6ztzIs5Ick5dmAZe7y5fj9KE3lF/mXmlwLFAW1dzcb4jz1f9JYI2q/jFqU5c9bxHJdlsCiEg3nDGRNTgJ4Ty3Wuw5N/xbnAfMUbcTeX+gqneoao6qjsT5e52jqpfQRc+3gYj0EJGeDcvAV4CVeP27neyBkQ4cgDkTWIfTr3pnsuNpx/P6J1AABHH6B6/C6Rt9F/gMeAfo59YVnKunPgc+AXKTHf9envOJOP2oK4Dl7s+ZXfm8gQnAMvecVwJ3u+WjgY+A9cBLQIZbnumur3e3j072OezDuU8BXvfD+brn97H7s6rhs8rr3217xIQxxvicX7qGjDHGtMASgTHG+JwlAmOM8TlLBMYY43OWCIwxxucsERgTQ0TC7pMfG37a7Wm1IjJSop4Ua0xnYI+YMCZejapOTHYQxnQUaxEY00buc+J/6z4r/iMRGeOWjxSROe7z4N8VkRFu+SARmenOIfCxiBzv7ipFRP7mzivwtnunsDFJY4nAmHjdYrqGLojaVqaqhwMP4zwdE+Ah4BlVnQA8D0xzy6cB76szh8CROHeKgvPs+L+o6nigFDjX4/MxplV2Z7ExMUSkUlWzEpRvxJkcZoP70LtCVe0vIjtxngEfdMsLVHWAiBQBOapaF7WPkcBsdSYYQURuA9JU9Vfen5kxiVmLwJg9oy0s74m6qOUwNlZnkswSgTF75oKo14Xu8gc4T8gEuASY7y6/C1wPjZPK9O6oII3ZE/ZNxJh43dyZwBr8V1UbLiHtKyIrcL7VX+SW3Qj8XURuAYqA77jlPwAeF5GrcL75X4/zpFhjOhUbIzCmjdwxglxV3ZnsWIxpT9Y1ZIwxPmctAmOM8TlrERhjjM9ZIjDGGJ+zRGCMMT5nicAYY3zOEoExxvjc/wOUiyta2AGIJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.46875\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.21      0.67      0.32        24\n",
      "   Pneumonia       0.85      0.42      0.56       104\n",
      "\n",
      "    accuracy                           0.47       128\n",
      "   macro avg       0.53      0.54      0.44       128\n",
      "weighted avg       0.73      0.47      0.52       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  8]\n",
      " [60 44]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
