{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 2\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 2 - trim5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'trim5'\n",
    "GROUP_TEST = 'trim5'\n",
    "DATASET = 'dataset_2'\n",
    "DURATION = 5\n",
    "SIZE = 216\n",
    "CSV_TRAIN = 'train2.csv'\n",
    "CSV_TEST = 'test2.csv'\n",
    "MODEL_NAME = f'CNN2_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  123  Healthy\n",
       "1  125  Healthy\n",
       "2  126  Healthy\n",
       "3  127  Healthy\n",
       "4  136  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  336  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['96' '72']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['9' '39']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 40, 216)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 40, 216, 1) (168, 2)\n",
      "(48, 40, 216, 1) (48, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 215, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 107, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 107, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 106, 16)       2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 53, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 53, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 52, 8)          520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 26, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 26, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 25, 4)          132       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 12, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 12, 4)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 2,886\n",
      "Trainable params: 2,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "48/48 [==============================] - 1s 20ms/sample - loss: 2.5555 - accuracy: 0.8125\n",
      "Pre-training accuracy: 81.2500%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 34 samples\n",
      "Epoch 1/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 12.7811 - accuracy: 0.4500\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47059, saving model to models/CNN2_dataset_2_trim5_01.h5\n",
      "134/134 [==============================] - 1s 6ms/sample - loss: 10.3162 - accuracy: 0.4627 - val_loss: 1.0667 - val_accuracy: 0.4706\n",
      "Epoch 2/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 3.1250 - accuracy: 0.5667\n",
      "Epoch 00002: val_accuracy improved from 0.47059 to 0.52941, saving model to models/CNN2_dataset_2_trim5_02.h5\n",
      "134/134 [==============================] - 0s 975us/sample - loss: 2.8070 - accuracy: 0.5522 - val_loss: 0.6958 - val_accuracy: 0.5294\n",
      "Epoch 3/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 1.4208 - accuracy: 0.5444\n",
      "Epoch 00003: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 740us/sample - loss: 1.4036 - accuracy: 0.5522 - val_loss: 0.6947 - val_accuracy: 0.5294\n",
      "Epoch 4/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 1.0010 - accuracy: 0.5600\n",
      "Epoch 00004: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 1.0429 - accuracy: 0.5299 - val_loss: 0.6905 - val_accuracy: 0.5294\n",
      "Epoch 5/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 1.2853 - accuracy: 0.3556\n",
      "Epoch 00005: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 772us/sample - loss: 1.1835 - accuracy: 0.3881 - val_loss: 0.6848 - val_accuracy: 0.5294\n",
      "Epoch 6/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.9043 - accuracy: 0.5700\n",
      "Epoch 00006: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 709us/sample - loss: 0.9338 - accuracy: 0.5522 - val_loss: 0.6830 - val_accuracy: 0.5294\n",
      "Epoch 7/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.9850 - accuracy: 0.4600\n",
      "Epoch 00007: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 694us/sample - loss: 0.9402 - accuracy: 0.4701 - val_loss: 0.6820 - val_accuracy: 0.5294\n",
      "Epoch 8/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.8249 - accuracy: 0.5100\n",
      "Epoch 00008: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 678us/sample - loss: 0.8540 - accuracy: 0.5149 - val_loss: 0.6823 - val_accuracy: 0.5294\n",
      "Epoch 9/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.7073 - accuracy: 0.6444\n",
      "Epoch 00009: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 757us/sample - loss: 0.7620 - accuracy: 0.5672 - val_loss: 0.6878 - val_accuracy: 0.5294\n",
      "Epoch 10/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.8682 - accuracy: 0.4222\n",
      "Epoch 00010: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 742us/sample - loss: 0.8496 - accuracy: 0.4328 - val_loss: 0.6884 - val_accuracy: 0.5294\n",
      "Epoch 11/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.7878 - accuracy: 0.5700\n",
      "Epoch 00011: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.7832 - accuracy: 0.5672 - val_loss: 0.6874 - val_accuracy: 0.5294\n",
      "Epoch 12/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.7947 - accuracy: 0.5700\n",
      "Epoch 00012: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 723us/sample - loss: 0.7950 - accuracy: 0.5448 - val_loss: 0.6879 - val_accuracy: 0.5294\n",
      "Epoch 13/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.7477 - accuracy: 0.5444\n",
      "Epoch 00013: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 747us/sample - loss: 0.7745 - accuracy: 0.5075 - val_loss: 0.6862 - val_accuracy: 0.5294\n",
      "Epoch 14/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.7336 - accuracy: 0.5300\n",
      "Epoch 00014: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 734us/sample - loss: 0.6906 - accuracy: 0.5821 - val_loss: 0.6860 - val_accuracy: 0.5294\n",
      "Epoch 15/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.7884 - accuracy: 0.5600\n",
      "Epoch 00015: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 718us/sample - loss: 0.7624 - accuracy: 0.5373 - val_loss: 0.6882 - val_accuracy: 0.5294\n",
      "Epoch 16/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.6467 - accuracy: 0.6100\n",
      "Epoch 00016: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 711us/sample - loss: 0.6564 - accuracy: 0.6045 - val_loss: 0.6915 - val_accuracy: 0.5294\n",
      "Epoch 17/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.6495 - accuracy: 0.5700\n",
      "Epoch 00017: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 733us/sample - loss: 0.6547 - accuracy: 0.5821 - val_loss: 0.6927 - val_accuracy: 0.5294\n",
      "Epoch 18/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.7047 - accuracy: 0.5889\n",
      "Epoch 00018: val_accuracy did not improve from 0.52941\n",
      "134/134 [==============================] - 0s 743us/sample - loss: 0.7224 - accuracy: 0.5746 - val_loss: 0.6926 - val_accuracy: 0.5294\n",
      "Epoch 19/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6761 - accuracy: 0.6444\n",
      "Epoch 00019: val_accuracy improved from 0.52941 to 0.55882, saving model to models/CNN2_dataset_2_trim5_19.h5\n",
      "134/134 [==============================] - 0s 956us/sample - loss: 0.7000 - accuracy: 0.5970 - val_loss: 0.6939 - val_accuracy: 0.5588\n",
      "Epoch 20/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.7010 - accuracy: 0.5778\n",
      "Epoch 00020: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 791us/sample - loss: 0.6901 - accuracy: 0.6119 - val_loss: 0.6947 - val_accuracy: 0.4412\n",
      "Epoch 21/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6152 - accuracy: 0.7111\n",
      "Epoch 00021: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 742us/sample - loss: 0.6275 - accuracy: 0.6716 - val_loss: 0.6948 - val_accuracy: 0.3824\n",
      "Epoch 22/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.6451 - accuracy: 0.6300\n",
      "Epoch 00022: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 738us/sample - loss: 0.6544 - accuracy: 0.6119 - val_loss: 0.6942 - val_accuracy: 0.4412\n",
      "Epoch 23/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.7548 - accuracy: 0.5000\n",
      "Epoch 00023: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 824us/sample - loss: 0.7181 - accuracy: 0.5373 - val_loss: 0.6954 - val_accuracy: 0.4706\n",
      "Epoch 24/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.6510 - accuracy: 0.6100\n",
      "Epoch 00024: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 736us/sample - loss: 0.6572 - accuracy: 0.6119 - val_loss: 0.6954 - val_accuracy: 0.4706\n",
      "Epoch 25/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6958 - accuracy: 0.5667\n",
      "Epoch 00025: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 852us/sample - loss: 0.6960 - accuracy: 0.5672 - val_loss: 0.6947 - val_accuracy: 0.4706\n",
      "Epoch 26/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.7099 - accuracy: 0.5750\n",
      "Epoch 00026: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 914us/sample - loss: 0.6773 - accuracy: 0.6119 - val_loss: 0.6962 - val_accuracy: 0.4706\n",
      "Epoch 27/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.6382 - accuracy: 0.6000\n",
      "Epoch 00027: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 885us/sample - loss: 0.6615 - accuracy: 0.5970 - val_loss: 0.6943 - val_accuracy: 0.4706\n",
      "Epoch 28/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6853 - accuracy: 0.6000\n",
      "Epoch 00028: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 881us/sample - loss: 0.6708 - accuracy: 0.6119 - val_loss: 0.6924 - val_accuracy: 0.4706\n",
      "Epoch 29/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6511 - accuracy: 0.5889\n",
      "Epoch 00029: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 842us/sample - loss: 0.6712 - accuracy: 0.5746 - val_loss: 0.6928 - val_accuracy: 0.4706\n",
      "Epoch 30/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.6685 - accuracy: 0.6125\n",
      "Epoch 00030: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 830us/sample - loss: 0.6755 - accuracy: 0.5970 - val_loss: 0.6943 - val_accuracy: 0.4706\n",
      "Epoch 31/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6743 - accuracy: 0.5667\n",
      "Epoch 00031: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 770us/sample - loss: 0.6353 - accuracy: 0.6045 - val_loss: 0.6940 - val_accuracy: 0.4706\n",
      "Epoch 32/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6502 - accuracy: 0.6444\n",
      "Epoch 00032: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 768us/sample - loss: 0.6758 - accuracy: 0.5821 - val_loss: 0.6903 - val_accuracy: 0.4706\n",
      "Epoch 33/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6190 - accuracy: 0.6667\n",
      "Epoch 00033: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 797us/sample - loss: 0.6158 - accuracy: 0.6642 - val_loss: 0.6907 - val_accuracy: 0.4706\n",
      "Epoch 34/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6631 - accuracy: 0.5667\n",
      "Epoch 00034: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 835us/sample - loss: 0.6532 - accuracy: 0.5746 - val_loss: 0.6895 - val_accuracy: 0.4706\n",
      "Epoch 35/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6798 - accuracy: 0.5444\n",
      "Epoch 00035: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 774us/sample - loss: 0.6585 - accuracy: 0.5746 - val_loss: 0.6865 - val_accuracy: 0.4706\n",
      "Epoch 36/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6362 - accuracy: 0.5778\n",
      "Epoch 00036: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 823us/sample - loss: 0.6318 - accuracy: 0.5896 - val_loss: 0.6835 - val_accuracy: 0.4706\n",
      "Epoch 37/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.6670 - accuracy: 0.5375\n",
      "Epoch 00037: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 800us/sample - loss: 0.6435 - accuracy: 0.5672 - val_loss: 0.6801 - val_accuracy: 0.4706\n",
      "Epoch 38/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.5780 - accuracy: 0.6600\n",
      "Epoch 00038: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 723us/sample - loss: 0.5928 - accuracy: 0.6493 - val_loss: 0.6753 - val_accuracy: 0.4706\n",
      "Epoch 39/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6428 - accuracy: 0.6333\n",
      "Epoch 00039: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 786us/sample - loss: 0.6250 - accuracy: 0.6567 - val_loss: 0.6759 - val_accuracy: 0.4706\n",
      "Epoch 40/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.5915 - accuracy: 0.6900\n",
      "Epoch 00040: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 725us/sample - loss: 0.5885 - accuracy: 0.6866 - val_loss: 0.6697 - val_accuracy: 0.5000\n",
      "Epoch 41/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6010 - accuracy: 0.6778\n",
      "Epoch 00041: val_accuracy did not improve from 0.55882\n",
      "134/134 [==============================] - 0s 760us/sample - loss: 0.5870 - accuracy: 0.6940 - val_loss: 0.6595 - val_accuracy: 0.4706\n",
      "Epoch 42/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.6210 - accuracy: 0.6250\n",
      "Epoch 00042: val_accuracy improved from 0.55882 to 0.64706, saving model to models/CNN2_dataset_2_trim5_42.h5\n",
      "134/134 [==============================] - 0s 982us/sample - loss: 0.6096 - accuracy: 0.6269 - val_loss: 0.6661 - val_accuracy: 0.6471\n",
      "Epoch 43/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6366 - accuracy: 0.5778\n",
      "Epoch 00043: val_accuracy improved from 0.64706 to 0.67647, saving model to models/CNN2_dataset_2_trim5_43.h5\n",
      "134/134 [==============================] - 0s 935us/sample - loss: 0.6174 - accuracy: 0.6045 - val_loss: 0.6621 - val_accuracy: 0.6765\n",
      "Epoch 44/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6792 - accuracy: 0.5333\n",
      "Epoch 00044: val_accuracy did not improve from 0.67647\n",
      "134/134 [==============================] - 0s 787us/sample - loss: 0.6369 - accuracy: 0.5896 - val_loss: 0.6581 - val_accuracy: 0.6765\n",
      "Epoch 45/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5687 - accuracy: 0.7222\n",
      "Epoch 00045: val_accuracy did not improve from 0.67647\n",
      "134/134 [==============================] - 0s 845us/sample - loss: 0.6073 - accuracy: 0.6716 - val_loss: 0.6488 - val_accuracy: 0.6176\n",
      "Epoch 46/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6021 - accuracy: 0.6222\n",
      "Epoch 00046: val_accuracy improved from 0.67647 to 0.73529, saving model to models/CNN2_dataset_2_trim5_46.h5\n",
      "134/134 [==============================] - 0s 990us/sample - loss: 0.5877 - accuracy: 0.6194 - val_loss: 0.6443 - val_accuracy: 0.7353\n",
      "Epoch 47/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5734 - accuracy: 0.7111\n",
      "Epoch 00047: val_accuracy did not improve from 0.73529\n",
      "134/134 [==============================] - 0s 790us/sample - loss: 0.5682 - accuracy: 0.6940 - val_loss: 0.6306 - val_accuracy: 0.7353\n",
      "Epoch 48/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.6088 - accuracy: 0.6333\n",
      "Epoch 00048: val_accuracy improved from 0.73529 to 0.79412, saving model to models/CNN2_dataset_2_trim5_48.h5\n",
      "134/134 [==============================] - 0s 957us/sample - loss: 0.5876 - accuracy: 0.6418 - val_loss: 0.6187 - val_accuracy: 0.7941\n",
      "Epoch 49/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.5647 - accuracy: 0.6500\n",
      "Epoch 00049: val_accuracy improved from 0.79412 to 0.82353, saving model to models/CNN2_dataset_2_trim5_49.h5\n",
      "134/134 [==============================] - 0s 880us/sample - loss: 0.5667 - accuracy: 0.6493 - val_loss: 0.6165 - val_accuracy: 0.8235\n",
      "Epoch 50/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5517 - accuracy: 0.7000\n",
      "Epoch 00050: val_accuracy did not improve from 0.82353\n",
      "134/134 [==============================] - 0s 820us/sample - loss: 0.5724 - accuracy: 0.6866 - val_loss: 0.6109 - val_accuracy: 0.8235\n",
      "Epoch 51/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5695 - accuracy: 0.6444\n",
      "Epoch 00051: val_accuracy did not improve from 0.82353\n",
      "134/134 [==============================] - 0s 850us/sample - loss: 0.5643 - accuracy: 0.6642 - val_loss: 0.6004 - val_accuracy: 0.8235\n",
      "Epoch 52/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.5855 - accuracy: 0.6625\n",
      "Epoch 00052: val_accuracy did not improve from 0.82353\n",
      "134/134 [==============================] - 0s 861us/sample - loss: 0.5777 - accuracy: 0.6642 - val_loss: 0.6039 - val_accuracy: 0.8235\n",
      "Epoch 53/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.5871 - accuracy: 0.6500\n",
      "Epoch 00053: val_accuracy did not improve from 0.82353\n",
      "134/134 [==============================] - 0s 887us/sample - loss: 0.5634 - accuracy: 0.6493 - val_loss: 0.5878 - val_accuracy: 0.7647\n",
      "Epoch 54/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.5072 - accuracy: 0.7250\n",
      "Epoch 00054: val_accuracy improved from 0.82353 to 0.85294, saving model to models/CNN2_dataset_2_trim5_54.h5\n",
      "134/134 [==============================] - 0s 1ms/sample - loss: 0.5336 - accuracy: 0.7313 - val_loss: 0.6013 - val_accuracy: 0.8529\n",
      "Epoch 55/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.6221 - accuracy: 0.7000\n",
      "Epoch 00055: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 907us/sample - loss: 0.6194 - accuracy: 0.6567 - val_loss: 0.5864 - val_accuracy: 0.7941\n",
      "Epoch 56/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.5402 - accuracy: 0.7400\n",
      "Epoch 00056: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 792us/sample - loss: 0.5705 - accuracy: 0.7164 - val_loss: 0.5972 - val_accuracy: 0.7647\n",
      "Epoch 57/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5460 - accuracy: 0.7556\n",
      "Epoch 00057: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 865us/sample - loss: 0.5570 - accuracy: 0.7015 - val_loss: 0.6011 - val_accuracy: 0.7353\n",
      "Epoch 58/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4892 - accuracy: 0.7750\n",
      "Epoch 00058: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 963us/sample - loss: 0.5213 - accuracy: 0.7537 - val_loss: 0.5906 - val_accuracy: 0.5882\n",
      "Epoch 59/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5449 - accuracy: 0.7222\n",
      "Epoch 00059: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 776us/sample - loss: 0.5204 - accuracy: 0.7537 - val_loss: 0.5823 - val_accuracy: 0.7353\n",
      "Epoch 60/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4976 - accuracy: 0.7333\n",
      "Epoch 00060: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 848us/sample - loss: 0.4961 - accuracy: 0.7239 - val_loss: 0.5670 - val_accuracy: 0.5882\n",
      "Epoch 61/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4992 - accuracy: 0.7000\n",
      "Epoch 00061: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 895us/sample - loss: 0.5469 - accuracy: 0.6791 - val_loss: 0.5696 - val_accuracy: 0.4706\n",
      "Epoch 62/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4886 - accuracy: 0.7250\n",
      "Epoch 00062: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 887us/sample - loss: 0.4918 - accuracy: 0.7463 - val_loss: 0.5629 - val_accuracy: 0.5588\n",
      "Epoch 63/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4388 - accuracy: 0.7667\n",
      "Epoch 00063: val_accuracy did not improve from 0.85294\n",
      "134/134 [==============================] - 0s 827us/sample - loss: 0.5077 - accuracy: 0.7388 - val_loss: 0.5477 - val_accuracy: 0.6765\n",
      "Epoch 64/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5188 - accuracy: 0.7000\n",
      "Epoch 00064: val_accuracy improved from 0.85294 to 0.88235, saving model to models/CNN2_dataset_2_trim5_64.h5\n",
      "134/134 [==============================] - 0s 1ms/sample - loss: 0.5337 - accuracy: 0.7164 - val_loss: 0.5432 - val_accuracy: 0.8824\n",
      "Epoch 65/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5323 - accuracy: 0.7333\n",
      "Epoch 00065: val_accuracy improved from 0.88235 to 0.91176, saving model to models/CNN2_dataset_2_trim5_65.h5\n",
      "134/134 [==============================] - 0s 1ms/sample - loss: 0.5385 - accuracy: 0.7090 - val_loss: 0.5389 - val_accuracy: 0.9118\n",
      "Epoch 66/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5031 - accuracy: 0.7778\n",
      "Epoch 00066: val_accuracy improved from 0.91176 to 0.94118, saving model to models/CNN2_dataset_2_trim5_66.h5\n",
      "134/134 [==============================] - 0s 1ms/sample - loss: 0.4840 - accuracy: 0.7687 - val_loss: 0.5243 - val_accuracy: 0.9412\n",
      "Epoch 67/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5251 - accuracy: 0.7111\n",
      "Epoch 00067: val_accuracy did not improve from 0.94118\n",
      "134/134 [==============================] - 0s 792us/sample - loss: 0.5093 - accuracy: 0.7313 - val_loss: 0.5152 - val_accuracy: 0.9118\n",
      "Epoch 68/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4586 - accuracy: 0.7778\n",
      "Epoch 00068: val_accuracy did not improve from 0.94118\n",
      "134/134 [==============================] - 0s 822us/sample - loss: 0.4986 - accuracy: 0.7164 - val_loss: 0.5146 - val_accuracy: 0.9118\n",
      "Epoch 69/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4964 - accuracy: 0.7222\n",
      "Epoch 00069: val_accuracy did not improve from 0.94118\n",
      "134/134 [==============================] - 0s 865us/sample - loss: 0.4850 - accuracy: 0.7388 - val_loss: 0.5137 - val_accuracy: 0.9118\n",
      "Epoch 70/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4763 - accuracy: 0.7625\n",
      "Epoch 00070: val_accuracy did not improve from 0.94118\n",
      "134/134 [==============================] - 0s 896us/sample - loss: 0.4879 - accuracy: 0.7612 - val_loss: 0.5281 - val_accuracy: 0.9118\n",
      "Epoch 71/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5532 - accuracy: 0.7556\n",
      "Epoch 00071: val_accuracy did not improve from 0.94118\n",
      "134/134 [==============================] - 0s 788us/sample - loss: 0.5488 - accuracy: 0.7388 - val_loss: 0.5137 - val_accuracy: 0.9412\n",
      "Epoch 72/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4997 - accuracy: 0.7000\n",
      "Epoch 00072: val_accuracy did not improve from 0.94118\n",
      "134/134 [==============================] - 0s 802us/sample - loss: 0.4822 - accuracy: 0.7090 - val_loss: 0.5121 - val_accuracy: 0.9412\n",
      "Epoch 73/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4818 - accuracy: 0.7556\n",
      "Epoch 00073: val_accuracy did not improve from 0.94118\n",
      "134/134 [==============================] - 0s 778us/sample - loss: 0.4819 - accuracy: 0.7612 - val_loss: 0.5019 - val_accuracy: 0.9412\n",
      "Epoch 74/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4816 - accuracy: 0.7778\n",
      "Epoch 00074: val_accuracy improved from 0.94118 to 0.97059, saving model to models/CNN2_dataset_2_trim5_74.h5\n",
      "134/134 [==============================] - 0s 921us/sample - loss: 0.4613 - accuracy: 0.7910 - val_loss: 0.4623 - val_accuracy: 0.9706\n",
      "Epoch 75/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.4811 - accuracy: 0.7500\n",
      "Epoch 00075: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 724us/sample - loss: 0.4690 - accuracy: 0.7687 - val_loss: 0.4647 - val_accuracy: 0.9412\n",
      "Epoch 76/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.5303 - accuracy: 0.6750\n",
      "Epoch 00076: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 810us/sample - loss: 0.4756 - accuracy: 0.7388 - val_loss: 0.4596 - val_accuracy: 0.9412\n",
      "Epoch 77/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4150 - accuracy: 0.7556\n",
      "Epoch 00077: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 820us/sample - loss: 0.4383 - accuracy: 0.7612 - val_loss: 0.4505 - val_accuracy: 0.9412\n",
      "Epoch 78/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4050 - accuracy: 0.8375\n",
      "Epoch 00078: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 849us/sample - loss: 0.4445 - accuracy: 0.8060 - val_loss: 0.4262 - val_accuracy: 0.9118\n",
      "Epoch 79/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3862 - accuracy: 0.8222\n",
      "Epoch 00079: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 836us/sample - loss: 0.4234 - accuracy: 0.8060 - val_loss: 0.4471 - val_accuracy: 0.8235\n",
      "Epoch 80/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5018 - accuracy: 0.7333\n",
      "Epoch 00080: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 814us/sample - loss: 0.4839 - accuracy: 0.7537 - val_loss: 0.4542 - val_accuracy: 0.9412\n",
      "Epoch 81/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4925 - accuracy: 0.7556\n",
      "Epoch 00081: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 790us/sample - loss: 0.4821 - accuracy: 0.7836 - val_loss: 0.4711 - val_accuracy: 0.9412\n",
      "Epoch 82/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5058 - accuracy: 0.7000\n",
      "Epoch 00082: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 772us/sample - loss: 0.4628 - accuracy: 0.7761 - val_loss: 0.4639 - val_accuracy: 0.9412\n",
      "Epoch 83/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.3835 - accuracy: 0.8000\n",
      "Epoch 00083: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 832us/sample - loss: 0.4370 - accuracy: 0.7761 - val_loss: 0.4579 - val_accuracy: 0.9118\n",
      "Epoch 84/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4760 - accuracy: 0.7556\n",
      "Epoch 00084: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 799us/sample - loss: 0.4645 - accuracy: 0.7761 - val_loss: 0.4470 - val_accuracy: 0.9118\n",
      "Epoch 85/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4696 - accuracy: 0.7875\n",
      "Epoch 00085: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 806us/sample - loss: 0.4258 - accuracy: 0.7985 - val_loss: 0.4330 - val_accuracy: 0.9412\n",
      "Epoch 86/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3875 - accuracy: 0.8111\n",
      "Epoch 00086: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 784us/sample - loss: 0.4058 - accuracy: 0.8060 - val_loss: 0.4231 - val_accuracy: 0.9118\n",
      "Epoch 87/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4500 - accuracy: 0.7750\n",
      "Epoch 00087: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 912us/sample - loss: 0.4191 - accuracy: 0.7910 - val_loss: 0.4297 - val_accuracy: 0.9412\n",
      "Epoch 88/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3784 - accuracy: 0.8111\n",
      "Epoch 00088: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 824us/sample - loss: 0.4103 - accuracy: 0.7836 - val_loss: 0.4035 - val_accuracy: 0.9118\n",
      "Epoch 89/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4360 - accuracy: 0.7778\n",
      "Epoch 00089: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 798us/sample - loss: 0.4370 - accuracy: 0.7910 - val_loss: 0.4036 - val_accuracy: 0.9412\n",
      "Epoch 90/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3805 - accuracy: 0.8444\n",
      "Epoch 00090: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 784us/sample - loss: 0.4502 - accuracy: 0.8060 - val_loss: 0.4002 - val_accuracy: 0.9412\n",
      "Epoch 91/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4262 - accuracy: 0.8000\n",
      "Epoch 00091: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 823us/sample - loss: 0.4019 - accuracy: 0.7985 - val_loss: 0.4088 - val_accuracy: 0.9412\n",
      "Epoch 92/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3747 - accuracy: 0.8111\n",
      "Epoch 00092: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 859us/sample - loss: 0.3566 - accuracy: 0.8284 - val_loss: 0.4024 - val_accuracy: 0.9412\n",
      "Epoch 93/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4129 - accuracy: 0.8000\n",
      "Epoch 00093: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 798us/sample - loss: 0.4233 - accuracy: 0.8060 - val_loss: 0.3796 - val_accuracy: 0.9412\n",
      "Epoch 94/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4184 - accuracy: 0.8125\n",
      "Epoch 00094: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 839us/sample - loss: 0.3885 - accuracy: 0.8209 - val_loss: 0.3854 - val_accuracy: 0.9412\n",
      "Epoch 95/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4053 - accuracy: 0.8111\n",
      "Epoch 00095: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 774us/sample - loss: 0.4327 - accuracy: 0.7836 - val_loss: 0.3631 - val_accuracy: 0.9412\n",
      "Epoch 96/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.3979 - accuracy: 0.8125\n",
      "Epoch 00096: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 936us/sample - loss: 0.5005 - accuracy: 0.7761 - val_loss: 0.3700 - val_accuracy: 0.9412\n",
      "Epoch 97/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4607 - accuracy: 0.7556\n",
      "Epoch 00097: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 848us/sample - loss: 0.4431 - accuracy: 0.7910 - val_loss: 0.4052 - val_accuracy: 0.9412\n",
      "Epoch 98/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4440 - accuracy: 0.8111\n",
      "Epoch 00098: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 818us/sample - loss: 0.4635 - accuracy: 0.7985 - val_loss: 0.3928 - val_accuracy: 0.9412\n",
      "Epoch 99/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3896 - accuracy: 0.8333\n",
      "Epoch 00099: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 887us/sample - loss: 0.4392 - accuracy: 0.8060 - val_loss: 0.3953 - val_accuracy: 0.9412\n",
      "Epoch 100/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5155 - accuracy: 0.7222\n",
      "Epoch 00100: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 890us/sample - loss: 0.4494 - accuracy: 0.7687 - val_loss: 0.3984 - val_accuracy: 0.9412\n",
      "Epoch 101/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4083 - accuracy: 0.8444\n",
      "Epoch 00101: val_accuracy improved from 0.97059 to 1.00000, saving model to models/CNN2_dataset_2_trim5_101.h5\n",
      "134/134 [==============================] - 0s 985us/sample - loss: 0.3835 - accuracy: 0.8657 - val_loss: 0.3952 - val_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4108 - accuracy: 0.7778\n",
      "Epoch 00102: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 815us/sample - loss: 0.4113 - accuracy: 0.7687 - val_loss: 0.3860 - val_accuracy: 0.9412\n",
      "Epoch 103/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.3663 - accuracy: 0.8100\n",
      "Epoch 00103: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 814us/sample - loss: 0.3748 - accuracy: 0.7985 - val_loss: 0.3600 - val_accuracy: 0.9706\n",
      "Epoch 104/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4464 - accuracy: 0.7889\n",
      "Epoch 00104: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.4437 - accuracy: 0.7985 - val_loss: 0.3821 - val_accuracy: 0.9412\n",
      "Epoch 105/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.5296 - accuracy: 0.7556\n",
      "Epoch 00105: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 833us/sample - loss: 0.4676 - accuracy: 0.7761 - val_loss: 0.3808 - val_accuracy: 0.9412\n",
      "Epoch 106/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4128 - accuracy: 0.8222\n",
      "Epoch 00106: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 809us/sample - loss: 0.4329 - accuracy: 0.8134 - val_loss: 0.3743 - val_accuracy: 0.9412\n",
      "Epoch 107/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4377 - accuracy: 0.7889\n",
      "Epoch 00107: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 827us/sample - loss: 0.4203 - accuracy: 0.8060 - val_loss: 0.3754 - val_accuracy: 0.9412\n",
      "Epoch 108/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.3832 - accuracy: 0.8100\n",
      "Epoch 00108: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 744us/sample - loss: 0.3929 - accuracy: 0.8284 - val_loss: 0.3622 - val_accuracy: 0.9412\n",
      "Epoch 109/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3464 - accuracy: 0.8222\n",
      "Epoch 00109: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 802us/sample - loss: 0.3709 - accuracy: 0.8134 - val_loss: 0.3353 - val_accuracy: 0.9706\n",
      "Epoch 110/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3618 - accuracy: 0.8111\n",
      "Epoch 00110: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 795us/sample - loss: 0.3549 - accuracy: 0.8209 - val_loss: 0.3209 - val_accuracy: 0.9412\n",
      "Epoch 111/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.4821 - accuracy: 0.7700\n",
      "Epoch 00111: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 808us/sample - loss: 0.4449 - accuracy: 0.8060 - val_loss: 0.3493 - val_accuracy: 0.9706\n",
      "Epoch 112/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4063 - accuracy: 0.8000\n",
      "Epoch 00112: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 866us/sample - loss: 0.3877 - accuracy: 0.7985 - val_loss: 0.3150 - val_accuracy: 0.9412\n",
      "Epoch 113/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3730 - accuracy: 0.8444\n",
      "Epoch 00113: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 817us/sample - loss: 0.3594 - accuracy: 0.8433 - val_loss: 0.3240 - val_accuracy: 0.9706\n",
      "Epoch 114/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4032 - accuracy: 0.8000\n",
      "Epoch 00114: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 875us/sample - loss: 0.4205 - accuracy: 0.7761 - val_loss: 0.3220 - val_accuracy: 0.9706\n",
      "Epoch 115/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3442 - accuracy: 0.8111\n",
      "Epoch 00115: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 813us/sample - loss: 0.3575 - accuracy: 0.8209 - val_loss: 0.3258 - val_accuracy: 0.9706\n",
      "Epoch 116/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3587 - accuracy: 0.8000\n",
      "Epoch 00116: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 839us/sample - loss: 0.3432 - accuracy: 0.8284 - val_loss: 0.3103 - val_accuracy: 0.9706\n",
      "Epoch 117/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3771 - accuracy: 0.8333\n",
      "Epoch 00117: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 827us/sample - loss: 0.3735 - accuracy: 0.8433 - val_loss: 0.3012 - val_accuracy: 0.9412\n",
      "Epoch 118/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4375 - accuracy: 0.7778\n",
      "Epoch 00118: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 814us/sample - loss: 0.4004 - accuracy: 0.8060 - val_loss: 0.3317 - val_accuracy: 0.9706\n",
      "Epoch 119/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3961 - accuracy: 0.8444\n",
      "Epoch 00119: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 827us/sample - loss: 0.3926 - accuracy: 0.8358 - val_loss: 0.3361 - val_accuracy: 0.9412\n",
      "Epoch 120/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3785 - accuracy: 0.8000\n",
      "Epoch 00120: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 815us/sample - loss: 0.4064 - accuracy: 0.7910 - val_loss: 0.3313 - val_accuracy: 0.9706\n",
      "Epoch 121/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3662 - accuracy: 0.8333\n",
      "Epoch 00121: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 798us/sample - loss: 0.3741 - accuracy: 0.8134 - val_loss: 0.3212 - val_accuracy: 0.9412\n",
      "Epoch 122/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4000 - accuracy: 0.8111\n",
      "Epoch 00122: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 788us/sample - loss: 0.4057 - accuracy: 0.7761 - val_loss: 0.3138 - val_accuracy: 0.9412\n",
      "Epoch 123/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3592 - accuracy: 0.8556\n",
      "Epoch 00123: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 851us/sample - loss: 0.3762 - accuracy: 0.8433 - val_loss: 0.3033 - val_accuracy: 0.9706\n",
      "Epoch 124/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4387 - accuracy: 0.7556\n",
      "Epoch 00124: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 818us/sample - loss: 0.4283 - accuracy: 0.7687 - val_loss: 0.3065 - val_accuracy: 0.9706\n",
      "Epoch 125/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3158 - accuracy: 0.8778\n",
      "Epoch 00125: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 806us/sample - loss: 0.3873 - accuracy: 0.7985 - val_loss: 0.3103 - val_accuracy: 0.9412\n",
      "Epoch 126/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3002 - accuracy: 0.8556\n",
      "Epoch 00126: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 769us/sample - loss: 0.3171 - accuracy: 0.8433 - val_loss: 0.3147 - val_accuracy: 0.9412\n",
      "Epoch 127/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3977 - accuracy: 0.8000\n",
      "Epoch 00127: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 896us/sample - loss: 0.3424 - accuracy: 0.8358 - val_loss: 0.3120 - val_accuracy: 0.9706\n",
      "Epoch 128/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3401 - accuracy: 0.8556\n",
      "Epoch 00128: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 828us/sample - loss: 0.3489 - accuracy: 0.8433 - val_loss: 0.2928 - val_accuracy: 0.9706\n",
      "Epoch 129/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3809 - accuracy: 0.8000\n",
      "Epoch 00129: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 855us/sample - loss: 0.3779 - accuracy: 0.8134 - val_loss: 0.2985 - val_accuracy: 0.9118\n",
      "Epoch 130/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3776 - accuracy: 0.8333\n",
      "Epoch 00130: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 881us/sample - loss: 0.4003 - accuracy: 0.8284 - val_loss: 0.2991 - val_accuracy: 0.9706\n",
      "Epoch 131/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.3463 - accuracy: 0.8250\n",
      "Epoch 00131: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 874us/sample - loss: 0.3491 - accuracy: 0.8209 - val_loss: 0.3018 - val_accuracy: 0.9412\n",
      "Epoch 132/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3641 - accuracy: 0.8333\n",
      "Epoch 00132: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 832us/sample - loss: 0.3748 - accuracy: 0.8209 - val_loss: 0.2983 - val_accuracy: 0.9706\n",
      "Epoch 133/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3450 - accuracy: 0.8333\n",
      "Epoch 00133: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 811us/sample - loss: 0.3558 - accuracy: 0.8358 - val_loss: 0.2844 - val_accuracy: 0.9706\n",
      "Epoch 134/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3833 - accuracy: 0.8222\n",
      "Epoch 00134: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 798us/sample - loss: 0.3509 - accuracy: 0.8433 - val_loss: 0.2825 - val_accuracy: 0.9706\n",
      "Epoch 135/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4211 - accuracy: 0.7778\n",
      "Epoch 00135: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 793us/sample - loss: 0.4151 - accuracy: 0.7910 - val_loss: 0.2890 - val_accuracy: 0.9412\n",
      "Epoch 136/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4247 - accuracy: 0.8111\n",
      "Epoch 00136: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 766us/sample - loss: 0.3938 - accuracy: 0.8358 - val_loss: 0.2947 - val_accuracy: 0.9412\n",
      "Epoch 137/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4098 - accuracy: 0.8000\n",
      "Epoch 00137: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.3692 - accuracy: 0.8284 - val_loss: 0.2999 - val_accuracy: 0.9706\n",
      "Epoch 138/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3130 - accuracy: 0.8333\n",
      "Epoch 00138: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 785us/sample - loss: 0.3502 - accuracy: 0.8209 - val_loss: 0.2816 - val_accuracy: 0.9412\n",
      "Epoch 139/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3358 - accuracy: 0.8000\n",
      "Epoch 00139: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 800us/sample - loss: 0.3315 - accuracy: 0.8134 - val_loss: 0.2760 - val_accuracy: 0.9706\n",
      "Epoch 140/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3196 - accuracy: 0.8778\n",
      "Epoch 00140: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 761us/sample - loss: 0.3828 - accuracy: 0.8358 - val_loss: 0.2797 - val_accuracy: 0.9118\n",
      "Epoch 141/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3103 - accuracy: 0.8444\n",
      "Epoch 00141: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 825us/sample - loss: 0.3677 - accuracy: 0.8358 - val_loss: 0.2819 - val_accuracy: 0.9706\n",
      "Epoch 142/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.3547 - accuracy: 0.8400\n",
      "Epoch 00142: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 733us/sample - loss: 0.3475 - accuracy: 0.8507 - val_loss: 0.2737 - val_accuracy: 0.9118\n",
      "Epoch 143/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3916 - accuracy: 0.8000\n",
      "Epoch 00143: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 810us/sample - loss: 0.4012 - accuracy: 0.8060 - val_loss: 0.2693 - val_accuracy: 0.9412\n",
      "Epoch 144/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2746 - accuracy: 0.8600\n",
      "Epoch 00144: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 778us/sample - loss: 0.3065 - accuracy: 0.8507 - val_loss: 0.2640 - val_accuracy: 0.9412\n",
      "Epoch 145/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3255 - accuracy: 0.8444\n",
      "Epoch 00145: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 804us/sample - loss: 0.3471 - accuracy: 0.8358 - val_loss: 0.2760 - val_accuracy: 0.9706\n",
      "Epoch 146/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3276 - accuracy: 0.8222\n",
      "Epoch 00146: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 774us/sample - loss: 0.3299 - accuracy: 0.8209 - val_loss: 0.2555 - val_accuracy: 0.9412\n",
      "Epoch 147/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3928 - accuracy: 0.8111\n",
      "Epoch 00147: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 770us/sample - loss: 0.3399 - accuracy: 0.8433 - val_loss: 0.2513 - val_accuracy: 0.9706\n",
      "Epoch 148/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3721 - accuracy: 0.8667\n",
      "Epoch 00148: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 772us/sample - loss: 0.3702 - accuracy: 0.8507 - val_loss: 0.2426 - val_accuracy: 0.9412\n",
      "Epoch 149/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3459 - accuracy: 0.8556\n",
      "Epoch 00149: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 786us/sample - loss: 0.3451 - accuracy: 0.8433 - val_loss: 0.2360 - val_accuracy: 0.9412\n",
      "Epoch 150/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2997 - accuracy: 0.8778\n",
      "Epoch 00150: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 787us/sample - loss: 0.3377 - accuracy: 0.8507 - val_loss: 0.2296 - val_accuracy: 0.9706\n",
      "Epoch 151/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3437 - accuracy: 0.8667\n",
      "Epoch 00151: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 822us/sample - loss: 0.3194 - accuracy: 0.8881 - val_loss: 0.2304 - val_accuracy: 0.9412\n",
      "Epoch 152/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.3874 - accuracy: 0.8000\n",
      "Epoch 00152: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 872us/sample - loss: 0.3847 - accuracy: 0.8134 - val_loss: 0.2138 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3347 - accuracy: 0.8333\n",
      "Epoch 00153: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 789us/sample - loss: 0.3676 - accuracy: 0.8060 - val_loss: 0.2113 - val_accuracy: 0.9706\n",
      "Epoch 154/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.4345 - accuracy: 0.7875\n",
      "Epoch 00154: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 883us/sample - loss: 0.3685 - accuracy: 0.8507 - val_loss: 0.2305 - val_accuracy: 0.9118\n",
      "Epoch 155/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2836 - accuracy: 0.8778\n",
      "Epoch 00155: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 818us/sample - loss: 0.3090 - accuracy: 0.8657 - val_loss: 0.2255 - val_accuracy: 0.9706\n",
      "Epoch 156/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3199 - accuracy: 0.8333\n",
      "Epoch 00156: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 814us/sample - loss: 0.3546 - accuracy: 0.8134 - val_loss: 0.2112 - val_accuracy: 0.9118\n",
      "Epoch 157/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3913 - accuracy: 0.8000\n",
      "Epoch 00157: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 831us/sample - loss: 0.3168 - accuracy: 0.8507 - val_loss: 0.2082 - val_accuracy: 0.9706\n",
      "Epoch 158/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3594 - accuracy: 0.8778\n",
      "Epoch 00158: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 939us/sample - loss: 0.3108 - accuracy: 0.8955 - val_loss: 0.1970 - val_accuracy: 0.9706\n",
      "Epoch 159/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3291 - accuracy: 0.8222\n",
      "Epoch 00159: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 793us/sample - loss: 0.3140 - accuracy: 0.8582 - val_loss: 0.1889 - val_accuracy: 0.9412\n",
      "Epoch 160/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2758 - accuracy: 0.8889\n",
      "Epoch 00160: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 800us/sample - loss: 0.2889 - accuracy: 0.8657 - val_loss: 0.1879 - val_accuracy: 0.9706\n",
      "Epoch 161/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3600 - accuracy: 0.8222\n",
      "Epoch 00161: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 816us/sample - loss: 0.3674 - accuracy: 0.8284 - val_loss: 0.1833 - val_accuracy: 0.9706\n",
      "Epoch 162/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3238 - accuracy: 0.8556\n",
      "Epoch 00162: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 793us/sample - loss: 0.3383 - accuracy: 0.8433 - val_loss: 0.1914 - val_accuracy: 0.9706\n",
      "Epoch 163/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2914 - accuracy: 0.8889\n",
      "Epoch 00163: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 803us/sample - loss: 0.3516 - accuracy: 0.8507 - val_loss: 0.1927 - val_accuracy: 0.9118\n",
      "Epoch 164/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2701 - accuracy: 0.8778\n",
      "Epoch 00164: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 843us/sample - loss: 0.2812 - accuracy: 0.8731 - val_loss: 0.1853 - val_accuracy: 0.9706\n",
      "Epoch 165/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3188 - accuracy: 0.8667\n",
      "Epoch 00165: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 864us/sample - loss: 0.2746 - accuracy: 0.8881 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2894 - accuracy: 0.8667\n",
      "Epoch 00166: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 816us/sample - loss: 0.3197 - accuracy: 0.8358 - val_loss: 0.1961 - val_accuracy: 0.9412\n",
      "Epoch 167/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3504 - accuracy: 0.8000\n",
      "Epoch 00167: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 798us/sample - loss: 0.3191 - accuracy: 0.8358 - val_loss: 0.1993 - val_accuracy: 0.9412\n",
      "Epoch 168/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3522 - accuracy: 0.8556\n",
      "Epoch 00168: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 882us/sample - loss: 0.3249 - accuracy: 0.8433 - val_loss: 0.2159 - val_accuracy: 0.9118\n",
      "Epoch 169/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2526 - accuracy: 0.8333\n",
      "Epoch 00169: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 813us/sample - loss: 0.2853 - accuracy: 0.8433 - val_loss: 0.1926 - val_accuracy: 0.9706\n",
      "Epoch 170/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3442 - accuracy: 0.8778\n",
      "Epoch 00170: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 835us/sample - loss: 0.3158 - accuracy: 0.8881 - val_loss: 0.1916 - val_accuracy: 0.9118\n",
      "Epoch 171/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3166 - accuracy: 0.8667\n",
      "Epoch 00171: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 829us/sample - loss: 0.3181 - accuracy: 0.8582 - val_loss: 0.1761 - val_accuracy: 0.9706\n",
      "Epoch 172/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2947 - accuracy: 0.8667\n",
      "Epoch 00172: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 820us/sample - loss: 0.3132 - accuracy: 0.8433 - val_loss: 0.1647 - val_accuracy: 0.9706\n",
      "Epoch 173/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3186 - accuracy: 0.8556\n",
      "Epoch 00173: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 792us/sample - loss: 0.2833 - accuracy: 0.8806 - val_loss: 0.1605 - val_accuracy: 0.9412\n",
      "Epoch 174/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2537 - accuracy: 0.9111\n",
      "Epoch 00174: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 801us/sample - loss: 0.2858 - accuracy: 0.8731 - val_loss: 0.1619 - val_accuracy: 0.9118\n",
      "Epoch 175/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2709 - accuracy: 0.8444\n",
      "Epoch 00175: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 798us/sample - loss: 0.3013 - accuracy: 0.8284 - val_loss: 0.1615 - val_accuracy: 0.9118\n",
      "Epoch 176/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2444 - accuracy: 0.8556\n",
      "Epoch 00176: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 768us/sample - loss: 0.3006 - accuracy: 0.8433 - val_loss: 0.1647 - val_accuracy: 0.9118\n",
      "Epoch 177/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3829 - accuracy: 0.8000\n",
      "Epoch 00177: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.3551 - accuracy: 0.8209 - val_loss: 0.1728 - val_accuracy: 0.9706\n",
      "Epoch 178/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2925 - accuracy: 0.8667\n",
      "Epoch 00178: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 795us/sample - loss: 0.2588 - accuracy: 0.8881 - val_loss: 0.1757 - val_accuracy: 0.9412\n",
      "Epoch 179/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2612 - accuracy: 0.8667\n",
      "Epoch 00179: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 782us/sample - loss: 0.3453 - accuracy: 0.8284 - val_loss: 0.1720 - val_accuracy: 0.9706\n",
      "Epoch 180/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2970 - accuracy: 0.8667\n",
      "Epoch 00180: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 789us/sample - loss: 0.3078 - accuracy: 0.8507 - val_loss: 0.1760 - val_accuracy: 0.9118\n",
      "Epoch 181/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2916 - accuracy: 0.8333\n",
      "Epoch 00181: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 800us/sample - loss: 0.3157 - accuracy: 0.8284 - val_loss: 0.1714 - val_accuracy: 0.9412\n",
      "Epoch 182/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2441 - accuracy: 0.8667\n",
      "Epoch 00182: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 809us/sample - loss: 0.2712 - accuracy: 0.8433 - val_loss: 0.1728 - val_accuracy: 0.9118\n",
      "Epoch 183/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4212 - accuracy: 0.7889\n",
      "Epoch 00183: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 810us/sample - loss: 0.3548 - accuracy: 0.8209 - val_loss: 0.1794 - val_accuracy: 0.9706\n",
      "Epoch 184/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2881 - accuracy: 0.8889\n",
      "Epoch 00184: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 829us/sample - loss: 0.2898 - accuracy: 0.8881 - val_loss: 0.1737 - val_accuracy: 0.9412\n",
      "Epoch 185/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2601 - accuracy: 0.8556\n",
      "Epoch 00185: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 829us/sample - loss: 0.2810 - accuracy: 0.8582 - val_loss: 0.1722 - val_accuracy: 0.9118\n",
      "Epoch 186/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2398 - accuracy: 0.8889\n",
      "Epoch 00186: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 822us/sample - loss: 0.2709 - accuracy: 0.8806 - val_loss: 0.1628 - val_accuracy: 0.9706\n",
      "Epoch 187/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2624 - accuracy: 0.8889\n",
      "Epoch 00187: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 823us/sample - loss: 0.3145 - accuracy: 0.8731 - val_loss: 0.1642 - val_accuracy: 0.9118\n",
      "Epoch 188/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3862 - accuracy: 0.8000\n",
      "Epoch 00188: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 815us/sample - loss: 0.3653 - accuracy: 0.8060 - val_loss: 0.1806 - val_accuracy: 0.9412\n",
      "Epoch 189/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2409 - accuracy: 0.9111\n",
      "Epoch 00189: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 807us/sample - loss: 0.2608 - accuracy: 0.8955 - val_loss: 0.1818 - val_accuracy: 0.9118\n",
      "Epoch 190/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3080 - accuracy: 0.8778\n",
      "Epoch 00190: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 790us/sample - loss: 0.2857 - accuracy: 0.8806 - val_loss: 0.1733 - val_accuracy: 0.9412\n",
      "Epoch 191/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2092 - accuracy: 0.9111\n",
      "Epoch 00191: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 785us/sample - loss: 0.2562 - accuracy: 0.8881 - val_loss: 0.1711 - val_accuracy: 0.9118\n",
      "Epoch 192/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2471 - accuracy: 0.9000\n",
      "Epoch 00192: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 789us/sample - loss: 0.2545 - accuracy: 0.8881 - val_loss: 0.1662 - val_accuracy: 0.9706\n",
      "Epoch 193/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1994 - accuracy: 0.9200\n",
      "Epoch 00193: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 783us/sample - loss: 0.2515 - accuracy: 0.8881 - val_loss: 0.1587 - val_accuracy: 0.9706\n",
      "Epoch 194/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2941 - accuracy: 0.8556\n",
      "Epoch 00194: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 834us/sample - loss: 0.2786 - accuracy: 0.8657 - val_loss: 0.1752 - val_accuracy: 0.9118\n",
      "Epoch 195/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2493 - accuracy: 0.8778\n",
      "Epoch 00195: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 825us/sample - loss: 0.2659 - accuracy: 0.8731 - val_loss: 0.1494 - val_accuracy: 0.9706\n",
      "Epoch 196/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2393 - accuracy: 0.8778\n",
      "Epoch 00196: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 840us/sample - loss: 0.2138 - accuracy: 0.8955 - val_loss: 0.1490 - val_accuracy: 0.9118\n",
      "Epoch 197/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2612 - accuracy: 0.8700\n",
      "Epoch 00197: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 763us/sample - loss: 0.2757 - accuracy: 0.8582 - val_loss: 0.1328 - val_accuracy: 0.9706\n",
      "Epoch 198/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2588 - accuracy: 0.8889\n",
      "Epoch 00198: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 802us/sample - loss: 0.2940 - accuracy: 0.8731 - val_loss: 0.1458 - val_accuracy: 0.9118\n",
      "Epoch 199/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2487 - accuracy: 0.9111\n",
      "Epoch 00199: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 811us/sample - loss: 0.2660 - accuracy: 0.8955 - val_loss: 0.1341 - val_accuracy: 0.9706\n",
      "Epoch 200/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2569 - accuracy: 0.9000\n",
      "Epoch 00200: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 889us/sample - loss: 0.2763 - accuracy: 0.8731 - val_loss: 0.1422 - val_accuracy: 0.9118\n",
      "Epoch 201/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2600 - accuracy: 0.8778\n",
      "Epoch 00201: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 806us/sample - loss: 0.3029 - accuracy: 0.8582 - val_loss: 0.1293 - val_accuracy: 0.9706\n",
      "Epoch 202/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2341 - accuracy: 0.8889\n",
      "Epoch 00202: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 815us/sample - loss: 0.2270 - accuracy: 0.8881 - val_loss: 0.1289 - val_accuracy: 0.9706\n",
      "Epoch 203/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.2671 - accuracy: 0.8875\n",
      "Epoch 00203: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 854us/sample - loss: 0.2908 - accuracy: 0.8657 - val_loss: 0.1360 - val_accuracy: 0.9118\n",
      "Epoch 204/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2349 - accuracy: 0.8889\n",
      "Epoch 00204: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 825us/sample - loss: 0.2763 - accuracy: 0.8657 - val_loss: 0.1299 - val_accuracy: 0.9706\n",
      "Epoch 205/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3214 - accuracy: 0.8667\n",
      "Epoch 00205: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 828us/sample - loss: 0.3822 - accuracy: 0.8582 - val_loss: 0.1434 - val_accuracy: 0.9412\n",
      "Epoch 206/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2778 - accuracy: 0.8778\n",
      "Epoch 00206: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 811us/sample - loss: 0.2436 - accuracy: 0.9030 - val_loss: 0.1478 - val_accuracy: 0.9706\n",
      "Epoch 207/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2016 - accuracy: 0.9111\n",
      "Epoch 00207: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 848us/sample - loss: 0.2481 - accuracy: 0.8881 - val_loss: 0.1429 - val_accuracy: 0.9706\n",
      "Epoch 208/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2567 - accuracy: 0.8889\n",
      "Epoch 00208: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 824us/sample - loss: 0.2208 - accuracy: 0.9104 - val_loss: 0.1441 - val_accuracy: 0.9706\n",
      "Epoch 209/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2813 - accuracy: 0.8889\n",
      "Epoch 00209: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 823us/sample - loss: 0.2628 - accuracy: 0.8955 - val_loss: 0.1376 - val_accuracy: 0.9706\n",
      "Epoch 210/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2752 - accuracy: 0.9000\n",
      "Epoch 00210: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.2662 - accuracy: 0.8881 - val_loss: 0.1265 - val_accuracy: 0.9706\n",
      "Epoch 211/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2138 - accuracy: 0.9111\n",
      "Epoch 00211: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 801us/sample - loss: 0.2120 - accuracy: 0.9104 - val_loss: 0.1272 - val_accuracy: 0.9706\n",
      "Epoch 212/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3346 - accuracy: 0.8333\n",
      "Epoch 00212: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 829us/sample - loss: 0.3162 - accuracy: 0.8507 - val_loss: 0.1319 - val_accuracy: 0.9706\n",
      "Epoch 213/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2686 - accuracy: 0.8900\n",
      "Epoch 00213: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 773us/sample - loss: 0.2539 - accuracy: 0.8955 - val_loss: 0.1290 - val_accuracy: 0.9706\n",
      "Epoch 214/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1988 - accuracy: 0.9300\n",
      "Epoch 00214: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 747us/sample - loss: 0.2318 - accuracy: 0.9179 - val_loss: 0.1218 - val_accuracy: 0.9706\n",
      "Epoch 215/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2938 - accuracy: 0.8778\n",
      "Epoch 00215: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 765us/sample - loss: 0.2835 - accuracy: 0.8881 - val_loss: 0.1240 - val_accuracy: 0.9706\n",
      "Epoch 216/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2502 - accuracy: 0.8900\n",
      "Epoch 00216: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.2552 - accuracy: 0.8881 - val_loss: 0.1265 - val_accuracy: 0.9706\n",
      "Epoch 217/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2276 - accuracy: 0.8778\n",
      "Epoch 00217: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 784us/sample - loss: 0.2111 - accuracy: 0.8806 - val_loss: 0.1252 - val_accuracy: 0.9706\n",
      "Epoch 218/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2732 - accuracy: 0.9111\n",
      "Epoch 00218: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 788us/sample - loss: 0.2543 - accuracy: 0.8955 - val_loss: 0.1280 - val_accuracy: 0.9412\n",
      "Epoch 219/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1963 - accuracy: 0.9333\n",
      "Epoch 00219: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 790us/sample - loss: 0.1932 - accuracy: 0.9254 - val_loss: 0.1141 - val_accuracy: 0.9706\n",
      "Epoch 220/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2741 - accuracy: 0.8667\n",
      "Epoch 00220: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 827us/sample - loss: 0.2319 - accuracy: 0.8881 - val_loss: 0.1158 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3246 - accuracy: 0.8333\n",
      "Epoch 00221: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 780us/sample - loss: 0.3123 - accuracy: 0.8507 - val_loss: 0.1226 - val_accuracy: 0.9706\n",
      "Epoch 222/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2571 - accuracy: 0.9000\n",
      "Epoch 00222: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 806us/sample - loss: 0.2734 - accuracy: 0.8731 - val_loss: 0.1330 - val_accuracy: 0.9706\n",
      "Epoch 223/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2447 - accuracy: 0.8800\n",
      "Epoch 00223: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 746us/sample - loss: 0.2239 - accuracy: 0.8955 - val_loss: 0.1196 - val_accuracy: 0.9706\n",
      "Epoch 224/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.3037 - accuracy: 0.8800\n",
      "Epoch 00224: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 739us/sample - loss: 0.2721 - accuracy: 0.8955 - val_loss: 0.1322 - val_accuracy: 0.9706\n",
      "Epoch 225/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2168 - accuracy: 0.9000\n",
      "Epoch 00225: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 754us/sample - loss: 0.2141 - accuracy: 0.8955 - val_loss: 0.1210 - val_accuracy: 0.9706\n",
      "Epoch 226/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2879 - accuracy: 0.8900\n",
      "Epoch 00226: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 790us/sample - loss: 0.2851 - accuracy: 0.8881 - val_loss: 0.1206 - val_accuracy: 0.9706\n",
      "Epoch 227/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2380 - accuracy: 0.8889\n",
      "Epoch 00227: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 795us/sample - loss: 0.2220 - accuracy: 0.9104 - val_loss: 0.1177 - val_accuracy: 0.9706\n",
      "Epoch 228/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2751 - accuracy: 0.8889\n",
      "Epoch 00228: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 801us/sample - loss: 0.2512 - accuracy: 0.9030 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2982 - accuracy: 0.8900\n",
      "Epoch 00229: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 759us/sample - loss: 0.3065 - accuracy: 0.8731 - val_loss: 0.1210 - val_accuracy: 0.9706\n",
      "Epoch 230/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1871 - accuracy: 0.9333\n",
      "Epoch 00230: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 814us/sample - loss: 0.2198 - accuracy: 0.9030 - val_loss: 0.1225 - val_accuracy: 0.9706\n",
      "Epoch 231/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2199 - accuracy: 0.9000\n",
      "Epoch 00231: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 822us/sample - loss: 0.2043 - accuracy: 0.9030 - val_loss: 0.1152 - val_accuracy: 0.9706\n",
      "Epoch 232/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2136 - accuracy: 0.8778\n",
      "Epoch 00232: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 806us/sample - loss: 0.2291 - accuracy: 0.8731 - val_loss: 0.1103 - val_accuracy: 0.9706\n",
      "Epoch 233/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2549 - accuracy: 0.9000\n",
      "Epoch 00233: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 772us/sample - loss: 0.2518 - accuracy: 0.9030 - val_loss: 0.1129 - val_accuracy: 0.9706\n",
      "Epoch 234/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2368 - accuracy: 0.9000\n",
      "Epoch 00234: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 784us/sample - loss: 0.1955 - accuracy: 0.9254 - val_loss: 0.1056 - val_accuracy: 0.9706\n",
      "Epoch 235/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2669 - accuracy: 0.9000\n",
      "Epoch 00235: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 784us/sample - loss: 0.2532 - accuracy: 0.8955 - val_loss: 0.1071 - val_accuracy: 0.9706\n",
      "Epoch 236/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2807 - accuracy: 0.8444\n",
      "Epoch 00236: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 800us/sample - loss: 0.2495 - accuracy: 0.8657 - val_loss: 0.1111 - val_accuracy: 0.9706\n",
      "Epoch 237/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2827 - accuracy: 0.8800\n",
      "Epoch 00237: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.2517 - accuracy: 0.8881 - val_loss: 0.1087 - val_accuracy: 0.9706\n",
      "Epoch 238/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1464 - accuracy: 0.9444\n",
      "Epoch 00238: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 751us/sample - loss: 0.1828 - accuracy: 0.9179 - val_loss: 0.0985 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2220 - accuracy: 0.9000\n",
      "Epoch 00239: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 787us/sample - loss: 0.2664 - accuracy: 0.8806 - val_loss: 0.1049 - val_accuracy: 0.9706\n",
      "Epoch 240/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1684 - accuracy: 0.9333\n",
      "Epoch 00240: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 768us/sample - loss: 0.1939 - accuracy: 0.9328 - val_loss: 0.1085 - val_accuracy: 0.9706\n",
      "Epoch 241/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2073 - accuracy: 0.9333\n",
      "Epoch 00241: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 802us/sample - loss: 0.1986 - accuracy: 0.9179 - val_loss: 0.1010 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2172 - accuracy: 0.9333\n",
      "Epoch 00242: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 794us/sample - loss: 0.2133 - accuracy: 0.9254 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3117 - accuracy: 0.8444\n",
      "Epoch 00243: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 780us/sample - loss: 0.2761 - accuracy: 0.8657 - val_loss: 0.0989 - val_accuracy: 0.9706\n",
      "Epoch 244/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2729 - accuracy: 0.8444\n",
      "Epoch 00244: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 847us/sample - loss: 0.3195 - accuracy: 0.8358 - val_loss: 0.1044 - val_accuracy: 0.9706\n",
      "Epoch 245/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1948 - accuracy: 0.9000\n",
      "Epoch 00245: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 804us/sample - loss: 0.2238 - accuracy: 0.8955 - val_loss: 0.1118 - val_accuracy: 0.9706\n",
      "Epoch 246/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2519 - accuracy: 0.9000\n",
      "Epoch 00246: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 810us/sample - loss: 0.2624 - accuracy: 0.9030 - val_loss: 0.1219 - val_accuracy: 0.9706\n",
      "Epoch 247/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2478 - accuracy: 0.8889\n",
      "Epoch 00247: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 777us/sample - loss: 0.2147 - accuracy: 0.9104 - val_loss: 0.1262 - val_accuracy: 0.9706\n",
      "Epoch 248/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2143 - accuracy: 0.8900\n",
      "Epoch 00248: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.1985 - accuracy: 0.9104 - val_loss: 0.1207 - val_accuracy: 0.9706\n",
      "Epoch 249/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2157 - accuracy: 0.8667\n",
      "Epoch 00249: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 811us/sample - loss: 0.2150 - accuracy: 0.8657 - val_loss: 0.1097 - val_accuracy: 0.9706\n",
      "Epoch 250/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2008 - accuracy: 0.9111\n",
      "Epoch 00250: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 815us/sample - loss: 0.1822 - accuracy: 0.9254 - val_loss: 0.1042 - val_accuracy: 0.9706\n",
      "Epoch 251/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2716 - accuracy: 0.9100\n",
      "Epoch 00251: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.2763 - accuracy: 0.9030 - val_loss: 0.0983 - val_accuracy: 0.9706\n",
      "Epoch 252/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.2892 - accuracy: 0.8875\n",
      "Epoch 00252: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 850us/sample - loss: 0.2490 - accuracy: 0.9030 - val_loss: 0.1011 - val_accuracy: 0.9706\n",
      "Epoch 253/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2315 - accuracy: 0.8900\n",
      "Epoch 00253: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 738us/sample - loss: 0.2235 - accuracy: 0.8881 - val_loss: 0.0883 - val_accuracy: 0.9706\n",
      "Epoch 254/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1944 - accuracy: 0.9222\n",
      "Epoch 00254: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 776us/sample - loss: 0.1914 - accuracy: 0.9030 - val_loss: 0.0861 - val_accuracy: 0.9706\n",
      "Epoch 255/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2442 - accuracy: 0.8900\n",
      "Epoch 00255: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 753us/sample - loss: 0.2030 - accuracy: 0.9179 - val_loss: 0.0871 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2522 - accuracy: 0.8556\n",
      "Epoch 00256: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 803us/sample - loss: 0.2425 - accuracy: 0.8657 - val_loss: 0.0881 - val_accuracy: 0.9706\n",
      "Epoch 257/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2379 - accuracy: 0.9200\n",
      "Epoch 00257: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 771us/sample - loss: 0.2220 - accuracy: 0.9104 - val_loss: 0.0840 - val_accuracy: 0.9706\n",
      "Epoch 258/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1257 - accuracy: 0.9556\n",
      "Epoch 00258: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 813us/sample - loss: 0.1400 - accuracy: 0.9328 - val_loss: 0.0784 - val_accuracy: 0.9706\n",
      "Epoch 259/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1465 - accuracy: 0.9667\n",
      "Epoch 00259: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 764us/sample - loss: 0.1285 - accuracy: 0.9701 - val_loss: 0.0796 - val_accuracy: 0.9706\n",
      "Epoch 260/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2669 - accuracy: 0.8556\n",
      "Epoch 00260: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 784us/sample - loss: 0.2309 - accuracy: 0.8731 - val_loss: 0.0829 - val_accuracy: 0.9706\n",
      "Epoch 261/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3060 - accuracy: 0.8333\n",
      "Epoch 00261: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 783us/sample - loss: 0.2493 - accuracy: 0.8731 - val_loss: 0.0913 - val_accuracy: 0.9706\n",
      "Epoch 262/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2004 - accuracy: 0.9000\n",
      "Epoch 00262: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 756us/sample - loss: 0.2090 - accuracy: 0.9104 - val_loss: 0.1152 - val_accuracy: 0.9412\n",
      "Epoch 263/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.3039 - accuracy: 0.8800\n",
      "Epoch 00263: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 747us/sample - loss: 0.3179 - accuracy: 0.8731 - val_loss: 0.1198 - val_accuracy: 0.9412\n",
      "Epoch 264/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4335 - accuracy: 0.8333\n",
      "Epoch 00264: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 776us/sample - loss: 0.3571 - accuracy: 0.8507 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1686 - accuracy: 0.9500\n",
      "Epoch 00265: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 734us/sample - loss: 0.1911 - accuracy: 0.9403 - val_loss: 0.1102 - val_accuracy: 0.9706\n",
      "Epoch 266/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1880 - accuracy: 0.9222\n",
      "Epoch 00266: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 775us/sample - loss: 0.2321 - accuracy: 0.8955 - val_loss: 0.1046 - val_accuracy: 0.9706\n",
      "Epoch 267/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1827 - accuracy: 0.9200\n",
      "Epoch 00267: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 765us/sample - loss: 0.1975 - accuracy: 0.9030 - val_loss: 0.1154 - val_accuracy: 0.9706\n",
      "Epoch 268/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1722 - accuracy: 0.9333\n",
      "Epoch 00268: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 760us/sample - loss: 0.2034 - accuracy: 0.9254 - val_loss: 0.1014 - val_accuracy: 0.9706\n",
      "Epoch 269/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1791 - accuracy: 0.9333\n",
      "Epoch 00269: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 756us/sample - loss: 0.2245 - accuracy: 0.8955 - val_loss: 0.0982 - val_accuracy: 0.9706\n",
      "Epoch 270/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3431 - accuracy: 0.8444\n",
      "Epoch 00270: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.3325 - accuracy: 0.8582 - val_loss: 0.1282 - val_accuracy: 0.9706\n",
      "Epoch 271/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2225 - accuracy: 0.8556\n",
      "Epoch 00271: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 808us/sample - loss: 0.2241 - accuracy: 0.8731 - val_loss: 0.1168 - val_accuracy: 0.9706\n",
      "Epoch 272/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2331 - accuracy: 0.8667\n",
      "Epoch 00272: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 775us/sample - loss: 0.1908 - accuracy: 0.9104 - val_loss: 0.1081 - val_accuracy: 0.9706\n",
      "Epoch 273/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2012 - accuracy: 0.9300\n",
      "Epoch 00273: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 755us/sample - loss: 0.2044 - accuracy: 0.9328 - val_loss: 0.1040 - val_accuracy: 0.9706\n",
      "Epoch 274/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1539 - accuracy: 0.9600\n",
      "Epoch 00274: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 790us/sample - loss: 0.1469 - accuracy: 0.9552 - val_loss: 0.0929 - val_accuracy: 0.9706\n",
      "Epoch 275/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1795 - accuracy: 0.9333\n",
      "Epoch 00275: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 761us/sample - loss: 0.1587 - accuracy: 0.9403 - val_loss: 0.0855 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2200 - accuracy: 0.9000\n",
      "Epoch 00276: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 763us/sample - loss: 0.2329 - accuracy: 0.8955 - val_loss: 0.0819 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1962 - accuracy: 0.9222\n",
      "Epoch 00277: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 775us/sample - loss: 0.2070 - accuracy: 0.9179 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1827 - accuracy: 0.9000\n",
      "Epoch 00278: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.1748 - accuracy: 0.9104 - val_loss: 0.0876 - val_accuracy: 0.9706\n",
      "Epoch 279/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2671 - accuracy: 0.8889\n",
      "Epoch 00279: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.2918 - accuracy: 0.8731 - val_loss: 0.0844 - val_accuracy: 0.9706\n",
      "Epoch 280/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2745 - accuracy: 0.8778\n",
      "Epoch 00280: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 760us/sample - loss: 0.2476 - accuracy: 0.8881 - val_loss: 0.0885 - val_accuracy: 0.9706\n",
      "Epoch 281/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1603 - accuracy: 0.9556\n",
      "Epoch 00281: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 739us/sample - loss: 0.1596 - accuracy: 0.9403 - val_loss: 0.0840 - val_accuracy: 0.9706\n",
      "Epoch 282/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2414 - accuracy: 0.8889\n",
      "Epoch 00282: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 753us/sample - loss: 0.2157 - accuracy: 0.9030 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1896 - accuracy: 0.9111\n",
      "Epoch 00283: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 788us/sample - loss: 0.2225 - accuracy: 0.9104 - val_loss: 0.0909 - val_accuracy: 0.9706\n",
      "Epoch 284/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2408 - accuracy: 0.9556\n",
      "Epoch 00284: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.2158 - accuracy: 0.9552 - val_loss: 0.0865 - val_accuracy: 0.9706\n",
      "Epoch 285/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2231 - accuracy: 0.9333\n",
      "Epoch 00285: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 749us/sample - loss: 0.2289 - accuracy: 0.9328 - val_loss: 0.0860 - val_accuracy: 0.9706\n",
      "Epoch 286/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1290 - accuracy: 0.9556\n",
      "Epoch 00286: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.1836 - accuracy: 0.9179 - val_loss: 0.0825 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1986 - accuracy: 0.8889\n",
      "Epoch 00287: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 757us/sample - loss: 0.1881 - accuracy: 0.8955 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1890 - accuracy: 0.9111\n",
      "Epoch 00288: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 760us/sample - loss: 0.1773 - accuracy: 0.9254 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.2819 - accuracy: 0.8875\n",
      "Epoch 00289: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 869us/sample - loss: 0.2179 - accuracy: 0.9179 - val_loss: 0.0843 - val_accuracy: 0.9706\n",
      "Epoch 290/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1656 - accuracy: 0.9200\n",
      "Epoch 00290: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 749us/sample - loss: 0.1713 - accuracy: 0.9104 - val_loss: 0.0815 - val_accuracy: 0.9706\n",
      "Epoch 291/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2400 - accuracy: 0.9000\n",
      "Epoch 00291: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 761us/sample - loss: 0.2150 - accuracy: 0.9179 - val_loss: 0.0811 - val_accuracy: 0.9706\n",
      "Epoch 292/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2357 - accuracy: 0.8778\n",
      "Epoch 00292: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 747us/sample - loss: 0.2125 - accuracy: 0.8881 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1663 - accuracy: 0.9333\n",
      "Epoch 00293: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 759us/sample - loss: 0.2434 - accuracy: 0.9030 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2092 - accuracy: 0.9000\n",
      "Epoch 00294: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 747us/sample - loss: 0.1788 - accuracy: 0.9254 - val_loss: 0.0907 - val_accuracy: 0.9706\n",
      "Epoch 295/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1935 - accuracy: 0.9111\n",
      "Epoch 00295: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 791us/sample - loss: 0.2082 - accuracy: 0.9030 - val_loss: 0.0722 - val_accuracy: 0.9706\n",
      "Epoch 296/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1266 - accuracy: 0.9556\n",
      "Epoch 00296: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 802us/sample - loss: 0.1463 - accuracy: 0.9478 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1670 - accuracy: 0.9300\n",
      "Epoch 00297: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 735us/sample - loss: 0.1757 - accuracy: 0.9328 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1728 - accuracy: 0.9300\n",
      "Epoch 00298: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 761us/sample - loss: 0.1727 - accuracy: 0.9328 - val_loss: 0.0780 - val_accuracy: 0.9706\n",
      "Epoch 299/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2760 - accuracy: 0.8889\n",
      "Epoch 00299: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.2612 - accuracy: 0.8806 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1930 - accuracy: 0.9000\n",
      "Epoch 00300: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 786us/sample - loss: 0.1856 - accuracy: 0.9179 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2734 - accuracy: 0.9222\n",
      "Epoch 00301: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 774us/sample - loss: 0.2175 - accuracy: 0.9403 - val_loss: 0.0974 - val_accuracy: 0.9412\n",
      "Epoch 302/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2205 - accuracy: 0.8900\n",
      "Epoch 00302: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 746us/sample - loss: 0.2271 - accuracy: 0.8955 - val_loss: 0.0896 - val_accuracy: 0.9706\n",
      "Epoch 303/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2271 - accuracy: 0.9000\n",
      "Epoch 00303: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 791us/sample - loss: 0.1995 - accuracy: 0.9104 - val_loss: 0.0679 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2517 - accuracy: 0.9000\n",
      "Epoch 00304: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 753us/sample - loss: 0.2338 - accuracy: 0.8955 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1727 - accuracy: 0.9333\n",
      "Epoch 00305: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 761us/sample - loss: 0.1976 - accuracy: 0.9104 - val_loss: 0.0951 - val_accuracy: 0.9706\n",
      "Epoch 306/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2337 - accuracy: 0.9111\n",
      "Epoch 00306: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 760us/sample - loss: 0.2086 - accuracy: 0.9254 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1718 - accuracy: 0.9400\n",
      "Epoch 00307: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 748us/sample - loss: 0.1626 - accuracy: 0.9328 - val_loss: 0.0726 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1318 - accuracy: 0.9400\n",
      "Epoch 00308: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 751us/sample - loss: 0.1400 - accuracy: 0.9328 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9444\n",
      "Epoch 00309: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 754us/sample - loss: 0.1377 - accuracy: 0.9552 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1428 - accuracy: 0.9667\n",
      "Epoch 00310: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 754us/sample - loss: 0.1666 - accuracy: 0.9403 - val_loss: 0.0617 - val_accuracy: 0.9706\n",
      "Epoch 311/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2198 - accuracy: 0.9300\n",
      "Epoch 00311: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 746us/sample - loss: 0.2175 - accuracy: 0.9104 - val_loss: 0.0920 - val_accuracy: 0.9706\n",
      "Epoch 312/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2245 - accuracy: 0.9100\n",
      "Epoch 00312: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 775us/sample - loss: 0.2081 - accuracy: 0.9104 - val_loss: 0.0955 - val_accuracy: 0.9706\n",
      "Epoch 313/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2477 - accuracy: 0.9200\n",
      "Epoch 00313: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 761us/sample - loss: 0.2422 - accuracy: 0.9179 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1928 - accuracy: 0.9400\n",
      "Epoch 00314: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 778us/sample - loss: 0.2028 - accuracy: 0.9403 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2145 - accuracy: 0.9222\n",
      "Epoch 00315: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 759us/sample - loss: 0.2092 - accuracy: 0.9179 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1496 - accuracy: 0.9600\n",
      "Epoch 00316: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 741us/sample - loss: 0.1882 - accuracy: 0.9328 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2136 - accuracy: 0.8778\n",
      "Epoch 00317: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 763us/sample - loss: 0.2001 - accuracy: 0.8806 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1833 - accuracy: 0.9500\n",
      "Epoch 00318: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 763us/sample - loss: 0.1641 - accuracy: 0.9478 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1561 - accuracy: 0.9500\n",
      "Epoch 00319: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 754us/sample - loss: 0.1591 - accuracy: 0.9552 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1953 - accuracy: 0.9222\n",
      "Epoch 00320: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 754us/sample - loss: 0.2031 - accuracy: 0.9179 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1423 - accuracy: 0.9200\n",
      "Epoch 00321: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 734us/sample - loss: 0.1641 - accuracy: 0.9179 - val_loss: 0.0726 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1699 - accuracy: 0.9100\n",
      "Epoch 00322: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 723us/sample - loss: 0.1532 - accuracy: 0.9179 - val_loss: 0.0706 - val_accuracy: 0.9706\n",
      "Epoch 323/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.2450 - accuracy: 0.8875\n",
      "Epoch 00323: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 800us/sample - loss: 0.2288 - accuracy: 0.8955 - val_loss: 0.0811 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1910 - accuracy: 0.9100\n",
      "Epoch 00324: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 749us/sample - loss: 0.1870 - accuracy: 0.9104 - val_loss: 0.1023 - val_accuracy: 0.9412\n",
      "Epoch 325/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2855 - accuracy: 0.8889\n",
      "Epoch 00325: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 771us/sample - loss: 0.2618 - accuracy: 0.9030 - val_loss: 0.0845 - val_accuracy: 0.9706\n",
      "Epoch 326/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1764 - accuracy: 0.9400\n",
      "Epoch 00326: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 759us/sample - loss: 0.1694 - accuracy: 0.9403 - val_loss: 0.0848 - val_accuracy: 0.9706\n",
      "Epoch 327/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1931 - accuracy: 0.9200\n",
      "Epoch 00327: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 744us/sample - loss: 0.1836 - accuracy: 0.9254 - val_loss: 0.0691 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1519 - accuracy: 0.9300\n",
      "Epoch 00328: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 752us/sample - loss: 0.1722 - accuracy: 0.9328 - val_loss: 0.0715 - val_accuracy: 0.9706\n",
      "Epoch 329/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1261 - accuracy: 0.9600\n",
      "Epoch 00329: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 745us/sample - loss: 0.1680 - accuracy: 0.9403 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1853 - accuracy: 0.9111\n",
      "Epoch 00330: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 753us/sample - loss: 0.1760 - accuracy: 0.9104 - val_loss: 0.0682 - val_accuracy: 0.9706\n",
      "Epoch 331/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1623 - accuracy: 0.9300\n",
      "Epoch 00331: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 764us/sample - loss: 0.1919 - accuracy: 0.9254 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1811 - accuracy: 0.9400\n",
      "Epoch 00332: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 765us/sample - loss: 0.1696 - accuracy: 0.9403 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1287 - accuracy: 0.9667\n",
      "Epoch 00333: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 768us/sample - loss: 0.1254 - accuracy: 0.9627 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1291 - accuracy: 0.9400\n",
      "Epoch 00334: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 752us/sample - loss: 0.1381 - accuracy: 0.9403 - val_loss: 0.0736 - val_accuracy: 0.9706\n",
      "Epoch 335/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1691 - accuracy: 0.9300\n",
      "Epoch 00335: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 763us/sample - loss: 0.1683 - accuracy: 0.9254 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1455 - accuracy: 0.9300\n",
      "Epoch 00336: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 756us/sample - loss: 0.1490 - accuracy: 0.9328 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1755 - accuracy: 0.9111\n",
      "Epoch 00337: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.1959 - accuracy: 0.9104 - val_loss: 0.0665 - val_accuracy: 0.9706\n",
      "Epoch 338/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2526 - accuracy: 0.8700\n",
      "Epoch 00338: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.2329 - accuracy: 0.8881 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1891 - accuracy: 0.9200\n",
      "Epoch 00339: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 754us/sample - loss: 0.1758 - accuracy: 0.9328 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1450 - accuracy: 0.9333\n",
      "Epoch 00340: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.1835 - accuracy: 0.9179 - val_loss: 0.0778 - val_accuracy: 0.9706\n",
      "Epoch 341/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1951 - accuracy: 0.8900\n",
      "Epoch 00341: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.1838 - accuracy: 0.8955 - val_loss: 0.0650 - val_accuracy: 0.9706\n",
      "Epoch 342/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1735 - accuracy: 0.9556\n",
      "Epoch 00342: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 763us/sample - loss: 0.1482 - accuracy: 0.9552 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2261 - accuracy: 0.8778\n",
      "Epoch 00343: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 785us/sample - loss: 0.2064 - accuracy: 0.8955 - val_loss: 0.0730 - val_accuracy: 0.9706\n",
      "Epoch 344/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2776 - accuracy: 0.8889\n",
      "Epoch 00344: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 748us/sample - loss: 0.2351 - accuracy: 0.9030 - val_loss: 0.1046 - val_accuracy: 0.9412\n",
      "Epoch 345/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1764 - accuracy: 0.9111\n",
      "Epoch 00345: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 754us/sample - loss: 0.1632 - accuracy: 0.9254 - val_loss: 0.0788 - val_accuracy: 0.9706\n",
      "Epoch 346/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1992 - accuracy: 0.9400\n",
      "Epoch 00346: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.1929 - accuracy: 0.9254 - val_loss: 0.0745 - val_accuracy: 0.9706\n",
      "Epoch 347/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1659 - accuracy: 0.9200\n",
      "Epoch 00347: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 755us/sample - loss: 0.1512 - accuracy: 0.9328 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1821 - accuracy: 0.9400\n",
      "Epoch 00348: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 745us/sample - loss: 0.1708 - accuracy: 0.9403 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1743 - accuracy: 0.9222\n",
      "Epoch 00349: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 752us/sample - loss: 0.2066 - accuracy: 0.8955 - val_loss: 0.0781 - val_accuracy: 0.9706\n",
      "Epoch 350/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1341 - accuracy: 0.9667\n",
      "Epoch 00350: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 762us/sample - loss: 0.1542 - accuracy: 0.9627 - val_loss: 0.0737 - val_accuracy: 0.9706\n",
      "Epoch 351/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1609 - accuracy: 0.9444\n",
      "Epoch 00351: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 747us/sample - loss: 0.2094 - accuracy: 0.9254 - val_loss: 0.0645 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1655 - accuracy: 0.9556\n",
      "Epoch 00352: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 874us/sample - loss: 0.1488 - accuracy: 0.9552 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1374 - accuracy: 0.9300\n",
      "Epoch 00353: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.1445 - accuracy: 0.9328 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1708 - accuracy: 0.9200\n",
      "Epoch 00354: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 759us/sample - loss: 0.1765 - accuracy: 0.9179 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1471 - accuracy: 0.9300\n",
      "Epoch 00355: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 725us/sample - loss: 0.1384 - accuracy: 0.9328 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1364 - accuracy: 0.9300\n",
      "Epoch 00356: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 790us/sample - loss: 0.1520 - accuracy: 0.9254 - val_loss: 0.0599 - val_accuracy: 0.9706\n",
      "Epoch 357/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1872 - accuracy: 0.8900\n",
      "Epoch 00357: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 729us/sample - loss: 0.1702 - accuracy: 0.9104 - val_loss: 0.0695 - val_accuracy: 0.9706\n",
      "Epoch 358/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1430 - accuracy: 0.9300\n",
      "Epoch 00358: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 770us/sample - loss: 0.1442 - accuracy: 0.9328 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0979 - accuracy: 0.9700\n",
      "Epoch 00359: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 727us/sample - loss: 0.1198 - accuracy: 0.9478 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1474 - accuracy: 0.9300\n",
      "Epoch 00360: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 756us/sample - loss: 0.1575 - accuracy: 0.9254 - val_loss: 0.0601 - val_accuracy: 0.9706\n",
      "Epoch 361/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1893 - accuracy: 0.9300\n",
      "Epoch 00361: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 741us/sample - loss: 0.1679 - accuracy: 0.9403 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1484 - accuracy: 0.9500\n",
      "Epoch 00362: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 744us/sample - loss: 0.1878 - accuracy: 0.9254 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1486 - accuracy: 0.9300\n",
      "Epoch 00363: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 729us/sample - loss: 0.1405 - accuracy: 0.9403 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1067 - accuracy: 0.9700\n",
      "Epoch 00364: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 764us/sample - loss: 0.1167 - accuracy: 0.9552 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1600 - accuracy: 0.9400\n",
      "Epoch 00365: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 722us/sample - loss: 0.1841 - accuracy: 0.9254 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1278 - accuracy: 0.9444\n",
      "Epoch 00366: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 766us/sample - loss: 0.1572 - accuracy: 0.9104 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2037 - accuracy: 0.9200\n",
      "Epoch 00367: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 722us/sample - loss: 0.1716 - accuracy: 0.9403 - val_loss: 0.0826 - val_accuracy: 0.9706\n",
      "Epoch 368/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1362 - accuracy: 0.9556\n",
      "Epoch 00368: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 773us/sample - loss: 0.1352 - accuracy: 0.9478 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1278 - accuracy: 0.9400\n",
      "Epoch 00369: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 721us/sample - loss: 0.1301 - accuracy: 0.9403 - val_loss: 0.0627 - val_accuracy: 0.9706\n",
      "Epoch 370/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1659 - accuracy: 0.9300\n",
      "Epoch 00370: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 762us/sample - loss: 0.1982 - accuracy: 0.9254 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1290 - accuracy: 0.9300\n",
      "Epoch 00371: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 740us/sample - loss: 0.1620 - accuracy: 0.9254 - val_loss: 0.0679 - val_accuracy: 0.9706\n",
      "Epoch 372/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2065 - accuracy: 0.9100\n",
      "Epoch 00372: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 730us/sample - loss: 0.1863 - accuracy: 0.9179 - val_loss: 0.0749 - val_accuracy: 0.9706\n",
      "Epoch 373/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2099 - accuracy: 0.9300\n",
      "Epoch 00373: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 723us/sample - loss: 0.1818 - accuracy: 0.9403 - val_loss: 0.0799 - val_accuracy: 0.9706\n",
      "Epoch 374/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2412 - accuracy: 0.9000\n",
      "Epoch 00374: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 733us/sample - loss: 0.2047 - accuracy: 0.9104 - val_loss: 0.0705 - val_accuracy: 0.9706\n",
      "Epoch 375/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2266 - accuracy: 0.8700\n",
      "Epoch 00375: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 735us/sample - loss: 0.1989 - accuracy: 0.8881 - val_loss: 0.0688 - val_accuracy: 0.9706\n",
      "Epoch 376/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0992 - accuracy: 0.9700\n",
      "Epoch 00376: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 833us/sample - loss: 0.0893 - accuracy: 0.9776 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0851 - accuracy: 0.9700\n",
      "Epoch 00377: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 729us/sample - loss: 0.1335 - accuracy: 0.9552 - val_loss: 0.0566 - val_accuracy: 0.9706\n",
      "Epoch 378/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1452 - accuracy: 0.9444\n",
      "Epoch 00378: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 779us/sample - loss: 0.2056 - accuracy: 0.9179 - val_loss: 0.0955 - val_accuracy: 0.9706\n",
      "Epoch 379/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1810 - accuracy: 0.9111\n",
      "Epoch 00379: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 736us/sample - loss: 0.2474 - accuracy: 0.8881 - val_loss: 0.0924 - val_accuracy: 0.9706\n",
      "Epoch 380/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1483 - accuracy: 0.9400\n",
      "Epoch 00380: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.1980 - accuracy: 0.9104 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1066 - accuracy: 0.9500\n",
      "Epoch 00381: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 721us/sample - loss: 0.1282 - accuracy: 0.9478 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1464 - accuracy: 0.9500\n",
      "Epoch 00382: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 745us/sample - loss: 0.1759 - accuracy: 0.9254 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1422 - accuracy: 0.9600\n",
      "Epoch 00383: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 740us/sample - loss: 0.1317 - accuracy: 0.9627 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1843 - accuracy: 0.9444\n",
      "Epoch 00384: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 746us/sample - loss: 0.1834 - accuracy: 0.9478 - val_loss: 0.0703 - val_accuracy: 0.9706\n",
      "Epoch 385/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1786 - accuracy: 0.9300\n",
      "Epoch 00385: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 760us/sample - loss: 0.1662 - accuracy: 0.9254 - val_loss: 0.0723 - val_accuracy: 0.9706\n",
      "Epoch 386/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1668 - accuracy: 0.9100\n",
      "Epoch 00386: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 718us/sample - loss: 0.1671 - accuracy: 0.9254 - val_loss: 0.0606 - val_accuracy: 0.9706\n",
      "Epoch 387/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1072 - accuracy: 0.9556\n",
      "Epoch 00387: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 762us/sample - loss: 0.1661 - accuracy: 0.9254 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1752 - accuracy: 0.9200\n",
      "Epoch 00388: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 729us/sample - loss: 0.1762 - accuracy: 0.9179 - val_loss: 0.0670 - val_accuracy: 0.9706\n",
      "Epoch 389/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2225 - accuracy: 0.9222\n",
      "Epoch 00389: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 748us/sample - loss: 0.1697 - accuracy: 0.9403 - val_loss: 0.0711 - val_accuracy: 0.9706\n",
      "Epoch 390/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1019 - accuracy: 0.9700\n",
      "Epoch 00390: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.1148 - accuracy: 0.9552 - val_loss: 0.0610 - val_accuracy: 0.9706\n",
      "Epoch 391/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1203 - accuracy: 0.9500\n",
      "Epoch 00391: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 748us/sample - loss: 0.1093 - accuracy: 0.9552 - val_loss: 0.0667 - val_accuracy: 0.9706\n",
      "Epoch 392/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1568 - accuracy: 0.9400\n",
      "Epoch 00392: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 774us/sample - loss: 0.1671 - accuracy: 0.9328 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1165 - accuracy: 0.9600\n",
      "Epoch 00393: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 721us/sample - loss: 0.1233 - accuracy: 0.9552 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1258 - accuracy: 0.9333\n",
      "Epoch 00394: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 742us/sample - loss: 0.1470 - accuracy: 0.9254 - val_loss: 0.0680 - val_accuracy: 0.9706\n",
      "Epoch 395/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1520 - accuracy: 0.9444\n",
      "Epoch 00395: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 779us/sample - loss: 0.1204 - accuracy: 0.9627 - val_loss: 0.0599 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2054 - accuracy: 0.9200\n",
      "Epoch 00396: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 716us/sample - loss: 0.1835 - accuracy: 0.9254 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1632 - accuracy: 0.9200\n",
      "Epoch 00397: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 741us/sample - loss: 0.1434 - accuracy: 0.9328 - val_loss: 0.0834 - val_accuracy: 0.9706\n",
      "Epoch 398/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1261 - accuracy: 0.9600\n",
      "Epoch 00398: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 747us/sample - loss: 0.1695 - accuracy: 0.9254 - val_loss: 0.0755 - val_accuracy: 0.9706\n",
      "Epoch 399/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1883 - accuracy: 0.9200\n",
      "Epoch 00399: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 716us/sample - loss: 0.1894 - accuracy: 0.9179 - val_loss: 0.0524 - val_accuracy: 0.9706\n",
      "Epoch 400/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0781 - accuracy: 0.9800\n",
      "Epoch 00400: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 833us/sample - loss: 0.0766 - accuracy: 0.9851 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1463 - accuracy: 0.9700\n",
      "Epoch 00401: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 737us/sample - loss: 0.1272 - accuracy: 0.9701 - val_loss: 0.0563 - val_accuracy: 0.9706\n",
      "Epoch 402/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1244 - accuracy: 0.9400\n",
      "Epoch 00402: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 755us/sample - loss: 0.1130 - accuracy: 0.9478 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1671 - accuracy: 0.9200\n",
      "Epoch 00403: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 734us/sample - loss: 0.1708 - accuracy: 0.9254 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1648 - accuracy: 0.9400\n",
      "Epoch 00404: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 762us/sample - loss: 0.1566 - accuracy: 0.9328 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1285 - accuracy: 0.9700\n",
      "Epoch 00405: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 749us/sample - loss: 0.1263 - accuracy: 0.9701 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1655 - accuracy: 0.9300\n",
      "Epoch 00406: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 719us/sample - loss: 0.1699 - accuracy: 0.9254 - val_loss: 0.0565 - val_accuracy: 0.9706\n",
      "Epoch 407/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2093 - accuracy: 0.9111\n",
      "Epoch 00407: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 752us/sample - loss: 0.1876 - accuracy: 0.9179 - val_loss: 0.0562 - val_accuracy: 0.9706\n",
      "Epoch 408/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1207 - accuracy: 0.9444\n",
      "Epoch 00408: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 772us/sample - loss: 0.1360 - accuracy: 0.9403 - val_loss: 0.0637 - val_accuracy: 0.9706\n",
      "Epoch 409/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2321 - accuracy: 0.9000\n",
      "Epoch 00409: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 737us/sample - loss: 0.1896 - accuracy: 0.9254 - val_loss: 0.0665 - val_accuracy: 0.9706\n",
      "Epoch 410/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1498 - accuracy: 0.9300\n",
      "Epoch 00410: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 768us/sample - loss: 0.1297 - accuracy: 0.9478 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1321 - accuracy: 0.9500\n",
      "Epoch 00411: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 737us/sample - loss: 0.1281 - accuracy: 0.9552 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0781 - accuracy: 0.9667\n",
      "Epoch 00412: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 769us/sample - loss: 0.0903 - accuracy: 0.9627 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2101 - accuracy: 0.9200\n",
      "Epoch 00413: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 762us/sample - loss: 0.1883 - accuracy: 0.9254 - val_loss: 0.0568 - val_accuracy: 0.9706\n",
      "Epoch 414/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1478 - accuracy: 0.9500\n",
      "Epoch 00414: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 725us/sample - loss: 0.1473 - accuracy: 0.9552 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1825 - accuracy: 0.9200\n",
      "Epoch 00415: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 723us/sample - loss: 0.1592 - accuracy: 0.9254 - val_loss: 0.0640 - val_accuracy: 0.9706\n",
      "Epoch 416/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2081 - accuracy: 0.9333\n",
      "Epoch 00416: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 757us/sample - loss: 0.1501 - accuracy: 0.9552 - val_loss: 0.0758 - val_accuracy: 0.9706\n",
      "Epoch 417/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1960 - accuracy: 0.9300\n",
      "Epoch 00417: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 780us/sample - loss: 0.1690 - accuracy: 0.9403 - val_loss: 0.0578 - val_accuracy: 0.9706\n",
      "Epoch 418/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1412 - accuracy: 0.9444\n",
      "Epoch 00418: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 806us/sample - loss: 0.1231 - accuracy: 0.9627 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0806 - accuracy: 0.9667\n",
      "Epoch 00419: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 871us/sample - loss: 0.1088 - accuracy: 0.9552 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0994 - accuracy: 0.9556\n",
      "Epoch 00420: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 794us/sample - loss: 0.1441 - accuracy: 0.9403 - val_loss: 0.0601 - val_accuracy: 0.9706\n",
      "Epoch 421/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2034 - accuracy: 0.9333\n",
      "Epoch 00421: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 730us/sample - loss: 0.1595 - accuracy: 0.9552 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1629 - accuracy: 0.9400\n",
      "Epoch 00422: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 858us/sample - loss: 0.1459 - accuracy: 0.9478 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1366 - accuracy: 0.9400\n",
      "Epoch 00423: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 789us/sample - loss: 0.1307 - accuracy: 0.9403 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1458 - accuracy: 0.9300\n",
      "Epoch 00424: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 741us/sample - loss: 0.1183 - accuracy: 0.9478 - val_loss: 0.0631 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1140 - accuracy: 0.9778\n",
      "Epoch 00425: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.1534 - accuracy: 0.9478 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1646 - accuracy: 0.9300\n",
      "Epoch 00426: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 749us/sample - loss: 0.1538 - accuracy: 0.9403 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0952 - accuracy: 0.9800\n",
      "Epoch 00427: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 776us/sample - loss: 0.1014 - accuracy: 0.9701 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2010 - accuracy: 0.9333\n",
      "Epoch 00428: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 817us/sample - loss: 0.1902 - accuracy: 0.9328 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1415 - accuracy: 0.9444\n",
      "Epoch 00429: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 820us/sample - loss: 0.1312 - accuracy: 0.9478 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2127 - accuracy: 0.9222\n",
      "Epoch 00430: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 773us/sample - loss: 0.1581 - accuracy: 0.9478 - val_loss: 0.0703 - val_accuracy: 0.9706\n",
      "Epoch 431/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1164 - accuracy: 0.9700\n",
      "Epoch 00431: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 739us/sample - loss: 0.1357 - accuracy: 0.9627 - val_loss: 0.0667 - val_accuracy: 0.9706\n",
      "Epoch 432/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1010 - accuracy: 0.9600\n",
      "Epoch 00432: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 730us/sample - loss: 0.0995 - accuracy: 0.9627 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1345 - accuracy: 0.9667\n",
      "Epoch 00433: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 758us/sample - loss: 0.1683 - accuracy: 0.9328 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1223 - accuracy: 0.9600\n",
      "Epoch 00434: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 744us/sample - loss: 0.1341 - accuracy: 0.9552 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1325 - accuracy: 0.9400\n",
      "Epoch 00435: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 739us/sample - loss: 0.1451 - accuracy: 0.9403 - val_loss: 0.0575 - val_accuracy: 0.9706\n",
      "Epoch 436/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1593 - accuracy: 0.9500\n",
      "Epoch 00436: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.2039 - accuracy: 0.9328 - val_loss: 0.0602 - val_accuracy: 0.9706\n",
      "Epoch 437/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1891 - accuracy: 0.9222\n",
      "Epoch 00437: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.1611 - accuracy: 0.9328 - val_loss: 0.0635 - val_accuracy: 0.9706\n",
      "Epoch 438/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1512 - accuracy: 0.9333\n",
      "Epoch 00438: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 733us/sample - loss: 0.1343 - accuracy: 0.9403 - val_loss: 0.0682 - val_accuracy: 0.9706\n",
      "Epoch 439/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1387 - accuracy: 0.9444\n",
      "Epoch 00439: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 736us/sample - loss: 0.1554 - accuracy: 0.9254 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1780 - accuracy: 0.9300\n",
      "Epoch 00440: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 791us/sample - loss: 0.1520 - accuracy: 0.9403 - val_loss: 0.0680 - val_accuracy: 0.9706\n",
      "Epoch 441/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1365 - accuracy: 0.9300\n",
      "Epoch 00441: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 769us/sample - loss: 0.1531 - accuracy: 0.9254 - val_loss: 0.0771 - val_accuracy: 0.9706\n",
      "Epoch 442/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1529 - accuracy: 0.9500\n",
      "Epoch 00442: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 782us/sample - loss: 0.1371 - accuracy: 0.9552 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1227 - accuracy: 0.9556\n",
      "Epoch 00443: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 827us/sample - loss: 0.1243 - accuracy: 0.9478 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1822 - accuracy: 0.9333\n",
      "Epoch 00444: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 806us/sample - loss: 0.1729 - accuracy: 0.9478 - val_loss: 0.0431 - val_accuracy: 0.9706\n",
      "Epoch 445/500\n",
      " 70/134 [==============>...............] - ETA: 0s - loss: 0.1371 - accuracy: 0.9429\n",
      "Epoch 00445: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 862us/sample - loss: 0.1487 - accuracy: 0.9328 - val_loss: 0.0678 - val_accuracy: 0.9706\n",
      "Epoch 446/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1469 - accuracy: 0.9400\n",
      "Epoch 00446: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.1372 - accuracy: 0.9403 - val_loss: 0.0586 - val_accuracy: 0.9706\n",
      "Epoch 447/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1537 - accuracy: 0.9100\n",
      "Epoch 00447: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 709us/sample - loss: 0.1853 - accuracy: 0.9104 - val_loss: 0.0722 - val_accuracy: 0.9706\n",
      "Epoch 448/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0969 - accuracy: 0.9700\n",
      "Epoch 00448: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.1561 - accuracy: 0.9478 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1787 - accuracy: 0.9300\n",
      "Epoch 00449: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 713us/sample - loss: 0.1565 - accuracy: 0.9403 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1084 - accuracy: 0.9600\n",
      "Epoch 00450: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 752us/sample - loss: 0.1305 - accuracy: 0.9478 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1509 - accuracy: 0.9100\n",
      "Epoch 00451: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 718us/sample - loss: 0.1679 - accuracy: 0.9179 - val_loss: 0.0628 - val_accuracy: 0.9706\n",
      "Epoch 452/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1371 - accuracy: 0.9300\n",
      "Epoch 00452: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.1283 - accuracy: 0.9403 - val_loss: 0.0814 - val_accuracy: 0.9706\n",
      "Epoch 453/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1371 - accuracy: 0.9500\n",
      "Epoch 00453: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 0.1362 - accuracy: 0.9478 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0816 - accuracy: 0.9600\n",
      "Epoch 00454: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 708us/sample - loss: 0.1179 - accuracy: 0.9478 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2018 - accuracy: 0.8800\n",
      "Epoch 00455: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 724us/sample - loss: 0.1886 - accuracy: 0.8881 - val_loss: 0.0573 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1920 - accuracy: 0.9300\n",
      "Epoch 00456: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 718us/sample - loss: 0.1659 - accuracy: 0.9328 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0966 - accuracy: 0.9600\n",
      "Epoch 00457: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 737us/sample - loss: 0.1087 - accuracy: 0.9552 - val_loss: 0.0821 - val_accuracy: 0.9706\n",
      "Epoch 458/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0999 - accuracy: 0.9600\n",
      "Epoch 00458: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 711us/sample - loss: 0.0949 - accuracy: 0.9627 - val_loss: 0.0621 - val_accuracy: 0.9706\n",
      "Epoch 459/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1314 - accuracy: 0.9600\n",
      "Epoch 00459: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 769us/sample - loss: 0.1453 - accuracy: 0.9552 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1224 - accuracy: 0.9300\n",
      "Epoch 00460: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 730us/sample - loss: 0.1243 - accuracy: 0.9403 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1711 - accuracy: 0.9300\n",
      "Epoch 00461: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 0.1492 - accuracy: 0.9478 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2049 - accuracy: 0.9500\n",
      "Epoch 00462: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 710us/sample - loss: 0.1661 - accuracy: 0.9627 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1347 - accuracy: 0.9500\n",
      "Epoch 00463: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 711us/sample - loss: 0.1566 - accuracy: 0.9328 - val_loss: 0.0527 - val_accuracy: 0.9706\n",
      "Epoch 464/500\n",
      " 80/134 [================>.............] - ETA: 0s - loss: 0.0977 - accuracy: 0.9750\n",
      "Epoch 00464: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 839us/sample - loss: 0.1564 - accuracy: 0.9403 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1006 - accuracy: 0.9600\n",
      "Epoch 00465: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 708us/sample - loss: 0.0971 - accuracy: 0.9552 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1222 - accuracy: 0.9600\n",
      "Epoch 00466: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 710us/sample - loss: 0.1039 - accuracy: 0.9701 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1380 - accuracy: 0.9300\n",
      "Epoch 00467: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 712us/sample - loss: 0.1265 - accuracy: 0.9403 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1240 - accuracy: 0.9400\n",
      "Epoch 00468: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 733us/sample - loss: 0.1499 - accuracy: 0.9403 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1697 - accuracy: 0.9300\n",
      "Epoch 00469: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 727us/sample - loss: 0.1441 - accuracy: 0.9403 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1205 - accuracy: 0.9600\n",
      "Epoch 00470: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 730us/sample - loss: 0.1189 - accuracy: 0.9627 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0824 - accuracy: 0.9700\n",
      "Epoch 00471: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 726us/sample - loss: 0.1115 - accuracy: 0.9627 - val_loss: 0.0592 - val_accuracy: 0.9706\n",
      "Epoch 472/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1398 - accuracy: 0.9500\n",
      "Epoch 00472: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 734us/sample - loss: 0.1403 - accuracy: 0.9552 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0945 - accuracy: 0.9500\n",
      "Epoch 00473: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 714us/sample - loss: 0.0814 - accuracy: 0.9627 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1518 - accuracy: 0.9400\n",
      "Epoch 00474: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 0.1332 - accuracy: 0.9478 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0629 - accuracy: 0.9800\n",
      "Epoch 00475: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.0571 - accuracy: 0.9851 - val_loss: 0.0526 - val_accuracy: 0.9706\n",
      "Epoch 476/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1321 - accuracy: 0.9600\n",
      "Epoch 00476: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 699us/sample - loss: 0.1294 - accuracy: 0.9552 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1374 - accuracy: 0.9600\n",
      "Epoch 00477: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 714us/sample - loss: 0.1221 - accuracy: 0.9627 - val_loss: 0.0495 - val_accuracy: 0.9706\n",
      "Epoch 478/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0690 - accuracy: 0.9700\n",
      "Epoch 00478: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.0766 - accuracy: 0.9701 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1084 - accuracy: 0.9600\n",
      "Epoch 00479: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 701us/sample - loss: 0.1230 - accuracy: 0.9552 - val_loss: 0.0423 - val_accuracy: 0.9706\n",
      "Epoch 480/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2082 - accuracy: 0.9500\n",
      "Epoch 00480: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 724us/sample - loss: 0.1656 - accuracy: 0.9627 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1132 - accuracy: 0.9400\n",
      "Epoch 00481: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 771us/sample - loss: 0.1011 - accuracy: 0.9552 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0992 - accuracy: 0.9700\n",
      "Epoch 00482: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 725us/sample - loss: 0.0909 - accuracy: 0.9701 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0617 - accuracy: 0.9900\n",
      "Epoch 00483: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 709us/sample - loss: 0.0981 - accuracy: 0.9701 - val_loss: 0.0477 - val_accuracy: 0.9706\n",
      "Epoch 484/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1804 - accuracy: 0.9400\n",
      "Epoch 00484: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.1696 - accuracy: 0.9403 - val_loss: 0.0512 - val_accuracy: 0.9706\n",
      "Epoch 485/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1370 - accuracy: 0.9500\n",
      "Epoch 00485: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 0.1300 - accuracy: 0.9478 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1376 - accuracy: 0.9300\n",
      "Epoch 00486: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 722us/sample - loss: 0.1312 - accuracy: 0.9328 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0919 - accuracy: 0.9900\n",
      "Epoch 00487: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 719us/sample - loss: 0.0922 - accuracy: 0.9851 - val_loss: 0.0500 - val_accuracy: 0.9706\n",
      "Epoch 488/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0887 - accuracy: 0.9800\n",
      "Epoch 00488: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 709us/sample - loss: 0.1477 - accuracy: 0.9627 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1526 - accuracy: 0.9400\n",
      "Epoch 00489: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 0.1771 - accuracy: 0.9328 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0605 - accuracy: 0.9900\n",
      "Epoch 00490: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 715us/sample - loss: 0.0759 - accuracy: 0.9776 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0802 - accuracy: 0.9889\n",
      "Epoch 00491: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 726us/sample - loss: 0.1105 - accuracy: 0.9627 - val_loss: 0.0445 - val_accuracy: 0.9706\n",
      "Epoch 492/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1803 - accuracy: 0.9200\n",
      "Epoch 00492: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 746us/sample - loss: 0.1664 - accuracy: 0.9254 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2207 - accuracy: 0.8900\n",
      "Epoch 00493: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 728us/sample - loss: 0.1923 - accuracy: 0.9030 - val_loss: 0.0531 - val_accuracy: 0.9706\n",
      "Epoch 494/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1175 - accuracy: 0.9500\n",
      "Epoch 00494: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 713us/sample - loss: 0.1228 - accuracy: 0.9552 - val_loss: 0.0705 - val_accuracy: 0.9706\n",
      "Epoch 495/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0814 - accuracy: 0.9700\n",
      "Epoch 00495: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 694us/sample - loss: 0.0842 - accuracy: 0.9701 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1080 - accuracy: 0.9500\n",
      "Epoch 00496: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 720us/sample - loss: 0.1073 - accuracy: 0.9552 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1001 - accuracy: 0.9600\n",
      "Epoch 00497: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 0.0977 - accuracy: 0.9627 - val_loss: 0.0509 - val_accuracy: 0.9706\n",
      "Epoch 498/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0912 - accuracy: 0.9700\n",
      "Epoch 00498: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 718us/sample - loss: 0.0830 - accuracy: 0.9701 - val_loss: 0.0621 - val_accuracy: 0.9706\n",
      "Epoch 499/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0807 - accuracy: 0.9800\n",
      "Epoch 00499: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 714us/sample - loss: 0.1002 - accuracy: 0.9627 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1402 - accuracy: 0.9500\n",
      "Epoch 00500: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 696us/sample - loss: 0.1344 - accuracy: 0.9552 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Training completed in time:  0:00:53.479539\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9477612\n",
      "Testing Accuracy:  0.5416667\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.24      0.67      0.35         9\n",
      "   Pneumonia       0.87      0.51      0.65        39\n",
      "\n",
      "    accuracy                           0.54        48\n",
      "   macro avg       0.55      0.59      0.50        48\n",
      "weighted avg       0.75      0.54      0.59        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  3]\n",
      " [19 20]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
