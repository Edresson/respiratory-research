{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 2\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 1 - trim5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'trim5'\n",
    "GROUP_TEST = 'trim5'\n",
    "DATASET = 'dataset_1'\n",
    "DURATION = 5\n",
    "SIZE = 216\n",
    "CSV_TRAIN = 'train1.csv'\n",
    "CSV_TEST = 'test1.csv'\n",
    "MODEL_NAME = f'CNN2_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  102  Healthy\n",
       "1  121  Healthy\n",
       "2  123  Healthy\n",
       "3  125  Healthy\n",
       "4  126  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  366  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAEYCAYAAAA57swgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO29e5Rtx13f+f2dvi3ZxtgWloOFJGOtRM5gHiEgbB6zZjngh2wYyyQkkROwcbyGycTOY2AGbMTCHhxlMZhMIMF4ohAFGzNRDIGgMAKNzJAwmUQgGYyNTAwXP9BVxDjCxo/I6Hb3+c0fZ+99ftX7W499und33+7vZ61et3vvXVW/ql1Vp+4+9d1fc3cIIYQQQghRYnHcAQghhBBCiJOPFo1CCCGEEKKKFo1CCCGEEKKKFo1CCCGEEKKKFo1CCCGEEKKKFo1CCCGEEKKKFo1CCCGEEKKKFo1CiANhZh82s4tmduW+479hZm5mzzSzH++u+XT4+cvh2r9iZvd3xx82s18ws/86nH+Wmf2UmT1iZp8ws/ea2beb2dZR1lUIIc4yWjQKIQ6DDwF4ef+HmX0xgCfsu+YH3P2J4edfdNd+O4AfAvD3AHwugGcA+FEAN3Xn/ySAXwXwIIAvdvcnA/iLAG4A8Nmz1koIIcSAyRFGCHEQzOzDAH4MwE3u/hXdsR8E8HEAfxfAdQDeCOCCu3/PvrRPBvAQgFe5+09l8n8HgCvc/evnqoMQQog6etIohDgM7gXwJDP7gu4r45sBvKMh3VcBeByAny1c83wAP33wEIUQQhwELRqFEIfFTwB4BYAXAPhtrJ4gRv4nM/uj7ueR7thTATzi7ruFfJ8K4OFDj1YIIcQkzh13AEKIU8NPAPgVrL6Ofjs5/4P7v54G8IcArjSzc4WF4x8CuOrwwhRCCLEJetIohDgU3P0jWAliXgLgZxqT/QcAjwF4WeGadwH4CweLTgghxEHRolEIcZi8GsDXuvt/abnY3T8B4HsBvMXMXmZmTzCzbTN7sZn9QHfZGwB8tZm92cyeDgBm9qfM7B1m9pRZaiGEEGKEvp4WQhwa7v57G6T5+2b2BwC+B8BPAvgUgHcDuLXP08y+Cisl9gNmdg7AhwH8s+5aIYQQR4BeuSOEEEIIIaro62khhBBCCFFFi0YhhBBCCFFFi0YhhBBCCFFFi0YhhBBCCFFlknr6qU98vD/jiifRc2YGALhkhDUszq4Oc2Ak7yNvqynlbdIWff4kbaz/nPXepJw5YrvkxkNP4R7WOBF9/BLmqMbIWYe2c2zvWt8/wBg5MVyic/UU3nPho4+4+9MOPeOJfPnis/yTvtd07Xk8dre73zhzSAdi0qLxGVc8Cf/2O/4qsFyOztn2NgDA90LjkOt8ue4cdm5rSvEpIe8+T1vwQRzLDAdHh2yri2cx4QFsF0dSLxLHkHcMIbYVK5PlTdrMd9s6ZFIeIYnbxvEM50OsSdldmyZ17a5NJggWR6H+q6zJPSZpNimHTl6k7yZpK+f7NqDjgcQQ2zHXj0tU26exny53VqYs8R7G69hY6s/X+nitbMYmY7u/lo77DCx/VnapvIQpbc/GCPsQZX2Oldk6bir51dqvWu8+n9i32ZxfG2uHDJsjknHazX3Z+95/doQ5stTnanNWhM3lrW3W3DcR6hvr0JVTnQ/J/N88Z8U5kt2HDeaI3Lz85O/44Y+0ZTAvn/Q9/NC5z2+69ht2f+fKmcM5MHpPoxBCCCHEHBhg240L4JyR6glCi0YhhBBCiBmwhWHr8Y3fqn5m3lgOAy0ahRBCCCHmwIDFuUt4/+s+tGgUQgghhJiDKV9PXwJMXzTmNk/3xyubq6ubW9mG28wm3IFB1FJ+BJyW3QkV4ubhygbx0qb81k3hwIab3Nl1i/GG7aEMtimaCBW6i7Pnp2yG9+VilMbQiQDYBvmY97IsBKHtSwQGOIi4KhdbHwMqwq5N9u53dYib3dlGdLpBPrTJkD72j1ahQxCFDaKWTcQ4FWFXTYxREqz1fQvY11bIi4tin2IwoUOSd5clE3vFm13bvD9FkDPkU1Lf58QUTKBYuo85QVtLWmT6D78wxNg4V6Ey5w/5NV4Xy2MCudrgJcLJ9uv4nMTeNoADjOMpn0FgbbDMz9XsuqTMisBwiDX0Z3YfauOnJp7dZKzNjZnpSaMQQgghhKhw5p80CiGEEEKIOtrTKIQQQgghapgBW5edHvM9LRqFEEIIIWbBNtojflLRolEIIYQQYg4MsK2z/qSRKKV6+7FEPUYsitJEFUVa4XyikurLmWLz1iu7FmW1FbOPSpScpf9BRGVosRSuRFzLN6PCNJRN1Lwl8rHm7RNpGRnFa2tbsOubVW/sHufUmUwNX7DyS2Kr9Fd2v/wAb/OnSsp9ZY4g/dkrYyBpc2bdVbHSHIZ0zSK0pjRv7bs1VWtJtcnU0RlLt6ljqcpUJTMa1Oe5tx/06UsnK7aGVVh/2NsZx8DyZPeQtD19k0WOvg6hzfrWje2Us7Ech1ixiox5lt6iQa7LvSWi9U0PfR2YPesoz/3x5OaVzva39TM413aledLZ522AWTcmebe+yaH1zSPHhAFYbJ2eJ42nZ/krhBBCCHGSsNXCt+WnmpXZ7Wb2UTP7rXDsc8zsHjP73e7fK7rjZmb/0MzOm9l7zezLDqM6WjQKIYQQQsyCYbHV9tPAjwO4cd+x1wH4JXe/HsAvdX8DwIsBXN/9fBuAtx5GbbRoFEIIIYSYATNgsb3V9FPD3X8FwMf2Hb4JwNu6398G4GXh+Nt9xb0AnmJmVx20PhLCCCGEEELMgW3msDWBz3X3h7vf/wDA53a/Xw3gwXDdhe7YwzgAB1s0RmFAv1l3QuMU7Y8y59kmdxZPZKpAYwp00/QmVmKtNlWtZZP8clZsrRaQpXKzVKwZWTyDpVm0J+s2gTO7syn+fUOfCsKHpDa9NSPbuE0374eyiSiG9gVWhyDISsoerCLDtf1G85hPv2k8bsSvCcOsz5vYgmUYBDfFqzLE9ulDj2K51rmjZqtWEFFkbR8L/TQdK0byqYiv9p9roWCRmQgiamO2scw5xQasfZI+vtXXa32o2WqVjP3Eqo4IGTllC1VmL5nYfTKxCsZCs02s82qU7l0iFAqxDfNpvLgkbiNzcQK7N3F9wPqh8blzfahgk8vm0BNL81fPAHClmd0f/r7N3W9rTezubmazeinqSaMQQgghxAzYtCeNj7j7DROL+P/M7Cp3f7j7+vmj3fGHAFwbrrumO3YgtKdRCCGEEGImbLFo+tmQOwG8svv9lQB+Lhx/Raei/koAnwhfY2+MnjQKIYQQQszBIe5pNLN/DuB5WH2NfQHAGwB8P4B3mtmrAXwEwF/qLr8LwEsAnAfwKIBXHUYMWjQKIYQQQsyAmWFr+3C+1HX3l2dOfR251gG85lAKDmjRKIQQQggxEwf46vnEsdmikVg4eXfMFlFlZqM0U6CqKR9bM/XXNVvaZfKpx7CVTUPLy9iUUcvA/jpmV0WO5RjOM2VaUl5FLdjXp6bAbaS5zXLpmeVdnz7WtTHebDv21mi9zRYyVly9CjS5r0TJ2dq/akpDUna0cRvKztlillS9TIEa1Ymx3xSs7Koq4orKvdRHsjZmbOyXLAFzlpP9aaI2TVSy+8rNQsZ+kk9UBzNry5JFJlHtZssuvAWAzkloH5c1W8PWeA4CewtEtu+y/sfmYNbnYj/u6pPcQzZmSTvDQ/2JLe0QQ02xj3E8OXvX9XUxffdv7EvMunJoi8zYLb0lIMZD1M6L7fXyY5jf99i9a39bwMyvttmM+V+5c6ToSaMQQgghxCy0WQReKmjRKIQQQggxE1o0CiGEEEKIIqv3NJ71PY1CCCGEEKLMIaqnTwLTF42LxXozathYvOhzqogSJolVmGCEiki2yvkVVvkxTat1E7XgO6hghGzSrlq6nSNilt2xnWPJjgkA3bA92EwxO6+kwLK4ZsiPtHPO0m19LREFLcYb21k71OLI2YsNx4lFX0J/vw8odqJ9k2xop3VkFnxkw36Njaw/W9s80z778+v+IOcXo3M1AUbRnrRmOTnFlo6x7MbfufE9ToWDTPRTznqdhufTKqqiFmxsHLM5rSayYQIfQnVeiTRaMtIxV7Gp7PtX7XOpKrRi4hgGiYePAdLHk3mKWZpWxtIuiac2X1REU0MMRPRK48mtD/p2a/0MZqK7UPZJQ08ahRBCCCFEkYk2giceLRqFEEIIIWZCi0YhhBBCCFHB9PW0EEIIIYSooK+nhRBCCCFEHWt3T7oE2GzR2Cuq4hNXYsnFlEzNiunVH6Nj1rd9TWpIVH41ZV9VNXeO2Ioxu7TKo+hBNUdEjLmySzHGstn55v/ltD5CJ8q8aj6Jwm2P5FNWFK/Ve+PBl7VnIwyDN9rtxb5rYwUmVfCSWFNVdKcQZ4rFCFPfx3gL944qmGM/ZH2S3YcA7XPBUnHIcwOVdq2cdYFMYXqwMmp2hMN1NVu6TSipSVfBJdcl1zL1b0WRXqOkIo75M/vE5L6TD8La3EjnS0aoY1ENH/Nh8xIZx7T+iX0dmUNJXXNvfxgR7xe7Lo5DdsGgYK5A+lTu7SCsTw9FTxnbjWrvdRncWnjoN43rgzhOE5vdcrTHgoQwQgghhBCiCe1pFEIIIYQQZUze00IIIYQQogE9aRRCCCGEEFX0pHETSivt3KboYTMv2VA7wTquF0dUBSyHDN1InlxQtriqMtGaMWuFxSy5uo3hVDiQiXvYpEzyTizHujTLnRBPo51V9X4xMUGSTxdj3Nie2KF19WbaB2b1SKzUkuNMWFG5X3TTfRD4FIVdUUAQNrv39yTJm4whaklGoH2pZllX2ahP7es6Fluhn+2xTfxkw3/Gdo3W4QCTOrUVrfTDZPM+sdWkcTU+rajem6LQLOQT+1dhjkjyqalEW+esxnHeav0aaRYY1sSWhCmivNbPnqFNrTwGknm5MLYPlb5M2qfWDG0e56eKMLVZAJWZg08KZjZpvXLS0ZNGIYQQQoiZyD1cuBTRolEIIYQQYg5MexqFEEIIIUQVqaeFEEIIIUQNw0YGCCcVLRqFEEIIIWbibD9pzCi+mhVpjJwtVne8asXGYmNqP6ZmI2rTGDdTPdXyoST2bctROUPelXZMVJdMQXcQmOKTWUFtccs/qs7rVY4VWzBmycWUiCVF9ChOZh3Xx0NTVNq/tU9NofV/oBUrNqpc36QcZhHK8gnWZ+v7yeMdqFjiDecmKFCZrdgQG1OT5hSrBcV+bNNhzMW8K29lKNU1iTdQTTMVNjfm2oIdL1kLBmqK/k3eVtFqAZlJnM0vZaxmn/RBX5lXBlh/38TmlbRz1Va0kudwb+NnTM2WtY899vcufZzz6Zy+N55DGDWl/YHn4JkxO13e06fnmakQQgghxAnDFoumn6a8zG40sw+Y2Xkze93MoY/Q19NCCCGEEDNxWF9Pm9kWgLcAeAGACwDuM7M73f39h1JAA3rSKIQQQggxB2ar7+dbfuo8B8B5d/+gu18EcAeAm2aNfx960iiEEEIIMRMTnjReaWb3h79vc/fbwt9XA3gw/H0BwHMPGN4kJi0a+w2dw8bTKZuaW+2j2EbhsME3sSXbl3drDNlyWi3dwgbeoqVbSJsIWFg8w8mx1VpuM3zJLq3aSSv7J9bpiR1VZlMv3Rjfx0g2+2f/Z0XEM+O4gv1atMsjtmslgU6WVguxml0c61PxGLPPIsWkYh4i2KqV0+fTKlSYIF5gm+FZDFUhQ+G+Zy3turbI9oH98WywIT2Jh4jPqCCNCAxytmmt82Cz7VzFUhGbiBbJnLYWKob6M1FPo31d9rOBCZJYvag15Tj/TWxXGXQuip8NXVtt8tVk4iBCxmTVonZfXNly4r1hY6Myppmoiq0P6OdojK2/j7V591J9dU173I+4+w1zhnJQ9KRRCCGEEGIGDlk9/RCAa8Pf13THjgwtGoUQQgghZuIQ39N4H4Drzew6rBaLNwP4K4eVeQtaNAohhBBCzEEvhDkE3H3XzF4L4G6s9o7d7u4PHErmjWjRKIQQQggxF4foCOPudwG469AynIgWjUIIIYQQM2GH9KTxJHCwRSOzkMtaZXXnmdKX2R8FEiVZzQ6sUHaimivEm1y3gTJ7SL9oz2dIw6zW4nVRqcks/krK0dDOSZv22bFEU9RqJXuyCSrHIQlTxJI+F+8Xvccs74yqsBhTRX2/r4DVP1FMSuq9kWXZvrRN6Qv9j76RYG9nnfdBNnETpXM1rinWZ60WcwVldlJm7b7245PMYzGeYhm5rJnClFikTbrvXZzLcI8X50h5FbX8usxwDw+gZE1tH/O2hUmapH061XwIh1ovtir62VsrIrXzJXLt1Nh+w5yfUd9XLURppv21ZctAOj9NtCRN8s6NgcbPhEsSw6E+aTxu9KRRCCGEEGIWTpf3tBaNQgghhBBzYLh03y9J0KJRCCGEEGIWbKWgPiVo0SiEEEIIMRN2Vp80unsixGAbspnAAggii4rQgwpKyKbp+sZ3sumeXle2plru7I7jZRt8a3k32rJV22Qv2fk9SnMQYQWFiD+Kdd6Q2v2km71L9mKVPA/cPszaK84Ly06gwSzmGDWBRoQIoJy5NLZad01gcv/K9PWhXch80GrHmIuneN8zfWVoi00s9ir0dZ1koTpF6Le/PFqH9g+tUvuldVj9u9hef4y09vfEBo/ZfdZEZ0Oa8bGatWc1NtYPa59b5Bz7TGxtnxj1kKaSdrkT7g2xMMzVZ51Bfq5JxV7ssorIlH1uh/mnOlftLztzj0+kkMZwaO9pPAnoSaMQQgghxCyY1NNCCCGEEKKM2QFfW3bC0KJRCCGEEGIWDs9G8CSgRaMQQgghxFxIPS2EEEIIIaqcVfW02erN5mtbo6i2avvOvlkxHfL3XYyOMaoqqvCIeBNV3QBT9jFLxQobqb5qj7mJfd2wnyK2c0xD6lBUb05Qrq2ViMSukSjBWdpYTs0msFVFm6OkDi6q+cAVoVGNy+wyhzrU2pTZmG2gfqY0KkMTGvtKVi1K7nezpdshK4sPmqY2p7Hr2D1mbUUtHivzbhpPf57k3Wi5maVizVhuN1KvTJ/q24DlltS18c0am5ynNnohRjbPMTvZKW8GKMXF56dyPM1zWpynyGe975TnoqHM2htM4tguWdAyYl8Jlqet65AjxfT1tBBCCCGEaEHqaSGEEEIIUWVxAp+AbogWjUIIIYQQc2B2dvc0CiGEEEKICUg9nSexmKtsaqUbktnm/mjr122KXsTNusMm08rGW5Y3tTFr39hd2t+aXN9qaxgh/zupblhvFEkkm+6Z+KPwP6PcRvJDszAcYieP9MmG66z4pb+2JLrIhtAoRslYRTIBQy+UiWOECkUqgq11fcvWW1WREnnhLLXzCjEO+dRs3npytmHNQqOxdedBhDBVaiIcdq4WW2WTP7XI3IAhH2K7mkkQft1ADNWn3SX9A3E+rYiPaiIIZps5iKZCrGzu45535XjYvNH4pIjORdV6re9XP/6Sz9Fu/NXuy4II7WpU7zWbO5P5oPB5XRE3bkTXlnGe8sMSuM6JhDBCCCGEEKKIvp4WQgghhBBN6OtpIYQQQghRxqSeFkIIIYQQFQz6eloIIYQQQpRxAH5Wv55299VPr9KLCqZBKVZWCdfUU0y9mZzvy2Gq51g0VUW3qfiiipFZ3U2yQiT5DOmrKtnu32hPR+JN0qC30iJ5O4/RtkgM3X2k1ncVtXJNicnUv0k+XcWb7dsS9eoGKvUIUf41K/KW436TtFV3jCmcmeo0uZbEs4kSsWaHNjoHwIg6OFF39tdtEdVuouRtLLumWiWWna19harrc2U35Lef1ntTtbvs56IYznKstm1+C0BNRVx5KwFluIfrMZfMK929p3WoPHnZyLqx8brk7Rg+7j99mmwZB1HvsznYxnNxQu3ekc+lZsV6Bd4GIchGK9PqWxBIvyiNbTb/nFxOl43g6amJEEIIIcRJwxZtPwcpwuwvmtkDZrY0sxv2nXu9mZ03sw+Y2YvC8Ru7Y+fN7HUt5ejraSGEEEKImTiir6d/C8CfB/CP40EzezaAmwF8IYDPA/AuM3tWd/otAF4A4AKA+8zsTnd/f6kQLRqFEEIIIebAjkY97e6/vSputEC9CcAd7v4YgA+Z2XkAz+nOnXf3D3bp7uiu1aJRCCGEEOJYaFdPX2lm94e/b3P32w5Y+tUA7g1/X+iOAcCD+44/t5bZ5EWj7+6VNyHX7OsyFn0DrHHDhlkqlOk3jYdzbMM/31ReObYBh7V5eIgnJw5a5jcKMwHGMrH7ahMK5SzCSjQLNMim5xzFjd21+3ZQW7FS2iSbsm0fvU9bvVhg+tcXibiK5NMs4In2h90Gc4tjLohZHL1YbExSdn9dxmZxf9wrNrfarFrwkTnAd0McjferaHGZS7skNnC1vt8oGIkM45hZWFIBFO8rtC36vpYIDEkQyVjq+iQT8k0Zs4UCa6Ix/nlSaR9WsYrQsQQT+a3Y6y9YX0vEctXPE1IOE+KxNMm96cUlNWFcIhQloZXItGPJnrQ4PvZxYJvCWbApX08/4u435E6a2bsAPJ2cusXdf26T6KaiJ41CCCGEEHNgODT1tLs/f4NkDwG4Nvx9TXcMheNZpJ4WQgghhJgJt0XTz0zcCeBmM7vczK4DcD2AXwNwH4Drzew6M7sMK7HMnbXM9KRRCCGEEGIWDEfhPW1m3wjgHwF4GoD/08ze4+4vcvcHzOydWAlcdgG8xn21scDMXgvgbqz2Ltzu7g/UytGiUQghhBBiJvxo1NM/C+BnM+duBXArOX4XgLumlKNFoxBCCCHEHNjpcoTZaNHYapXFVWYVOz2i/IuUysypE4fzUSlWUGnn1G6HpswqqQCZZdsebxOqtOvUqMyqbkEsAfdfW6KsJsW6XjmrqH1xYxOrMNJ2VWu4CawtMqsXrv7JWVeS+zAnG5XDrLvI1yh1JechUVIKE1VljSRukLqS8UDnnwl9qlmFTWCWpVHpe2DbyP1UFNzU7nLCA5OhLRsV/VUFcwX2Fojq2x8Kb1OIY5u9mYPOyxPezkDfWmGFvlKZVzOF8PR9aNGOr5BnbEdW75r9b00Vzqwr+7mIflbHsmtvRTlmzrT3tBBCCCGEmMBZf9IohBBCCCHqOH2z7aWJFo1CCCGEELNgc75O58jRolEIIYQQYg7saNTTR8WBFo2Htsk/s1GYC266xp+yKbgXlJAN/8lG4GqYxAYOeSu/HEUxD7HcquWdbNLuNvezDeC2vb1OVGmzYpnOraAW220igPV9rdj7Vai2uY03Vzffp4qNGbduHFuo8bDK8dQ22K830Fc23ddsD/vN6TtrP73F5ZetksaN7Yn1V5d1RURCxxURs7DrkjGQEYGNymZiKHa/DigsoeXt7ax/L7Q5FeZEKiKK4X5nxh+8G+fh3tH+3tsa1oRxoZzFdvdRQebdxGYyWDOWxGIHFVTR9IuxeCi16KMZjQ7Rz51NRCgEJgRh83cy5irCwSHOUNch71o7N9ojxnHopP5UKFSxt60dp7aGE2w1TwquJ41CCCGEEKIJqaeFEEIIIUQNPWkUQgghhBAVTOppIYQQQghRR08ahRBCCCFEGTP4FCulE87hLRoPaN/GmKqwS9RaS2J1FBSLg5K6ph7LKRWHg2OlGLNHpEo8VvZiirUesapjyj72v5yakrxXWFaUvonKtlfE7nL1YonWez1FCc2sGfumqNlV1tTRJYVgIdPul7LaPbVvW6VZbNestHprs/GxeljhHvW/ZzZuD32EtF+idCZ9PKGkQCV9Kkufzwb9rNkWc4I1HDs+WEpGBWrGfnJ/nFQhnxQXy+vjLSvJKYk6eG+UZqjDQd82sRiPAdZXNlJXt859EXa/ava2pb5WeetCtNEdlQdwK1uWN7MHZDaUB1Ub9wr45N5Mt9at2QzSz0QyxwzVblR9nwRkIyiEEEIIIZrQ19NCCCGEEKKKhDBCCCGEEKKCXu4thBBCCCEaOLt7Gt1XG2PZqrk7lrMbWvT2SBtsTE42uvabvInQpbYZPtlU3qcnQpdNNmGzNLlN99RCrL+Obv7ldlb9tYkAwfOxR4uvJLaaaGGUJiNUIKKE5W4vqJm+eZpZw9WEAbR/bWBDldv4vb+cKI6h/XQD0n6z/5dMG3QxxpZt3SDO6lcTPKTjnIwbsqG/dt/X144FNYm1oDtJ00jshxjfuyTereHkKJtlGKcLZqmYxLVXjNWGqXH6vEPLDveGWsx1ooRcm5Ys3aiALGfb14+hWO/hcyCWN86yxlBHIjZs72cZBrVcWWyRlEM+/2qfCUMaOs/Ffji+x2ys1e0jGz/rSL2TfkYtTdvGZHYMMDte9nm+bIv3JOFmWEo9LYQQQgghamhPoxBCCCGEqKI9jUIIIYQQooqeNAohhBBCiCIu9bQQQgghhGjhTD9pXKmTKgrf4dgi/jG6blA6ZVTPa0VjweqJXJ89v1ezjutUaAuuQtvI2oqW06jSJrZziRK4pBaP/7PxsaqZKskLsaZZh3tI7LXSNssrj6tlUlVcUCf2asFMO+w91qjcrth8tdKqREzqQK5L8xwrLKNie2BJVIykv7cqS6OyOFFlVsbQ/nxSNWmYbli/WI5VxkMcIYZE9bvOPBae/ouMYphY5x1YeTuEs85nSRTHUY1aLLPyRghqz8ZsBJPCyZsu2H21cftQdfCEpyhOlL4shpotK8+7UTlbe8vGXrkvTP5sydn/taTN5OMsCcs7Z39IlNutcbDPcDrXMDV37rO+2HzjNxEkFo/h/N5jF/MZHSNLzP+k0czeDOC/BXARwO8BeJW7/1F37vUAXo1VA/4td7+7O34jgB/GapHxY+7+/bVyTs8zUyGEEEKIE4XBsWj6OSD3APgid/8SAL8D4PUAYGbPBnAzgC8EcCOAHzWzLTPbAvAWAC8G8GwAL++uLaJFoxBCCCHEDDi6fY0NPwcqx/3/ch/exnwvgGu6328CcIe7P+buHwJwHsBzup/z7v5Bd78I4I7u2iJaNAohhBBCzMRRLBr38dcA/EL3+9UAHgznLnTHcseLSAgjhBBCCDETExaEV5rZ/eHv29z9tv4PM3sXgKeTdLe4+4+K9KQAACAASURBVM9119wCYBfAT24YbpGNFo1MmNI/tEysA7e3Sdrxxtu4WdeILRYve/qmaC6oWYx+38SKiKYxLqKhlmW9HRPdDD5dnJGWN7bFohuSiZiAxrgkogPwNjjIJvbafWCbr5N73KeP+/mprSGxPqvAyl5sj4dTavk3Fnr4chclSjZdyT0mtmppHGORVyvMti+WXRIAObEuK4RJsslbC8ZyWslu9p+YT+w/fIyEvjv0Q/7BUbWoK123gTvZMN9mxu5wPsTA7AqbSfrKeC5aPjb+HHAmYlqM23mKsLIEq79dth7PVHBUK6ck/sykL4lsctam67Ht5FhFBFiJoZ8v42Vs6NbEqrzvhjY9wDhunbOPj0lPER9x9xtyJ939+cWSzL4VwDcA+DpfT9wPAbg2XHZNdwyF41n09bQQQgghxAw4gKUvmn4OQqeE/k4AL3X3R8OpOwHcbGaXm9l1AK4H8GsA7gNwvZldZ2aXYSWWubNWjr6eFkIIIYSYiSN6T+OPALgcwD3dq8Xudfe/7u4PmNk7Abwfq6+tX+O+esmRmb0WwN1YvXLndnd/oFaIFo1CCCGEEDNxFItGd/9ThXO3AriVHL8LwF1TytGiUQghhBBiFgzuZ9gRRgghhBBC1HEAyzNrI2gG29rKKDo7BdOBbczGCrGo3FurudoVU30+THFWiyFRDRYkn6kCt6IEJkqxXmW7kYo4abNVvDlLrhKWiNmYhWPfjjnLO6IcXWfYHM86n3FfqCnyEojCkqmHmdLViM1b1VIxqmj79AWLxhyszVlbUKu1qDqt1JsryYl6k1pFjtMk7WP92E0qFgpvm0SHfhz/px76dnMdNrAs7WOfpPwc5ojxGyGycx95U0FiHVogmWN7aziiLE3tPMc2eUk/JuWwdg6FNMUa40le5MA+J2ryemKDx8trmzuTepH+TFXqFvvcKp9oGbluU95XSrEl1pMV9f2QX0Z9vo6nrFZutclN22WsbF/f47Kam1pSEqbY9y6Yyv0EcKa9p4UQQgghRAOOAyujTxJaNAohhBBCzIL2NAohhBBCiAq99/RpQYtGIYQQQoiZOLNPGs0Mi+1zwbKMiTZq9j7ku/2svdbYMpBuxC6WtyYVLRTST7ARHPJcBMvE3fFG8+XO2i6OWzwtR2nW1xPB0QT4Znh6YVM+6f2oCZuIoKZqq5YvO27mZgIMJohotWnLxsTEDRM2pY/OVQQ+sX2bbQ0rYg1mU1kktiNiDFv58mibrGNgVogsfVXglAgQuv4V25sJT3wsVEiz7PIMZTPxx7oflu8/Ox/vB7NTTegHARFbZNunF9SQOjqI8GErzFmJT9wq9igCbBXoxXr36TexZa3a362DmJDnKh8uMuFlD5ft7IzOt8598XMyFcq05bMW9PE2oY6wg4VhZs7v+xUVZY7n0ymWgKVxnLdCHNuTluK2RJ86QRx5TJx0o8Mp6EmjEEIIIcRMnNknjUIIIYQQog2HST0thBBCCCHqSAgjhBBCCCHK+CSZxIlHi0YhhBBCiBnQK3eAtbJyb4eci9ZU4+/xN1H/RgalVLSZ8rGqt55PXrUalYbMSipJQ+q4tpDL1JUo9hhcnVhRFRJVHLsPxbSIVoHltDWrqIGqdWB7OaXr9p3ofmm38ivZpNWU7cxesWq1ica+S9LUbDGT9uvd+CrKyL4/m4W0sc91x6mtGsE9WjSW1efM6o+N9zRtr9CNYzav8s+1Weu8xOc00gdqNnhJno0fKKw/03mwlk2tDotR3mzuG96MkFHkrxW143jp2KZ2jGiuF0ubszwdKKnco+XfbhzHXX3OlQfBQT7r6Dyf7VPEhrF/g8AEWz2qYCb3K6rB+Tge99MFa6tQH9qHWsfQlPt9TEgII4QQQgghqri+nhZCCCGEECUchj2pp4UQQgghRA09aRRCCCGEEFXOrBDG3eF7e8OG2eXFtTVe3eqoW2ozQUNGPNO8kbhV8BA2zC62e/u/aJfWlRttptgm7LiRnAkQus3HiYAgsRAbCyuGNGRDMNuYXIVtDs5tLid5DvEyq8i9mlUkoSKQarVlm2IJ2MfZbGcZ0yYiCZKabOxOxQR9vCGfLh4j7V1tx2r7lO2+mq0k++vDf42jKIYJv6jgq78u2K+lDUks5gqWZjnhTUng0iwwAb83VChEhGapNdpYREHHbJK+r+PW+Dy5LpfPUNy58VyTnN9iNoukraIgiQgq1ulJ3DHerIipQE38QmwWWwUzzB6xJnJLMxiP7R7WD+N1rGw2b0zpu32ZUcDZbnMZ72tvD0zuV8ZWdGi/OB8ux/Nub1mZn6vT/FZp2uqSfh6fwMWZXrkjhBBCCCFqOKSeFkIIIYQQDWhPoxBCCCGEqLKnJ41CCCGEEKKEw/T1tBBCCCGEqHCmhTCdenrZqYs9qut666BEzEYs1CpKqFSJWLK7GluS5ZSjVH3FFLy9Rdr2ullSG7Q2dV6fJlGdBnVZXzK1IzygJRmFqnVr9ndjlWi9mLwqelCVZmhV+rb3j30q+P3XoVIvMspjf++V8TnVM2u2QZk7QRk5pI2qzL5ei3ie2KElinWiVmaQ+sS3AKBXzi/Lqt5BPR6U9vFtC3Yur1pl+aSq3LJilinb+zkrN3szlTa1I6RuaBUl/tAGY+XsviDG8VTua5p8nKY07tK3IJTfSlDtN+S64rzCqCihaypjb3ULJfaIjGRsk7c/sPklmVeIsph+Jibk2ydnkcfm2HVfqKj4Kwz5ZKx1h2OhLYY3EdTGRa1PDX0g3KRKnlNsE4+So9jTaGZvAnATgCWAjwL4Vnf/T7ZaiPwwgJcAeLQ7/utdmlcC+J4ui7/r7m+rlXN6XlMuhBBCCHHCcFjTzwF5s7t/ibt/KYCfB/C93fEXA7i++/k2AG8FADP7HABvAPBcAM8B8AYzu6JWiBaNQgghhBAz4Fg9dG75OVA57p8Mf35WVzSwevr4dl9xL4CnmNlVAF4E4B53/5i7fxzAPQBurJWjPY1CCCGEEDPR6oEB4Eozuz/8fZu739aa2MxuBfAKAJ8A8Oe6w1cDeDBcdqE7ljteRItGIYQQQogZcAeW7erpR9z9htxJM3sXgKeTU7e4+8+5+y0AbjGz1wN4LVZfPx8qkxeNy9299QbfuLG2YK20SujJdUDYUFxZhifn2TPcc2NbrKr11w4RmZAN9AmDWKVi7bXshQqbCB5iGmItSCyeqBVb1bqsbJOH5Uq0EDdx0w34cWM3xgKWXoBQ3xQ9vse+JBvNabAbWE/GuJkVG7NWDMeWnT1ePOZEyLCIG7NL/SHew8Z+U7uHNSFRKDCc3x2drYlV1nZoJO9Qr2Xox32JXrGX5BAby3g/ibUgIxHyDXZpUVgxFs+U7CyBILhh5WVEXLU8h+vYJv+aUI2J4Ii9Zs7+NZd2f3qWDxPmUJvUiniBCi+IIJKKP0iag4tDVumT/lyoQ/XzK7YP6T/9HDylf/iyt+/kop9hzFLb2rKAiaVJ01v/S8xglE+NtQ1lHH+VNCf0LdqHFZa7P7/x0p8EcBdWi8aHAFwbzl3THXsIwPP2Hf83tYy1p1EIIYQQYibc234OgpldH/68CcB/7H6/E8ArbMVXAviEuz8M4G4ALzSzKzoBzAu7Y0X09bQQQgghxEwc0Xsav9/M/jRWr9z5CIC/3h2/C6vX7ZzH6pU7rwIAd/9Y95qe+7rrvs/dP1YrRItGIYQQQogZcOBIHGHc/S9kjjuA12TO3Q7g9inlaNEohBBCCDEHDuy1q6dPPJstGvuNrpVnrnSTbdxQi/Em9mRTMNnkTsvpNw9H0cZWsuu3+4e5jrS+lX6dJxWeEJY7PO/1xvewpbQXfdScEMhm5pimd91gApa6G8hYtLCIQoWt7S6/IMAg2VRFLTVBTasLTZ83cWGYAhO9JCIJ5uSyN76OkeSDXrA1Fu5Qd6WYD3OwIW2WbIYviDKSvNm9iX2hUSjEhEBJmtp9J8KnUVyZ9FGUYF6Yn8g9BNb1Se5NLxgh9cqKG0p1ZHPb6sQ4DYPMY5ukaRWLpeWMxTO1evVtycRBrJ1zsPlrGDdUADZFWNML9SruN5X5aRh/y7EwLhnPFSEonU/G2rRm0vsxrmMv6APWc0fVWYblH9tsEKYyhyMuQmJzA/t8owLWNBE/foysnjQedxSHh540CiGEEELMhBaNQgghhBCiyhEJYY4ELRqFEEIIIebgEF6nc5LQolEIIYQQYgYck2wETzxaNAohhBBCzMSZXTS6e6J0SyzUuuOplRFTL4bW6xWoQV232N4m5RIlKzu/5ApLqvAitoc1VaEV7NKqlm3U5ozZY7X3rkFBuDe20orRsCfjUV3NbLFoeY3nE7V3X9d43/p2zNxXZj9Gy2PqRHK+RqK0rylu+zRdvNk69GpTpmAmSsxEGRplvb3KP6rhS15aOXu7vTaVaK88jnEz9euiZrlJylhcflnIgKi0eyUns7QLISRxs/HSqT/p/c/lsyjPIQfBSFvF9u1V4+y6SH8fcnMwhnlla5Sm+gaKoM733cbv0ti4IG8GqM27tTFXVEPXlOuJQreb5y6O5ch+wDc69PfTyZxutaGSqMKJ9WKjap7OCiGfksVljKNs25iyVoCH+aK3WCXWip6Ipyt9sqCQjwO53X70eFh5Tx93FIeHnjQKIYQQQszESfXE3gQtGoUQQgghZuIUrRm1aBRCCCGEmIszu6dRCCGEEEK04Wf6lTvebfjtN54ymyAbiyDi+SQ7svE22hq1RrzOp91vadFZuiXij/6/A2Fj7SJs5l3urWJLxA2L3n4sbNwmIomk/l3yxfa6MsNm3ppdFRGjsLal9QosKiITEJENsw2jcURxEcZ9haatbTQnG8RZOydp+vvEhBWR2oZ3ItzZH0MpjlFcrF9k/iu6Pk9EGxPK6fNf7vLx2bN3cSy2SOjacm9nPdbMegFGWQzGrP6ciABQsZzkdqCh7NKG/yjU2B2Xw4RLTJyXYxAEJgIVFgerF7MQJWVkRFN9my7ZXFvru8zylQmuauI0ZiFKrDQplXmFWRQye82c7SqIHehwv5jVX8ZyshRj7LtU2ERsM1vnvjSf8RwScxkEiMTWECiL6VrtRwGsxw212gxzBLGCZHN5EkcvdKxZluaEYScIeU8LIYQQQogqk/ziTzhaNAohhBBCzIBeuSOEEEIIIZo4u3sahRBCCCFEM2yf8aWKFo1CCCGEEDPg0JPGgapqNznRK5O3RsdqKusEouyqpWEKy17MlNildbFvBVVztJfqr03tmFa/R1u1wUqq8nImplisqZ4jvTqPtl8l7XJnrGxLGOyhiBJxgr3WKK5ceZU0zdcRVWEU1FFlO1H+xRh7RT+tQ20E1SyuBqusjE1X6R7HYqhl11iZnCp0x8p/agVJVKC9YnqVfpzP/jIAcFV9Rl095L0cK7PTcvp+Oq5XPDaMz9q4CGO7qAavzTlxXLCXOlTfXkDs6Lo6pG90KM8h1MaTxUCm7ap9K1WKl+3vmKUeswNlNqdMeZzUoe/jRFEdSe5r6Y0QTNmfnGfK7dBmXd9NroppFuMxwObdddxxDiBlhn5ml5UnJmbZ2b+VoW7TGdI0Cq1r1oROMrKCMjtbTmtAR4k79vSkUQghhBBC1Gh8tnJJoEWjEEIIIcQMrL6e1pNGIYQQQghRwmUjKIQQQgghGtCTRmK3x6B2ROEYEx1ESoKJ+kZhtvG2vDk9bu4vlxOsmZiQobeHIrZXMU4nbVGzcKqKhhrvTU2UwOwRB8uovXHcEdYWTEyR3dRc23zdp+83ikz4bxzbnM/KThz4dnu7r3Wa3oYyK4go3AcmUEnEC1Fk0pVDN6cvxgIEzwip1vexYqlIzlHRS7ifvTCDWtWF32nfrvXTCqxejGV1XPWCo3H7JGKTvf3lpkIQ69tibyyws4zwpGaTNlzX97lYttds/bo5lrn3TdicP9QhlNffz0H4hzAushkV7GRDo8QWKY3ZWN4gqInHapZ4vVAoiiR3xnaxraI8Jp5aXtyh5/vbngiFmIinMoesjxErv4wwZOgXGH8OpPUei0iTNKXP8ERwROYsEm8CEa/R8jJ5nhQcp+vl3ifTqFEIIYQQ4lLHgeWeN/0cBmb2HWbmZnZl97eZ2T80s/Nm9l4z+7Jw7SvN7He7n1e25K+vp4UQQgghZuKoXu5tZtcCeCGA3w+HXwzg+u7nuQDeCuC5ZvY5AN4A4AasHoi+28zudPePl8rQk0YhhBBCiBlw9+afQ+AfAPhOrBaBPTcBeLuvuBfAU8zsKgAvAnCPu3+sWyjeA+DGWgF60iiEEEIIMRMT3tN4pZndH/6+zd1va0loZjcBeMjdf3OfPuNqAA+Gvy90x3LHi2jRKIQQQggxE8v2p4iPuPsNuZNm9i4ATyenbgHw3Vh9NT0rExeNDl96UFQRWzWiLAaC8jRRDfbKtbXaLauK6iHqqGZbOo8qtcJ1FTUbszFL05ftpZh9W8mSiinyYhqq8I5xE7sqVsfUJm98XX/zEuvF8Htv1casELei6puo9GowF7RBvZmxKBx+j1Z1u63WhOO+y9T1uTalY6Ri7UXjKLRRco8Hm0BufTbYybHxFeqwdfll6bl9aXp1cKKm7G3tPLbzXhIXkCo52ZhdbI0tE1ldakpWpqge+mRUlG9Fq7rCWwCW5B4E9ThTJkdFtC87NW5uNxCzbxsCD21K4o7lsDqusym/GaHV5pO2U5wPwvFBVR/ue9F2lNQ1HmcxOq1DWTEcGdTgsX+ReSX3Joz959M3a1TmGjrnj+0+hzkkqWvFonZ3rNin97iiPKZqcGK1SfNmcyMbS8jUh9lv7s+vkOdJ4rBeuePuz2fHzeyLAVwHoH/KeA2AXzez5wB4CMC14fJrumMPAXjevuP/phaD9jQKIYQQQsyAO7C3500/m5fh73P3P+Huz3T3Z2L1VfOXufsfALgTwCs6FfVXAviEuz8M4G4ALzSzK8zsCqyeUt5dK0tfTwshhBBCzETrez5n4i4ALwFwHsCjAF4FAO7+MTN7E4D7uuu+z90/VstMi0YhhBBCiBlw9yl7Gg+rzGeG3x3AazLX3Q7g9il5a9EohBBCCDETx/yk8VCZuGg02MKG/e6J9dmy32hfs2cL53vhBNlYCwC+220gjwIWJkaobM0c0uc2Wu+PMZa3HFuo1UQSbNNrcn5IH8QEg2VS3DQ+jjumGSwM98YbgeNm+UHAkvvfDtlHbI12TLHsPc9bIaY2biQeIlAwskm7Zu+3yf1K6sPavLDxPcbD7BWj3Z7tFmz7Yv+I+ZB7OwgZlnyTezPkHi86IcyC2D6uCmWKJNJXiD0io2Yt2J/P5kPsyWK7jK6LZbN2brQ1TMbHubL1GxMBGBGGMeFAIogYLNTKQg8qxCNzaO4eU1vR/XXJlXMx1GExvndr8SOxVU3EKGvrPTZvMRvP3q6P5b0//+HY6Eg4x4ScWPcVOudX5k1mSVmlyzNxDGGilUTYVZ6f+msXjSuApC32xp9R6edbW55J/mT8sXamMTSKuI6TM7xoFEIIIYQQTfjp8p7WolEIIYQQYgYcjuXeBo9fTyhaNAohhBBCzIEfnff0UaBFoxBCCCHETBzWy71PAlo0CiGEEELMgOMsC2Hcsbezy5XQvQKusqJO1Gy9cnLBlaM9y91oqTRWR9UskdaqwqiyYrZrqzSJqpDEVlPhDcrZRCE5JqlLn/cuUeBWFGF7F8d+S1uXjW3XcvlQ9SKLkVpKxXYex9ErGZc7u+FYzSZud3QdVVQPQYQYYp4F5TFq15H8k3tIFdXjNndyb2pqwHg/+3y2ggXhYPsYQ9wZt9lie5vGtj5WsakkaQdLvKhe7C3LwrgZVM8ZG0QjSt9+7ojRLHd2unzKe4LiWxtY32VjIO2747FPxwXLp9K3qSKb2KkmCl3SbrV5oDTOWfvl30rRzUWVcdHnmbbp2GKUqZnjscW5sRVd7UO2V2bjsXCsS9Pnt/qDfCYQdf4U+9ohNtbOzKqwouDOXTukqdjArinfr/RzYvV7Mq/0to+Zt1qwsn13PO8M+U1QMg/z5S77DKl9Xpzw/YJ+lheNQgghhBCikaN/ufecaNEohBBCCDEDDkg9LYQQQgghKkg9LYQQQgghWjizexp9ucTOpz8zbGJmm8Yjy7DxNtmcPOTHBCrlzbO5jfW5vHN59lZHbEPtlHioVR0TwtQ2dg+WgMweigsVSmWzzcHp/WKilnHbJmkwbp/a/fDleKN5X3aufVjsW5eRvCv7RPqN+knfI6KWTQa0cSPKIkz4NYQVhAo5W81SGnq+VeCTWHKVBRODpRmJl2+GH9tepmnW5/tN+bth3tjrrOFyY7Lvn7YYW+K1xpimGbd965zTkn9PSZiUO8+EOQcpb5HUdTwWNxEYxPmrv3dbl60FWSAisP4eplZ1oWxm+dn3SYvzSt8+0U6vTZjC+lQNJtCsz/Nt51PB6FgckqYhnxnks6HWj23BRC9lsRzLkwpKK/T1XpI+WcsnN8ecHFyv3BFCCCGEEGXcT+pidjO0aBRCCCGEmAntaRRCCCGEEGVc3tNCCCGEEKLC2XaEEUIIIYQQzSz9jD5pXO4tcfFTnxn+jhZEg8IpqNmiKrOk1o2bRJnCt6YO5krEmno6n0/ebm9ch1bVHLf2GlsG7u2M1Whb21ylXlIhlxR1+9Mw9WKprizueJ4qNaPFXLN93TqeQYFZUlJm0vf2WKVrS2X30HhjPNEGjqXfKqgAQ1qmIIxWdbT9JrRLiZ1HV75su4+ty+MKybLl29Zlq7qeu/wcve6xT/0xgLRfPO7JjweQ2p314yGOgbScc8m/AFc97/7xxVF5rWOpXv/yuOnbcrEV7Pb2Dkc9PeX8/usSKz8SW61eMc3+tDH9ucvHtphJPmT+if2PxcDGwNZ22dqzjy3GzRS6sS+xsof8yDidMqexGGufEywNo69Pba4upW2Jlx0riT5ySuj1WsBH18a3X7DP6ESdfxKRjaAQQgghhKjhcC0ahRBCCCFEHb2nUQghhBBClHFgb4JBwElHi0YhhBBCiBlwOPysCmH2HtvFH/7efx42qG4/fr0BlW2KjrCN32zza4RtLu432e4+xi2w9ucd8RDD3k6/kbrd6m8q6Wbd8QbpvYvlTcZs43bc7G2FNnfS3klsW2MhTG0j+ZA202brDfTrY32eJTFSLv+ccGeIu6sD61s5mH1dzYqNWo1t2ehYrA/rX63tG0UATKDRE0UmNYswLrwYH/vkQ58EAPyXC48Nx/Y+Q8bSzjjtZZ+zng/OPWnVpy5/8tr/cRlEXp/83UcBANufva7DEz7v8lV5O0EY17Xz9hP4Zvdzj1ulP3f5WEAX22Tn0ZWl3SIIalgaRsynb8d4LI7jPvaaHWhsCzbOh7EU7ltpvMf07F6z+Tkr+OvijHVgVqbbj1u1X7xfLM849/X1iTHWBTXks4PUkcXDiGn7Mdn3I2DdL2pzROvnRavVY8yTiaJivZZMMBnmg75Nc23BRFPM/o/GE+9dN55a+3NundCfj32FiWaoEGa7nObYOWVCmLLUSwghhBBCbIwvvennIJjZG83sITN7T/fzknDu9WZ23sw+YGYvCsdv7I6dN7PXtZSjr6eFEEIIIWbBj/I9jf/A3X8wHjCzZwO4GcAXAvg8AO8ys2d1p98C4AUALgC4z8zudPf3lwrQolEIIYQQYgb8+L+evgnAHe7+GIAPmdl5AM/pzp139w8CgJnd0V1bXDTq62khhBBCiDnw1R7olh8AV5rZ/eHn2yaW9loze6+Z3W5mV3THrgbwYLjmQncsd7yInjQKIYQQQszCJPX0I+5+Q+6kmb0LwNPJqVsAvBXAm7Cyu34TgL8P4K9Ni7XOpEXjhcuegddf8yPY7SzN9nZ2hnNVC75ekRcazzqlVFQ8LUL6JbHx6vPfesrW6LrI1tbYLoyp4VqtlSILCyrIQmeoWSvVbLF4nmXbw5ramcbW1YG9S6rVPgsAtrr7aKF99jorSaburVpKkbaNeS+7vBeXBbUfSbMg9n25rwv69LGc0nW5fBaPI2WSNFQV/sRx2uXe2A7Mg2p3Qdo+aQvqgDg++MSveBIA4PHPe8I4AVJLr/3xXOys+oB1X9oL9ocxbZ//bjh/8Y9Xim3Wn3eJjSKwbpclGWuJxdxTx226S+YvBrMbjPNLYkG3tTVKM9gRhvvB5qdWcv2nVIdWu89IjJdbx43Vtq2Wd6xNWd5pmrKauS+bqX8jse37+Sl+lvV9KWfrWJqXWufabGyPy38kb8V+tr1+m0AfZ5wjavR13CpZmwZyfXSYg7fGbyKo2VCyexzr0Me4mDA+di9G+8mvaU43Jw6+RtkoL/fnt1xnZv8EwM93fz4E4Npw+pruGArHs+jraSGEEEKIOfDVArnl5yCY2VXhz28E8Fvd73cCuNnMLjez6wBcD+DXANwH4Hozu87MLsNKLHNnrRx9PS2EEEIIMQtH5j39A2b2pVg93PwwgP8eANz9ATN7J1YCl10Ar3H3PQAws9cCuBvAFoDb3f2BWiFaNAohhBBCzMRROMK4+7cUzt0K4FZy/C4Ad00pR4tGIYQQQogZcPeqY9elhLm3PzY1s08B+MB84VwyXAngkeMO4oSgtlihdlijtlihdlijtlihdlgzd1t8vrs/bcb8mzCzX8Sqri084u43zhnPQZm6aLy/JAc/K6gd1qgtVqgd1qgtVqgd1qgtVqgd1qgtLk2knhZCCCGEEFW0aBRCCCGEEFWmLhpvmyWKSw+1wxq1xQq1wxq1xQq1wxq1xQq1wxq1xSXIpD2NQgghhBDibKKvp4UQQgghRBUtGoUQQgghRJWmRaOZ3WhmHzCz82b2urmDOim01NvM/pKZvd/MHjCz/+OoYzwKzOx2M/uomf1W5vxfNbP3mtn7zOzfm9mfOeoYj4KGdniymf1rM/vNrj+86qhjPCrM7Foz++XQ9/924dqvMLNdfvYBiAAABoJJREFUM/umo4zxuDCzx5nZr4V+8L8cd0xHQWu9z8KcCQBmtmVmv2FmP0/OfXvXBu81s18ys88/jhiPgko7PKObR36ja4uXHEeMop3qnkYz2wLwOwBeAOACVibXL3f3988f3vHRUm8zux7AOwF8rbt/3Mz+hLt/9FgCnhEz+28AfBrA2939i8j5rwbw210bvBjAG939uUcd59w0tMN3A3iyu3+XmT0NqxfhP93dLx5xqLNjZlcBuMrdf93MPhvAuwG8bP+80I2jewD8MVbepj999NEeLWZmAD7L3T9tZtsA/h2Av+3u9x5zaLPSUu+zMmcCq4UhgBsAPMndv2HfuT8H4Ffd/VEz+x8APM/d//JxxDk3lXa4DcBvuPtbzezZAO5y92ceQ5iikZYnjc8BcN7dP9h9+N0B4KZ5wzoRtNT7vwPwFnf/OACc1snP3X8FwMcK5/993wYA7gVwzZEEdsTU2gEro/jP7j48n9hdu3sUsR017v6wu/969/unAPw2gKvJpX8TwL8EcCrHBsNXfLr7c7v7OfWKw8Z6n4k508yuAfD1AH6MnXf3X3b3R7s/T+2cWWsHrPrHk7rfnwzgPx1FXGJzWhaNVwN4MPx9AfzD4bTRUu9nAXiWmf2/ZnavmZ1o+58j4tUAfuG4gzgmfgTAF2A18b0Pq6cs8zvVHzNm9kwAfxbAr+47fjWAbwTw1qOP6njpvpJ7D1aL5Xvc/VdraU4DDfU+K3PmDwH4TgAt4/80z5m1dngjgG82swsA7sLqP5niBCMhzME4B+B6AM8D8HIA/8TMnnKsER0j3VcurwbwXccdyzHxIgDvAfB5AL4UwI+Y2ZPKSS5tzOyJWD1J/Dvu/sl9p38IwHedhYXzftx9z92/FKsnSM8xs9F2htNIQ71P/ZxpZt8A4KPu/u6Ga78Zq69u3zx7YEdMYzu8HMCPu/s1AF4C4CfMTOuSE0zLzXkIwLXh72u6Y6edlnpfAHCnu++4+4ew2gN5/RHFd6Iwsy/B6iuIm9z9D487nmPiVQB+pvua7jyADwH4r445ptno9q39SwA/6e4/Qy65AcAdZvZhAN8E4EfN7GVHGOKx4+5/BOCXAZzWJ2qUQr3Pwpz5NQBe2vX7OwB8rZm9Y/9FZvZ8ALcAeKm7P3a0IR4JLe3waqz2uMLd/wOAxwG48iiDFNNoWTTeB+B6M7vOzC4DcDOAO+cN60TQUu9/hdX/mGFmV2L11csHjzLIk4CZPQPAzwD4Fnf/neOO5xj5fQBfBwBm9rkA/jROaX/o9m3+U6wEUP8bu8bdr3P3Z3Yb238awN9w9391hGEeC2b2tP7pmZk9Hisx3X883qjmp7Hep37OdPfXu/s1Xb+/GcD/7e7fHK8xsz8L4B9jtWA8lfs6W9oB6Zz5BVgtGv/zkQYqJnGudoG775rZawHcDWALKwXkA7NHdszk6m1m3wfgfne/szv3QjN7P4A9AP/zaXzKZmb/HKuJ/spu78kbsNrkDnf/3wF8L4CnYvUkCQB23f2G44l2Phra4U0AftzM3gfAsPpq9pFjCnduvgbAtwB4X7eHDQC+G8AzgKE9zipXAXhbpxxfAHinu49eN3IKofU+i3MmY187vBkrsdxPdXPm77v7S48zvqNiXzt8B1ZbFP5HrEQx3+qyqTvRyEZQCCGEEEJU0YZTIYQQQghRRYtGIYQQQghRRYtGIYQQQghRRYtGIYQQQghRRYtGIYQQQghRRYtGIcShYWZPNbP3dD9/YGYPdb9/2sx+9LjjE0IIsTl65Y4QYhbM7I0APu3uP3jcsQghhDg4etIohJgdM3uemf189/sbzextZvb/mNlHzOzPm9kPmNn7zOwXO3tCmNmXm9m/NbN3m9ndZnbV8dZCCCHONlo0CiGOgz8J4GsBvBTAOwD8srt/MYDPAPj6buH4jwB8k7t/OYDbAdx6XMEKIYRosBEUQogZ+AV33+ksF7cA/GJ3/H0AnomVb/cXAbins1nbAvDwMcQphBCiQ4tGIcRx8BgAuPvSzHaC3+wSq3nJADzg7l91XAEKIYRI0dfTQoiTyAcAPM3MvgoAzGzbzL7wmGMSQogzjRaNQogTh7tfBPBNAP5XM/tNAO8B8NXHG5UQQpxt9ModIYQQQghRRU8ahRBCCCFEFS0ahRBCCCFEFS0ahRBCCCFEFS0ahRBCCCFEFS0ahRBCCCFEFS0ahRBCCCFEFS0ahRBCCCFElf8fkt0+OvU7tykAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['96' '87']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['9' '24']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAHwCAYAAABkJOM0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deZhtZ1kn7N9DwhAMJECOMQlIQECGNIMeZsUIOIAoYEPERglIm6ZbQIYWcGhpcYJuPmZQ06AERaYQZBRBJIDIlEAwBlAiYyDDAQIkMiY83x9rVVJUqs6penOq9qnkvq+rrtrrXcN+1t6rdv32u9+1dnV3AACAjbvKogsAAIDtSpgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEzDFURV/WlV/a9F17HdVdUZVXX0ouu4PKrq5Kr6rxtc55Ljp6qOrqqzNqGuq1fVR6rqsL297b1tsx6DK4qqelRVPW3RdcC+QJiGbaCqPlVVX6+qC6rqy1X1T1X1iKq65G+4ux/R3b+/yDrXq6oOq6oXVdXZ8z59rKp+r6q+Z5Pv939X1V/tbpnuvlV3nzy4/ftW1WlV9dWq+kJV/UNV3Wio2E0yPwbfrqoLl/08YYuOn+OSvLO7z55reXFVdVXdYVl9N6mqy/UFCPM+dlXdcQPrdFXd5PLc776iqh5aVf+4xryTq+ob8/P+hao6af57/K1lx8M3quriZdNnzOsuf4z+X5IHV9X3btV+wb5KmIbt42e7+1pJbpjkqUmemORFiy1p46rquknek+SAJHee9+knkhyc5AcWWdvlMYeMlyR5fJKDktwoyfOTXLzIutbwiu4+cNnP/9mi+31Ekr9c0falJH+wt+6gqirJQ+btPmRvbXdfVVX7D6z2yO4+MMlNkhyY5Ond/UdLx0Om5+k9y46PW63cQHd/I8nf5krwGMOeCNOwzXT3V7r7dUl+IcmxVXVUckkv3x/Mtw+pqjfMvdhfqqp3LfViV9XhVfXqqtpVVZ+sqkcvbbuq7lBV75nXO7uqnldVV5vnVVU9s6rOm3teT19231evqqdX1Weq6tx5yMABa+zC45JckOSXuvtT8z59trt/vbv/ed7eXarqA1X1lfn3XZbV+Kmquuey6Ut6m6vqyLn37Ni5li9U1W/P8346yW8l+YW5t+3DqxW3fPvztl9ZVS+Ze9DPqKqda+zXbZN8srvf1pMLuvvV3f2ZZY/Rs6rq8/PPs6rq6vO8y/QkLu8FnJ/b51fVG+c63ldVP7Bs2Z+oqXf/K1X1vCS1Ro1rWn78rDJvT8fMKfMxcW5VPWONbXx/khsned+KWSckuXVV/dhu7vt183F8ZlX96h525UeTHJbk0UketHT8ztu6SVW9Y36cvlBVr5jb3zkv8uH52PiFZes8fj7mz66qhy1rf3FVvaCq/nZe591V9X3z83r+/HzcbtnyT6qqf5+fv49U1f3X2oE9HCtHV9VZVfXEqjonyV/s4fFYU3d/OcnfZDp2R5yc5GdG7x+uKIRp2Ka6+/1JzsoUHlZ6/DxvR5JDM4XIrilQvz7Jh5MckeQeSR5TVT81r3dxkscmOSTJnef5/2Oe95NJ7pbkZpl6Xo9J8sV53lPn9ttm6u06IsnvrlH6PZOc1N3fWW1mTT3Xb0zynCTXS/KMJG+squut/Whcxo8k+cG5/t+tqlt095uT/FEu7ZW9zTq39XNJXp6p5/x1SZ63xnIfTHLz+Q3Hj1fVgSvm/3aSO2V6jG6T5A5JfmcD+/SgJL+X5DpJzkzyh8n0xinJSfO2Dkny70nuuoHt7tY6jplnJ3l2d1870ycLr1xjU/8pySe6+6IV7V/L9Lz84RrrvTzTsXx4kgck+aOquvtuSj52rnepjp9dNu/3k7wl02N4/STPTZLuvts8/zbzsfGKefr7Mh3rRyR5eJLnV9V1lm3vmFz6uH8z0ycuH5ynT8x07C7590x/qwdleh7/qtYeO76nY+X7klw306dUx639UOze/Df185mOpxEfneuDKzVhGra3z2f6p7rStzP1zt2wu7/d3e/q7k5y+yQ7uvsp3f2t7v5EprGPD0qS7j61u9/b3RfNvcZ/luTHlm3zWklunqS6+6PdfXZVVaZ/6I/t7i919wWZwtGD1qj5eknO3s0+/UySj3f3X851vCzJx/LdoWhPfq+7v97dH84UAi/PP/x/7O43dffFmYYorLqt+bE8OlPwemWSL8y9l0uh+sFJntLd53X3rkyB6pc3UMdruvv9cxh9aS7tTbx3kjO6+8Tu/naSZyU5Zw/bOqamTx+Wfg7fzbK7PWYyHRc3qapDuvvC7n7vGts5ONMnEqv5syTfX1X3Wt5YVTfI9Mbgid39je4+LckLs8bQgqq6ZpIHJvnr+bE4ccWy384UQA+ft7fquOIVyz9l/ht6U5ILM71JW/Ka+W/mG0lek+Qb3f2S+Vh5RZJLeqa7+1Xd/fnu/s4c1j+eKSSvZk/HyneSPLm7v9ndX9/DPqzmOVX1lSRfyBT8HzWwjWR6Pg8aXBeuMIRp2N6OyDQ2dKX/m6m36S1V9YmqetLcfsMkhy8PUpl6rQ9Nkqq6WU3DQ86pqq9mCsWHJEl3/0OmXtnnJzmvqo6vqmtn6v2+ZpJTl23zzXP7ar6YKeiv5fAkn17R9ul5X9dreZj8WqZxoaNWbusatcY41fmNyDHdvSNTL+TdMvUyJpfdr0/PbaN1LO3T4Uk+u6yGXj69hld298HLfj6/m2V3e8xk6rG9WZKP1TQk5z5rbOf8TG/GLqO7v5mp13jlCZCHJ1l6g7Zkd8fC/ZNclORN8/RLk9yrqpaOxSdkGgLz/pqG7PzKGttZ8sUVPekrj6Vzl93++irTlyxbVQ+p6eTUpcfwqMx/W6vY07Gyaw7wox7d3QcluXUu7aUfca0kX7kcdcAVgjAN21RV3T5TqLhM79o8Xvfx3X3jTMMUHldV98gUsj65Ikhdq7vvPa/6J5l6gW86f2z/W1k2/ra7n9PdP5zklpkC1G9k6t36epJbLdvmQfOJTKv5+yT3r2VXIlnh85kC3HLfn+Rz8+3/yBTel3zfGttZzeW6SsRGdPcHMg2/OGpuWrlf3z+3JSv2qao2sk9nJ7nBsnVr+fResNtjprs/3t2/mOR7kzwtyYm1+lVZ/jnJjdZ6I5Jp7O/BmYYdLPl8kutW1fIQvvxYWOnYTAH2M/N44lcluWqS/zLXek53/2p3H57kvyV5QW3BFTyq6oaZevMfmeR63X1wkn/J2mPbd3esJHvpOO7u0zOd/Pn8+bjZqFtk+uQHrtSEadhmqurac+/fy5P81fwPceUy95lPtqpMPUcXZ/po+P1JLphPXjqgqvarqqPmYJ5MPU1fTXJhVd08yX9fts3bV9Udq+qqmcLfN5J8Zx77/P+SPLPmy2RV1RHLxtSu9Iwk105ywhwylpZ/RlXdOlOv4s2q6r9U1f7zyWC3TPKGef3TMp1YdtWaTgZ8wAYevnOTHLmbID+sqn6kqn512WNw80xvZJaGPbwsye9U1Y55nPPvJlm6TN+Hk9yqqm5bVddI8r83cNdvnNf9+TmoPjobe4OxJ7s9Zqrql6pqx3wcfHle5zLj4bv7rEyflqw6tGHuAX5ypqvULLV9Nsk/JfnjqrrGfHw8PJc+bpeoqqXx3PfJNARmabzx0zIP9aiqB1bVUi/s+ZlC6VKt52Y6QXIzfM98X7vmOh6WS99krWZ3x8p61fyYXfKzxnInZPqU4ec2uP1kGgL2twPrwRWKMA3bx+ur6oJMPYW/nSmUPmyNZW+aqQf4wkwnRb2gu98+j+VcChufzNSr/MJcOu7xf2bqxbsgU0B+xbJtXntuOz/Tx85fzDScJJkC0JlJ3jsPD/n7fPfY0kt095eS3CXTeNT3zfv0tkyh/8zu/uJc4+Pn+3hCkvt09xfmTfyvTCe6nZ9pLOlfr/mIXdar5t9frKoPbmC99fhypkByelVdmGmoy2uSLF127g+SnJKph/b0TCeq/UGSdPe/JXlKpsft41nl04a1zI/LAzOdBPrFTM/9uy//7lyy/T0dMz+d5Ix5n5+d5EG7Gcf7Z9n9OPGX5bLj6X8xyZGZemZfk2ms8N+vsu4vJzmtu98y90Cf093nZDqR9dY1XXnm9pmOuQsznUz66/MY8GR6A3PCPAzjmN3UuGHd/ZEk/1+mv8VzM52MubvnaM1jZQPukukTo0t+VvtUoLu/lel529AXPs3h/N6ZwjhcqdU0vA4ANldNl3f7UJJ79PzFLWxPVfWoJDfo7icsuhZYNGEaAAAGGeYBAACDhGkAABgkTAMAwCBhGgAABq118fzLrar+PNPllM7r7qPmtutmutTWkUk+leSY7j5/vhbuszNdZudrSR7a3Xu8bNUhhxzSRx555KbUDwAAS0499dQvzN9w+102LUwneXGmrx5+ybK2JyV5W3c/df564ydluj7tvTJdG/WmSe6Y6VvY7rinOzjyyCNzyimn7OWyAQDgu1XVp1dr37RhHt39ziRfWtF831x6gfcTktxvWftLevLeJAdX1WGbVRsAAOwNWz1m+tBlF+o/J9NXmCbJEZm+1W3JWXPbZVTVcVV1SlWdsmvXrs2rFAAA9mBhJyD29G0xG/7GmO4+vrt3dvfOHTsuM2wFAAC2zFaH6XOXhm/Mv8+b2z+X5AbLlrv+3AYAAPusrQ7Tr0ty7Hz72CSvXdb+kJrcKclXlg0HAQCAfdJmXhrvZUmOTnJIVZ2V5MlJnprklVX18CSfTnLMvPibMl0W78xMl8Z72GbVBQAAe8umhenu/sU1Zt1jlWU7ya9tVi0AALAZfAMiAAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABi0/6IL2K6e+dZ/W3QJwDbz2J+42aJLAGAv0zMNAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMGj/RRcAwJXTM9/6b4suAdhmHvsTN1t0CZehZxoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMGghYbqqHltVZ1TVv1TVy6rqGlV1o6p6X1WdWVWvqKqrLaI2AABYry0P01V1RJJHJ9nZ3Ucl2S/Jg5I8Lckzu/smSc5P8vCtrg0AADZiUcM89k9yQFXtn+SaSc5OcvckJ87zT0hyvwXVBgAA67LlYbq7P5fk6Uk+kylEfyXJqUm+3N0XzYudleSIra4NAAA2YhHDPK6T5L5JbpTk8CTfk+SnN7D+cVV1SlWdsmvXrk2qEgAA9mwRwzzumeST3b2ru7+d5KQkd01y8DzsI0mun+Rzq63c3cd3987u3rljx46tqRgAAFaxiDD9mSR3qqprVlUluUeSjyR5e5IHzMscm+S1C6gNAADWbRFjpt+X6UTDDyY5fa7h+CRPTPK4qjozyfWSvGirawMAgI3Yf8+L7H3d/eQkT17R/Ikkd1hAOQAAMMQ3IAIAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAxaSJiuqoOr6sSq+lhVfbSq7lxV162qt1bVx+ff11lEbQAAsF6L6pl+dpI3d/fNk9wmyUeTPCnJ27r7pkneNk8DAMA+a8vDdFUdlORuSV6UJN39re7+cpL7JjlhXuyEJPfb6toAAGAjFtEzfaMku5L8RVV9qKpeWFXfk+TQ7j57XuacJIcuoDYAAFi3RYTp/ZP8UJI/6e7bJfmPrBjS0d2dpFdbuaqOq6pTquqUXbt2bXqxAACwlkWE6bOSnNXd75unT8wUrs+tqsOSZP593mord/fx3b2zu3fu2LFjSwoGAIDVbHmY7u5zkny2qn5wbrpHko8keV2SY+e2Y5O8dqtrAwCAjdh/Qff7qCQvraqrJflEkodlCvavrKqHJ/l0kmMWVBsAAKzLQsJ0d5+WZOcqs+6x1bUAAMAo34AIAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADFpXmK6qu66nDQAArkzW2zP93HW2AQDAlcb+u5tZVXdOcpckO6rqcctmXTvJfptZGAAA7Ot2G6aTXC3JgfNy11rW/tUkD9isogAAYDvYbZju7nckeUdVvbi7P71FNQEAwLawp57pJVevquOTHLl8ne6++2YUBQAA28F6w/SrkvxpkhcmuXjzygEAgO1jvWH6ou7+k02tBAAAtpn1Xhrv9VX1P6rqsKq67tLPplYGAAD7uPX2TB87//6NZW2d5MZ7txwAANg+1hWmu/tGm10IAABsN+sK01X1kNXau/sle7ccAADYPtY7zOP2y25fI8k9knwwiTANAMCV1nqHeTxq+XRVHZzk5ZtSEQAAbBPrvZrHSv+RxDhqAACu1NY7Zvr1ma7ekST7JblFklduVlEAALAdrHfM9NOX3b4oyae7+6xNqAcAALaNdQ3z6O53JPlYkmsluU6Sb21mUQAAsB2sK0xX1TFJ3p/kgUmOSfK+qnrAZhYGAAD7uvUO8/jtJLfv7vOSpKp2JPn7JCduVmEAALCvW+/VPK6yFKRnX9zAugAAcIW03p7pN1fV3yV52Tz9C0netDklAQDA9rDbMF1VN0lyaHf/RlX9fJIfmWe9J8lLN7s4AADYl+2pZ/pZSX4zSbr7pCQnJUlV/ad53s9uanUAALAP29O450O7+/SVjXPbkZtSEQAAbBN7CtMH72beAXuzEAAA2G72FKZPqapfXdlYVf81yambUxIAAGwPexoz/Zgkr6mqB+fS8LwzydWS3H8zCwMAgH3dbsN0d5+b5C5V9eNJjpqb39jd/7DplQEAwD5uXdeZ7u63J3n7JtcCAADbim8xBACAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQQsL01W1X1V9qKreME/fqKreV1VnVtUrqupqi6oNAADWY5E907+e5KPLpp+W5JndfZMk5yd5+EKqAgCAdVpImK6q6yf5mSQvnKcryd2TnDgvckKS+y2iNgAAWK9F9Uw/K8kTknxnnr5eki9390Xz9FlJjlhtxao6rqpOqapTdu3atfmVAgDAGrY8TFfVfZKc192njqzf3cd3987u3rljx469XB0AAKzf/gu4z7sm+bmquneSayS5dpJnJzm4qvafe6evn+RzC6gNAADWbct7prv7N7v7+t19ZJIHJfmH7n5wkrcnecC82LFJXrvVtQEAwEbsS9eZfmKSx1XVmZnGUL9owfUAAMBuLWKYxyW6++QkJ8+3P5HkDousBwAANmJf6pkGAIBtRZgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg7Y8TFfVDarq7VX1kao6o6p+fW6/blW9tao+Pv++zlbXBgAAG7GInumLkjy+u2+Z5E5Jfq2qbpnkSUne1t03TfK2eRoAAPZZWx6mu/vs7v7gfPuCJB9NckSS+yY5YV7shCT32+raAABgIxY6ZrqqjkxyuyTvS3Jod589zzonyaELKgsAANZlYWG6qg5M8uokj+nury6f192dpNdY77iqOqWqTtm1a9cWVAoAAKtbSJiuqqtmCtIv7e6T5uZzq+qwef5hSc5bbd3uPr67d3b3zh07dmxNwQAAsIpFXM2jkrwoyUe7+xnLZr0uybHz7WOTvHarawMAgI3YfwH3edckv5zk9Ko6bW77rSRPTfLKqnp4kk8nOWYBtQEAwLpteZju7n9MUmvMvsdW1gIAAJeHb0AEAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYtE+F6ar66ar616o6s6qetOh6AABgd/aZMF1V+yV5fpJ7Jbllkl+sqlsutioAAFjbPhOmk9whyZnd/Ynu/laSlye574JrAgCANe1LYfqIJJ9dNn3W3AYAAPuk/RddwEZV1XFJjpsnL6yqf11kPbCKQ5J8YdFFsO953KILgO3D6yirWvDr6A1Xa9yXwvTnktxg2fT157bv0t3HJzl+q4qCjaqqU7p756LrANiuvI6ynexLwzw+kOSmVXWjqrpakgcled2CawIAgDXtMz3T3X1RVT0yyd8l2S/Jn3f3GQsuCwAA1rTPhOkk6e43JXnTouuAy8kwJIDLx+so20Z196JrAACAbWlfGjMNAADbijANSarqwhXTD62q5w1u6+iqesOy23dZNu/FVfWAy1ctwNarqour6rSq+peqelVVXXPRNa1HVe2squcsug6uuIRp2FxHJ7nLnhYC2Aa+3t237e6jknwrySMWXdB6dPcp3f3oRdfBFZcwDXtQVTuq6tVV9YH5565z+x2q6j1V9aGq+qeq+sEV6x2Z6Z/NY+fenB+dZ91tXv4TS73UVfWSqrrfsnVfWlX33ZIdBNi4dyW5yfzp28lVdWJVfWx+7aokqaofrqp3VNWpVfV3VXXY3H5yVe2cbx9SVZ+abz+0qv6mqt5aVZ+qqkdW1ePm19j3VtV15+VuO0//c1W9pqqus2y7T6uq91fVvy295q74tHC3r9swQpiGyQFz4D2tqk5L8pRl856d5Jndffsk/znJC+f2jyX50e6+XZLfTfJHyzfY3Z9K8qfzurft7nfNsw5L8iNJ7pPkqXPbi5I8NEmq6qBMvdlv3Kt7CLAXVNX+Se6V5PS56XZJHpPklklunOSuVXXVJM9N8oDu/uEkf57kD9ex+aOS/HyS28/Lf21+jX1PkofMy7wkyRO7+9ZzDU9etv7+3X2HuZ7l7Ut2+7oNI/apS+PBAn29u2+7NFFVD02y9O1b90xyy7mzJUmuXVUHJjkoyQlVddMkneSq67yvv+nu7yT5SFUdmiTd/Y6qekFV7cgU2F/d3Rdd3p0C2IsOmDsbkqln+kWZ3vi/v7vPSpJ5/pFJvpwpGL91fu3cL8nZ67iPt3f3BUkuqKqvJHn93H56klvPnQ0Hd/c75vYTkrxq2fonzb9PnetYafR1G9YkTMOeXSXJnbr7G8sb5xMU397d95+HdJy8zu19c/lmlnEv9QAAAAOtSURBVN1+SZJfyvTtnw8bLRZgk3xXp0OSzEF5+WvaxZmyRSU5o7vvvMp2Lsqln4xfY8W85dv6zrLp72R9mWVp+aU6Vvr9jL1uw5oM84A9e0uSRy1NVNXSP5ODknxuvv3QNda9IMm11nk/L8700WS6+yMbLRJgH/KvSXZU1Z2TpKquWlW3mud9KskPz7c3dHWj7v5KkvOXnYPyy0nesZtVVlrP6zZsiDANe/boJDvnk10+kkvPYP8/Sf64qj6UtXtMXp/k/itOQFxVd5+b5KNJ/mIv1Q2wEN39rUxB+WlV9eEkp+XSKxs9Pcl/n187DxnY/LFJ/m9V/XOS2+a7z3HZk/W8bsOG+AZE2EfM12w9PckPzb0vAMA+Ts807AOq6p6ZeqWfK0gDwPahZxoAAAbpmQYAgEHCNAAADBKmAQBgkDANsA1U1cXzJRbPqKoPV9Xjq+oq87ydVfWcRdcIcGXkBESAbaCqLuzuA+fb35vkr5O8u7ufvNjKAK7c9EwDbDPdfV6S45I8siZHV9UbkqSqfmzuwT6tqj5UVdea23+jqj4wf/nQ7y1tq6r+pqpOnXu8j5vb9quqF1fVv1TV6VX12Ln9B6rqzfPy76qqm2/93gPsW3z7D8A21N2fqKr9knzviln/M8mvdfe7q+rAJN+oqp9MctMkd0hSSV5XVXfr7ncm+ZXu/lJVHZDkA1X16iRHJjmiu49Kkqo6eN728Uke0d0fr6o7JnlBkrtv8q4C7NOEaYArlncneUZVvTTJSd191hymfzLJh+ZlDswUrt+Z5NFVdf+5/QZz+78muXFVPTfJG5O8ZQ7md0nyqqpauq+rb8UOAezLhGmAbaiqbpzk4iTnJbnFUnt3P7Wq3pjk3kneXVU/lak3+o+7+89WbOPoJPdMcufu/lpVnZzkGt19flXdJslPJXlEkmOSPCbJl7v7tpu+cwDbiDHTANtMVe1I8qdJntcrziKvqh/o7tO7+2lJPpDk5kn+LsmvzL3Lqaoj5pMYD0py/hykb57kTvP8Q5JcpbtfneR3kvxQd381ySer6oHzMjUHboArNT3TANvDAVV1WpKrJrkoyV8mecYqyz2mqn48yXeSnJHkb7v7m1V1iyTvmYdoXJjkl5K8OckjquqjmYZ2vHfexhFJ/mLp0ntJfnP+/eAkf1JVvzPX8fIkH967uwmwvbg0HgAADDLMAwAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMCg/x9vD1TnFui7IgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 40, 216)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 40, 216, 1) (183, 2)\n",
      "(33, 40, 216, 1) (33, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 215, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 107, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 107, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 106, 16)       2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 53, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 53, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 52, 8)          520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 26, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 26, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 25, 4)          132       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 12, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 12, 4)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 2,886\n",
      "Trainable params: 2,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "33/33 [==============================] - 1s 29ms/sample - loss: 26.9060 - accuracy: 0.2727\n",
      "Pre-training accuracy: 27.2727%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146 samples, validate on 37 samples\n",
      "Epoch 1/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 38.1147 - accuracy: 0.5600\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48649, saving model to models/CNN2_dataset_1_trim5_01.h5\n",
      "146/146 [==============================] - 1s 6ms/sample - loss: 31.9771 - accuracy: 0.5342 - val_loss: 0.7053 - val_accuracy: 0.4865\n",
      "Epoch 2/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 7.9400 - accuracy: 0.5500 \n",
      "Epoch 00002: val_accuracy improved from 0.48649 to 0.59459, saving model to models/CNN2_dataset_1_trim5_02.h5\n",
      "146/146 [==============================] - 0s 831us/sample - loss: 6.7562 - accuracy: 0.5342 - val_loss: 0.6829 - val_accuracy: 0.5946\n",
      "Epoch 3/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 3.2775 - accuracy: 0.5100\n",
      "Epoch 00003: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 2.7036 - accuracy: 0.5342 - val_loss: 0.6931 - val_accuracy: 0.5135\n",
      "Epoch 4/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 1.4449 - accuracy: 0.5400\n",
      "Epoch 00004: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 676us/sample - loss: 1.3982 - accuracy: 0.5342 - val_loss: 0.6932 - val_accuracy: 0.5135\n",
      "Epoch 5/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.9265 - accuracy: 0.5636\n",
      "Epoch 00005: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 662us/sample - loss: 0.9657 - accuracy: 0.5548 - val_loss: 0.6935 - val_accuracy: 0.5135\n",
      "Epoch 6/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.9266 - accuracy: 0.4800\n",
      "Epoch 00006: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 665us/sample - loss: 0.8585 - accuracy: 0.5000 - val_loss: 0.6938 - val_accuracy: 0.5135\n",
      "Epoch 7/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.7287 - accuracy: 0.5000\n",
      "Epoch 00007: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 663us/sample - loss: 0.7582 - accuracy: 0.5274 - val_loss: 0.6940 - val_accuracy: 0.5135\n",
      "Epoch 8/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.8280 - accuracy: 0.5400\n",
      "Epoch 00008: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 673us/sample - loss: 0.8336 - accuracy: 0.5479 - val_loss: 0.6942 - val_accuracy: 0.5135\n",
      "Epoch 9/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.7836 - accuracy: 0.5273\n",
      "Epoch 00009: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 664us/sample - loss: 0.7817 - accuracy: 0.5411 - val_loss: 0.6944 - val_accuracy: 0.5135\n",
      "Epoch 10/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.7298 - accuracy: 0.5700\n",
      "Epoch 00010: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 660us/sample - loss: 0.7137 - accuracy: 0.5753 - val_loss: 0.6946 - val_accuracy: 0.5135\n",
      "Epoch 11/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.7131 - accuracy: 0.5100\n",
      "Epoch 00011: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.7126 - accuracy: 0.4932 - val_loss: 0.6948 - val_accuracy: 0.5135\n",
      "Epoch 12/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.7400 - accuracy: 0.5400\n",
      "Epoch 00012: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.7204 - accuracy: 0.5890 - val_loss: 0.6949 - val_accuracy: 0.5135\n",
      "Epoch 13/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.7553 - accuracy: 0.5000\n",
      "Epoch 00013: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 0.7327 - accuracy: 0.4932 - val_loss: 0.6950 - val_accuracy: 0.5135\n",
      "Epoch 14/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.7057 - accuracy: 0.5909\n",
      "Epoch 00014: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 663us/sample - loss: 0.7047 - accuracy: 0.5616 - val_loss: 0.6951 - val_accuracy: 0.5135\n",
      "Epoch 15/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.7422 - accuracy: 0.4909\n",
      "Epoch 00015: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.7370 - accuracy: 0.5068 - val_loss: 0.6952 - val_accuracy: 0.5135\n",
      "Epoch 16/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.7319 - accuracy: 0.5800\n",
      "Epoch 00016: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.7102 - accuracy: 0.6027 - val_loss: 0.6953 - val_accuracy: 0.5135\n",
      "Epoch 17/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6790 - accuracy: 0.4900\n",
      "Epoch 00017: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 691us/sample - loss: 0.6725 - accuracy: 0.5205 - val_loss: 0.6952 - val_accuracy: 0.5135\n",
      "Epoch 18/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.6619 - accuracy: 0.5818\n",
      "Epoch 00018: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 662us/sample - loss: 0.6766 - accuracy: 0.6027 - val_loss: 0.6953 - val_accuracy: 0.5135\n",
      "Epoch 19/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.7270 - accuracy: 0.5000\n",
      "Epoch 00019: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 687us/sample - loss: 0.7302 - accuracy: 0.5068 - val_loss: 0.6953 - val_accuracy: 0.5135\n",
      "Epoch 20/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6953 - accuracy: 0.5400\n",
      "Epoch 00020: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 678us/sample - loss: 0.7073 - accuracy: 0.5411 - val_loss: 0.6955 - val_accuracy: 0.5135\n",
      "Epoch 21/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.7046 - accuracy: 0.5455\n",
      "Epoch 00021: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.6724 - accuracy: 0.5822 - val_loss: 0.6957 - val_accuracy: 0.5135\n",
      "Epoch 22/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.7287 - accuracy: 0.5100\n",
      "Epoch 00022: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 729us/sample - loss: 0.7148 - accuracy: 0.5548 - val_loss: 0.6958 - val_accuracy: 0.5135\n",
      "Epoch 23/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6802 - accuracy: 0.5600\n",
      "Epoch 00023: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 700us/sample - loss: 0.6915 - accuracy: 0.5342 - val_loss: 0.6959 - val_accuracy: 0.5135\n",
      "Epoch 24/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.7134 - accuracy: 0.5200\n",
      "Epoch 00024: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 689us/sample - loss: 0.7104 - accuracy: 0.4863 - val_loss: 0.6961 - val_accuracy: 0.5135\n",
      "Epoch 25/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6631 - accuracy: 0.5700\n",
      "Epoch 00025: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.6527 - accuracy: 0.5685 - val_loss: 0.6961 - val_accuracy: 0.5135\n",
      "Epoch 26/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6850 - accuracy: 0.6000\n",
      "Epoch 00026: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 745us/sample - loss: 0.7031 - accuracy: 0.6096 - val_loss: 0.6961 - val_accuracy: 0.5135\n",
      "Epoch 27/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6646 - accuracy: 0.6000\n",
      "Epoch 00027: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.6642 - accuracy: 0.5822 - val_loss: 0.6963 - val_accuracy: 0.5135\n",
      "Epoch 28/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6516 - accuracy: 0.5667\n",
      "Epoch 00028: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.6460 - accuracy: 0.6096 - val_loss: 0.6967 - val_accuracy: 0.5135\n",
      "Epoch 29/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6560 - accuracy: 0.4556\n",
      "Epoch 00029: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.6498 - accuracy: 0.5137 - val_loss: 0.6970 - val_accuracy: 0.5135\n",
      "Epoch 30/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6466 - accuracy: 0.5667\n",
      "Epoch 00030: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 723us/sample - loss: 0.6449 - accuracy: 0.6164 - val_loss: 0.6972 - val_accuracy: 0.5135\n",
      "Epoch 31/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6208 - accuracy: 0.6444\n",
      "Epoch 00031: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.6756 - accuracy: 0.5890 - val_loss: 0.6974 - val_accuracy: 0.5135\n",
      "Epoch 32/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6733 - accuracy: 0.5889\n",
      "Epoch 00032: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 762us/sample - loss: 0.6416 - accuracy: 0.5959 - val_loss: 0.6981 - val_accuracy: 0.5135\n",
      "Epoch 33/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5891 - accuracy: 0.6333\n",
      "Epoch 00033: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.6211 - accuracy: 0.6301 - val_loss: 0.6989 - val_accuracy: 0.5135\n",
      "Epoch 34/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6158 - accuracy: 0.6444\n",
      "Epoch 00034: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.6456 - accuracy: 0.5959 - val_loss: 0.6989 - val_accuracy: 0.5135\n",
      "Epoch 35/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6012 - accuracy: 0.6222\n",
      "Epoch 00035: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.6289 - accuracy: 0.5890 - val_loss: 0.6989 - val_accuracy: 0.5135\n",
      "Epoch 36/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6256 - accuracy: 0.5667\n",
      "Epoch 00036: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 711us/sample - loss: 0.6342 - accuracy: 0.5959 - val_loss: 0.6991 - val_accuracy: 0.5135\n",
      "Epoch 37/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6833 - accuracy: 0.6000\n",
      "Epoch 00037: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 715us/sample - loss: 0.6598 - accuracy: 0.6027 - val_loss: 0.6993 - val_accuracy: 0.5135\n",
      "Epoch 38/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6167 - accuracy: 0.6400\n",
      "Epoch 00038: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.6115 - accuracy: 0.6301 - val_loss: 0.6993 - val_accuracy: 0.5135\n",
      "Epoch 39/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6179 - accuracy: 0.6333\n",
      "Epoch 00039: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 757us/sample - loss: 0.6532 - accuracy: 0.6233 - val_loss: 0.6993 - val_accuracy: 0.5135\n",
      "Epoch 40/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6547 - accuracy: 0.6889\n",
      "Epoch 00040: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 721us/sample - loss: 0.6483 - accuracy: 0.6438 - val_loss: 0.7000 - val_accuracy: 0.5135\n",
      "Epoch 41/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6559 - accuracy: 0.5889\n",
      "Epoch 00041: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.6572 - accuracy: 0.5616 - val_loss: 0.6999 - val_accuracy: 0.5135\n",
      "Epoch 42/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6483 - accuracy: 0.5778\n",
      "Epoch 00042: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 706us/sample - loss: 0.6317 - accuracy: 0.5753 - val_loss: 0.6996 - val_accuracy: 0.5135\n",
      "Epoch 43/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6290 - accuracy: 0.5600\n",
      "Epoch 00043: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.6360 - accuracy: 0.5616 - val_loss: 0.6994 - val_accuracy: 0.5135\n",
      "Epoch 44/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6533 - accuracy: 0.5778\n",
      "Epoch 00044: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.6181 - accuracy: 0.6164 - val_loss: 0.6990 - val_accuracy: 0.5135\n",
      "Epoch 45/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5743 - accuracy: 0.6778\n",
      "Epoch 00045: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.5909 - accuracy: 0.6575 - val_loss: 0.6962 - val_accuracy: 0.5405\n",
      "Epoch 46/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6308 - accuracy: 0.5700\n",
      "Epoch 00046: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 699us/sample - loss: 0.6092 - accuracy: 0.6301 - val_loss: 0.6970 - val_accuracy: 0.5405\n",
      "Epoch 47/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5885 - accuracy: 0.6556\n",
      "Epoch 00047: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 715us/sample - loss: 0.5921 - accuracy: 0.6438 - val_loss: 0.6946 - val_accuracy: 0.5405\n",
      "Epoch 48/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5903 - accuracy: 0.6300\n",
      "Epoch 00048: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 0.5982 - accuracy: 0.6438 - val_loss: 0.6976 - val_accuracy: 0.5405\n",
      "Epoch 49/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5944 - accuracy: 0.6800\n",
      "Epoch 00049: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 711us/sample - loss: 0.5925 - accuracy: 0.6370 - val_loss: 0.6992 - val_accuracy: 0.5135\n",
      "Epoch 50/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6109 - accuracy: 0.6667\n",
      "Epoch 00050: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 826us/sample - loss: 0.6099 - accuracy: 0.6438 - val_loss: 0.6997 - val_accuracy: 0.5135\n",
      "Epoch 51/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6388 - accuracy: 0.6222\n",
      "Epoch 00051: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 794us/sample - loss: 0.6120 - accuracy: 0.6507 - val_loss: 0.6972 - val_accuracy: 0.5405\n",
      "Epoch 52/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6358 - accuracy: 0.5778\n",
      "Epoch 00052: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 765us/sample - loss: 0.6187 - accuracy: 0.6164 - val_loss: 0.6899 - val_accuracy: 0.5405\n",
      "Epoch 53/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5728 - accuracy: 0.7333\n",
      "Epoch 00053: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.6055 - accuracy: 0.6644 - val_loss: 0.6908 - val_accuracy: 0.5405\n",
      "Epoch 54/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6060 - accuracy: 0.7222\n",
      "Epoch 00054: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.5893 - accuracy: 0.7260 - val_loss: 0.6978 - val_accuracy: 0.5405\n",
      "Epoch 55/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6271 - accuracy: 0.5700\n",
      "Epoch 00055: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 0.6036 - accuracy: 0.6507 - val_loss: 0.6955 - val_accuracy: 0.5405\n",
      "Epoch 56/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5500 - accuracy: 0.6800\n",
      "Epoch 00056: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 700us/sample - loss: 0.5756 - accuracy: 0.6712 - val_loss: 0.6852 - val_accuracy: 0.5405\n",
      "Epoch 57/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5627 - accuracy: 0.6900\n",
      "Epoch 00057: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 0.5937 - accuracy: 0.6438 - val_loss: 0.6741 - val_accuracy: 0.5676\n",
      "Epoch 58/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5889 - accuracy: 0.6889\n",
      "Epoch 00058: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.5932 - accuracy: 0.6507 - val_loss: 0.6854 - val_accuracy: 0.5405\n",
      "Epoch 59/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5799 - accuracy: 0.6300\n",
      "Epoch 00059: val_accuracy did not improve from 0.59459\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.5905 - accuracy: 0.6507 - val_loss: 0.6766 - val_accuracy: 0.5676\n",
      "Epoch 60/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5652 - accuracy: 0.7111\n",
      "Epoch 00060: val_accuracy improved from 0.59459 to 0.62162, saving model to models/CNN2_dataset_1_trim5_60.h5\n",
      "146/146 [==============================] - 0s 876us/sample - loss: 0.5699 - accuracy: 0.6849 - val_loss: 0.6566 - val_accuracy: 0.6216\n",
      "Epoch 61/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6302 - accuracy: 0.6778\n",
      "Epoch 00061: val_accuracy did not improve from 0.62162\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.5702 - accuracy: 0.7192 - val_loss: 0.6746 - val_accuracy: 0.5676\n",
      "Epoch 62/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5696 - accuracy: 0.7444\n",
      "Epoch 00062: val_accuracy did not improve from 0.62162\n",
      "146/146 [==============================] - 0s 743us/sample - loss: 0.5511 - accuracy: 0.7123 - val_loss: 0.6672 - val_accuracy: 0.5676\n",
      "Epoch 63/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5285 - accuracy: 0.7667\n",
      "Epoch 00063: val_accuracy improved from 0.62162 to 0.67568, saving model to models/CNN2_dataset_1_trim5_63.h5\n",
      "146/146 [==============================] - 0s 855us/sample - loss: 0.5477 - accuracy: 0.7329 - val_loss: 0.6424 - val_accuracy: 0.6757\n",
      "Epoch 64/500\n",
      " 70/146 [=============>................] - ETA: 0s - loss: 0.5499 - accuracy: 0.7143\n",
      "Epoch 00064: val_accuracy did not improve from 0.67568\n",
      "146/146 [==============================] - 0s 939us/sample - loss: 0.5709 - accuracy: 0.7055 - val_loss: 0.6457 - val_accuracy: 0.6757\n",
      "Epoch 65/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5876 - accuracy: 0.7000\n",
      "Epoch 00065: val_accuracy did not improve from 0.67568\n",
      "146/146 [==============================] - 0s 750us/sample - loss: 0.5602 - accuracy: 0.7260 - val_loss: 0.6505 - val_accuracy: 0.6216\n",
      "Epoch 66/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5741 - accuracy: 0.6889\n",
      "Epoch 00066: val_accuracy did not improve from 0.67568\n",
      "146/146 [==============================] - 0s 710us/sample - loss: 0.5526 - accuracy: 0.7192 - val_loss: 0.6383 - val_accuracy: 0.6757\n",
      "Epoch 67/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5282 - accuracy: 0.7111\n",
      "Epoch 00067: val_accuracy did not improve from 0.67568\n",
      "146/146 [==============================] - 0s 723us/sample - loss: 0.5429 - accuracy: 0.7260 - val_loss: 0.6485 - val_accuracy: 0.6486\n",
      "Epoch 68/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5808 - accuracy: 0.7300\n",
      "Epoch 00068: val_accuracy did not improve from 0.67568\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 0.5742 - accuracy: 0.6781 - val_loss: 0.6383 - val_accuracy: 0.6757\n",
      "Epoch 69/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5561 - accuracy: 0.6400\n",
      "Epoch 00069: val_accuracy improved from 0.67568 to 0.70270, saving model to models/CNN2_dataset_1_trim5_69.h5\n",
      "146/146 [==============================] - 0s 844us/sample - loss: 0.5306 - accuracy: 0.6849 - val_loss: 0.6157 - val_accuracy: 0.7027\n",
      "Epoch 70/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5587 - accuracy: 0.6889\n",
      "Epoch 00070: val_accuracy did not improve from 0.70270\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.5522 - accuracy: 0.6986 - val_loss: 0.6136 - val_accuracy: 0.7027\n",
      "Epoch 71/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5787 - accuracy: 0.6889\n",
      "Epoch 00071: val_accuracy did not improve from 0.70270\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.5282 - accuracy: 0.7123 - val_loss: 0.6283 - val_accuracy: 0.6757\n",
      "Epoch 72/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5204 - accuracy: 0.7100\n",
      "Epoch 00072: val_accuracy did not improve from 0.70270\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.5388 - accuracy: 0.7123 - val_loss: 0.6252 - val_accuracy: 0.6757\n",
      "Epoch 73/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5304 - accuracy: 0.7400\n",
      "Epoch 00073: val_accuracy did not improve from 0.70270\n",
      "146/146 [==============================] - 0s 672us/sample - loss: 0.5359 - accuracy: 0.7397 - val_loss: 0.6233 - val_accuracy: 0.7027\n",
      "Epoch 74/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4951 - accuracy: 0.7889\n",
      "Epoch 00074: val_accuracy improved from 0.70270 to 0.72973, saving model to models/CNN2_dataset_1_trim5_74.h5\n",
      "146/146 [==============================] - 0s 949us/sample - loss: 0.5147 - accuracy: 0.7808 - val_loss: 0.6007 - val_accuracy: 0.7297\n",
      "Epoch 75/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5418 - accuracy: 0.7667\n",
      "Epoch 00075: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 776us/sample - loss: 0.5678 - accuracy: 0.7397 - val_loss: 0.6087 - val_accuracy: 0.7027\n",
      "Epoch 76/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5701 - accuracy: 0.6900\n",
      "Epoch 00076: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.5401 - accuracy: 0.7260 - val_loss: 0.6140 - val_accuracy: 0.7027\n",
      "Epoch 77/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5464 - accuracy: 0.7100\n",
      "Epoch 00077: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 710us/sample - loss: 0.5240 - accuracy: 0.7466 - val_loss: 0.5951 - val_accuracy: 0.7297\n",
      "Epoch 78/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6145 - accuracy: 0.7000\n",
      "Epoch 00078: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.5992 - accuracy: 0.7123 - val_loss: 0.6087 - val_accuracy: 0.7027\n",
      "Epoch 79/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5276 - accuracy: 0.7000\n",
      "Epoch 00079: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.5234 - accuracy: 0.6986 - val_loss: 0.5985 - val_accuracy: 0.7297\n",
      "Epoch 80/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5265 - accuracy: 0.7200\n",
      "Epoch 00080: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.5074 - accuracy: 0.7192 - val_loss: 0.5903 - val_accuracy: 0.7297\n",
      "Epoch 81/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5364 - accuracy: 0.6900\n",
      "Epoch 00081: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.5339 - accuracy: 0.7123 - val_loss: 0.5858 - val_accuracy: 0.7297\n",
      "Epoch 82/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5039 - accuracy: 0.7400\n",
      "Epoch 00082: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.5303 - accuracy: 0.7123 - val_loss: 0.5823 - val_accuracy: 0.7297\n",
      "Epoch 83/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5048 - accuracy: 0.7600\n",
      "Epoch 00083: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.5360 - accuracy: 0.7260 - val_loss: 0.5891 - val_accuracy: 0.7297\n",
      "Epoch 84/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4871 - accuracy: 0.8400\n",
      "Epoch 00084: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 680us/sample - loss: 0.5294 - accuracy: 0.7740 - val_loss: 0.5804 - val_accuracy: 0.7297\n",
      "Epoch 85/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4924 - accuracy: 0.7700\n",
      "Epoch 00085: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 0.5023 - accuracy: 0.7671 - val_loss: 0.5872 - val_accuracy: 0.7297\n",
      "Epoch 86/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4610 - accuracy: 0.8100\n",
      "Epoch 00086: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.4973 - accuracy: 0.7534 - val_loss: 0.5761 - val_accuracy: 0.7297\n",
      "Epoch 87/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4843 - accuracy: 0.8100\n",
      "Epoch 00087: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 679us/sample - loss: 0.4884 - accuracy: 0.7945 - val_loss: 0.5808 - val_accuracy: 0.7297\n",
      "Epoch 88/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4961 - accuracy: 0.7556\n",
      "Epoch 00088: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.5288 - accuracy: 0.7397 - val_loss: 0.5730 - val_accuracy: 0.7297\n",
      "Epoch 89/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4832 - accuracy: 0.7800\n",
      "Epoch 00089: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.5001 - accuracy: 0.7534 - val_loss: 0.5782 - val_accuracy: 0.7297\n",
      "Epoch 90/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5140 - accuracy: 0.7100\n",
      "Epoch 00090: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 713us/sample - loss: 0.5190 - accuracy: 0.7055 - val_loss: 0.5791 - val_accuracy: 0.7297\n",
      "Epoch 91/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4853 - accuracy: 0.7300\n",
      "Epoch 00091: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 0.4879 - accuracy: 0.7603 - val_loss: 0.5679 - val_accuracy: 0.7297\n",
      "Epoch 92/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4731 - accuracy: 0.7300\n",
      "Epoch 00092: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.5269 - accuracy: 0.7397 - val_loss: 0.5717 - val_accuracy: 0.7297\n",
      "Epoch 93/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5240 - accuracy: 0.7300\n",
      "Epoch 00093: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.5185 - accuracy: 0.7329 - val_loss: 0.6080 - val_accuracy: 0.7027\n",
      "Epoch 94/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5061 - accuracy: 0.7200\n",
      "Epoch 00094: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 688us/sample - loss: 0.5003 - accuracy: 0.7397 - val_loss: 0.5624 - val_accuracy: 0.7297\n",
      "Epoch 95/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5348 - accuracy: 0.6900\n",
      "Epoch 00095: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 771us/sample - loss: 0.5218 - accuracy: 0.7192 - val_loss: 0.5648 - val_accuracy: 0.7297\n",
      "Epoch 96/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5025 - accuracy: 0.7889\n",
      "Epoch 00096: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4839 - accuracy: 0.8014 - val_loss: 0.5594 - val_accuracy: 0.7297\n",
      "Epoch 97/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4959 - accuracy: 0.7900\n",
      "Epoch 00097: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 851us/sample - loss: 0.5028 - accuracy: 0.7671 - val_loss: 0.5773 - val_accuracy: 0.7297\n",
      "Epoch 98/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.4739 - accuracy: 0.8500\n",
      "Epoch 00098: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 837us/sample - loss: 0.5008 - accuracy: 0.7740 - val_loss: 0.5670 - val_accuracy: 0.7297\n",
      "Epoch 99/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4889 - accuracy: 0.7333\n",
      "Epoch 00099: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 851us/sample - loss: 0.5024 - accuracy: 0.7329 - val_loss: 0.5783 - val_accuracy: 0.7297\n",
      "Epoch 100/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5269 - accuracy: 0.7778\n",
      "Epoch 00100: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 740us/sample - loss: 0.4979 - accuracy: 0.7808 - val_loss: 0.5537 - val_accuracy: 0.7297\n",
      "Epoch 101/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5118 - accuracy: 0.7667\n",
      "Epoch 00101: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 710us/sample - loss: 0.5180 - accuracy: 0.7329 - val_loss: 0.5633 - val_accuracy: 0.7297\n",
      "Epoch 102/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5114 - accuracy: 0.7700\n",
      "Epoch 00102: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 700us/sample - loss: 0.5128 - accuracy: 0.7466 - val_loss: 0.5536 - val_accuracy: 0.7297\n",
      "Epoch 103/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4608 - accuracy: 0.7900\n",
      "Epoch 00103: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 0.5062 - accuracy: 0.7603 - val_loss: 0.5484 - val_accuracy: 0.7027\n",
      "Epoch 104/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4968 - accuracy: 0.7600\n",
      "Epoch 00104: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 715us/sample - loss: 0.4933 - accuracy: 0.7671 - val_loss: 0.5672 - val_accuracy: 0.7297\n",
      "Epoch 105/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5098 - accuracy: 0.7500\n",
      "Epoch 00105: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.4887 - accuracy: 0.7808 - val_loss: 0.5402 - val_accuracy: 0.7027\n",
      "Epoch 106/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4702 - accuracy: 0.7900\n",
      "Epoch 00106: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 697us/sample - loss: 0.4840 - accuracy: 0.7945 - val_loss: 0.5667 - val_accuracy: 0.7297\n",
      "Epoch 107/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4755 - accuracy: 0.8111\n",
      "Epoch 00107: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 0.4865 - accuracy: 0.7877 - val_loss: 0.5695 - val_accuracy: 0.7297\n",
      "Epoch 108/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5186 - accuracy: 0.7700\n",
      "Epoch 00108: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.4854 - accuracy: 0.7740 - val_loss: 0.5478 - val_accuracy: 0.7297\n",
      "Epoch 109/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4739 - accuracy: 0.7800\n",
      "Epoch 00109: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.4539 - accuracy: 0.8082 - val_loss: 0.5634 - val_accuracy: 0.7297\n",
      "Epoch 110/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.5284 - accuracy: 0.7750\n",
      "Epoch 00110: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 824us/sample - loss: 0.4774 - accuracy: 0.8151 - val_loss: 0.5418 - val_accuracy: 0.7027\n",
      "Epoch 111/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4611 - accuracy: 0.7778\n",
      "Epoch 00111: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 0.4700 - accuracy: 0.7877 - val_loss: 0.5809 - val_accuracy: 0.7297\n",
      "Epoch 112/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4881 - accuracy: 0.8100\n",
      "Epoch 00112: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 742us/sample - loss: 0.4879 - accuracy: 0.7740 - val_loss: 0.5814 - val_accuracy: 0.7297\n",
      "Epoch 113/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4651 - accuracy: 0.7889\n",
      "Epoch 00113: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 785us/sample - loss: 0.4568 - accuracy: 0.7603 - val_loss: 0.5585 - val_accuracy: 0.7297\n",
      "Epoch 114/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4640 - accuracy: 0.7778\n",
      "Epoch 00114: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 738us/sample - loss: 0.4623 - accuracy: 0.7808 - val_loss: 0.5834 - val_accuracy: 0.7297\n",
      "Epoch 115/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4603 - accuracy: 0.8000\n",
      "Epoch 00115: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.4554 - accuracy: 0.7877 - val_loss: 0.5456 - val_accuracy: 0.7027\n",
      "Epoch 116/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4476 - accuracy: 0.8600\n",
      "Epoch 00116: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.4556 - accuracy: 0.8219 - val_loss: 0.5517 - val_accuracy: 0.7027\n",
      "Epoch 117/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4792 - accuracy: 0.7667\n",
      "Epoch 00117: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.4820 - accuracy: 0.7740 - val_loss: 0.5613 - val_accuracy: 0.7297\n",
      "Epoch 118/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4236 - accuracy: 0.8778\n",
      "Epoch 00118: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.4471 - accuracy: 0.8219 - val_loss: 0.5481 - val_accuracy: 0.7027\n",
      "Epoch 119/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4388 - accuracy: 0.8300\n",
      "Epoch 00119: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.4570 - accuracy: 0.8014 - val_loss: 0.5590 - val_accuracy: 0.7027\n",
      "Epoch 120/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4729 - accuracy: 0.8100\n",
      "Epoch 00120: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.4657 - accuracy: 0.8014 - val_loss: 0.5576 - val_accuracy: 0.7027\n",
      "Epoch 121/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4738 - accuracy: 0.7889\n",
      "Epoch 00121: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 728us/sample - loss: 0.4643 - accuracy: 0.8014 - val_loss: 0.5421 - val_accuracy: 0.7027\n",
      "Epoch 122/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4960 - accuracy: 0.7889\n",
      "Epoch 00122: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 743us/sample - loss: 0.4591 - accuracy: 0.8082 - val_loss: 0.5476 - val_accuracy: 0.7027\n",
      "Epoch 123/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4903 - accuracy: 0.7600\n",
      "Epoch 00123: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.4833 - accuracy: 0.7740 - val_loss: 0.5831 - val_accuracy: 0.7297\n",
      "Epoch 124/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4663 - accuracy: 0.7600\n",
      "Epoch 00124: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.4681 - accuracy: 0.7808 - val_loss: 0.5345 - val_accuracy: 0.7027\n",
      "Epoch 125/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4617 - accuracy: 0.7667\n",
      "Epoch 00125: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 811us/sample - loss: 0.4641 - accuracy: 0.7671 - val_loss: 0.5492 - val_accuracy: 0.7027\n",
      "Epoch 126/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4287 - accuracy: 0.8111\n",
      "Epoch 00126: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 812us/sample - loss: 0.4472 - accuracy: 0.8082 - val_loss: 0.5423 - val_accuracy: 0.7027\n",
      "Epoch 127/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4210 - accuracy: 0.7889\n",
      "Epoch 00127: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 771us/sample - loss: 0.4502 - accuracy: 0.7945 - val_loss: 0.5433 - val_accuracy: 0.7027\n",
      "Epoch 128/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5246 - accuracy: 0.7900\n",
      "Epoch 00128: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 699us/sample - loss: 0.5172 - accuracy: 0.7740 - val_loss: 0.5667 - val_accuracy: 0.7297\n",
      "Epoch 129/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4514 - accuracy: 0.8000\n",
      "Epoch 00129: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.4793 - accuracy: 0.7603 - val_loss: 0.5295 - val_accuracy: 0.7027\n",
      "Epoch 130/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4552 - accuracy: 0.8100\n",
      "Epoch 00130: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 715us/sample - loss: 0.4598 - accuracy: 0.8014 - val_loss: 0.5529 - val_accuracy: 0.7297\n",
      "Epoch 131/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4256 - accuracy: 0.8111\n",
      "Epoch 00131: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 0.4320 - accuracy: 0.8082 - val_loss: 0.5486 - val_accuracy: 0.7297\n",
      "Epoch 132/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4583 - accuracy: 0.8000\n",
      "Epoch 00132: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 791us/sample - loss: 0.4641 - accuracy: 0.7877 - val_loss: 0.5478 - val_accuracy: 0.7297\n",
      "Epoch 133/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4973 - accuracy: 0.7800\n",
      "Epoch 00133: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.4756 - accuracy: 0.7945 - val_loss: 0.5667 - val_accuracy: 0.7297\n",
      "Epoch 134/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4911 - accuracy: 0.7800\n",
      "Epoch 00134: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 702us/sample - loss: 0.4796 - accuracy: 0.7740 - val_loss: 0.5382 - val_accuracy: 0.7297\n",
      "Epoch 135/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.5320 - accuracy: 0.7700\n",
      "Epoch 00135: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.4890 - accuracy: 0.7945 - val_loss: 0.5488 - val_accuracy: 0.7297\n",
      "Epoch 136/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4460 - accuracy: 0.8222\n",
      "Epoch 00136: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 0.4716 - accuracy: 0.7945 - val_loss: 0.5335 - val_accuracy: 0.7297\n",
      "Epoch 137/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4871 - accuracy: 0.7444\n",
      "Epoch 00137: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 856us/sample - loss: 0.4584 - accuracy: 0.7808 - val_loss: 0.5287 - val_accuracy: 0.7297\n",
      "Epoch 138/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4177 - accuracy: 0.8444\n",
      "Epoch 00138: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 808us/sample - loss: 0.4493 - accuracy: 0.8288 - val_loss: 0.5393 - val_accuracy: 0.7297\n",
      "Epoch 139/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.5541 - accuracy: 0.6875\n",
      "Epoch 00139: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 827us/sample - loss: 0.4619 - accuracy: 0.7808 - val_loss: 0.5398 - val_accuracy: 0.7297\n",
      "Epoch 140/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5193 - accuracy: 0.7556\n",
      "Epoch 00140: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 836us/sample - loss: 0.4582 - accuracy: 0.7945 - val_loss: 0.5470 - val_accuracy: 0.7297\n",
      "Epoch 141/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4917 - accuracy: 0.7556\n",
      "Epoch 00141: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 797us/sample - loss: 0.4478 - accuracy: 0.8014 - val_loss: 0.5464 - val_accuracy: 0.7297\n",
      "Epoch 142/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4793 - accuracy: 0.8200\n",
      "Epoch 00142: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 774us/sample - loss: 0.4494 - accuracy: 0.8219 - val_loss: 0.5318 - val_accuracy: 0.7297\n",
      "Epoch 143/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4052 - accuracy: 0.8400\n",
      "Epoch 00143: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 706us/sample - loss: 0.4488 - accuracy: 0.8014 - val_loss: 0.5447 - val_accuracy: 0.7297\n",
      "Epoch 144/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4403 - accuracy: 0.8200\n",
      "Epoch 00144: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 757us/sample - loss: 0.4558 - accuracy: 0.8014 - val_loss: 0.6004 - val_accuracy: 0.7027\n",
      "Epoch 145/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4129 - accuracy: 0.7889\n",
      "Epoch 00145: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 793us/sample - loss: 0.4281 - accuracy: 0.7945 - val_loss: 0.5264 - val_accuracy: 0.7297\n",
      "Epoch 146/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4435 - accuracy: 0.7900\n",
      "Epoch 00146: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 796us/sample - loss: 0.4186 - accuracy: 0.8082 - val_loss: 0.5490 - val_accuracy: 0.7297\n",
      "Epoch 147/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5149 - accuracy: 0.7556\n",
      "Epoch 00147: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 819us/sample - loss: 0.4555 - accuracy: 0.8151 - val_loss: 0.5251 - val_accuracy: 0.7297\n",
      "Epoch 148/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4372 - accuracy: 0.8000\n",
      "Epoch 00148: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 812us/sample - loss: 0.4395 - accuracy: 0.8082 - val_loss: 0.5257 - val_accuracy: 0.7297\n",
      "Epoch 149/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4734 - accuracy: 0.7778\n",
      "Epoch 00149: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 779us/sample - loss: 0.4740 - accuracy: 0.8014 - val_loss: 0.5751 - val_accuracy: 0.7297\n",
      "Epoch 150/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4228 - accuracy: 0.8111\n",
      "Epoch 00150: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 806us/sample - loss: 0.4470 - accuracy: 0.7945 - val_loss: 0.5427 - val_accuracy: 0.7297\n",
      "Epoch 151/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4311 - accuracy: 0.7889\n",
      "Epoch 00151: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 799us/sample - loss: 0.4354 - accuracy: 0.8151 - val_loss: 0.5687 - val_accuracy: 0.7297\n",
      "Epoch 152/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4259 - accuracy: 0.8444\n",
      "Epoch 00152: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 773us/sample - loss: 0.4359 - accuracy: 0.8288 - val_loss: 0.5420 - val_accuracy: 0.7297\n",
      "Epoch 153/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4536 - accuracy: 0.8111\n",
      "Epoch 00153: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.4439 - accuracy: 0.8014 - val_loss: 0.5565 - val_accuracy: 0.7297\n",
      "Epoch 154/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4009 - accuracy: 0.8600\n",
      "Epoch 00154: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 773us/sample - loss: 0.4311 - accuracy: 0.8151 - val_loss: 0.5253 - val_accuracy: 0.7297\n",
      "Epoch 155/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4373 - accuracy: 0.8400\n",
      "Epoch 00155: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 727us/sample - loss: 0.4312 - accuracy: 0.8151 - val_loss: 0.5240 - val_accuracy: 0.7297\n",
      "Epoch 156/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4501 - accuracy: 0.8111\n",
      "Epoch 00156: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 871us/sample - loss: 0.4335 - accuracy: 0.8288 - val_loss: 0.5161 - val_accuracy: 0.7297\n",
      "Epoch 157/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3820 - accuracy: 0.8444\n",
      "Epoch 00157: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 815us/sample - loss: 0.3911 - accuracy: 0.8356 - val_loss: 0.5196 - val_accuracy: 0.7297\n",
      "Epoch 158/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3555 - accuracy: 0.8556\n",
      "Epoch 00158: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 796us/sample - loss: 0.4399 - accuracy: 0.8219 - val_loss: 0.5218 - val_accuracy: 0.7297\n",
      "Epoch 159/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4104 - accuracy: 0.8556\n",
      "Epoch 00159: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 814us/sample - loss: 0.4243 - accuracy: 0.8493 - val_loss: 0.4897 - val_accuracy: 0.7297\n",
      "Epoch 160/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4145 - accuracy: 0.7889\n",
      "Epoch 00160: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 859us/sample - loss: 0.4296 - accuracy: 0.7877 - val_loss: 0.5459 - val_accuracy: 0.7297\n",
      "Epoch 161/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.3987 - accuracy: 0.8375\n",
      "Epoch 00161: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 872us/sample - loss: 0.3950 - accuracy: 0.8630 - val_loss: 0.4999 - val_accuracy: 0.7297\n",
      "Epoch 162/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5179 - accuracy: 0.7889\n",
      "Epoch 00162: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 787us/sample - loss: 0.4620 - accuracy: 0.8082 - val_loss: 0.5042 - val_accuracy: 0.7297\n",
      "Epoch 163/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4813 - accuracy: 0.8100\n",
      "Epoch 00163: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 0.4392 - accuracy: 0.8288 - val_loss: 0.5255 - val_accuracy: 0.7297\n",
      "Epoch 164/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4319 - accuracy: 0.8222\n",
      "Epoch 00164: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 780us/sample - loss: 0.4074 - accuracy: 0.8493 - val_loss: 0.4972 - val_accuracy: 0.7297\n",
      "Epoch 165/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3829 - accuracy: 0.8111\n",
      "Epoch 00165: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 772us/sample - loss: 0.4227 - accuracy: 0.8151 - val_loss: 0.5302 - val_accuracy: 0.7297\n",
      "Epoch 166/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4130 - accuracy: 0.8333\n",
      "Epoch 00166: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.4284 - accuracy: 0.8219 - val_loss: 0.5028 - val_accuracy: 0.7297\n",
      "Epoch 167/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4375 - accuracy: 0.8300\n",
      "Epoch 00167: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.4212 - accuracy: 0.8288 - val_loss: 0.5612 - val_accuracy: 0.7297\n",
      "Epoch 168/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4015 - accuracy: 0.8333\n",
      "Epoch 00168: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 810us/sample - loss: 0.4322 - accuracy: 0.8151 - val_loss: 0.4947 - val_accuracy: 0.7297\n",
      "Epoch 169/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3691 - accuracy: 0.8778\n",
      "Epoch 00169: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.3927 - accuracy: 0.8493 - val_loss: 0.5413 - val_accuracy: 0.7297\n",
      "Epoch 170/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4278 - accuracy: 0.8000\n",
      "Epoch 00170: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 804us/sample - loss: 0.4118 - accuracy: 0.8082 - val_loss: 0.4954 - val_accuracy: 0.7297\n",
      "Epoch 171/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4078 - accuracy: 0.8500\n",
      "Epoch 00171: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 0.4138 - accuracy: 0.8425 - val_loss: 0.5068 - val_accuracy: 0.7297\n",
      "Epoch 172/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3499 - accuracy: 0.9000\n",
      "Epoch 00172: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.3631 - accuracy: 0.8973 - val_loss: 0.4872 - val_accuracy: 0.7297\n",
      "Epoch 173/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4132 - accuracy: 0.8000\n",
      "Epoch 00173: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 765us/sample - loss: 0.4198 - accuracy: 0.8014 - val_loss: 0.5235 - val_accuracy: 0.7297\n",
      "Epoch 174/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4100 - accuracy: 0.8667\n",
      "Epoch 00174: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 801us/sample - loss: 0.3920 - accuracy: 0.8562 - val_loss: 0.4792 - val_accuracy: 0.7297\n",
      "Epoch 175/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4042 - accuracy: 0.8333\n",
      "Epoch 00175: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.4160 - accuracy: 0.8493 - val_loss: 0.5407 - val_accuracy: 0.7297\n",
      "Epoch 176/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4054 - accuracy: 0.8111\n",
      "Epoch 00176: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 807us/sample - loss: 0.4212 - accuracy: 0.8219 - val_loss: 0.4966 - val_accuracy: 0.7297\n",
      "Epoch 177/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.3598 - accuracy: 0.8750\n",
      "Epoch 00177: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 825us/sample - loss: 0.4144 - accuracy: 0.8219 - val_loss: 0.5394 - val_accuracy: 0.7297\n",
      "Epoch 178/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4224 - accuracy: 0.8556\n",
      "Epoch 00178: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 795us/sample - loss: 0.4166 - accuracy: 0.8425 - val_loss: 0.5231 - val_accuracy: 0.7297\n",
      "Epoch 179/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4131 - accuracy: 0.8444\n",
      "Epoch 00179: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 791us/sample - loss: 0.4070 - accuracy: 0.8493 - val_loss: 0.5249 - val_accuracy: 0.7297\n",
      "Epoch 180/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3594 - accuracy: 0.8444\n",
      "Epoch 00180: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 808us/sample - loss: 0.3986 - accuracy: 0.8356 - val_loss: 0.5312 - val_accuracy: 0.7297\n",
      "Epoch 181/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4158 - accuracy: 0.8200\n",
      "Epoch 00181: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.4124 - accuracy: 0.8151 - val_loss: 0.4837 - val_accuracy: 0.7297\n",
      "Epoch 182/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3978 - accuracy: 0.8200\n",
      "Epoch 00182: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 744us/sample - loss: 0.4102 - accuracy: 0.8219 - val_loss: 0.5003 - val_accuracy: 0.7297\n",
      "Epoch 183/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4276 - accuracy: 0.8100\n",
      "Epoch 00183: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 766us/sample - loss: 0.4203 - accuracy: 0.8425 - val_loss: 0.5235 - val_accuracy: 0.7297\n",
      "Epoch 184/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4313 - accuracy: 0.7889\n",
      "Epoch 00184: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 773us/sample - loss: 0.4134 - accuracy: 0.8082 - val_loss: 0.5117 - val_accuracy: 0.7297\n",
      "Epoch 185/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4316 - accuracy: 0.8111\n",
      "Epoch 00185: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.3971 - accuracy: 0.8493 - val_loss: 0.4907 - val_accuracy: 0.7297\n",
      "Epoch 186/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4451 - accuracy: 0.8444\n",
      "Epoch 00186: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 804us/sample - loss: 0.4306 - accuracy: 0.8425 - val_loss: 0.5091 - val_accuracy: 0.7297\n",
      "Epoch 187/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 0.4290 - accuracy: 0.8071\n",
      "Epoch 00187: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 956us/sample - loss: 0.4285 - accuracy: 0.8082 - val_loss: 0.5618 - val_accuracy: 0.7027\n",
      "Epoch 188/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3917 - accuracy: 0.8500\n",
      "Epoch 00188: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.4376 - accuracy: 0.8151 - val_loss: 0.4951 - val_accuracy: 0.7297\n",
      "Epoch 189/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3584 - accuracy: 0.8500\n",
      "Epoch 00189: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 763us/sample - loss: 0.4006 - accuracy: 0.8219 - val_loss: 0.5643 - val_accuracy: 0.6757\n",
      "Epoch 190/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3995 - accuracy: 0.8500\n",
      "Epoch 00190: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.3878 - accuracy: 0.8425 - val_loss: 0.4833 - val_accuracy: 0.7297\n",
      "Epoch 191/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3615 - accuracy: 0.8778\n",
      "Epoch 00191: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 783us/sample - loss: 0.4140 - accuracy: 0.8151 - val_loss: 0.5906 - val_accuracy: 0.6757\n",
      "Epoch 192/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3910 - accuracy: 0.8333\n",
      "Epoch 00192: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 785us/sample - loss: 0.4452 - accuracy: 0.8288 - val_loss: 0.4997 - val_accuracy: 0.7297\n",
      "Epoch 193/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3921 - accuracy: 0.8556\n",
      "Epoch 00193: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 797us/sample - loss: 0.3713 - accuracy: 0.8562 - val_loss: 0.4940 - val_accuracy: 0.7297\n",
      "Epoch 194/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3954 - accuracy: 0.8333\n",
      "Epoch 00194: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 821us/sample - loss: 0.3763 - accuracy: 0.8562 - val_loss: 0.4859 - val_accuracy: 0.7297\n",
      "Epoch 195/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3569 - accuracy: 0.8556\n",
      "Epoch 00195: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 779us/sample - loss: 0.3975 - accuracy: 0.8425 - val_loss: 0.4947 - val_accuracy: 0.7297\n",
      "Epoch 196/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4001 - accuracy: 0.8222\n",
      "Epoch 00196: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 784us/sample - loss: 0.3898 - accuracy: 0.8425 - val_loss: 0.5074 - val_accuracy: 0.7297\n",
      "Epoch 197/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3453 - accuracy: 0.8667\n",
      "Epoch 00197: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.3925 - accuracy: 0.8356 - val_loss: 0.5072 - val_accuracy: 0.7297\n",
      "Epoch 198/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4626 - accuracy: 0.7778\n",
      "Epoch 00198: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.4231 - accuracy: 0.8082 - val_loss: 0.5211 - val_accuracy: 0.7297\n",
      "Epoch 199/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4024 - accuracy: 0.8444\n",
      "Epoch 00199: val_accuracy did not improve from 0.72973\n",
      "146/146 [==============================] - 0s 774us/sample - loss: 0.3709 - accuracy: 0.8630 - val_loss: 0.5213 - val_accuracy: 0.7297\n",
      "Epoch 200/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4060 - accuracy: 0.8333\n",
      "Epoch 00200: val_accuracy improved from 0.72973 to 0.75676, saving model to models/CNN2_dataset_1_trim5_200.h5\n",
      "146/146 [==============================] - 0s 936us/sample - loss: 0.3685 - accuracy: 0.8562 - val_loss: 0.4727 - val_accuracy: 0.7568\n",
      "Epoch 201/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3603 - accuracy: 0.8222\n",
      "Epoch 00201: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 797us/sample - loss: 0.3877 - accuracy: 0.8082 - val_loss: 0.5386 - val_accuracy: 0.7297\n",
      "Epoch 202/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4197 - accuracy: 0.8222\n",
      "Epoch 00202: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 822us/sample - loss: 0.4051 - accuracy: 0.8356 - val_loss: 0.4528 - val_accuracy: 0.7297\n",
      "Epoch 203/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3714 - accuracy: 0.8200\n",
      "Epoch 00203: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 781us/sample - loss: 0.3610 - accuracy: 0.8493 - val_loss: 0.4979 - val_accuracy: 0.7297\n",
      "Epoch 204/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3199 - accuracy: 0.9111\n",
      "Epoch 00204: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 771us/sample - loss: 0.3734 - accuracy: 0.8630 - val_loss: 0.4896 - val_accuracy: 0.7297\n",
      "Epoch 205/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3604 - accuracy: 0.8556\n",
      "Epoch 00205: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 764us/sample - loss: 0.3955 - accuracy: 0.8630 - val_loss: 0.4720 - val_accuracy: 0.7297\n",
      "Epoch 206/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3404 - accuracy: 0.8556\n",
      "Epoch 00206: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 785us/sample - loss: 0.3797 - accuracy: 0.8425 - val_loss: 0.5074 - val_accuracy: 0.7297\n",
      "Epoch 207/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3317 - accuracy: 0.8889\n",
      "Epoch 00207: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 0.3544 - accuracy: 0.8699 - val_loss: 0.4493 - val_accuracy: 0.7568\n",
      "Epoch 208/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4207 - accuracy: 0.8778\n",
      "Epoch 00208: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 775us/sample - loss: 0.4013 - accuracy: 0.8699 - val_loss: 0.5317 - val_accuracy: 0.7297\n",
      "Epoch 209/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4283 - accuracy: 0.8222\n",
      "Epoch 00209: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 791us/sample - loss: 0.3850 - accuracy: 0.8562 - val_loss: 0.4942 - val_accuracy: 0.7297\n",
      "Epoch 210/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3737 - accuracy: 0.8400\n",
      "Epoch 00210: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 774us/sample - loss: 0.3823 - accuracy: 0.8493 - val_loss: 0.4846 - val_accuracy: 0.7297\n",
      "Epoch 211/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3843 - accuracy: 0.8500\n",
      "Epoch 00211: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 789us/sample - loss: 0.3656 - accuracy: 0.8699 - val_loss: 0.4983 - val_accuracy: 0.7297\n",
      "Epoch 212/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3651 - accuracy: 0.8667\n",
      "Epoch 00212: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 782us/sample - loss: 0.3645 - accuracy: 0.8630 - val_loss: 0.5437 - val_accuracy: 0.7027\n",
      "Epoch 213/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3516 - accuracy: 0.8444\n",
      "Epoch 00213: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 0.3664 - accuracy: 0.8425 - val_loss: 0.5086 - val_accuracy: 0.7297\n",
      "Epoch 214/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4029 - accuracy: 0.8556\n",
      "Epoch 00214: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 793us/sample - loss: 0.3783 - accuracy: 0.8630 - val_loss: 0.4790 - val_accuracy: 0.7297\n",
      "Epoch 215/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3157 - accuracy: 0.8667\n",
      "Epoch 00215: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.3592 - accuracy: 0.8562 - val_loss: 0.4524 - val_accuracy: 0.7568\n",
      "Epoch 216/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3961 - accuracy: 0.8333\n",
      "Epoch 00216: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 773us/sample - loss: 0.3686 - accuracy: 0.8356 - val_loss: 0.5278 - val_accuracy: 0.7027\n",
      "Epoch 217/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3329 - accuracy: 0.8800\n",
      "Epoch 00217: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 757us/sample - loss: 0.4231 - accuracy: 0.8219 - val_loss: 0.4879 - val_accuracy: 0.7297\n",
      "Epoch 218/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3555 - accuracy: 0.8500\n",
      "Epoch 00218: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 779us/sample - loss: 0.3935 - accuracy: 0.8151 - val_loss: 0.5047 - val_accuracy: 0.7297\n",
      "Epoch 219/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3686 - accuracy: 0.8556\n",
      "Epoch 00219: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 779us/sample - loss: 0.3933 - accuracy: 0.8356 - val_loss: 0.4731 - val_accuracy: 0.7297\n",
      "Epoch 220/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4204 - accuracy: 0.8000\n",
      "Epoch 00220: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 790us/sample - loss: 0.3980 - accuracy: 0.8219 - val_loss: 0.5240 - val_accuracy: 0.7027\n",
      "Epoch 221/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3853 - accuracy: 0.8500\n",
      "Epoch 00221: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 744us/sample - loss: 0.3628 - accuracy: 0.8699 - val_loss: 0.4650 - val_accuracy: 0.7297\n",
      "Epoch 222/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3831 - accuracy: 0.8556\n",
      "Epoch 00222: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 784us/sample - loss: 0.3807 - accuracy: 0.8356 - val_loss: 0.4903 - val_accuracy: 0.7297\n",
      "Epoch 223/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3625 - accuracy: 0.8444\n",
      "Epoch 00223: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.3842 - accuracy: 0.8288 - val_loss: 0.4917 - val_accuracy: 0.7297\n",
      "Epoch 224/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3837 - accuracy: 0.8333\n",
      "Epoch 00224: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 768us/sample - loss: 0.3777 - accuracy: 0.8356 - val_loss: 0.4937 - val_accuracy: 0.7297\n",
      "Epoch 225/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3596 - accuracy: 0.8667\n",
      "Epoch 00225: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 765us/sample - loss: 0.3690 - accuracy: 0.8562 - val_loss: 0.4953 - val_accuracy: 0.7297\n",
      "Epoch 226/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3521 - accuracy: 0.8444\n",
      "Epoch 00226: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 765us/sample - loss: 0.3233 - accuracy: 0.8699 - val_loss: 0.4794 - val_accuracy: 0.7568\n",
      "Epoch 227/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3572 - accuracy: 0.8778\n",
      "Epoch 00227: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 815us/sample - loss: 0.3536 - accuracy: 0.8767 - val_loss: 0.4965 - val_accuracy: 0.7297\n",
      "Epoch 228/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.4260 - accuracy: 0.8111\n",
      "Epoch 00228: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 806us/sample - loss: 0.3893 - accuracy: 0.8288 - val_loss: 0.4758 - val_accuracy: 0.7297\n",
      "Epoch 229/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3626 - accuracy: 0.8444\n",
      "Epoch 00229: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 804us/sample - loss: 0.3475 - accuracy: 0.8493 - val_loss: 0.5035 - val_accuracy: 0.7297\n",
      "Epoch 230/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3419 - accuracy: 0.8667\n",
      "Epoch 00230: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 787us/sample - loss: 0.3485 - accuracy: 0.8493 - val_loss: 0.5069 - val_accuracy: 0.7297\n",
      "Epoch 231/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3444 - accuracy: 0.8778\n",
      "Epoch 00231: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 750us/sample - loss: 0.3374 - accuracy: 0.8630 - val_loss: 0.4646 - val_accuracy: 0.7568\n",
      "Epoch 232/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.4231 - accuracy: 0.8000\n",
      "Epoch 00232: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 975us/sample - loss: 0.3716 - accuracy: 0.8425 - val_loss: 0.5030 - val_accuracy: 0.7297\n",
      "Epoch 233/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3771 - accuracy: 0.8700\n",
      "Epoch 00233: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.3769 - accuracy: 0.8562 - val_loss: 0.4862 - val_accuracy: 0.7297\n",
      "Epoch 234/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3173 - accuracy: 0.8800\n",
      "Epoch 00234: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 738us/sample - loss: 0.3247 - accuracy: 0.8767 - val_loss: 0.4924 - val_accuracy: 0.7297\n",
      "Epoch 235/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3285 - accuracy: 0.8333\n",
      "Epoch 00235: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.3458 - accuracy: 0.8562 - val_loss: 0.4997 - val_accuracy: 0.7297\n",
      "Epoch 236/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3436 - accuracy: 0.8556\n",
      "Epoch 00236: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 775us/sample - loss: 0.3934 - accuracy: 0.8493 - val_loss: 0.5242 - val_accuracy: 0.7027\n",
      "Epoch 237/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4275 - accuracy: 0.7800\n",
      "Epoch 00237: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 745us/sample - loss: 0.4062 - accuracy: 0.8151 - val_loss: 0.5169 - val_accuracy: 0.7027\n",
      "Epoch 238/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3886 - accuracy: 0.8111\n",
      "Epoch 00238: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 797us/sample - loss: 0.3670 - accuracy: 0.8493 - val_loss: 0.4601 - val_accuracy: 0.7297\n",
      "Epoch 239/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3440 - accuracy: 0.8444\n",
      "Epoch 00239: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 762us/sample - loss: 0.3406 - accuracy: 0.8493 - val_loss: 0.5038 - val_accuracy: 0.7297\n",
      "Epoch 240/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2796 - accuracy: 0.9000\n",
      "Epoch 00240: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 744us/sample - loss: 0.3402 - accuracy: 0.8562 - val_loss: 0.4342 - val_accuracy: 0.7568\n",
      "Epoch 241/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3909 - accuracy: 0.8222\n",
      "Epoch 00241: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 765us/sample - loss: 0.3486 - accuracy: 0.8630 - val_loss: 0.5163 - val_accuracy: 0.7027\n",
      "Epoch 242/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3782 - accuracy: 0.8444\n",
      "Epoch 00242: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 766us/sample - loss: 0.3575 - accuracy: 0.8699 - val_loss: 0.4692 - val_accuracy: 0.7568\n",
      "Epoch 243/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3386 - accuracy: 0.8900\n",
      "Epoch 00243: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 762us/sample - loss: 0.3718 - accuracy: 0.8562 - val_loss: 0.4995 - val_accuracy: 0.7297\n",
      "Epoch 244/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3448 - accuracy: 0.8778\n",
      "Epoch 00244: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 806us/sample - loss: 0.3640 - accuracy: 0.8493 - val_loss: 0.4669 - val_accuracy: 0.7297\n",
      "Epoch 245/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3785 - accuracy: 0.8444\n",
      "Epoch 00245: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 777us/sample - loss: 0.3563 - accuracy: 0.8630 - val_loss: 0.4806 - val_accuracy: 0.7297\n",
      "Epoch 246/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3125 - accuracy: 0.8778\n",
      "Epoch 00246: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 759us/sample - loss: 0.3477 - accuracy: 0.8425 - val_loss: 0.4654 - val_accuracy: 0.7297\n",
      "Epoch 247/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3196 - accuracy: 0.8556\n",
      "Epoch 00247: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 783us/sample - loss: 0.3562 - accuracy: 0.8425 - val_loss: 0.5045 - val_accuracy: 0.7297\n",
      "Epoch 248/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3209 - accuracy: 0.8700\n",
      "Epoch 00248: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 790us/sample - loss: 0.3468 - accuracy: 0.8425 - val_loss: 0.4998 - val_accuracy: 0.7297\n",
      "Epoch 249/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3967 - accuracy: 0.8556\n",
      "Epoch 00249: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.3630 - accuracy: 0.8562 - val_loss: 0.4823 - val_accuracy: 0.7297\n",
      "Epoch 250/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3795 - accuracy: 0.8222\n",
      "Epoch 00250: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 0.3674 - accuracy: 0.8493 - val_loss: 0.5272 - val_accuracy: 0.7027\n",
      "Epoch 251/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3111 - accuracy: 0.9000\n",
      "Epoch 00251: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.3068 - accuracy: 0.8904 - val_loss: 0.4330 - val_accuracy: 0.7568\n",
      "Epoch 252/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3868 - accuracy: 0.8222\n",
      "Epoch 00252: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 782us/sample - loss: 0.3420 - accuracy: 0.8630 - val_loss: 0.5416 - val_accuracy: 0.7027\n",
      "Epoch 253/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3462 - accuracy: 0.8444\n",
      "Epoch 00253: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 793us/sample - loss: 0.3549 - accuracy: 0.8356 - val_loss: 0.4737 - val_accuracy: 0.7297\n",
      "Epoch 254/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3281 - accuracy: 0.8778\n",
      "Epoch 00254: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 796us/sample - loss: 0.3378 - accuracy: 0.8425 - val_loss: 0.4916 - val_accuracy: 0.7297\n",
      "Epoch 255/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3195 - accuracy: 0.8667\n",
      "Epoch 00255: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 772us/sample - loss: 0.3242 - accuracy: 0.8630 - val_loss: 0.4863 - val_accuracy: 0.7297\n",
      "Epoch 256/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3160 - accuracy: 0.9000\n",
      "Epoch 00256: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.3103 - accuracy: 0.8904 - val_loss: 0.4758 - val_accuracy: 0.7297\n",
      "Epoch 257/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3048 - accuracy: 0.8778\n",
      "Epoch 00257: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 777us/sample - loss: 0.3477 - accuracy: 0.8699 - val_loss: 0.5280 - val_accuracy: 0.7027\n",
      "Epoch 258/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3069 - accuracy: 0.8700\n",
      "Epoch 00258: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.3119 - accuracy: 0.8767 - val_loss: 0.5198 - val_accuracy: 0.7027\n",
      "Epoch 259/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3824 - accuracy: 0.8400\n",
      "Epoch 00259: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.3654 - accuracy: 0.8288 - val_loss: 0.5774 - val_accuracy: 0.7027\n",
      "Epoch 260/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3314 - accuracy: 0.9000\n",
      "Epoch 00260: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 0.3164 - accuracy: 0.8904 - val_loss: 0.4808 - val_accuracy: 0.7297\n",
      "Epoch 261/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3809 - accuracy: 0.8333\n",
      "Epoch 00261: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 760us/sample - loss: 0.3482 - accuracy: 0.8699 - val_loss: 0.5521 - val_accuracy: 0.7027\n",
      "Epoch 262/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3227 - accuracy: 0.8400\n",
      "Epoch 00262: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 743us/sample - loss: 0.3176 - accuracy: 0.8493 - val_loss: 0.4660 - val_accuracy: 0.7027\n",
      "Epoch 263/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3261 - accuracy: 0.8778\n",
      "Epoch 00263: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.3436 - accuracy: 0.8630 - val_loss: 0.4549 - val_accuracy: 0.7297\n",
      "Epoch 264/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2682 - accuracy: 0.8778\n",
      "Epoch 00264: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.3168 - accuracy: 0.8630 - val_loss: 0.5432 - val_accuracy: 0.7027\n",
      "Epoch 265/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2764 - accuracy: 0.9200\n",
      "Epoch 00265: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 760us/sample - loss: 0.3733 - accuracy: 0.8699 - val_loss: 0.5106 - val_accuracy: 0.7027\n",
      "Epoch 266/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3395 - accuracy: 0.8556\n",
      "Epoch 00266: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 812us/sample - loss: 0.3375 - accuracy: 0.8493 - val_loss: 0.4764 - val_accuracy: 0.7297\n",
      "Epoch 267/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3323 - accuracy: 0.9000\n",
      "Epoch 00267: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 750us/sample - loss: 0.3321 - accuracy: 0.8630 - val_loss: 0.4773 - val_accuracy: 0.7297\n",
      "Epoch 268/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3336 - accuracy: 0.8556\n",
      "Epoch 00268: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.3240 - accuracy: 0.8699 - val_loss: 0.4231 - val_accuracy: 0.7568\n",
      "Epoch 269/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.3410 - accuracy: 0.8875\n",
      "Epoch 00269: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 826us/sample - loss: 0.3320 - accuracy: 0.8836 - val_loss: 0.4587 - val_accuracy: 0.7297\n",
      "Epoch 270/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.3470 - accuracy: 0.8500\n",
      "Epoch 00270: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 813us/sample - loss: 0.3266 - accuracy: 0.8699 - val_loss: 0.5059 - val_accuracy: 0.7027\n",
      "Epoch 271/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3563 - accuracy: 0.8556\n",
      "Epoch 00271: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 811us/sample - loss: 0.3153 - accuracy: 0.8836 - val_loss: 0.4879 - val_accuracy: 0.7027\n",
      "Epoch 272/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3491 - accuracy: 0.8400\n",
      "Epoch 00272: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 0.3220 - accuracy: 0.8767 - val_loss: 0.4891 - val_accuracy: 0.7027\n",
      "Epoch 273/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3474 - accuracy: 0.8444\n",
      "Epoch 00273: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 790us/sample - loss: 0.3222 - accuracy: 0.8562 - val_loss: 0.4665 - val_accuracy: 0.7297\n",
      "Epoch 274/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3169 - accuracy: 0.8667\n",
      "Epoch 00274: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 751us/sample - loss: 0.3004 - accuracy: 0.8699 - val_loss: 0.4781 - val_accuracy: 0.7297\n",
      "Epoch 275/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2690 - accuracy: 0.8889\n",
      "Epoch 00275: val_accuracy did not improve from 0.75676\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.2712 - accuracy: 0.8973 - val_loss: 0.5117 - val_accuracy: 0.7027\n",
      "Epoch 276/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2851 - accuracy: 0.9111\n",
      "Epoch 00276: val_accuracy improved from 0.75676 to 0.78378, saving model to models/CNN2_dataset_1_trim5_276.h5\n",
      "146/146 [==============================] - 0s 949us/sample - loss: 0.2831 - accuracy: 0.9178 - val_loss: 0.4385 - val_accuracy: 0.7838\n",
      "Epoch 277/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3436 - accuracy: 0.8667\n",
      "Epoch 00277: val_accuracy did not improve from 0.78378\n",
      "146/146 [==============================] - 0s 773us/sample - loss: 0.3409 - accuracy: 0.8562 - val_loss: 0.5352 - val_accuracy: 0.7027\n",
      "Epoch 278/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2925 - accuracy: 0.8800\n",
      "Epoch 00278: val_accuracy did not improve from 0.78378\n",
      "146/146 [==============================] - 0s 745us/sample - loss: 0.2946 - accuracy: 0.8904 - val_loss: 0.4740 - val_accuracy: 0.7027\n",
      "Epoch 279/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2563 - accuracy: 0.9111\n",
      "Epoch 00279: val_accuracy did not improve from 0.78378\n",
      "146/146 [==============================] - 0s 775us/sample - loss: 0.2854 - accuracy: 0.8904 - val_loss: 0.4829 - val_accuracy: 0.7027\n",
      "Epoch 280/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3237 - accuracy: 0.8889\n",
      "Epoch 00280: val_accuracy did not improve from 0.78378\n",
      "146/146 [==============================] - 0s 784us/sample - loss: 0.3360 - accuracy: 0.8699 - val_loss: 0.5399 - val_accuracy: 0.7027\n",
      "Epoch 281/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2548 - accuracy: 0.9000\n",
      "Epoch 00281: val_accuracy improved from 0.78378 to 0.81081, saving model to models/CNN2_dataset_1_trim5_281.h5\n",
      "146/146 [==============================] - 0s 954us/sample - loss: 0.2825 - accuracy: 0.8767 - val_loss: 0.3971 - val_accuracy: 0.8108\n",
      "Epoch 282/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3004 - accuracy: 0.8556\n",
      "Epoch 00282: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.2902 - accuracy: 0.8699 - val_loss: 0.4923 - val_accuracy: 0.7027\n",
      "Epoch 283/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3066 - accuracy: 0.8667\n",
      "Epoch 00283: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 760us/sample - loss: 0.3107 - accuracy: 0.8562 - val_loss: 0.4516 - val_accuracy: 0.7027\n",
      "Epoch 284/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2595 - accuracy: 0.9000\n",
      "Epoch 00284: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.2579 - accuracy: 0.9041 - val_loss: 0.4250 - val_accuracy: 0.7838\n",
      "Epoch 285/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3037 - accuracy: 0.8800\n",
      "Epoch 00285: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.2890 - accuracy: 0.8904 - val_loss: 0.5454 - val_accuracy: 0.7027\n",
      "Epoch 286/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2869 - accuracy: 0.8778\n",
      "Epoch 00286: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 772us/sample - loss: 0.3012 - accuracy: 0.8767 - val_loss: 0.4122 - val_accuracy: 0.8108\n",
      "Epoch 287/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3113 - accuracy: 0.8444\n",
      "Epoch 00287: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.2983 - accuracy: 0.8767 - val_loss: 0.4978 - val_accuracy: 0.7027\n",
      "Epoch 288/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2503 - accuracy: 0.9000\n",
      "Epoch 00288: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.2955 - accuracy: 0.8973 - val_loss: 0.3772 - val_accuracy: 0.8108\n",
      "Epoch 289/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2850 - accuracy: 0.9000\n",
      "Epoch 00289: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 773us/sample - loss: 0.2834 - accuracy: 0.8904 - val_loss: 0.4484 - val_accuracy: 0.7027\n",
      "Epoch 290/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2769 - accuracy: 0.9111\n",
      "Epoch 00290: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 774us/sample - loss: 0.2823 - accuracy: 0.9041 - val_loss: 0.4918 - val_accuracy: 0.7027\n",
      "Epoch 291/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2887 - accuracy: 0.9111\n",
      "Epoch 00291: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.2760 - accuracy: 0.9110 - val_loss: 0.4602 - val_accuracy: 0.7297\n",
      "Epoch 292/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3081 - accuracy: 0.8778\n",
      "Epoch 00292: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 762us/sample - loss: 0.2807 - accuracy: 0.8904 - val_loss: 0.4401 - val_accuracy: 0.7297\n",
      "Epoch 293/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.2680 - accuracy: 0.9000\n",
      "Epoch 00293: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 979us/sample - loss: 0.3032 - accuracy: 0.8904 - val_loss: 0.5710 - val_accuracy: 0.7027\n",
      "Epoch 294/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3108 - accuracy: 0.8300\n",
      "Epoch 00294: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.3103 - accuracy: 0.8356 - val_loss: 0.4126 - val_accuracy: 0.7838\n",
      "Epoch 295/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2638 - accuracy: 0.8800\n",
      "Epoch 00295: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.2647 - accuracy: 0.8836 - val_loss: 0.4544 - val_accuracy: 0.7297\n",
      "Epoch 296/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2904 - accuracy: 0.8700\n",
      "Epoch 00296: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.2865 - accuracy: 0.8836 - val_loss: 0.5202 - val_accuracy: 0.7027\n",
      "Epoch 297/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2609 - accuracy: 0.9333\n",
      "Epoch 00297: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 758us/sample - loss: 0.2414 - accuracy: 0.9384 - val_loss: 0.4005 - val_accuracy: 0.7838\n",
      "Epoch 298/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2881 - accuracy: 0.8889\n",
      "Epoch 00298: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.2746 - accuracy: 0.8973 - val_loss: 0.4881 - val_accuracy: 0.7297\n",
      "Epoch 299/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2225 - accuracy: 0.9444\n",
      "Epoch 00299: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 754us/sample - loss: 0.2807 - accuracy: 0.8836 - val_loss: 0.4619 - val_accuracy: 0.7297\n",
      "Epoch 300/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2899 - accuracy: 0.8667\n",
      "Epoch 00300: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 750us/sample - loss: 0.2774 - accuracy: 0.8904 - val_loss: 0.4602 - val_accuracy: 0.7297\n",
      "Epoch 301/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2683 - accuracy: 0.9000\n",
      "Epoch 00301: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 763us/sample - loss: 0.2718 - accuracy: 0.8836 - val_loss: 0.4087 - val_accuracy: 0.7838\n",
      "Epoch 302/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2476 - accuracy: 0.9222\n",
      "Epoch 00302: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 790us/sample - loss: 0.2670 - accuracy: 0.9041 - val_loss: 0.4436 - val_accuracy: 0.7297\n",
      "Epoch 303/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2332 - accuracy: 0.9222\n",
      "Epoch 00303: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.2570 - accuracy: 0.9247 - val_loss: 0.4302 - val_accuracy: 0.7568\n",
      "Epoch 304/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2832 - accuracy: 0.9100\n",
      "Epoch 00304: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.2593 - accuracy: 0.9247 - val_loss: 0.4587 - val_accuracy: 0.7297\n",
      "Epoch 305/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2630 - accuracy: 0.9222\n",
      "Epoch 00305: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 743us/sample - loss: 0.2323 - accuracy: 0.9315 - val_loss: 0.4348 - val_accuracy: 0.7568\n",
      "Epoch 306/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2770 - accuracy: 0.8889\n",
      "Epoch 00306: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 751us/sample - loss: 0.2486 - accuracy: 0.9178 - val_loss: 0.4139 - val_accuracy: 0.7568\n",
      "Epoch 307/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2242 - accuracy: 0.9200\n",
      "Epoch 00307: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 739us/sample - loss: 0.2262 - accuracy: 0.9178 - val_loss: 0.3525 - val_accuracy: 0.8108\n",
      "Epoch 308/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2088 - accuracy: 0.9444\n",
      "Epoch 00308: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 753us/sample - loss: 0.2433 - accuracy: 0.9178 - val_loss: 0.5129 - val_accuracy: 0.7027\n",
      "Epoch 309/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3137 - accuracy: 0.8333\n",
      "Epoch 00309: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.2814 - accuracy: 0.8699 - val_loss: 0.4075 - val_accuracy: 0.7838\n",
      "Epoch 310/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2176 - accuracy: 0.9400\n",
      "Epoch 00310: val_accuracy did not improve from 0.81081\n",
      "146/146 [==============================] - 0s 758us/sample - loss: 0.2161 - accuracy: 0.9384 - val_loss: 0.5083 - val_accuracy: 0.7027\n",
      "Epoch 311/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2312 - accuracy: 0.9200\n",
      "Epoch 00311: val_accuracy improved from 0.81081 to 0.83784, saving model to models/CNN2_dataset_1_trim5_311.h5\n",
      "146/146 [==============================] - 0s 925us/sample - loss: 0.2546 - accuracy: 0.8973 - val_loss: 0.3214 - val_accuracy: 0.8378\n",
      "Epoch 312/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2745 - accuracy: 0.9222\n",
      "Epoch 00312: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.2574 - accuracy: 0.9178 - val_loss: 0.4769 - val_accuracy: 0.7027\n",
      "Epoch 313/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2121 - accuracy: 0.9222\n",
      "Epoch 00313: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 731us/sample - loss: 0.2452 - accuracy: 0.9178 - val_loss: 0.3993 - val_accuracy: 0.7838\n",
      "Epoch 314/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2318 - accuracy: 0.9222\n",
      "Epoch 00314: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.2512 - accuracy: 0.9110 - val_loss: 0.4549 - val_accuracy: 0.7297\n",
      "Epoch 315/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2123 - accuracy: 0.9400\n",
      "Epoch 00315: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.2150 - accuracy: 0.9521 - val_loss: 0.3149 - val_accuracy: 0.8108\n",
      "Epoch 316/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2741 - accuracy: 0.9000\n",
      "Epoch 00316: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 766us/sample - loss: 0.2594 - accuracy: 0.9110 - val_loss: 0.5334 - val_accuracy: 0.7027\n",
      "Epoch 317/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3003 - accuracy: 0.8778\n",
      "Epoch 00317: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.2580 - accuracy: 0.9041 - val_loss: 0.3287 - val_accuracy: 0.8108\n",
      "Epoch 318/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2671 - accuracy: 0.9111\n",
      "Epoch 00318: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.2439 - accuracy: 0.9041 - val_loss: 0.3657 - val_accuracy: 0.8108\n",
      "Epoch 319/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2560 - accuracy: 0.9000\n",
      "Epoch 00319: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 763us/sample - loss: 0.2190 - accuracy: 0.9247 - val_loss: 0.4447 - val_accuracy: 0.7838\n",
      "Epoch 320/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2669 - accuracy: 0.9000\n",
      "Epoch 00320: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 759us/sample - loss: 0.2518 - accuracy: 0.9041 - val_loss: 0.5371 - val_accuracy: 0.7027\n",
      "Epoch 321/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2821 - accuracy: 0.9100\n",
      "Epoch 00321: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.2603 - accuracy: 0.9247 - val_loss: 0.3581 - val_accuracy: 0.7838\n",
      "Epoch 322/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2346 - accuracy: 0.9300\n",
      "Epoch 00322: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 733us/sample - loss: 0.2242 - accuracy: 0.9247 - val_loss: 0.4741 - val_accuracy: 0.7568\n",
      "Epoch 323/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1979 - accuracy: 0.9500\n",
      "Epoch 00323: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 745us/sample - loss: 0.2067 - accuracy: 0.9384 - val_loss: 0.3317 - val_accuracy: 0.8108\n",
      "Epoch 324/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2142 - accuracy: 0.9300\n",
      "Epoch 00324: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 721us/sample - loss: 0.2180 - accuracy: 0.9384 - val_loss: 0.4203 - val_accuracy: 0.7838\n",
      "Epoch 325/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2424 - accuracy: 0.8800\n",
      "Epoch 00325: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.2442 - accuracy: 0.8973 - val_loss: 0.3968 - val_accuracy: 0.7838\n",
      "Epoch 326/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1700 - accuracy: 0.9556\n",
      "Epoch 00326: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.1902 - accuracy: 0.9521 - val_loss: 0.3772 - val_accuracy: 0.7838\n",
      "Epoch 327/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2421 - accuracy: 0.9556\n",
      "Epoch 00327: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 757us/sample - loss: 0.2401 - accuracy: 0.9521 - val_loss: 0.4609 - val_accuracy: 0.7568\n",
      "Epoch 328/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2732 - accuracy: 0.8889\n",
      "Epoch 00328: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 791us/sample - loss: 0.2332 - accuracy: 0.9247 - val_loss: 0.3905 - val_accuracy: 0.7838\n",
      "Epoch 329/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2318 - accuracy: 0.9444\n",
      "Epoch 00329: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 802us/sample - loss: 0.2460 - accuracy: 0.9315 - val_loss: 0.4134 - val_accuracy: 0.7838\n",
      "Epoch 330/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2565 - accuracy: 0.8778\n",
      "Epoch 00330: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.2328 - accuracy: 0.9041 - val_loss: 0.4363 - val_accuracy: 0.7838\n",
      "Epoch 331/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2098 - accuracy: 0.9400\n",
      "Epoch 00331: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.2176 - accuracy: 0.9384 - val_loss: 0.4766 - val_accuracy: 0.7838\n",
      "Epoch 332/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1872 - accuracy: 0.9444\n",
      "Epoch 00332: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.2124 - accuracy: 0.9247 - val_loss: 0.4183 - val_accuracy: 0.7838\n",
      "Epoch 333/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2532 - accuracy: 0.9100\n",
      "Epoch 00333: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 742us/sample - loss: 0.2205 - accuracy: 0.9384 - val_loss: 0.5226 - val_accuracy: 0.7027\n",
      "Epoch 334/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2529 - accuracy: 0.8667\n",
      "Epoch 00334: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.2420 - accuracy: 0.8767 - val_loss: 0.3544 - val_accuracy: 0.8108\n",
      "Epoch 335/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2545 - accuracy: 0.9400\n",
      "Epoch 00335: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.2512 - accuracy: 0.9178 - val_loss: 0.4603 - val_accuracy: 0.7568\n",
      "Epoch 336/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2491 - accuracy: 0.9000\n",
      "Epoch 00336: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 763us/sample - loss: 0.2593 - accuracy: 0.8836 - val_loss: 0.4253 - val_accuracy: 0.7568\n",
      "Epoch 337/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1800 - accuracy: 0.9667\n",
      "Epoch 00337: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 751us/sample - loss: 0.1998 - accuracy: 0.9521 - val_loss: 0.3355 - val_accuracy: 0.8108\n",
      "Epoch 338/500\n",
      " 70/146 [=============>................] - ETA: 0s - loss: 0.2319 - accuracy: 0.8857\n",
      "Epoch 00338: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 982us/sample - loss: 0.2317 - accuracy: 0.8904 - val_loss: 0.3713 - val_accuracy: 0.7838\n",
      "Epoch 339/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2479 - accuracy: 0.9200\n",
      "Epoch 00339: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 778us/sample - loss: 0.2533 - accuracy: 0.9110 - val_loss: 0.4252 - val_accuracy: 0.7838\n",
      "Epoch 340/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2029 - accuracy: 0.9400\n",
      "Epoch 00340: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 718us/sample - loss: 0.2051 - accuracy: 0.9452 - val_loss: 0.3319 - val_accuracy: 0.8108\n",
      "Epoch 341/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2069 - accuracy: 0.9700\n",
      "Epoch 00341: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.2055 - accuracy: 0.9589 - val_loss: 0.3556 - val_accuracy: 0.7838\n",
      "Epoch 342/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1994 - accuracy: 0.9200\n",
      "Epoch 00342: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 783us/sample - loss: 0.2066 - accuracy: 0.9315 - val_loss: 0.4640 - val_accuracy: 0.7838\n",
      "Epoch 343/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1879 - accuracy: 0.9111\n",
      "Epoch 00343: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 822us/sample - loss: 0.1979 - accuracy: 0.9041 - val_loss: 0.3658 - val_accuracy: 0.7838\n",
      "Epoch 344/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1882 - accuracy: 0.9444\n",
      "Epoch 00344: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 804us/sample - loss: 0.2335 - accuracy: 0.9041 - val_loss: 0.4362 - val_accuracy: 0.7838\n",
      "Epoch 345/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2015 - accuracy: 0.9333\n",
      "Epoch 00345: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 814us/sample - loss: 0.1831 - accuracy: 0.9452 - val_loss: 0.3601 - val_accuracy: 0.7838\n",
      "Epoch 346/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1803 - accuracy: 0.9444\n",
      "Epoch 00346: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 814us/sample - loss: 0.1745 - accuracy: 0.9452 - val_loss: 0.3820 - val_accuracy: 0.7838\n",
      "Epoch 347/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.1798 - accuracy: 0.9625\n",
      "Epoch 00347: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 863us/sample - loss: 0.1954 - accuracy: 0.9452 - val_loss: 0.3756 - val_accuracy: 0.7838\n",
      "Epoch 348/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2285 - accuracy: 0.9222\n",
      "Epoch 00348: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 795us/sample - loss: 0.1968 - accuracy: 0.9384 - val_loss: 0.4586 - val_accuracy: 0.7838\n",
      "Epoch 349/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1846 - accuracy: 0.9333\n",
      "Epoch 00349: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 791us/sample - loss: 0.1898 - accuracy: 0.9452 - val_loss: 0.3127 - val_accuracy: 0.8108\n",
      "Epoch 350/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2161 - accuracy: 0.9111\n",
      "Epoch 00350: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 751us/sample - loss: 0.2162 - accuracy: 0.9247 - val_loss: 0.3867 - val_accuracy: 0.7838\n",
      "Epoch 351/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2103 - accuracy: 0.9111\n",
      "Epoch 00351: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.2205 - accuracy: 0.8973 - val_loss: 0.3558 - val_accuracy: 0.7838\n",
      "Epoch 352/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1707 - accuracy: 0.9556\n",
      "Epoch 00352: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 825us/sample - loss: 0.2267 - accuracy: 0.9178 - val_loss: 0.5150 - val_accuracy: 0.7027\n",
      "Epoch 353/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1864 - accuracy: 0.9444\n",
      "Epoch 00353: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 0.1880 - accuracy: 0.9452 - val_loss: 0.3628 - val_accuracy: 0.7838\n",
      "Epoch 354/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2028 - accuracy: 0.9222\n",
      "Epoch 00354: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 802us/sample - loss: 0.2158 - accuracy: 0.9110 - val_loss: 0.4286 - val_accuracy: 0.7568\n",
      "Epoch 355/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1699 - accuracy: 0.9556\n",
      "Epoch 00355: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 835us/sample - loss: 0.1927 - accuracy: 0.9384 - val_loss: 0.3819 - val_accuracy: 0.7568\n",
      "Epoch 356/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2424 - accuracy: 0.9000\n",
      "Epoch 00356: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.2317 - accuracy: 0.9178 - val_loss: 0.4712 - val_accuracy: 0.7568\n",
      "Epoch 357/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2389 - accuracy: 0.9200\n",
      "Epoch 00357: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 0.2065 - accuracy: 0.9384 - val_loss: 0.2956 - val_accuracy: 0.8108\n",
      "Epoch 358/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1882 - accuracy: 0.9444\n",
      "Epoch 00358: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 793us/sample - loss: 0.1806 - accuracy: 0.9521 - val_loss: 0.3760 - val_accuracy: 0.7838\n",
      "Epoch 359/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1598 - accuracy: 0.9333\n",
      "Epoch 00359: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 760us/sample - loss: 0.1761 - accuracy: 0.9384 - val_loss: 0.3565 - val_accuracy: 0.7838\n",
      "Epoch 360/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2032 - accuracy: 0.9300\n",
      "Epoch 00360: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.1937 - accuracy: 0.9384 - val_loss: 0.4779 - val_accuracy: 0.7297\n",
      "Epoch 361/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2367 - accuracy: 0.9111\n",
      "Epoch 00361: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.2302 - accuracy: 0.9110 - val_loss: 0.3664 - val_accuracy: 0.7838\n",
      "Epoch 362/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1970 - accuracy: 0.9100\n",
      "Epoch 00362: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.1883 - accuracy: 0.9247 - val_loss: 0.3604 - val_accuracy: 0.7838\n",
      "Epoch 363/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1520 - accuracy: 0.9700\n",
      "Epoch 00363: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.1909 - accuracy: 0.9384 - val_loss: 0.3923 - val_accuracy: 0.7838\n",
      "Epoch 364/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2386 - accuracy: 0.9100\n",
      "Epoch 00364: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.2205 - accuracy: 0.9110 - val_loss: 0.3569 - val_accuracy: 0.7838\n",
      "Epoch 365/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1876 - accuracy: 0.9300\n",
      "Epoch 00365: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 688us/sample - loss: 0.1947 - accuracy: 0.9247 - val_loss: 0.3935 - val_accuracy: 0.7838\n",
      "Epoch 366/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 0.2006 - accuracy: 0.9286\n",
      "Epoch 00366: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 887us/sample - loss: 0.1994 - accuracy: 0.9247 - val_loss: 0.4280 - val_accuracy: 0.7838\n",
      "Epoch 367/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2209 - accuracy: 0.8900\n",
      "Epoch 00367: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 750us/sample - loss: 0.2012 - accuracy: 0.9110 - val_loss: 0.3225 - val_accuracy: 0.8108\n",
      "Epoch 368/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2999 - accuracy: 0.8900\n",
      "Epoch 00368: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.2622 - accuracy: 0.9041 - val_loss: 0.5205 - val_accuracy: 0.7027\n",
      "Epoch 369/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1903 - accuracy: 0.9364\n",
      "Epoch 00369: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 667us/sample - loss: 0.1811 - accuracy: 0.9452 - val_loss: 0.3485 - val_accuracy: 0.8108\n",
      "Epoch 370/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1929 - accuracy: 0.9400\n",
      "Epoch 00370: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.2062 - accuracy: 0.9384 - val_loss: 0.3852 - val_accuracy: 0.7838\n",
      "Epoch 371/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2117 - accuracy: 0.9100\n",
      "Epoch 00371: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.1922 - accuracy: 0.9178 - val_loss: 0.3442 - val_accuracy: 0.8108\n",
      "Epoch 372/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1856 - accuracy: 0.9400\n",
      "Epoch 00372: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 721us/sample - loss: 0.2023 - accuracy: 0.9247 - val_loss: 0.3784 - val_accuracy: 0.7838\n",
      "Epoch 373/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2065 - accuracy: 0.9300\n",
      "Epoch 00373: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 0.2190 - accuracy: 0.9247 - val_loss: 0.3413 - val_accuracy: 0.8108\n",
      "Epoch 374/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1601 - accuracy: 0.9500\n",
      "Epoch 00374: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.1722 - accuracy: 0.9452 - val_loss: 0.3782 - val_accuracy: 0.7838\n",
      "Epoch 375/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1708 - accuracy: 0.9500\n",
      "Epoch 00375: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 0.1918 - accuracy: 0.9315 - val_loss: 0.3843 - val_accuracy: 0.7838\n",
      "Epoch 376/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1841 - accuracy: 0.9300\n",
      "Epoch 00376: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.1675 - accuracy: 0.9452 - val_loss: 0.3209 - val_accuracy: 0.8378\n",
      "Epoch 377/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2042 - accuracy: 0.9200\n",
      "Epoch 00377: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.1808 - accuracy: 0.9384 - val_loss: 0.3629 - val_accuracy: 0.7838\n",
      "Epoch 378/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1459 - accuracy: 0.9800\n",
      "Epoch 00378: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 692us/sample - loss: 0.1675 - accuracy: 0.9589 - val_loss: 0.3532 - val_accuracy: 0.7838\n",
      "Epoch 379/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1931 - accuracy: 0.9400\n",
      "Epoch 00379: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 692us/sample - loss: 0.2234 - accuracy: 0.9384 - val_loss: 0.4057 - val_accuracy: 0.7838\n",
      "Epoch 380/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2013 - accuracy: 0.9100\n",
      "Epoch 00380: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 740us/sample - loss: 0.2178 - accuracy: 0.9041 - val_loss: 0.4481 - val_accuracy: 0.7838\n",
      "Epoch 381/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1503 - accuracy: 0.9600\n",
      "Epoch 00381: val_accuracy improved from 0.83784 to 0.86486, saving model to models/CNN2_dataset_1_trim5_381.h5\n",
      "146/146 [==============================] - 0s 845us/sample - loss: 0.1753 - accuracy: 0.9452 - val_loss: 0.2572 - val_accuracy: 0.8649\n",
      "Epoch 382/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.2180 - accuracy: 0.9091\n",
      "Epoch 00382: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 665us/sample - loss: 0.2031 - accuracy: 0.9178 - val_loss: 0.4438 - val_accuracy: 0.7838\n",
      "Epoch 383/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2611 - accuracy: 0.8700\n",
      "Epoch 00383: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 687us/sample - loss: 0.2428 - accuracy: 0.8973 - val_loss: 0.3355 - val_accuracy: 0.8108\n",
      "Epoch 384/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2059 - accuracy: 0.9400\n",
      "Epoch 00384: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.1746 - accuracy: 0.9589 - val_loss: 0.2480 - val_accuracy: 0.8649\n",
      "Epoch 385/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2303 - accuracy: 0.9300\n",
      "Epoch 00385: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 760us/sample - loss: 0.1963 - accuracy: 0.9384 - val_loss: 0.4015 - val_accuracy: 0.7838\n",
      "Epoch 386/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1885 - accuracy: 0.9700\n",
      "Epoch 00386: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.1717 - accuracy: 0.9658 - val_loss: 0.4090 - val_accuracy: 0.7838\n",
      "Epoch 387/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1641 - accuracy: 0.9300\n",
      "Epoch 00387: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 715us/sample - loss: 0.1599 - accuracy: 0.9384 - val_loss: 0.2911 - val_accuracy: 0.8378\n",
      "Epoch 388/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1733 - accuracy: 0.9400\n",
      "Epoch 00388: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 697us/sample - loss: 0.1981 - accuracy: 0.9247 - val_loss: 0.3856 - val_accuracy: 0.7838\n",
      "Epoch 389/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1664 - accuracy: 0.9400\n",
      "Epoch 00389: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.1526 - accuracy: 0.9521 - val_loss: 0.3782 - val_accuracy: 0.7838\n",
      "Epoch 390/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1844 - accuracy: 0.9100\n",
      "Epoch 00390: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.1916 - accuracy: 0.9178 - val_loss: 0.5401 - val_accuracy: 0.7568\n",
      "Epoch 391/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2149 - accuracy: 0.9300\n",
      "Epoch 00391: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 719us/sample - loss: 0.2060 - accuracy: 0.9315 - val_loss: 0.2589 - val_accuracy: 0.8378\n",
      "Epoch 392/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1926 - accuracy: 0.9600\n",
      "Epoch 00392: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.1986 - accuracy: 0.9452 - val_loss: 0.3027 - val_accuracy: 0.8378\n",
      "Epoch 393/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1769 - accuracy: 0.9400\n",
      "Epoch 00393: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.1757 - accuracy: 0.9384 - val_loss: 0.3780 - val_accuracy: 0.7838\n",
      "Epoch 394/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1441 - accuracy: 0.9800\n",
      "Epoch 00394: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 697us/sample - loss: 0.1614 - accuracy: 0.9589 - val_loss: 0.3569 - val_accuracy: 0.7838\n",
      "Epoch 395/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1134 - accuracy: 0.9889\n",
      "Epoch 00395: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.1610 - accuracy: 0.9452 - val_loss: 0.4588 - val_accuracy: 0.7568\n",
      "Epoch 396/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1735 - accuracy: 0.9400\n",
      "Epoch 00396: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 733us/sample - loss: 0.1878 - accuracy: 0.9452 - val_loss: 0.3604 - val_accuracy: 0.7838\n",
      "Epoch 397/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2079 - accuracy: 0.9100\n",
      "Epoch 00397: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.1855 - accuracy: 0.9247 - val_loss: 0.3838 - val_accuracy: 0.7838\n",
      "Epoch 398/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 0.1825 - accuracy: 0.9571\n",
      "Epoch 00398: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 933us/sample - loss: 0.1820 - accuracy: 0.9589 - val_loss: 0.3278 - val_accuracy: 0.8108\n",
      "Epoch 399/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1851 - accuracy: 0.9222\n",
      "Epoch 00399: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.1929 - accuracy: 0.9247 - val_loss: 0.3637 - val_accuracy: 0.7838\n",
      "Epoch 400/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1723 - accuracy: 0.9300\n",
      "Epoch 00400: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 700us/sample - loss: 0.1745 - accuracy: 0.9384 - val_loss: 0.3213 - val_accuracy: 0.8378\n",
      "Epoch 401/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1758 - accuracy: 0.9300\n",
      "Epoch 00401: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 662us/sample - loss: 0.1617 - accuracy: 0.9384 - val_loss: 0.3385 - val_accuracy: 0.8108\n",
      "Epoch 402/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1285 - accuracy: 0.9909\n",
      "Epoch 00402: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 665us/sample - loss: 0.1339 - accuracy: 0.9795 - val_loss: 0.3897 - val_accuracy: 0.7838\n",
      "Epoch 403/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1446 - accuracy: 0.9556\n",
      "Epoch 00403: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.1507 - accuracy: 0.9589 - val_loss: 0.4169 - val_accuracy: 0.7838\n",
      "Epoch 404/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1439 - accuracy: 0.9700\n",
      "Epoch 00404: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 669us/sample - loss: 0.1538 - accuracy: 0.9521 - val_loss: 0.3603 - val_accuracy: 0.7838\n",
      "Epoch 405/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1625 - accuracy: 0.9273\n",
      "Epoch 00405: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 667us/sample - loss: 0.1979 - accuracy: 0.9041 - val_loss: 0.3797 - val_accuracy: 0.7838\n",
      "Epoch 406/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1509 - accuracy: 0.9500\n",
      "Epoch 00406: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 669us/sample - loss: 0.1626 - accuracy: 0.9521 - val_loss: 0.2565 - val_accuracy: 0.8649\n",
      "Epoch 407/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2017 - accuracy: 0.9300\n",
      "Epoch 00407: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 670us/sample - loss: 0.2100 - accuracy: 0.9178 - val_loss: 0.4531 - val_accuracy: 0.7838\n",
      "Epoch 408/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1706 - accuracy: 0.9300\n",
      "Epoch 00408: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 699us/sample - loss: 0.1780 - accuracy: 0.9384 - val_loss: 0.3554 - val_accuracy: 0.7838\n",
      "Epoch 409/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1446 - accuracy: 0.9500\n",
      "Epoch 00409: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.1613 - accuracy: 0.9452 - val_loss: 0.3328 - val_accuracy: 0.8378\n",
      "Epoch 410/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1602 - accuracy: 0.9556\n",
      "Epoch 00410: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.1551 - accuracy: 0.9589 - val_loss: 0.3748 - val_accuracy: 0.7838\n",
      "Epoch 411/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1631 - accuracy: 0.9400\n",
      "Epoch 00411: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 698us/sample - loss: 0.1699 - accuracy: 0.9384 - val_loss: 0.3157 - val_accuracy: 0.8378\n",
      "Epoch 412/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2096 - accuracy: 0.9000\n",
      "Epoch 00412: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.2311 - accuracy: 0.8904 - val_loss: 0.2674 - val_accuracy: 0.8649\n",
      "Epoch 413/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1538 - accuracy: 0.9545\n",
      "Epoch 00413: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 653us/sample - loss: 0.1618 - accuracy: 0.9452 - val_loss: 0.3387 - val_accuracy: 0.8378\n",
      "Epoch 414/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2376 - accuracy: 0.8700\n",
      "Epoch 00414: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 679us/sample - loss: 0.2019 - accuracy: 0.8973 - val_loss: 0.3412 - val_accuracy: 0.8378\n",
      "Epoch 415/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1418 - accuracy: 0.9600\n",
      "Epoch 00415: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 675us/sample - loss: 0.1653 - accuracy: 0.9521 - val_loss: 0.3328 - val_accuracy: 0.8378\n",
      "Epoch 416/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1538 - accuracy: 0.9500\n",
      "Epoch 00416: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.1740 - accuracy: 0.9384 - val_loss: 0.3587 - val_accuracy: 0.7838\n",
      "Epoch 417/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1533 - accuracy: 0.9500\n",
      "Epoch 00417: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 674us/sample - loss: 0.1544 - accuracy: 0.9521 - val_loss: 0.2215 - val_accuracy: 0.8649\n",
      "Epoch 418/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1845 - accuracy: 0.9500\n",
      "Epoch 00418: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.1761 - accuracy: 0.9589 - val_loss: 0.3057 - val_accuracy: 0.8378\n",
      "Epoch 419/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1515 - accuracy: 0.9667\n",
      "Epoch 00419: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 786us/sample - loss: 0.1435 - accuracy: 0.9589 - val_loss: 0.3151 - val_accuracy: 0.8378\n",
      "Epoch 420/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2301 - accuracy: 0.8900\n",
      "Epoch 00420: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 713us/sample - loss: 0.1902 - accuracy: 0.9110 - val_loss: 0.4458 - val_accuracy: 0.7568\n",
      "Epoch 421/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1645 - accuracy: 0.9500\n",
      "Epoch 00421: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.1578 - accuracy: 0.9452 - val_loss: 0.2523 - val_accuracy: 0.8649\n",
      "Epoch 422/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1233 - accuracy: 0.9700\n",
      "Epoch 00422: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.1534 - accuracy: 0.9452 - val_loss: 0.3640 - val_accuracy: 0.8108\n",
      "Epoch 423/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1614 - accuracy: 0.9500\n",
      "Epoch 00423: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.1482 - accuracy: 0.9521 - val_loss: 0.2416 - val_accuracy: 0.8649\n",
      "Epoch 424/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1533 - accuracy: 0.9400\n",
      "Epoch 00424: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.1579 - accuracy: 0.9384 - val_loss: 0.2761 - val_accuracy: 0.8649\n",
      "Epoch 425/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1217 - accuracy: 0.9700\n",
      "Epoch 00425: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 718us/sample - loss: 0.1454 - accuracy: 0.9589 - val_loss: 0.3345 - val_accuracy: 0.8108\n",
      "Epoch 426/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1209 - accuracy: 0.9800\n",
      "Epoch 00426: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 710us/sample - loss: 0.1338 - accuracy: 0.9589 - val_loss: 0.2932 - val_accuracy: 0.8649\n",
      "Epoch 427/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1574 - accuracy: 0.9400\n",
      "Epoch 00427: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.1615 - accuracy: 0.9315 - val_loss: 0.3606 - val_accuracy: 0.7838\n",
      "Epoch 428/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1586 - accuracy: 0.9500\n",
      "Epoch 00428: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 679us/sample - loss: 0.1619 - accuracy: 0.9452 - val_loss: 0.4012 - val_accuracy: 0.7838\n",
      "Epoch 429/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1599 - accuracy: 0.9400\n",
      "Epoch 00429: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 698us/sample - loss: 0.1419 - accuracy: 0.9589 - val_loss: 0.2995 - val_accuracy: 0.8378\n",
      "Epoch 430/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1056 - accuracy: 0.9900\n",
      "Epoch 00430: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.1398 - accuracy: 0.9521 - val_loss: 0.3657 - val_accuracy: 0.8108\n",
      "Epoch 431/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1138 - accuracy: 0.9700\n",
      "Epoch 00431: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 733us/sample - loss: 0.1411 - accuracy: 0.9658 - val_loss: 0.3162 - val_accuracy: 0.8378\n",
      "Epoch 432/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1598 - accuracy: 0.9400\n",
      "Epoch 00432: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 0.1697 - accuracy: 0.9315 - val_loss: 0.4447 - val_accuracy: 0.7838\n",
      "Epoch 433/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1629 - accuracy: 0.9500\n",
      "Epoch 00433: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 698us/sample - loss: 0.1592 - accuracy: 0.9521 - val_loss: 0.2616 - val_accuracy: 0.8649\n",
      "Epoch 434/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.1110 - accuracy: 0.9875\n",
      "Epoch 00434: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 789us/sample - loss: 0.1326 - accuracy: 0.9658 - val_loss: 0.3321 - val_accuracy: 0.8378\n",
      "Epoch 435/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1621 - accuracy: 0.9700\n",
      "Epoch 00435: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.1486 - accuracy: 0.9726 - val_loss: 0.3577 - val_accuracy: 0.7838\n",
      "Epoch 436/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1866 - accuracy: 0.9100\n",
      "Epoch 00436: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 676us/sample - loss: 0.2054 - accuracy: 0.9041 - val_loss: 0.3380 - val_accuracy: 0.7838\n",
      "Epoch 437/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2170 - accuracy: 0.9000\n",
      "Epoch 00437: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 0.2067 - accuracy: 0.9110 - val_loss: 0.3099 - val_accuracy: 0.8378\n",
      "Epoch 438/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1860 - accuracy: 0.9333\n",
      "Epoch 00438: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 787us/sample - loss: 0.1817 - accuracy: 0.9384 - val_loss: 0.3252 - val_accuracy: 0.8378\n",
      "Epoch 439/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1390 - accuracy: 0.9333\n",
      "Epoch 00439: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.1475 - accuracy: 0.9452 - val_loss: 0.2277 - val_accuracy: 0.8649\n",
      "Epoch 440/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1963 - accuracy: 0.9000\n",
      "Epoch 00440: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 692us/sample - loss: 0.1797 - accuracy: 0.9178 - val_loss: 0.3792 - val_accuracy: 0.8108\n",
      "Epoch 441/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1944 - accuracy: 0.9273\n",
      "Epoch 00441: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 664us/sample - loss: 0.1843 - accuracy: 0.9315 - val_loss: 0.2285 - val_accuracy: 0.8649\n",
      "Epoch 442/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1390 - accuracy: 0.9700\n",
      "Epoch 00442: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 681us/sample - loss: 0.1414 - accuracy: 0.9658 - val_loss: 0.2911 - val_accuracy: 0.8649\n",
      "Epoch 443/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1361 - accuracy: 0.9556\n",
      "Epoch 00443: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 756us/sample - loss: 0.1488 - accuracy: 0.9384 - val_loss: 0.3092 - val_accuracy: 0.8649\n",
      "Epoch 444/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1135 - accuracy: 0.9778\n",
      "Epoch 00444: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 768us/sample - loss: 0.1389 - accuracy: 0.9658 - val_loss: 0.2282 - val_accuracy: 0.8649\n",
      "Epoch 445/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1744 - accuracy: 0.9500\n",
      "Epoch 00445: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 0.1584 - accuracy: 0.9589 - val_loss: 0.3345 - val_accuracy: 0.8378\n",
      "Epoch 446/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1371 - accuracy: 0.9600\n",
      "Epoch 00446: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 675us/sample - loss: 0.1325 - accuracy: 0.9658 - val_loss: 0.3035 - val_accuracy: 0.8378\n",
      "Epoch 447/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1770 - accuracy: 0.9300\n",
      "Epoch 00447: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 683us/sample - loss: 0.2036 - accuracy: 0.9110 - val_loss: 0.3528 - val_accuracy: 0.8108\n",
      "Epoch 448/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1494 - accuracy: 0.9500\n",
      "Epoch 00448: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 688us/sample - loss: 0.1359 - accuracy: 0.9589 - val_loss: 0.3167 - val_accuracy: 0.8378\n",
      "Epoch 449/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.2063 - accuracy: 0.9182\n",
      "Epoch 00449: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 667us/sample - loss: 0.1900 - accuracy: 0.9247 - val_loss: 0.2779 - val_accuracy: 0.8649\n",
      "Epoch 450/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1895 - accuracy: 0.9200\n",
      "Epoch 00450: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 680us/sample - loss: 0.1782 - accuracy: 0.9178 - val_loss: 0.3676 - val_accuracy: 0.8108\n",
      "Epoch 451/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2020 - accuracy: 0.8900\n",
      "Epoch 00451: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.1594 - accuracy: 0.9247 - val_loss: 0.2994 - val_accuracy: 0.8649\n",
      "Epoch 452/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1295 - accuracy: 0.9600\n",
      "Epoch 00452: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.1761 - accuracy: 0.9452 - val_loss: 0.3286 - val_accuracy: 0.8108\n",
      "Epoch 453/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1437 - accuracy: 0.9500\n",
      "Epoch 00453: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 689us/sample - loss: 0.1434 - accuracy: 0.9452 - val_loss: 0.2868 - val_accuracy: 0.8649\n",
      "Epoch 454/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1296 - accuracy: 0.9800\n",
      "Epoch 00454: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 669us/sample - loss: 0.1371 - accuracy: 0.9726 - val_loss: 0.3041 - val_accuracy: 0.8649\n",
      "Epoch 455/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1417 - accuracy: 0.9400\n",
      "Epoch 00455: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 692us/sample - loss: 0.1625 - accuracy: 0.9315 - val_loss: 0.2738 - val_accuracy: 0.8649\n",
      "Epoch 456/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1018 - accuracy: 0.9700\n",
      "Epoch 00456: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 691us/sample - loss: 0.1106 - accuracy: 0.9726 - val_loss: 0.3414 - val_accuracy: 0.8108\n",
      "Epoch 457/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1380 - accuracy: 0.9600\n",
      "Epoch 00457: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 0.1540 - accuracy: 0.9589 - val_loss: 0.2596 - val_accuracy: 0.8649\n",
      "Epoch 458/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1328 - accuracy: 0.9500\n",
      "Epoch 00458: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 673us/sample - loss: 0.1284 - accuracy: 0.9521 - val_loss: 0.3960 - val_accuracy: 0.8108\n",
      "Epoch 459/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1740 - accuracy: 0.9200\n",
      "Epoch 00459: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 689us/sample - loss: 0.1644 - accuracy: 0.9315 - val_loss: 0.2341 - val_accuracy: 0.8649\n",
      "Epoch 460/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1594 - accuracy: 0.9500\n",
      "Epoch 00460: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 0.1352 - accuracy: 0.9658 - val_loss: 0.3231 - val_accuracy: 0.8108\n",
      "Epoch 461/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1245 - accuracy: 0.9600\n",
      "Epoch 00461: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 681us/sample - loss: 0.1488 - accuracy: 0.9452 - val_loss: 0.3494 - val_accuracy: 0.8108\n",
      "Epoch 462/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1711 - accuracy: 0.9300\n",
      "Epoch 00462: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.1521 - accuracy: 0.9452 - val_loss: 0.3180 - val_accuracy: 0.8378\n",
      "Epoch 463/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1241 - accuracy: 0.9800\n",
      "Epoch 00463: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.1346 - accuracy: 0.9658 - val_loss: 0.3984 - val_accuracy: 0.7838\n",
      "Epoch 464/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1850 - accuracy: 0.9400\n",
      "Epoch 00464: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 0.1659 - accuracy: 0.9521 - val_loss: 0.2938 - val_accuracy: 0.8649\n",
      "Epoch 465/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1884 - accuracy: 0.9100\n",
      "Epoch 00465: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 673us/sample - loss: 0.1672 - accuracy: 0.9247 - val_loss: 0.2786 - val_accuracy: 0.8649\n",
      "Epoch 466/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0954 - accuracy: 0.9800\n",
      "Epoch 00466: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 674us/sample - loss: 0.1129 - accuracy: 0.9658 - val_loss: 0.2583 - val_accuracy: 0.8649\n",
      "Epoch 467/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1747 - accuracy: 0.9200\n",
      "Epoch 00467: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 670us/sample - loss: 0.1811 - accuracy: 0.9178 - val_loss: 0.4316 - val_accuracy: 0.7838\n",
      "Epoch 468/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1361 - accuracy: 0.9500\n",
      "Epoch 00468: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 680us/sample - loss: 0.1372 - accuracy: 0.9521 - val_loss: 0.2901 - val_accuracy: 0.8649\n",
      "Epoch 469/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1341 - accuracy: 0.9500\n",
      "Epoch 00469: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 674us/sample - loss: 0.1386 - accuracy: 0.9521 - val_loss: 0.3224 - val_accuracy: 0.8108\n",
      "Epoch 470/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1111 - accuracy: 0.9700\n",
      "Epoch 00470: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 668us/sample - loss: 0.1538 - accuracy: 0.9521 - val_loss: 0.3170 - val_accuracy: 0.8378\n",
      "Epoch 471/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1651 - accuracy: 0.9200\n",
      "Epoch 00471: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 665us/sample - loss: 0.1608 - accuracy: 0.9315 - val_loss: 0.2101 - val_accuracy: 0.8649\n",
      "Epoch 472/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1593 - accuracy: 0.9500\n",
      "Epoch 00472: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 700us/sample - loss: 0.1520 - accuracy: 0.9521 - val_loss: 0.3031 - val_accuracy: 0.8649\n",
      "Epoch 473/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0997 - accuracy: 0.9700\n",
      "Epoch 00473: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.1150 - accuracy: 0.9658 - val_loss: 0.3853 - val_accuracy: 0.8108\n",
      "Epoch 474/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1543 - accuracy: 0.9300\n",
      "Epoch 00474: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 0.1441 - accuracy: 0.9452 - val_loss: 0.3370 - val_accuracy: 0.8378\n",
      "Epoch 475/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1745 - accuracy: 0.9200\n",
      "Epoch 00475: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.1704 - accuracy: 0.9315 - val_loss: 0.2935 - val_accuracy: 0.8649\n",
      "Epoch 476/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1157 - accuracy: 0.9700\n",
      "Epoch 00476: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 675us/sample - loss: 0.1104 - accuracy: 0.9726 - val_loss: 0.3074 - val_accuracy: 0.8649\n",
      "Epoch 477/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1356 - accuracy: 0.9500\n",
      "Epoch 00477: val_accuracy improved from 0.86486 to 0.89189, saving model to models/CNN2_dataset_1_trim5_477.h5\n",
      "146/146 [==============================] - 0s 853us/sample - loss: 0.1428 - accuracy: 0.9521 - val_loss: 0.1876 - val_accuracy: 0.8919\n",
      "Epoch 478/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1419 - accuracy: 0.9500\n",
      "Epoch 00478: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 670us/sample - loss: 0.1511 - accuracy: 0.9521 - val_loss: 0.2847 - val_accuracy: 0.8649\n",
      "Epoch 479/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1144 - accuracy: 0.9600\n",
      "Epoch 00479: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 0.1316 - accuracy: 0.9452 - val_loss: 0.3685 - val_accuracy: 0.8108\n",
      "Epoch 480/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1443 - accuracy: 0.9700\n",
      "Epoch 00480: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 691us/sample - loss: 0.1269 - accuracy: 0.9795 - val_loss: 0.2964 - val_accuracy: 0.8649\n",
      "Epoch 481/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1502 - accuracy: 0.9200\n",
      "Epoch 00481: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 669us/sample - loss: 0.1505 - accuracy: 0.9247 - val_loss: 0.4985 - val_accuracy: 0.7568\n",
      "Epoch 482/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1254 - accuracy: 0.9700\n",
      "Epoch 00482: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.1739 - accuracy: 0.9384 - val_loss: 0.3088 - val_accuracy: 0.8378\n",
      "Epoch 483/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1436 - accuracy: 0.9500\n",
      "Epoch 00483: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.1387 - accuracy: 0.9452 - val_loss: 0.2896 - val_accuracy: 0.8378\n",
      "Epoch 484/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1358 - accuracy: 0.9500\n",
      "Epoch 00484: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.1530 - accuracy: 0.9452 - val_loss: 0.3067 - val_accuracy: 0.8378\n",
      "Epoch 485/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1642 - accuracy: 0.9400\n",
      "Epoch 00485: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 0.1452 - accuracy: 0.9452 - val_loss: 0.2902 - val_accuracy: 0.8649\n",
      "Epoch 486/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1095 - accuracy: 0.9700\n",
      "Epoch 00486: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.1385 - accuracy: 0.9452 - val_loss: 0.3678 - val_accuracy: 0.8108\n",
      "Epoch 487/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1276 - accuracy: 0.9455\n",
      "Epoch 00487: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 669us/sample - loss: 0.1436 - accuracy: 0.9452 - val_loss: 0.2127 - val_accuracy: 0.8649\n",
      "Epoch 488/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1211 - accuracy: 0.9636\n",
      "Epoch 00488: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 661us/sample - loss: 0.1148 - accuracy: 0.9726 - val_loss: 0.3132 - val_accuracy: 0.8378\n",
      "Epoch 489/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1149 - accuracy: 0.9700\n",
      "Epoch 00489: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 670us/sample - loss: 0.1325 - accuracy: 0.9726 - val_loss: 0.2589 - val_accuracy: 0.8649\n",
      "Epoch 490/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1110 - accuracy: 0.9700\n",
      "Epoch 00490: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.1327 - accuracy: 0.9589 - val_loss: 0.3502 - val_accuracy: 0.8108\n",
      "Epoch 491/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1668 - accuracy: 0.9600\n",
      "Epoch 00491: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.1419 - accuracy: 0.9658 - val_loss: 0.3248 - val_accuracy: 0.8378\n",
      "Epoch 492/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1236 - accuracy: 0.9700\n",
      "Epoch 00492: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 723us/sample - loss: 0.1497 - accuracy: 0.9589 - val_loss: 0.2597 - val_accuracy: 0.8649\n",
      "Epoch 493/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1328 - accuracy: 0.9500\n",
      "Epoch 00493: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.1484 - accuracy: 0.9452 - val_loss: 0.4120 - val_accuracy: 0.7838\n",
      "Epoch 494/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1286 - accuracy: 0.9500\n",
      "Epoch 00494: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.1230 - accuracy: 0.9521 - val_loss: 0.2468 - val_accuracy: 0.8649\n",
      "Epoch 495/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1625 - accuracy: 0.9364\n",
      "Epoch 00495: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.1455 - accuracy: 0.9452 - val_loss: 0.3265 - val_accuracy: 0.8378\n",
      "Epoch 496/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.1455 - accuracy: 0.9636\n",
      "Epoch 00496: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.1242 - accuracy: 0.9658 - val_loss: 0.2263 - val_accuracy: 0.8649\n",
      "Epoch 497/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1164 - accuracy: 0.9600\n",
      "Epoch 00497: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 681us/sample - loss: 0.1420 - accuracy: 0.9452 - val_loss: 0.5141 - val_accuracy: 0.7568\n",
      "Epoch 498/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1225 - accuracy: 0.9400\n",
      "Epoch 00498: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.1267 - accuracy: 0.9452 - val_loss: 0.2468 - val_accuracy: 0.8649\n",
      "Epoch 499/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1548 - accuracy: 0.9400\n",
      "Epoch 00499: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 727us/sample - loss: 0.1252 - accuracy: 0.9589 - val_loss: 0.4185 - val_accuracy: 0.7838\n",
      "Epoch 500/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1174 - accuracy: 0.9400\n",
      "Epoch 00500: val_accuracy did not improve from 0.89189\n",
      "146/146 [==============================] - 0s 681us/sample - loss: 0.1468 - accuracy: 0.9247 - val_loss: 0.2496 - val_accuracy: 0.8378\n",
      "Training completed in time:  0:00:55.440221\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8082192\n",
      "Testing Accuracy:  0.6363636\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.29      0.22      0.25         9\n",
      "   Pneumonia       0.73      0.79      0.76        24\n",
      "\n",
      "    accuracy                           0.64        33\n",
      "   macro avg       0.51      0.51      0.51        33\n",
      "weighted avg       0.61      0.64      0.62        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  7]\n",
      " [ 5 19]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
