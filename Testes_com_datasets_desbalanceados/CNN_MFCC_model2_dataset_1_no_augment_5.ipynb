{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 2\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 1 - no_augment_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'no_augment_5'\n",
    "GROUP_TEST = 'no_augment_5'\n",
    "DATASET = 'dataset_1'\n",
    "DURATION = 5\n",
    "SIZE = 216\n",
    "CSV_TRAIN = 'train1.csv'\n",
    "CSV_TEST = 'test1.csv'\n",
    "MODEL_NAME = f'CNN2_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  102  Healthy\n",
       "1  121  Healthy\n",
       "2  123  Healthy\n",
       "3  125  Healthy\n",
       "4  126  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  122  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['32' '29']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['3' '8']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 40, 216)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 40, 216, 1) (61, 2)\n",
      "(11, 40, 216, 1) (11, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 215, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 107, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 107, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 106, 16)       2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 53, 16)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 53, 16)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 52, 8)          520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 26, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 26, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 25, 4)          132       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 12, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 12, 4)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 2,886\n",
      "Trainable params: 2,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "11/11 [==============================] - 1s 84ms/sample - loss: 11.2894 - accuracy: 0.2727\n",
      "Pre-training accuracy: 27.2727%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48 samples, validate on 13 samples\n",
      "Epoch 1/500\n",
      "10/48 [=====>........................] - ETA: 2s - loss: 13.6231 - accuracy: 0.6000\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.53846, saving model to models/CNN2_dataset_1_no_augment_5_01.h5\n",
      "48/48 [==============================] - 1s 16ms/sample - loss: 15.9720 - accuracy: 0.5417 - val_loss: 3.1102 - val_accuracy: 0.5385\n",
      "Epoch 2/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 7.4192 - accuracy: 0.7000\n",
      "Epoch 00002: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 879us/sample - loss: 6.1231 - accuracy: 0.5417 - val_loss: 0.9991 - val_accuracy: 0.4615\n",
      "Epoch 3/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 4.6638 - accuracy: 0.5000\n",
      "Epoch 00003: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 887us/sample - loss: 4.5726 - accuracy: 0.4375 - val_loss: 1.5434 - val_accuracy: 0.4615\n",
      "Epoch 4/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 2.5887 - accuracy: 0.5000\n",
      "Epoch 00004: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 938us/sample - loss: 2.8014 - accuracy: 0.5833 - val_loss: 1.2885 - val_accuracy: 0.4615\n",
      "Epoch 5/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 4.8130 - accuracy: 0.5000\n",
      "Epoch 00005: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 882us/sample - loss: 3.0844 - accuracy: 0.5000 - val_loss: 1.0692 - val_accuracy: 0.4615\n",
      "Epoch 6/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 3.5218 - accuracy: 0.4000\n",
      "Epoch 00006: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 981us/sample - loss: 2.7013 - accuracy: 0.5000 - val_loss: 0.9613 - val_accuracy: 0.1538\n",
      "Epoch 7/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 3.2796 - accuracy: 0.3000\n",
      "Epoch 00007: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 967us/sample - loss: 2.6149 - accuracy: 0.4583 - val_loss: 0.8847 - val_accuracy: 0.2308\n",
      "Epoch 8/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 3.9132 - accuracy: 0.4000\n",
      "Epoch 00008: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 840us/sample - loss: 1.9604 - accuracy: 0.6042 - val_loss: 0.9409 - val_accuracy: 0.4615\n",
      "Epoch 9/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7400 - accuracy: 0.6000\n",
      "Epoch 00009: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 819us/sample - loss: 1.6149 - accuracy: 0.5625 - val_loss: 1.0648 - val_accuracy: 0.4615\n",
      "Epoch 10/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0149 - accuracy: 0.5000\n",
      "Epoch 00010: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 1.6444 - accuracy: 0.4375 - val_loss: 1.0704 - val_accuracy: 0.4615\n",
      "Epoch 11/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9012 - accuracy: 0.8000\n",
      "Epoch 00011: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 812us/sample - loss: 1.6378 - accuracy: 0.5417 - val_loss: 1.0240 - val_accuracy: 0.4615\n",
      "Epoch 12/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 2.8608 - accuracy: 0.2000\n",
      "Epoch 00012: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 791us/sample - loss: 1.5934 - accuracy: 0.5000 - val_loss: 0.9095 - val_accuracy: 0.4615\n",
      "Epoch 13/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9514 - accuracy: 0.7000\n",
      "Epoch 00013: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 837us/sample - loss: 1.4520 - accuracy: 0.5833 - val_loss: 0.8449 - val_accuracy: 0.4615\n",
      "Epoch 14/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 2.4079 - accuracy: 0.2000\n",
      "Epoch 00014: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 818us/sample - loss: 1.7531 - accuracy: 0.4583 - val_loss: 0.8197 - val_accuracy: 0.4615\n",
      "Epoch 15/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8740 - accuracy: 0.8000\n",
      "Epoch 00015: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 840us/sample - loss: 1.2692 - accuracy: 0.5625 - val_loss: 0.8069 - val_accuracy: 0.4615\n",
      "Epoch 16/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.4776 - accuracy: 0.4000\n",
      "Epoch 00016: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 932us/sample - loss: 1.2221 - accuracy: 0.4583 - val_loss: 0.8079 - val_accuracy: 0.4615\n",
      "Epoch 17/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8476 - accuracy: 0.6000\n",
      "Epoch 00017: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 1.1325 - accuracy: 0.6458 - val_loss: 0.8048 - val_accuracy: 0.4615\n",
      "Epoch 18/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 2.0327 - accuracy: 0.4000\n",
      "Epoch 00018: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 852us/sample - loss: 1.2518 - accuracy: 0.4583 - val_loss: 0.8026 - val_accuracy: 0.4615\n",
      "Epoch 19/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0605 - accuracy: 0.7000\n",
      "Epoch 00019: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 877us/sample - loss: 0.9736 - accuracy: 0.6042 - val_loss: 0.7934 - val_accuracy: 0.4615\n",
      "Epoch 20/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.5945 - accuracy: 0.4000\n",
      "Epoch 00020: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 866us/sample - loss: 1.3109 - accuracy: 0.4792 - val_loss: 0.7686 - val_accuracy: 0.4615\n",
      "Epoch 21/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8677 - accuracy: 0.6000\n",
      "Epoch 00021: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 902us/sample - loss: 0.9187 - accuracy: 0.5417 - val_loss: 0.7514 - val_accuracy: 0.4615\n",
      "Epoch 22/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.2516 - accuracy: 0.5000\n",
      "Epoch 00022: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 907us/sample - loss: 1.2365 - accuracy: 0.4792 - val_loss: 0.7480 - val_accuracy: 0.4615\n",
      "Epoch 23/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.2963 - accuracy: 0.4000\n",
      "Epoch 00023: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 1.3260 - accuracy: 0.3958 - val_loss: 0.7420 - val_accuracy: 0.4615\n",
      "Epoch 24/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0950 - accuracy: 0.4000\n",
      "Epoch 00024: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 981us/sample - loss: 1.0749 - accuracy: 0.4167 - val_loss: 0.7427 - val_accuracy: 0.4615\n",
      "Epoch 25/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.3246 - accuracy: 0.4000\n",
      "Epoch 00025: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 898us/sample - loss: 1.0116 - accuracy: 0.5833 - val_loss: 0.7444 - val_accuracy: 0.4615\n",
      "Epoch 26/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5107 - accuracy: 0.7000\n",
      "Epoch 00026: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 902us/sample - loss: 0.7212 - accuracy: 0.5625 - val_loss: 0.7482 - val_accuracy: 0.4615\n",
      "Epoch 27/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8512 - accuracy: 0.6000\n",
      "Epoch 00027: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 918us/sample - loss: 0.9125 - accuracy: 0.5417 - val_loss: 0.7464 - val_accuracy: 0.4615\n",
      "Epoch 28/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8728 - accuracy: 0.5000\n",
      "Epoch 00028: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 946us/sample - loss: 0.9385 - accuracy: 0.5417 - val_loss: 0.7338 - val_accuracy: 0.4615\n",
      "Epoch 29/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0808 - accuracy: 0.6000\n",
      "Epoch 00029: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 917us/sample - loss: 0.9599 - accuracy: 0.5833 - val_loss: 0.7190 - val_accuracy: 0.4615\n",
      "Epoch 30/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9153 - accuracy: 0.6000\n",
      "Epoch 00030: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 921us/sample - loss: 0.9999 - accuracy: 0.4792 - val_loss: 0.7160 - val_accuracy: 0.4615\n",
      "Epoch 31/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5910 - accuracy: 0.6000\n",
      "Epoch 00031: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 915us/sample - loss: 0.7709 - accuracy: 0.6250 - val_loss: 0.7142 - val_accuracy: 0.4615\n",
      "Epoch 32/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5832 - accuracy: 0.7000\n",
      "Epoch 00032: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 913us/sample - loss: 0.7734 - accuracy: 0.5208 - val_loss: 0.7122 - val_accuracy: 0.4615\n",
      "Epoch 33/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0560 - accuracy: 0.3000\n",
      "Epoch 00033: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 977us/sample - loss: 0.9994 - accuracy: 0.4167 - val_loss: 0.7087 - val_accuracy: 0.4615\n",
      "Epoch 34/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7806 - accuracy: 0.7000\n",
      "Epoch 00034: val_accuracy did not improve from 0.53846\n",
      "48/48 [==============================] - 0s 875us/sample - loss: 0.8231 - accuracy: 0.6042 - val_loss: 0.6972 - val_accuracy: 0.4615\n",
      "Epoch 35/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8386 - accuracy: 0.5000\n",
      "Epoch 00035: val_accuracy improved from 0.53846 to 0.76923, saving model to models/CNN2_dataset_1_no_augment_5_35.h5\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.9619 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.7692\n",
      "Epoch 36/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9875 - accuracy: 0.5000\n",
      "Epoch 00036: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 847us/sample - loss: 0.8009 - accuracy: 0.4792 - val_loss: 0.6890 - val_accuracy: 0.7692\n",
      "Epoch 37/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6584 - accuracy: 0.6000\n",
      "Epoch 00037: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 881us/sample - loss: 0.7912 - accuracy: 0.5833 - val_loss: 0.6844 - val_accuracy: 0.6923\n",
      "Epoch 38/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5922 - accuracy: 0.8000\n",
      "Epoch 00038: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 911us/sample - loss: 0.7756 - accuracy: 0.5417 - val_loss: 0.6843 - val_accuracy: 0.6923\n",
      "Epoch 39/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5134 - accuracy: 0.7000\n",
      "Epoch 00039: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 940us/sample - loss: 0.7601 - accuracy: 0.6458 - val_loss: 0.6813 - val_accuracy: 0.6923\n",
      "Epoch 40/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4974 - accuracy: 0.7000\n",
      "Epoch 00040: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 997us/sample - loss: 0.6660 - accuracy: 0.6042 - val_loss: 0.6788 - val_accuracy: 0.7692\n",
      "Epoch 41/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5452 - accuracy: 0.5000\n",
      "Epoch 00041: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 920us/sample - loss: 0.7534 - accuracy: 0.5417 - val_loss: 0.6763 - val_accuracy: 0.7692\n",
      "Epoch 42/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6077 - accuracy: 0.7000\n",
      "Epoch 00042: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7450 - accuracy: 0.6250 - val_loss: 0.6729 - val_accuracy: 0.7692\n",
      "Epoch 43/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0314 - accuracy: 0.3000\n",
      "Epoch 00043: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.9008 - accuracy: 0.5208 - val_loss: 0.6720 - val_accuracy: 0.7692\n",
      "Epoch 44/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5643 - accuracy: 0.6000\n",
      "Epoch 00044: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 980us/sample - loss: 0.6532 - accuracy: 0.6458 - val_loss: 0.6720 - val_accuracy: 0.7692\n",
      "Epoch 45/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7520 - accuracy: 0.7000\n",
      "Epoch 00045: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 935us/sample - loss: 1.0203 - accuracy: 0.4167 - val_loss: 0.6720 - val_accuracy: 0.6923\n",
      "Epoch 46/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7654 - accuracy: 0.6000\n",
      "Epoch 00046: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6673 - accuracy: 0.6250 - val_loss: 0.6733 - val_accuracy: 0.6923\n",
      "Epoch 47/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7460 - accuracy: 0.5000\n",
      "Epoch 00047: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 969us/sample - loss: 0.7295 - accuracy: 0.6042 - val_loss: 0.6707 - val_accuracy: 0.6923\n",
      "Epoch 48/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6277 - accuracy: 0.8000\n",
      "Epoch 00048: val_accuracy did not improve from 0.76923\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7143 - accuracy: 0.5625 - val_loss: 0.6663 - val_accuracy: 0.7692\n",
      "Epoch 49/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6796 - accuracy: 0.7000\n",
      "Epoch 00049: val_accuracy improved from 0.76923 to 0.84615, saving model to models/CNN2_dataset_1_no_augment_5_49.h5\n",
      "48/48 [==============================] - 0s 2ms/sample - loss: 0.7171 - accuracy: 0.5833 - val_loss: 0.6656 - val_accuracy: 0.8462\n",
      "Epoch 50/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8719 - accuracy: 0.5000\n",
      "Epoch 00050: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 876us/sample - loss: 0.7505 - accuracy: 0.6250 - val_loss: 0.6634 - val_accuracy: 0.7692\n",
      "Epoch 51/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.0525 - accuracy: 0.3000\n",
      "Epoch 00051: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.8523 - accuracy: 0.5417 - val_loss: 0.6631 - val_accuracy: 0.7692\n",
      "Epoch 52/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5935 - accuracy: 0.7000\n",
      "Epoch 00052: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 976us/sample - loss: 0.7462 - accuracy: 0.5833 - val_loss: 0.6614 - val_accuracy: 0.7692\n",
      "Epoch 53/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6693 - accuracy: 0.6000\n",
      "Epoch 00053: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.7123 - accuracy: 0.6042 - val_loss: 0.6576 - val_accuracy: 0.8462\n",
      "Epoch 54/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6470 - accuracy: 0.8000\n",
      "Epoch 00054: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 0.6508 - accuracy: 0.6667 - val_loss: 0.6530 - val_accuracy: 0.8462\n",
      "Epoch 55/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7534 - accuracy: 0.6000\n",
      "Epoch 00055: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 970us/sample - loss: 0.7330 - accuracy: 0.6042 - val_loss: 0.6493 - val_accuracy: 0.8462\n",
      "Epoch 56/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4310 - accuracy: 0.8000\n",
      "Epoch 00056: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 879us/sample - loss: 0.6313 - accuracy: 0.6458 - val_loss: 0.6457 - val_accuracy: 0.8462\n",
      "Epoch 57/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8808 - accuracy: 0.3000\n",
      "Epoch 00057: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 854us/sample - loss: 0.6857 - accuracy: 0.5417 - val_loss: 0.6433 - val_accuracy: 0.8462\n",
      "Epoch 58/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6113 - accuracy: 0.8000\n",
      "Epoch 00058: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 868us/sample - loss: 0.7072 - accuracy: 0.6250 - val_loss: 0.6431 - val_accuracy: 0.8462\n",
      "Epoch 59/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8010 - accuracy: 0.4000\n",
      "Epoch 00059: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6525 - accuracy: 0.6250 - val_loss: 0.6433 - val_accuracy: 0.8462\n",
      "Epoch 60/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7425 - accuracy: 0.5000\n",
      "Epoch 00060: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 906us/sample - loss: 0.6941 - accuracy: 0.6458 - val_loss: 0.6421 - val_accuracy: 0.8462\n",
      "Epoch 61/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6508 - accuracy: 0.6000\n",
      "Epoch 00061: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 872us/sample - loss: 0.6844 - accuracy: 0.5000 - val_loss: 0.6390 - val_accuracy: 0.6923\n",
      "Epoch 62/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6546 - accuracy: 0.6000\n",
      "Epoch 00062: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 900us/sample - loss: 0.6027 - accuracy: 0.6458 - val_loss: 0.6359 - val_accuracy: 0.6923\n",
      "Epoch 63/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4625 - accuracy: 0.8000\n",
      "Epoch 00063: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 876us/sample - loss: 0.5911 - accuracy: 0.6667 - val_loss: 0.6337 - val_accuracy: 0.6923\n",
      "Epoch 64/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7025 - accuracy: 0.5000\n",
      "Epoch 00064: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 843us/sample - loss: 0.7428 - accuracy: 0.5417 - val_loss: 0.6331 - val_accuracy: 0.7692\n",
      "Epoch 65/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8036 - accuracy: 0.4000\n",
      "Epoch 00065: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 885us/sample - loss: 0.7789 - accuracy: 0.5000 - val_loss: 0.6368 - val_accuracy: 0.7692\n",
      "Epoch 66/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6544 - accuracy: 0.6000\n",
      "Epoch 00066: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 855us/sample - loss: 0.6431 - accuracy: 0.5625 - val_loss: 0.6395 - val_accuracy: 0.7692\n",
      "Epoch 67/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5340 - accuracy: 0.7000\n",
      "Epoch 00067: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 856us/sample - loss: 0.6346 - accuracy: 0.6042 - val_loss: 0.6414 - val_accuracy: 0.7692\n",
      "Epoch 68/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7202 - accuracy: 0.5000\n",
      "Epoch 00068: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 917us/sample - loss: 0.6385 - accuracy: 0.6042 - val_loss: 0.6391 - val_accuracy: 0.7692\n",
      "Epoch 69/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6507 - accuracy: 0.8000\n",
      "Epoch 00069: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 900us/sample - loss: 0.6555 - accuracy: 0.6250 - val_loss: 0.6362 - val_accuracy: 0.7692\n",
      "Epoch 70/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5602 - accuracy: 0.8000\n",
      "Epoch 00070: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 857us/sample - loss: 0.5568 - accuracy: 0.7083 - val_loss: 0.6351 - val_accuracy: 0.7692\n",
      "Epoch 71/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9301 - accuracy: 0.3000\n",
      "Epoch 00071: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 934us/sample - loss: 0.7563 - accuracy: 0.5208 - val_loss: 0.6323 - val_accuracy: 0.7692\n",
      "Epoch 72/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4357 - accuracy: 0.8000\n",
      "Epoch 00072: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 864us/sample - loss: 0.6142 - accuracy: 0.6042 - val_loss: 0.6287 - val_accuracy: 0.7692\n",
      "Epoch 73/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6418 - accuracy: 0.5000\n",
      "Epoch 00073: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6156 - accuracy: 0.6667 - val_loss: 0.6280 - val_accuracy: 0.7692\n",
      "Epoch 74/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5306 - accuracy: 0.8000\n",
      "Epoch 00074: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 854us/sample - loss: 0.5679 - accuracy: 0.6875 - val_loss: 0.6266 - val_accuracy: 0.7692\n",
      "Epoch 75/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8096 - accuracy: 0.4000\n",
      "Epoch 00075: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.6117 - accuracy: 0.6042 - val_loss: 0.6219 - val_accuracy: 0.7692\n",
      "Epoch 76/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7083 - accuracy: 0.6000\n",
      "Epoch 00076: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 944us/sample - loss: 0.6213 - accuracy: 0.6667 - val_loss: 0.6179 - val_accuracy: 0.7692\n",
      "Epoch 77/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3910 - accuracy: 0.7000\n",
      "Epoch 00077: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 864us/sample - loss: 0.5824 - accuracy: 0.7083 - val_loss: 0.6147 - val_accuracy: 0.7692\n",
      "Epoch 78/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4959 - accuracy: 0.8000\n",
      "Epoch 00078: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 905us/sample - loss: 0.6154 - accuracy: 0.6667 - val_loss: 0.6148 - val_accuracy: 0.7692\n",
      "Epoch 79/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6345 - accuracy: 0.6000\n",
      "Epoch 00079: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 927us/sample - loss: 0.4894 - accuracy: 0.7708 - val_loss: 0.6133 - val_accuracy: 0.7692\n",
      "Epoch 80/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5480 - accuracy: 0.8000\n",
      "Epoch 00080: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 847us/sample - loss: 0.5958 - accuracy: 0.7292 - val_loss: 0.6111 - val_accuracy: 0.6923\n",
      "Epoch 81/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5786 - accuracy: 0.8000\n",
      "Epoch 00081: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 846us/sample - loss: 0.5812 - accuracy: 0.7083 - val_loss: 0.6100 - val_accuracy: 0.6923\n",
      "Epoch 82/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4136 - accuracy: 0.9000\n",
      "Epoch 00082: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 824us/sample - loss: 0.5634 - accuracy: 0.6875 - val_loss: 0.6103 - val_accuracy: 0.6923\n",
      "Epoch 83/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5109 - accuracy: 0.7000\n",
      "Epoch 00083: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 894us/sample - loss: 0.5027 - accuracy: 0.7708 - val_loss: 0.6060 - val_accuracy: 0.6923\n",
      "Epoch 84/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3831 - accuracy: 0.9000\n",
      "Epoch 00084: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 907us/sample - loss: 0.6301 - accuracy: 0.6250 - val_loss: 0.6082 - val_accuracy: 0.6923\n",
      "Epoch 85/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6199 - accuracy: 0.5000\n",
      "Epoch 00085: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 939us/sample - loss: 0.6318 - accuracy: 0.6250 - val_loss: 0.6083 - val_accuracy: 0.6923\n",
      "Epoch 86/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6225 - accuracy: 0.7000\n",
      "Epoch 00086: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 917us/sample - loss: 0.5790 - accuracy: 0.6875 - val_loss: 0.5969 - val_accuracy: 0.6923\n",
      "Epoch 87/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6778 - accuracy: 0.7000\n",
      "Epoch 00087: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 923us/sample - loss: 0.6899 - accuracy: 0.6667 - val_loss: 0.5919 - val_accuracy: 0.6923\n",
      "Epoch 88/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4754 - accuracy: 0.8000\n",
      "Epoch 00088: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 852us/sample - loss: 0.5512 - accuracy: 0.7083 - val_loss: 0.5880 - val_accuracy: 0.6923\n",
      "Epoch 89/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6384 - accuracy: 0.6000\n",
      "Epoch 00089: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 852us/sample - loss: 0.5666 - accuracy: 0.6667 - val_loss: 0.5845 - val_accuracy: 0.6923\n",
      "Epoch 90/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6858 - accuracy: 0.5000\n",
      "Epoch 00090: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 827us/sample - loss: 0.7131 - accuracy: 0.5833 - val_loss: 0.5769 - val_accuracy: 0.6923\n",
      "Epoch 91/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3828 - accuracy: 0.8000\n",
      "Epoch 00091: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 871us/sample - loss: 0.6122 - accuracy: 0.6042 - val_loss: 0.5763 - val_accuracy: 0.6923\n",
      "Epoch 92/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5283 - accuracy: 0.9000\n",
      "Epoch 00092: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 855us/sample - loss: 0.5943 - accuracy: 0.6875 - val_loss: 0.5763 - val_accuracy: 0.6923\n",
      "Epoch 93/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6201 - accuracy: 0.5000\n",
      "Epoch 00093: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 844us/sample - loss: 0.6370 - accuracy: 0.6042 - val_loss: 0.5748 - val_accuracy: 0.6923\n",
      "Epoch 94/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5730 - accuracy: 0.8000\n",
      "Epoch 00094: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 912us/sample - loss: 0.5464 - accuracy: 0.7708 - val_loss: 0.5857 - val_accuracy: 0.6923\n",
      "Epoch 95/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5349 - accuracy: 0.7000\n",
      "Epoch 00095: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 862us/sample - loss: 0.6687 - accuracy: 0.5833 - val_loss: 0.5911 - val_accuracy: 0.6923\n",
      "Epoch 96/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7039 - accuracy: 0.6000\n",
      "Epoch 00096: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 873us/sample - loss: 0.5627 - accuracy: 0.6458 - val_loss: 0.5807 - val_accuracy: 0.6923\n",
      "Epoch 97/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5507 - accuracy: 0.7000\n",
      "Epoch 00097: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 932us/sample - loss: 0.5564 - accuracy: 0.6667 - val_loss: 0.5676 - val_accuracy: 0.6923\n",
      "Epoch 98/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6993 - accuracy: 0.4000\n",
      "Epoch 00098: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 875us/sample - loss: 0.6044 - accuracy: 0.6250 - val_loss: 0.5499 - val_accuracy: 0.6923\n",
      "Epoch 99/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6549 - accuracy: 0.5000\n",
      "Epoch 00099: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 911us/sample - loss: 0.6067 - accuracy: 0.6875 - val_loss: 0.5415 - val_accuracy: 0.6923\n",
      "Epoch 100/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5690 - accuracy: 0.5000\n",
      "Epoch 00100: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 870us/sample - loss: 0.5380 - accuracy: 0.6667 - val_loss: 0.5365 - val_accuracy: 0.7692\n",
      "Epoch 101/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5358 - accuracy: 0.6000\n",
      "Epoch 00101: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 870us/sample - loss: 0.5248 - accuracy: 0.7292 - val_loss: 0.5329 - val_accuracy: 0.7692\n",
      "Epoch 102/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6904 - accuracy: 0.5000\n",
      "Epoch 00102: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 859us/sample - loss: 0.4407 - accuracy: 0.7917 - val_loss: 0.5375 - val_accuracy: 0.6923\n",
      "Epoch 103/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5965 - accuracy: 0.8000\n",
      "Epoch 00103: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 825us/sample - loss: 0.5838 - accuracy: 0.7292 - val_loss: 0.5396 - val_accuracy: 0.6923\n",
      "Epoch 104/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4093 - accuracy: 0.9000\n",
      "Epoch 00104: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 857us/sample - loss: 0.5399 - accuracy: 0.6875 - val_loss: 0.5295 - val_accuracy: 0.7692\n",
      "Epoch 105/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5302 - accuracy: 0.7000\n",
      "Epoch 00105: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 875us/sample - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.5166 - val_accuracy: 0.7692\n",
      "Epoch 106/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5156 - accuracy: 0.8000\n",
      "Epoch 00106: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 888us/sample - loss: 0.5232 - accuracy: 0.7083 - val_loss: 0.5032 - val_accuracy: 0.7692\n",
      "Epoch 107/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5896 - accuracy: 0.6000\n",
      "Epoch 00107: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 816us/sample - loss: 0.4930 - accuracy: 0.7500 - val_loss: 0.4989 - val_accuracy: 0.7692\n",
      "Epoch 108/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5974 - accuracy: 0.6000\n",
      "Epoch 00108: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 914us/sample - loss: 0.5290 - accuracy: 0.6875 - val_loss: 0.4966 - val_accuracy: 0.7692\n",
      "Epoch 109/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6154 - accuracy: 0.6000\n",
      "Epoch 00109: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 844us/sample - loss: 0.5029 - accuracy: 0.7083 - val_loss: 0.4923 - val_accuracy: 0.7692\n",
      "Epoch 110/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5351 - accuracy: 0.7000\n",
      "Epoch 00110: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 845us/sample - loss: 0.5407 - accuracy: 0.7083 - val_loss: 0.4889 - val_accuracy: 0.7692\n",
      "Epoch 111/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4397 - accuracy: 0.8000\n",
      "Epoch 00111: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 930us/sample - loss: 0.4546 - accuracy: 0.7917 - val_loss: 0.5036 - val_accuracy: 0.7692\n",
      "Epoch 112/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2852 - accuracy: 0.9000\n",
      "Epoch 00112: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 839us/sample - loss: 0.4721 - accuracy: 0.7083 - val_loss: 0.5216 - val_accuracy: 0.6923\n",
      "Epoch 113/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6161 - accuracy: 0.8000\n",
      "Epoch 00113: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 916us/sample - loss: 0.4668 - accuracy: 0.8333 - val_loss: 0.5222 - val_accuracy: 0.6923\n",
      "Epoch 114/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2835 - accuracy: 0.9000\n",
      "Epoch 00114: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 844us/sample - loss: 0.4555 - accuracy: 0.7708 - val_loss: 0.5105 - val_accuracy: 0.7692\n",
      "Epoch 115/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5217 - accuracy: 0.6000\n",
      "Epoch 00115: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 866us/sample - loss: 0.6365 - accuracy: 0.6250 - val_loss: 0.4998 - val_accuracy: 0.7692\n",
      "Epoch 116/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3918 - accuracy: 0.8000\n",
      "Epoch 00116: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 812us/sample - loss: 0.4194 - accuracy: 0.8125 - val_loss: 0.4976 - val_accuracy: 0.7692\n",
      "Epoch 117/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3279 - accuracy: 0.9000\n",
      "Epoch 00117: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 860us/sample - loss: 0.4322 - accuracy: 0.8125 - val_loss: 0.5001 - val_accuracy: 0.7692\n",
      "Epoch 118/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3592 - accuracy: 0.8000\n",
      "Epoch 00118: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 839us/sample - loss: 0.3742 - accuracy: 0.8125 - val_loss: 0.5119 - val_accuracy: 0.7692\n",
      "Epoch 119/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7084 - accuracy: 0.6000\n",
      "Epoch 00119: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 887us/sample - loss: 0.5500 - accuracy: 0.7083 - val_loss: 0.5014 - val_accuracy: 0.7692\n",
      "Epoch 120/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4726 - accuracy: 0.7000\n",
      "Epoch 00120: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 805us/sample - loss: 0.5064 - accuracy: 0.7083 - val_loss: 0.4849 - val_accuracy: 0.7692\n",
      "Epoch 121/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3806 - accuracy: 0.8000\n",
      "Epoch 00121: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 800us/sample - loss: 0.5146 - accuracy: 0.7500 - val_loss: 0.4873 - val_accuracy: 0.7692\n",
      "Epoch 122/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3738 - accuracy: 0.8000\n",
      "Epoch 00122: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 907us/sample - loss: 0.4876 - accuracy: 0.7500 - val_loss: 0.4906 - val_accuracy: 0.7692\n",
      "Epoch 123/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3963 - accuracy: 0.8000\n",
      "Epoch 00123: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 920us/sample - loss: 0.4160 - accuracy: 0.7500 - val_loss: 0.4935 - val_accuracy: 0.7692\n",
      "Epoch 124/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2593 - accuracy: 0.8000\n",
      "Epoch 00124: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 848us/sample - loss: 0.4147 - accuracy: 0.7500 - val_loss: 0.4893 - val_accuracy: 0.7692\n",
      "Epoch 125/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4904 - accuracy: 0.7000\n",
      "Epoch 00125: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 892us/sample - loss: 0.4531 - accuracy: 0.7500 - val_loss: 0.4688 - val_accuracy: 0.7692\n",
      "Epoch 126/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4520 - accuracy: 0.8000\n",
      "Epoch 00126: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 817us/sample - loss: 0.3599 - accuracy: 0.8542 - val_loss: 0.4540 - val_accuracy: 0.8462\n",
      "Epoch 127/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2680 - accuracy: 0.9000\n",
      "Epoch 00127: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 820us/sample - loss: 0.3944 - accuracy: 0.7708 - val_loss: 0.4546 - val_accuracy: 0.7692\n",
      "Epoch 128/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2083 - accuracy: 1.0000\n",
      "Epoch 00128: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 920us/sample - loss: 0.5272 - accuracy: 0.7292 - val_loss: 0.4738 - val_accuracy: 0.7692\n",
      "Epoch 129/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4278 - accuracy: 0.7000\n",
      "Epoch 00129: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 857us/sample - loss: 0.4731 - accuracy: 0.7708 - val_loss: 0.4915 - val_accuracy: 0.7692\n",
      "Epoch 130/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4414 - accuracy: 0.8000\n",
      "Epoch 00130: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 903us/sample - loss: 0.3822 - accuracy: 0.8333 - val_loss: 0.4811 - val_accuracy: 0.7692\n",
      "Epoch 131/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5597 - accuracy: 0.7000\n",
      "Epoch 00131: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 0.4931 - accuracy: 0.6667 - val_loss: 0.4819 - val_accuracy: 0.7692\n",
      "Epoch 132/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3455 - accuracy: 0.9000\n",
      "Epoch 00132: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 923us/sample - loss: 0.5162 - accuracy: 0.7292 - val_loss: 0.4356 - val_accuracy: 0.8462\n",
      "Epoch 133/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3265 - accuracy: 0.8000\n",
      "Epoch 00133: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 839us/sample - loss: 0.4332 - accuracy: 0.7292 - val_loss: 0.4321 - val_accuracy: 0.8462\n",
      "Epoch 134/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3408 - accuracy: 0.9000\n",
      "Epoch 00134: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 891us/sample - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.4511 - val_accuracy: 0.8462\n",
      "Epoch 135/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4590 - accuracy: 0.8000\n",
      "Epoch 00135: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4250 - accuracy: 0.8125 - val_loss: 0.4863 - val_accuracy: 0.7692\n",
      "Epoch 136/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4830 - accuracy: 0.7000\n",
      "Epoch 00136: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 904us/sample - loss: 0.4431 - accuracy: 0.7292 - val_loss: 0.4633 - val_accuracy: 0.7692\n",
      "Epoch 137/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2626 - accuracy: 1.0000\n",
      "Epoch 00137: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 926us/sample - loss: 0.3850 - accuracy: 0.8542 - val_loss: 0.4114 - val_accuracy: 0.8462\n",
      "Epoch 138/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2363 - accuracy: 1.0000\n",
      "Epoch 00138: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 934us/sample - loss: 0.3170 - accuracy: 0.8542 - val_loss: 0.4180 - val_accuracy: 0.8462\n",
      "Epoch 139/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5226 - accuracy: 0.7000\n",
      "Epoch 00139: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 980us/sample - loss: 0.4548 - accuracy: 0.7708 - val_loss: 0.5224 - val_accuracy: 0.7692\n",
      "Epoch 140/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 1.3077 - accuracy: 0.5000\n",
      "Epoch 00140: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 971us/sample - loss: 0.5648 - accuracy: 0.7292 - val_loss: 0.5216 - val_accuracy: 0.7692\n",
      "Epoch 141/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3275 - accuracy: 0.9000\n",
      "Epoch 00141: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 973us/sample - loss: 0.3296 - accuracy: 0.8333 - val_loss: 0.4513 - val_accuracy: 0.8462\n",
      "Epoch 142/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1927 - accuracy: 1.0000\n",
      "Epoch 00142: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 933us/sample - loss: 0.3007 - accuracy: 0.8750 - val_loss: 0.4236 - val_accuracy: 0.8462\n",
      "Epoch 143/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2483 - accuracy: 0.8000\n",
      "Epoch 00143: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 910us/sample - loss: 0.2774 - accuracy: 0.8750 - val_loss: 0.4386 - val_accuracy: 0.8462\n",
      "Epoch 144/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3254 - accuracy: 0.8000\n",
      "Epoch 00144: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 945us/sample - loss: 0.2907 - accuracy: 0.8542 - val_loss: 0.4502 - val_accuracy: 0.8462\n",
      "Epoch 145/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5430 - accuracy: 0.8000\n",
      "Epoch 00145: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 945us/sample - loss: 0.4794 - accuracy: 0.7917 - val_loss: 0.4525 - val_accuracy: 0.8462\n",
      "Epoch 146/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2224 - accuracy: 0.9000\n",
      "Epoch 00146: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 853us/sample - loss: 0.3685 - accuracy: 0.8333 - val_loss: 0.4240 - val_accuracy: 0.8462\n",
      "Epoch 147/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2389 - accuracy: 0.8000\n",
      "Epoch 00147: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3011 - accuracy: 0.8333 - val_loss: 0.4204 - val_accuracy: 0.8462\n",
      "Epoch 148/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3945 - accuracy: 0.9000\n",
      "Epoch 00148: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 997us/sample - loss: 0.3914 - accuracy: 0.8333 - val_loss: 0.4014 - val_accuracy: 0.8462\n",
      "Epoch 149/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4895 - accuracy: 0.8000\n",
      "Epoch 00149: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3885 - accuracy: 0.8750 - val_loss: 0.4167 - val_accuracy: 0.8462\n",
      "Epoch 150/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2131 - accuracy: 1.0000\n",
      "Epoch 00150: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 906us/sample - loss: 0.3692 - accuracy: 0.8750 - val_loss: 0.4037 - val_accuracy: 0.8462\n",
      "Epoch 151/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4325 - accuracy: 0.7000\n",
      "Epoch 00151: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 0.4274 - accuracy: 0.8125 - val_loss: 0.3872 - val_accuracy: 0.8462\n",
      "Epoch 152/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1583 - accuracy: 1.0000\n",
      "Epoch 00152: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 860us/sample - loss: 0.5682 - accuracy: 0.7500 - val_loss: 0.4741 - val_accuracy: 0.7692\n",
      "Epoch 153/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3262 - accuracy: 0.8000\n",
      "Epoch 00153: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 914us/sample - loss: 0.4111 - accuracy: 0.7917 - val_loss: 0.4978 - val_accuracy: 0.7692\n",
      "Epoch 154/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4056 - accuracy: 0.7000\n",
      "Epoch 00154: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 978us/sample - loss: 0.4752 - accuracy: 0.7708 - val_loss: 0.4221 - val_accuracy: 0.7692\n",
      "Epoch 155/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1253 - accuracy: 1.0000\n",
      "Epoch 00155: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 897us/sample - loss: 0.4306 - accuracy: 0.8125 - val_loss: 0.3717 - val_accuracy: 0.8462\n",
      "Epoch 156/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3781 - accuracy: 0.9000\n",
      "Epoch 00156: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 907us/sample - loss: 0.3624 - accuracy: 0.8750 - val_loss: 0.3888 - val_accuracy: 0.8462\n",
      "Epoch 157/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4221 - accuracy: 0.8000\n",
      "Epoch 00157: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.4260 - accuracy: 0.7917 - val_loss: 0.4186 - val_accuracy: 0.8462\n",
      "Epoch 158/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5543 - accuracy: 0.7000\n",
      "Epoch 00158: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 942us/sample - loss: 0.4111 - accuracy: 0.8125 - val_loss: 0.4198 - val_accuracy: 0.8462\n",
      "Epoch 159/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5032 - accuracy: 0.7000\n",
      "Epoch 00159: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 886us/sample - loss: 0.3647 - accuracy: 0.7708 - val_loss: 0.4166 - val_accuracy: 0.8462\n",
      "Epoch 160/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2587 - accuracy: 0.9000\n",
      "Epoch 00160: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 882us/sample - loss: 0.3073 - accuracy: 0.8750 - val_loss: 0.3772 - val_accuracy: 0.8462\n",
      "Epoch 161/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5251 - accuracy: 0.7000\n",
      "Epoch 00161: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 904us/sample - loss: 0.4721 - accuracy: 0.7917 - val_loss: 0.3822 - val_accuracy: 0.8462\n",
      "Epoch 162/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2041 - accuracy: 0.9000\n",
      "Epoch 00162: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 899us/sample - loss: 0.3423 - accuracy: 0.8125 - val_loss: 0.4081 - val_accuracy: 0.8462\n",
      "Epoch 163/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3555 - accuracy: 0.8000\n",
      "Epoch 00163: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 904us/sample - loss: 0.4521 - accuracy: 0.7917 - val_loss: 0.3883 - val_accuracy: 0.8462\n",
      "Epoch 164/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2994 - accuracy: 0.8000\n",
      "Epoch 00164: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3259 - accuracy: 0.8542 - val_loss: 0.3878 - val_accuracy: 0.8462\n",
      "Epoch 165/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2489 - accuracy: 0.9000\n",
      "Epoch 00165: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 977us/sample - loss: 0.2666 - accuracy: 0.8542 - val_loss: 0.3849 - val_accuracy: 0.8462\n",
      "Epoch 166/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1983 - accuracy: 0.9000\n",
      "Epoch 00166: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 936us/sample - loss: 0.2364 - accuracy: 0.9167 - val_loss: 0.4253 - val_accuracy: 0.8462\n",
      "Epoch 167/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3406 - accuracy: 0.7000\n",
      "Epoch 00167: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 876us/sample - loss: 0.2850 - accuracy: 0.8542 - val_loss: 0.4229 - val_accuracy: 0.8462\n",
      "Epoch 168/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5139 - accuracy: 0.8000\n",
      "Epoch 00168: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 894us/sample - loss: 0.4209 - accuracy: 0.8333 - val_loss: 0.4549 - val_accuracy: 0.8462\n",
      "Epoch 169/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1336 - accuracy: 0.9000\n",
      "Epoch 00169: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 922us/sample - loss: 0.3097 - accuracy: 0.8333 - val_loss: 0.4197 - val_accuracy: 0.8462\n",
      "Epoch 170/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3672 - accuracy: 0.7000\n",
      "Epoch 00170: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 835us/sample - loss: 0.3756 - accuracy: 0.8333 - val_loss: 0.4344 - val_accuracy: 0.8462\n",
      "Epoch 171/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3218 - accuracy: 0.8000\n",
      "Epoch 00171: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 938us/sample - loss: 0.2503 - accuracy: 0.8958 - val_loss: 0.3956 - val_accuracy: 0.8462\n",
      "Epoch 172/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2397 - accuracy: 0.9000\n",
      "Epoch 00172: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 935us/sample - loss: 0.3121 - accuracy: 0.8542 - val_loss: 0.4652 - val_accuracy: 0.8462\n",
      "Epoch 173/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1109 - accuracy: 1.0000\n",
      "Epoch 00173: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 879us/sample - loss: 0.2330 - accuracy: 0.9167 - val_loss: 0.5350 - val_accuracy: 0.8462\n",
      "Epoch 174/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3431 - accuracy: 0.7000\n",
      "Epoch 00174: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 873us/sample - loss: 0.2914 - accuracy: 0.8542 - val_loss: 0.4679 - val_accuracy: 0.8462\n",
      "Epoch 175/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1082 - accuracy: 1.0000\n",
      "Epoch 00175: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 846us/sample - loss: 0.2884 - accuracy: 0.9167 - val_loss: 0.3253 - val_accuracy: 0.8462\n",
      "Epoch 176/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2218 - accuracy: 0.8000\n",
      "Epoch 00176: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 788us/sample - loss: 0.4122 - accuracy: 0.7917 - val_loss: 0.3643 - val_accuracy: 0.8462\n",
      "Epoch 177/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2486 - accuracy: 0.9000\n",
      "Epoch 00177: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 922us/sample - loss: 0.3411 - accuracy: 0.8750 - val_loss: 0.4797 - val_accuracy: 0.8462\n",
      "Epoch 178/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1515 - accuracy: 1.0000\n",
      "Epoch 00178: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 905us/sample - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.4704 - val_accuracy: 0.8462\n",
      "Epoch 179/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2041 - accuracy: 0.9000\n",
      "Epoch 00179: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 920us/sample - loss: 0.3010 - accuracy: 0.8333 - val_loss: 0.3622 - val_accuracy: 0.8462\n",
      "Epoch 180/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1199 - accuracy: 1.0000\n",
      "Epoch 00180: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 943us/sample - loss: 0.4070 - accuracy: 0.8333 - val_loss: 0.3628 - val_accuracy: 0.8462\n",
      "Epoch 181/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2728 - accuracy: 0.9000\n",
      "Epoch 00181: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 919us/sample - loss: 0.4126 - accuracy: 0.8125 - val_loss: 0.4205 - val_accuracy: 0.8462\n",
      "Epoch 182/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2296 - accuracy: 0.9000\n",
      "Epoch 00182: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 875us/sample - loss: 0.2626 - accuracy: 0.8958 - val_loss: 0.4597 - val_accuracy: 0.8462\n",
      "Epoch 183/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4497 - accuracy: 0.9000\n",
      "Epoch 00183: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 922us/sample - loss: 0.2542 - accuracy: 0.9375 - val_loss: 0.4076 - val_accuracy: 0.8462\n",
      "Epoch 184/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2614 - accuracy: 0.9000\n",
      "Epoch 00184: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 973us/sample - loss: 0.2893 - accuracy: 0.8542 - val_loss: 0.3528 - val_accuracy: 0.8462\n",
      "Epoch 185/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0748 - accuracy: 1.0000\n",
      "Epoch 00185: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 933us/sample - loss: 0.3253 - accuracy: 0.8542 - val_loss: 0.3481 - val_accuracy: 0.8462\n",
      "Epoch 186/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4441 - accuracy: 0.7000\n",
      "Epoch 00186: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 936us/sample - loss: 0.3230 - accuracy: 0.8125 - val_loss: 0.4191 - val_accuracy: 0.8462\n",
      "Epoch 187/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3622 - accuracy: 0.8000\n",
      "Epoch 00187: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3319 - accuracy: 0.8125 - val_loss: 0.4447 - val_accuracy: 0.8462\n",
      "Epoch 188/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4411 - accuracy: 0.9000\n",
      "Epoch 00188: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 939us/sample - loss: 0.3585 - accuracy: 0.8542 - val_loss: 0.3841 - val_accuracy: 0.8462\n",
      "Epoch 189/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0711 - accuracy: 1.0000\n",
      "Epoch 00189: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 856us/sample - loss: 0.3176 - accuracy: 0.8750 - val_loss: 0.3566 - val_accuracy: 0.8462\n",
      "Epoch 190/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1480 - accuracy: 1.0000\n",
      "Epoch 00190: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 862us/sample - loss: 0.2737 - accuracy: 0.8958 - val_loss: 0.3694 - val_accuracy: 0.8462\n",
      "Epoch 191/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2678 - accuracy: 0.9000\n",
      "Epoch 00191: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 841us/sample - loss: 0.2613 - accuracy: 0.9167 - val_loss: 0.4020 - val_accuracy: 0.8462\n",
      "Epoch 192/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4303 - accuracy: 0.8000\n",
      "Epoch 00192: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 901us/sample - loss: 0.2799 - accuracy: 0.8750 - val_loss: 0.4848 - val_accuracy: 0.7692\n",
      "Epoch 193/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3785 - accuracy: 0.8000\n",
      "Epoch 00193: val_accuracy did not improve from 0.84615\n",
      "48/48 [==============================] - 0s 820us/sample - loss: 0.4170 - accuracy: 0.8542 - val_loss: 0.4030 - val_accuracy: 0.8462\n",
      "Epoch 194/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0688 - accuracy: 1.0000\n",
      "Epoch 00194: val_accuracy improved from 0.84615 to 0.92308, saving model to models/CNN2_dataset_1_no_augment_5_194.h5\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2314 - accuracy: 0.8750 - val_loss: 0.3203 - val_accuracy: 0.9231\n",
      "Epoch 195/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2234 - accuracy: 0.9000\n",
      "Epoch 00195: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 841us/sample - loss: 0.4243 - accuracy: 0.7917 - val_loss: 0.3500 - val_accuracy: 0.8462\n",
      "Epoch 196/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2030 - accuracy: 1.0000\n",
      "Epoch 00196: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 884us/sample - loss: 0.3411 - accuracy: 0.8333 - val_loss: 0.4310 - val_accuracy: 0.8462\n",
      "Epoch 197/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2774 - accuracy: 0.8000\n",
      "Epoch 00197: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 879us/sample - loss: 0.3427 - accuracy: 0.8333 - val_loss: 0.4229 - val_accuracy: 0.8462\n",
      "Epoch 198/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4977 - accuracy: 0.7000\n",
      "Epoch 00198: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 910us/sample - loss: 0.4143 - accuracy: 0.7917 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
      "Epoch 199/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5491 - accuracy: 0.7000\n",
      "Epoch 00199: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 910us/sample - loss: 0.3450 - accuracy: 0.8542 - val_loss: 0.4345 - val_accuracy: 0.8462\n",
      "Epoch 200/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2301 - accuracy: 1.0000\n",
      "Epoch 00200: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 908us/sample - loss: 0.3410 - accuracy: 0.8333 - val_loss: 0.3803 - val_accuracy: 0.8462\n",
      "Epoch 201/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2516 - accuracy: 0.9000\n",
      "Epoch 00201: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 904us/sample - loss: 0.3344 - accuracy: 0.8750 - val_loss: 0.3266 - val_accuracy: 0.8462\n",
      "Epoch 202/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3173 - accuracy: 0.8000\n",
      "Epoch 00202: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 924us/sample - loss: 0.3799 - accuracy: 0.8125 - val_loss: 0.3653 - val_accuracy: 0.8462\n",
      "Epoch 203/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3303 - accuracy: 0.9000\n",
      "Epoch 00203: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 949us/sample - loss: 0.3418 - accuracy: 0.8750 - val_loss: 0.4164 - val_accuracy: 0.8462\n",
      "Epoch 204/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3421 - accuracy: 0.8000\n",
      "Epoch 00204: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 876us/sample - loss: 0.2754 - accuracy: 0.8542 - val_loss: 0.4043 - val_accuracy: 0.8462\n",
      "Epoch 205/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4189 - accuracy: 0.7000\n",
      "Epoch 00205: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 840us/sample - loss: 0.4094 - accuracy: 0.7708 - val_loss: 0.3607 - val_accuracy: 0.8462\n",
      "Epoch 206/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.8506 - accuracy: 0.6000\n",
      "Epoch 00206: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 836us/sample - loss: 0.3924 - accuracy: 0.8542 - val_loss: 0.4250 - val_accuracy: 0.8462\n",
      "Epoch 207/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5318 - accuracy: 0.7000\n",
      "Epoch 00207: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 868us/sample - loss: 0.2713 - accuracy: 0.8750 - val_loss: 0.4401 - val_accuracy: 0.8462\n",
      "Epoch 208/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2329 - accuracy: 0.9000\n",
      "Epoch 00208: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 809us/sample - loss: 0.2612 - accuracy: 0.9375 - val_loss: 0.4099 - val_accuracy: 0.8462\n",
      "Epoch 209/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3535 - accuracy: 0.8000\n",
      "Epoch 00209: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 880us/sample - loss: 0.4093 - accuracy: 0.8125 - val_loss: 0.4253 - val_accuracy: 0.8462\n",
      "Epoch 210/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4958 - accuracy: 0.8000\n",
      "Epoch 00210: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 832us/sample - loss: 0.3820 - accuracy: 0.8542 - val_loss: 0.3925 - val_accuracy: 0.8462\n",
      "Epoch 211/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5851 - accuracy: 0.9000\n",
      "Epoch 00211: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 845us/sample - loss: 0.3849 - accuracy: 0.8542 - val_loss: 0.3316 - val_accuracy: 0.8462\n",
      "Epoch 212/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5643 - accuracy: 0.7000\n",
      "Epoch 00212: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 807us/sample - loss: 0.4147 - accuracy: 0.7917 - val_loss: 0.3777 - val_accuracy: 0.8462\n",
      "Epoch 213/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3038 - accuracy: 0.8000\n",
      "Epoch 00213: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 861us/sample - loss: 0.3578 - accuracy: 0.8542 - val_loss: 0.4048 - val_accuracy: 0.8462\n",
      "Epoch 214/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2891 - accuracy: 0.8000\n",
      "Epoch 00214: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 838us/sample - loss: 0.2979 - accuracy: 0.8542 - val_loss: 0.3571 - val_accuracy: 0.8462\n",
      "Epoch 215/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3281 - accuracy: 0.8000\n",
      "Epoch 00215: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 818us/sample - loss: 0.3310 - accuracy: 0.8125 - val_loss: 0.3652 - val_accuracy: 0.8462\n",
      "Epoch 216/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0963 - accuracy: 1.0000\n",
      "Epoch 00216: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 815us/sample - loss: 0.3145 - accuracy: 0.8333 - val_loss: 0.3592 - val_accuracy: 0.8462\n",
      "Epoch 217/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3704 - accuracy: 0.9000\n",
      "Epoch 00217: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 799us/sample - loss: 0.4098 - accuracy: 0.7917 - val_loss: 0.3408 - val_accuracy: 0.8462\n",
      "Epoch 218/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4086 - accuracy: 0.8000\n",
      "Epoch 00218: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 838us/sample - loss: 0.2667 - accuracy: 0.8958 - val_loss: 0.3708 - val_accuracy: 0.8462\n",
      "Epoch 219/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1450 - accuracy: 0.9000\n",
      "Epoch 00219: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 865us/sample - loss: 0.2720 - accuracy: 0.8542 - val_loss: 0.4141 - val_accuracy: 0.8462\n",
      "Epoch 220/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7458 - accuracy: 0.7000\n",
      "Epoch 00220: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 875us/sample - loss: 0.3625 - accuracy: 0.7917 - val_loss: 0.3982 - val_accuracy: 0.8462\n",
      "Epoch 221/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3058 - accuracy: 0.8000\n",
      "Epoch 00221: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 796us/sample - loss: 0.2845 - accuracy: 0.8958 - val_loss: 0.3875 - val_accuracy: 0.8462\n",
      "Epoch 222/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2974 - accuracy: 0.8000\n",
      "Epoch 00222: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 863us/sample - loss: 0.3684 - accuracy: 0.8542 - val_loss: 0.4172 - val_accuracy: 0.8462\n",
      "Epoch 223/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3001 - accuracy: 0.8000\n",
      "Epoch 00223: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 844us/sample - loss: 0.3296 - accuracy: 0.7917 - val_loss: 0.3643 - val_accuracy: 0.8462\n",
      "Epoch 224/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3679 - accuracy: 0.9000\n",
      "Epoch 00224: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 859us/sample - loss: 0.3091 - accuracy: 0.8333 - val_loss: 0.3223 - val_accuracy: 0.8462\n",
      "Epoch 225/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2733 - accuracy: 0.9000\n",
      "Epoch 00225: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 941us/sample - loss: 0.3541 - accuracy: 0.8542 - val_loss: 0.3601 - val_accuracy: 0.8462\n",
      "Epoch 226/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1993 - accuracy: 0.9000\n",
      "Epoch 00226: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 870us/sample - loss: 0.2656 - accuracy: 0.8542 - val_loss: 0.4327 - val_accuracy: 0.8462\n",
      "Epoch 227/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5143 - accuracy: 0.7000\n",
      "Epoch 00227: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 847us/sample - loss: 0.4346 - accuracy: 0.7917 - val_loss: 0.4442 - val_accuracy: 0.8462\n",
      "Epoch 228/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1907 - accuracy: 0.9000\n",
      "Epoch 00228: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 836us/sample - loss: 0.3381 - accuracy: 0.8750 - val_loss: 0.3308 - val_accuracy: 0.8462\n",
      "Epoch 229/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5395 - accuracy: 0.7000\n",
      "Epoch 00229: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 837us/sample - loss: 0.2970 - accuracy: 0.8125 - val_loss: 0.3450 - val_accuracy: 0.8462\n",
      "Epoch 230/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3340 - accuracy: 0.9000\n",
      "Epoch 00230: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 854us/sample - loss: 0.3093 - accuracy: 0.8958 - val_loss: 0.3657 - val_accuracy: 0.8462\n",
      "Epoch 231/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1699 - accuracy: 1.0000\n",
      "Epoch 00231: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 857us/sample - loss: 0.2684 - accuracy: 0.9375 - val_loss: 0.3944 - val_accuracy: 0.8462\n",
      "Epoch 232/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5700 - accuracy: 0.8000\n",
      "Epoch 00232: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 816us/sample - loss: 0.3140 - accuracy: 0.8750 - val_loss: 0.3933 - val_accuracy: 0.8462\n",
      "Epoch 233/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4999 - accuracy: 0.8000\n",
      "Epoch 00233: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 817us/sample - loss: 0.2939 - accuracy: 0.8542 - val_loss: 0.3868 - val_accuracy: 0.8462\n",
      "Epoch 234/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4509 - accuracy: 0.8000\n",
      "Epoch 00234: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 860us/sample - loss: 0.2804 - accuracy: 0.8750 - val_loss: 0.3522 - val_accuracy: 0.8462\n",
      "Epoch 235/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3557 - accuracy: 0.9000\n",
      "Epoch 00235: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 846us/sample - loss: 0.2673 - accuracy: 0.8542 - val_loss: 0.3662 - val_accuracy: 0.8462\n",
      "Epoch 236/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2167 - accuracy: 0.9000\n",
      "Epoch 00236: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 857us/sample - loss: 0.2787 - accuracy: 0.8125 - val_loss: 0.3612 - val_accuracy: 0.8462\n",
      "Epoch 237/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1632 - accuracy: 1.0000\n",
      "Epoch 00237: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 897us/sample - loss: 0.1922 - accuracy: 0.9375 - val_loss: 0.3730 - val_accuracy: 0.8462\n",
      "Epoch 238/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1231 - accuracy: 1.0000\n",
      "Epoch 00238: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 863us/sample - loss: 0.2842 - accuracy: 0.8542 - val_loss: 0.3921 - val_accuracy: 0.8462\n",
      "Epoch 239/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3796 - accuracy: 0.8000\n",
      "Epoch 00239: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 909us/sample - loss: 0.3063 - accuracy: 0.8542 - val_loss: 0.3190 - val_accuracy: 0.8462\n",
      "Epoch 240/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4088 - accuracy: 0.7000\n",
      "Epoch 00240: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 925us/sample - loss: 0.3460 - accuracy: 0.8125 - val_loss: 0.2972 - val_accuracy: 0.9231\n",
      "Epoch 241/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2201 - accuracy: 0.8000\n",
      "Epoch 00241: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 957us/sample - loss: 0.3630 - accuracy: 0.7708 - val_loss: 0.3287 - val_accuracy: 0.8462\n",
      "Epoch 242/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3657 - accuracy: 0.9000\n",
      "Epoch 00242: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 912us/sample - loss: 0.2902 - accuracy: 0.8750 - val_loss: 0.3656 - val_accuracy: 0.8462\n",
      "Epoch 243/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3136 - accuracy: 0.9000\n",
      "Epoch 00243: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 920us/sample - loss: 0.2820 - accuracy: 0.8958 - val_loss: 0.3720 - val_accuracy: 0.8462\n",
      "Epoch 244/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3414 - accuracy: 0.8000\n",
      "Epoch 00244: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 881us/sample - loss: 0.2046 - accuracy: 0.9167 - val_loss: 0.3845 - val_accuracy: 0.8462\n",
      "Epoch 245/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0909 - accuracy: 1.0000\n",
      "Epoch 00245: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2230 - accuracy: 0.9167 - val_loss: 0.3711 - val_accuracy: 0.8462\n",
      "Epoch 246/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1537 - accuracy: 0.9000\n",
      "Epoch 00246: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 877us/sample - loss: 0.2925 - accuracy: 0.8750 - val_loss: 0.3720 - val_accuracy: 0.8462\n",
      "Epoch 247/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4303 - accuracy: 0.9000\n",
      "Epoch 00247: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 924us/sample - loss: 0.2707 - accuracy: 0.8750 - val_loss: 0.3491 - val_accuracy: 0.8462\n",
      "Epoch 248/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6171 - accuracy: 0.8000\n",
      "Epoch 00248: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3414 - accuracy: 0.8750 - val_loss: 0.4719 - val_accuracy: 0.8462\n",
      "Epoch 249/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2374 - accuracy: 0.9000\n",
      "Epoch 00249: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 959us/sample - loss: 0.2901 - accuracy: 0.8542 - val_loss: 0.4456 - val_accuracy: 0.8462\n",
      "Epoch 250/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4352 - accuracy: 0.9000\n",
      "Epoch 00250: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 917us/sample - loss: 0.2970 - accuracy: 0.8958 - val_loss: 0.4199 - val_accuracy: 0.8462\n",
      "Epoch 251/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2426 - accuracy: 0.9000\n",
      "Epoch 00251: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 935us/sample - loss: 0.2480 - accuracy: 0.8750 - val_loss: 0.3567 - val_accuracy: 0.8462\n",
      "Epoch 252/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 00252: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 964us/sample - loss: 0.2376 - accuracy: 0.8750 - val_loss: 0.3194 - val_accuracy: 0.8462\n",
      "Epoch 253/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0697 - accuracy: 1.0000\n",
      "Epoch 00253: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 878us/sample - loss: 0.2735 - accuracy: 0.8542 - val_loss: 0.3246 - val_accuracy: 0.8462\n",
      "Epoch 254/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5323 - accuracy: 0.8000\n",
      "Epoch 00254: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 921us/sample - loss: 0.2391 - accuracy: 0.9167 - val_loss: 0.3455 - val_accuracy: 0.8462\n",
      "Epoch 255/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0872 - accuracy: 1.0000\n",
      "Epoch 00255: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 904us/sample - loss: 0.3461 - accuracy: 0.8333 - val_loss: 0.3515 - val_accuracy: 0.8462\n",
      "Epoch 256/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1201 - accuracy: 1.0000\n",
      "Epoch 00256: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 908us/sample - loss: 0.2215 - accuracy: 0.8750 - val_loss: 0.3449 - val_accuracy: 0.8462\n",
      "Epoch 257/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3584 - accuracy: 0.8000\n",
      "Epoch 00257: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 898us/sample - loss: 0.3050 - accuracy: 0.8750 - val_loss: 0.3104 - val_accuracy: 0.8462\n",
      "Epoch 258/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2044 - accuracy: 0.9000\n",
      "Epoch 00258: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 985us/sample - loss: 0.4133 - accuracy: 0.8542 - val_loss: 0.3599 - val_accuracy: 0.8462\n",
      "Epoch 259/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1769 - accuracy: 0.9000\n",
      "Epoch 00259: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 907us/sample - loss: 0.1788 - accuracy: 0.9167 - val_loss: 0.3956 - val_accuracy: 0.8462\n",
      "Epoch 260/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2119 - accuracy: 0.9000\n",
      "Epoch 00260: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 903us/sample - loss: 0.2773 - accuracy: 0.8750 - val_loss: 0.3530 - val_accuracy: 0.8462\n",
      "Epoch 261/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2386 - accuracy: 0.9000\n",
      "Epoch 00261: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 931us/sample - loss: 0.3542 - accuracy: 0.8333 - val_loss: 0.3071 - val_accuracy: 0.8462\n",
      "Epoch 262/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5893 - accuracy: 0.7000\n",
      "Epoch 00262: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 886us/sample - loss: 0.2786 - accuracy: 0.8750 - val_loss: 0.2986 - val_accuracy: 0.9231\n",
      "Epoch 263/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5638 - accuracy: 0.8000\n",
      "Epoch 00263: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 891us/sample - loss: 0.3355 - accuracy: 0.8750 - val_loss: 0.3535 - val_accuracy: 0.8462\n",
      "Epoch 264/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4108 - accuracy: 0.7000\n",
      "Epoch 00264: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 888us/sample - loss: 0.2784 - accuracy: 0.8750 - val_loss: 0.4034 - val_accuracy: 0.8462\n",
      "Epoch 265/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.9037 - accuracy: 0.7000\n",
      "Epoch 00265: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 933us/sample - loss: 0.3806 - accuracy: 0.8750 - val_loss: 0.3399 - val_accuracy: 0.8462\n",
      "Epoch 266/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4259 - accuracy: 0.8000\n",
      "Epoch 00266: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 918us/sample - loss: 0.2749 - accuracy: 0.8542 - val_loss: 0.2829 - val_accuracy: 0.9231\n",
      "Epoch 267/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1536 - accuracy: 0.9000\n",
      "Epoch 00267: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 851us/sample - loss: 0.4284 - accuracy: 0.7917 - val_loss: 0.2977 - val_accuracy: 0.9231\n",
      "Epoch 268/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2221 - accuracy: 0.9000\n",
      "Epoch 00268: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 915us/sample - loss: 0.3295 - accuracy: 0.8958 - val_loss: 0.3699 - val_accuracy: 0.8462\n",
      "Epoch 269/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1514 - accuracy: 1.0000\n",
      "Epoch 00269: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 909us/sample - loss: 0.2201 - accuracy: 0.9167 - val_loss: 0.3947 - val_accuracy: 0.8462\n",
      "Epoch 270/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1905 - accuracy: 1.0000\n",
      "Epoch 00270: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 859us/sample - loss: 0.2904 - accuracy: 0.8333 - val_loss: 0.3749 - val_accuracy: 0.8462\n",
      "Epoch 271/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4783 - accuracy: 0.7000\n",
      "Epoch 00271: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 858us/sample - loss: 0.2935 - accuracy: 0.8542 - val_loss: 0.3304 - val_accuracy: 0.8462\n",
      "Epoch 272/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2442 - accuracy: 0.9000\n",
      "Epoch 00272: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 859us/sample - loss: 0.2348 - accuracy: 0.8958 - val_loss: 0.3100 - val_accuracy: 0.8462\n",
      "Epoch 273/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1657 - accuracy: 0.9000\n",
      "Epoch 00273: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 867us/sample - loss: 0.2878 - accuracy: 0.8542 - val_loss: 0.3654 - val_accuracy: 0.8462\n",
      "Epoch 274/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2892 - accuracy: 0.9000\n",
      "Epoch 00274: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 871us/sample - loss: 0.3126 - accuracy: 0.8542 - val_loss: 0.3839 - val_accuracy: 0.8462\n",
      "Epoch 275/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6790 - accuracy: 0.7000\n",
      "Epoch 00275: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 924us/sample - loss: 0.3286 - accuracy: 0.8542 - val_loss: 0.3271 - val_accuracy: 0.8462\n",
      "Epoch 276/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3127 - accuracy: 0.8000\n",
      "Epoch 00276: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 888us/sample - loss: 0.2467 - accuracy: 0.9375 - val_loss: 0.3008 - val_accuracy: 0.9231\n",
      "Epoch 277/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2092 - accuracy: 0.8000\n",
      "Epoch 00277: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 893us/sample - loss: 0.2192 - accuracy: 0.8750 - val_loss: 0.3239 - val_accuracy: 0.8462\n",
      "Epoch 278/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2910 - accuracy: 0.8000\n",
      "Epoch 00278: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 853us/sample - loss: 0.3416 - accuracy: 0.8333 - val_loss: 0.3481 - val_accuracy: 0.8462\n",
      "Epoch 279/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7485 - accuracy: 0.6000\n",
      "Epoch 00279: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 778us/sample - loss: 0.2920 - accuracy: 0.8958 - val_loss: 0.3466 - val_accuracy: 0.8462\n",
      "Epoch 280/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2576 - accuracy: 0.9000\n",
      "Epoch 00280: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 895us/sample - loss: 0.2775 - accuracy: 0.8958 - val_loss: 0.2953 - val_accuracy: 0.9231\n",
      "Epoch 281/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4324 - accuracy: 0.8000\n",
      "Epoch 00281: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 915us/sample - loss: 0.2752 - accuracy: 0.8750 - val_loss: 0.2657 - val_accuracy: 0.9231\n",
      "Epoch 282/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2696 - accuracy: 0.9000\n",
      "Epoch 00282: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 932us/sample - loss: 0.3340 - accuracy: 0.8542 - val_loss: 0.3430 - val_accuracy: 0.8462\n",
      "Epoch 283/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2351 - accuracy: 0.9000\n",
      "Epoch 00283: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 889us/sample - loss: 0.2156 - accuracy: 0.8750 - val_loss: 0.4080 - val_accuracy: 0.8462\n",
      "Epoch 284/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3883 - accuracy: 0.9000\n",
      "Epoch 00284: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 892us/sample - loss: 0.3689 - accuracy: 0.8542 - val_loss: 0.3603 - val_accuracy: 0.8462\n",
      "Epoch 285/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1948 - accuracy: 1.0000\n",
      "Epoch 00285: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 888us/sample - loss: 0.3612 - accuracy: 0.8333 - val_loss: 0.2939 - val_accuracy: 0.8462\n",
      "Epoch 286/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2973 - accuracy: 0.9000\n",
      "Epoch 00286: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 918us/sample - loss: 0.3157 - accuracy: 0.8750 - val_loss: 0.2493 - val_accuracy: 0.9231\n",
      "Epoch 287/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3035 - accuracy: 0.8000\n",
      "Epoch 00287: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 957us/sample - loss: 0.3354 - accuracy: 0.8125 - val_loss: 0.2771 - val_accuracy: 0.9231\n",
      "Epoch 288/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2565 - accuracy: 0.9000\n",
      "Epoch 00288: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 936us/sample - loss: 0.2417 - accuracy: 0.9167 - val_loss: 0.3573 - val_accuracy: 0.8462\n",
      "Epoch 289/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3670 - accuracy: 0.7000\n",
      "Epoch 00289: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 982us/sample - loss: 0.3610 - accuracy: 0.8542 - val_loss: 0.4283 - val_accuracy: 0.8462\n",
      "Epoch 290/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6076 - accuracy: 0.8000\n",
      "Epoch 00290: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 900us/sample - loss: 0.2866 - accuracy: 0.8750 - val_loss: 0.3110 - val_accuracy: 0.8462\n",
      "Epoch 291/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2404 - accuracy: 0.9000\n",
      "Epoch 00291: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 901us/sample - loss: 0.3006 - accuracy: 0.8542 - val_loss: 0.2665 - val_accuracy: 0.9231\n",
      "Epoch 292/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0900 - accuracy: 1.0000\n",
      "Epoch 00292: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 872us/sample - loss: 0.3280 - accuracy: 0.8542 - val_loss: 0.2879 - val_accuracy: 0.9231\n",
      "Epoch 293/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4615 - accuracy: 0.8000\n",
      "Epoch 00293: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 905us/sample - loss: 0.2964 - accuracy: 0.8333 - val_loss: 0.3993 - val_accuracy: 0.8462\n",
      "Epoch 294/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2779 - accuracy: 0.9000\n",
      "Epoch 00294: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3179 - accuracy: 0.8542 - val_loss: 0.4455 - val_accuracy: 0.8462\n",
      "Epoch 295/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1156 - accuracy: 1.0000\n",
      "Epoch 00295: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 931us/sample - loss: 0.2809 - accuracy: 0.8750 - val_loss: 0.3517 - val_accuracy: 0.8462\n",
      "Epoch 296/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3748 - accuracy: 0.7000\n",
      "Epoch 00296: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 919us/sample - loss: 0.3245 - accuracy: 0.8333 - val_loss: 0.2900 - val_accuracy: 0.9231\n",
      "Epoch 297/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1445 - accuracy: 1.0000\n",
      "Epoch 00297: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 869us/sample - loss: 0.2603 - accuracy: 0.8958 - val_loss: 0.2850 - val_accuracy: 0.9231\n",
      "Epoch 298/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6806 - accuracy: 0.6000\n",
      "Epoch 00298: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 908us/sample - loss: 0.3789 - accuracy: 0.7500 - val_loss: 0.3077 - val_accuracy: 0.8462\n",
      "Epoch 299/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.7175 - accuracy: 0.6000\n",
      "Epoch 00299: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 0.3461 - accuracy: 0.8125 - val_loss: 0.3249 - val_accuracy: 0.8462\n",
      "Epoch 300/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3232 - accuracy: 0.9000\n",
      "Epoch 00300: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 863us/sample - loss: 0.2641 - accuracy: 0.8958 - val_loss: 0.3241 - val_accuracy: 0.8462\n",
      "Epoch 301/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1601 - accuracy: 0.9000\n",
      "Epoch 00301: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 857us/sample - loss: 0.2978 - accuracy: 0.8333 - val_loss: 0.3186 - val_accuracy: 0.8462\n",
      "Epoch 302/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1107 - accuracy: 1.0000\n",
      "Epoch 00302: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 852us/sample - loss: 0.2545 - accuracy: 0.9167 - val_loss: 0.3176 - val_accuracy: 0.8462\n",
      "Epoch 303/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4804 - accuracy: 0.6000\n",
      "Epoch 00303: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 836us/sample - loss: 0.2384 - accuracy: 0.8750 - val_loss: 0.3089 - val_accuracy: 0.8462\n",
      "Epoch 304/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3828 - accuracy: 0.8000\n",
      "Epoch 00304: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 838us/sample - loss: 0.2743 - accuracy: 0.8542 - val_loss: 0.3354 - val_accuracy: 0.8462\n",
      "Epoch 305/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1551 - accuracy: 1.0000\n",
      "Epoch 00305: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 825us/sample - loss: 0.2251 - accuracy: 0.8750 - val_loss: 0.3588 - val_accuracy: 0.8462\n",
      "Epoch 306/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3082 - accuracy: 0.9000\n",
      "Epoch 00306: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 828us/sample - loss: 0.2883 - accuracy: 0.8750 - val_loss: 0.3009 - val_accuracy: 0.8462\n",
      "Epoch 307/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1679 - accuracy: 1.0000\n",
      "Epoch 00307: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 827us/sample - loss: 0.2280 - accuracy: 0.9167 - val_loss: 0.2904 - val_accuracy: 0.8462\n",
      "Epoch 308/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1058 - accuracy: 1.0000\n",
      "Epoch 00308: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 813us/sample - loss: 0.1910 - accuracy: 0.9583 - val_loss: 0.3078 - val_accuracy: 0.8462\n",
      "Epoch 309/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0429 - accuracy: 1.0000\n",
      "Epoch 00309: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 825us/sample - loss: 0.2835 - accuracy: 0.8542 - val_loss: 0.3340 - val_accuracy: 0.8462\n",
      "Epoch 310/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2356 - accuracy: 0.8000\n",
      "Epoch 00310: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 823us/sample - loss: 0.2696 - accuracy: 0.8750 - val_loss: 0.4004 - val_accuracy: 0.8462\n",
      "Epoch 311/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2368 - accuracy: 0.9000\n",
      "Epoch 00311: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 800us/sample - loss: 0.2929 - accuracy: 0.8333 - val_loss: 0.3522 - val_accuracy: 0.8462\n",
      "Epoch 312/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 00312: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 809us/sample - loss: 0.2084 - accuracy: 0.8958 - val_loss: 0.2709 - val_accuracy: 0.9231\n",
      "Epoch 313/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3424 - accuracy: 0.8000\n",
      "Epoch 00313: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 820us/sample - loss: 0.2842 - accuracy: 0.8542 - val_loss: 0.2721 - val_accuracy: 0.8462\n",
      "Epoch 314/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch 00314: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 845us/sample - loss: 0.3038 - accuracy: 0.8333 - val_loss: 0.3342 - val_accuracy: 0.8462\n",
      "Epoch 315/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2450 - accuracy: 0.9000\n",
      "Epoch 00315: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 869us/sample - loss: 0.2373 - accuracy: 0.8958 - val_loss: 0.3305 - val_accuracy: 0.8462\n",
      "Epoch 316/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4062 - accuracy: 0.7000\n",
      "Epoch 00316: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 885us/sample - loss: 0.1785 - accuracy: 0.8958 - val_loss: 0.3349 - val_accuracy: 0.8462\n",
      "Epoch 317/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0740 - accuracy: 1.0000\n",
      "Epoch 00317: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 912us/sample - loss: 0.2213 - accuracy: 0.8750 - val_loss: 0.3567 - val_accuracy: 0.8462\n",
      "Epoch 318/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3612 - accuracy: 0.8000\n",
      "Epoch 00318: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 907us/sample - loss: 0.2458 - accuracy: 0.8333 - val_loss: 0.2972 - val_accuracy: 0.8462\n",
      "Epoch 319/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2316 - accuracy: 0.9000\n",
      "Epoch 00319: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 842us/sample - loss: 0.3303 - accuracy: 0.8542 - val_loss: 0.2709 - val_accuracy: 0.8462\n",
      "Epoch 320/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3880 - accuracy: 0.8000\n",
      "Epoch 00320: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 884us/sample - loss: 0.2489 - accuracy: 0.8750 - val_loss: 0.3385 - val_accuracy: 0.8462\n",
      "Epoch 321/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4865 - accuracy: 0.7000\n",
      "Epoch 00321: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 928us/sample - loss: 0.2802 - accuracy: 0.8750 - val_loss: 0.3675 - val_accuracy: 0.8462\n",
      "Epoch 322/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1552 - accuracy: 0.9000\n",
      "Epoch 00322: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 882us/sample - loss: 0.2950 - accuracy: 0.8542 - val_loss: 0.3346 - val_accuracy: 0.8462\n",
      "Epoch 323/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5216 - accuracy: 0.7000\n",
      "Epoch 00323: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 856us/sample - loss: 0.2850 - accuracy: 0.8958 - val_loss: 0.2391 - val_accuracy: 0.9231\n",
      "Epoch 324/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1144 - accuracy: 1.0000\n",
      "Epoch 00324: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 862us/sample - loss: 0.3342 - accuracy: 0.8542 - val_loss: 0.2677 - val_accuracy: 0.9231\n",
      "Epoch 325/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3596 - accuracy: 0.9000\n",
      "Epoch 00325: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 874us/sample - loss: 0.2015 - accuracy: 0.9167 - val_loss: 0.3660 - val_accuracy: 0.8462\n",
      "Epoch 326/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4635 - accuracy: 0.8000\n",
      "Epoch 00326: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 861us/sample - loss: 0.2580 - accuracy: 0.9167 - val_loss: 0.3762 - val_accuracy: 0.8462\n",
      "Epoch 327/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1994 - accuracy: 0.9000\n",
      "Epoch 00327: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 854us/sample - loss: 0.1828 - accuracy: 0.9167 - val_loss: 0.3364 - val_accuracy: 0.8462\n",
      "Epoch 328/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0894 - accuracy: 1.0000\n",
      "Epoch 00328: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 913us/sample - loss: 0.1635 - accuracy: 0.9792 - val_loss: 0.3178 - val_accuracy: 0.8462\n",
      "Epoch 329/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0784 - accuracy: 1.0000\n",
      "Epoch 00329: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 875us/sample - loss: 0.2043 - accuracy: 0.9167 - val_loss: 0.2827 - val_accuracy: 0.8462\n",
      "Epoch 330/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3455 - accuracy: 0.9000\n",
      "Epoch 00330: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 863us/sample - loss: 0.2445 - accuracy: 0.9167 - val_loss: 0.2632 - val_accuracy: 0.8462\n",
      "Epoch 331/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2829 - accuracy: 0.9000\n",
      "Epoch 00331: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 886us/sample - loss: 0.2953 - accuracy: 0.8750 - val_loss: 0.3036 - val_accuracy: 0.8462\n",
      "Epoch 332/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0748 - accuracy: 1.0000\n",
      "Epoch 00332: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 881us/sample - loss: 0.2396 - accuracy: 0.8958 - val_loss: 0.2741 - val_accuracy: 0.8462\n",
      "Epoch 333/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1425 - accuracy: 1.0000\n",
      "Epoch 00333: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 843us/sample - loss: 0.1819 - accuracy: 0.9375 - val_loss: 0.2824 - val_accuracy: 0.8462\n",
      "Epoch 334/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2593 - accuracy: 0.9000\n",
      "Epoch 00334: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 909us/sample - loss: 0.2379 - accuracy: 0.8958 - val_loss: 0.3009 - val_accuracy: 0.8462\n",
      "Epoch 335/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1318 - accuracy: 1.0000\n",
      "Epoch 00335: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 858us/sample - loss: 0.2644 - accuracy: 0.9167 - val_loss: 0.3302 - val_accuracy: 0.8462\n",
      "Epoch 336/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1928 - accuracy: 0.9000\n",
      "Epoch 00336: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 852us/sample - loss: 0.2020 - accuracy: 0.9167 - val_loss: 0.2925 - val_accuracy: 0.8462\n",
      "Epoch 337/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2603 - accuracy: 0.8000\n",
      "Epoch 00337: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 800us/sample - loss: 0.2324 - accuracy: 0.8542 - val_loss: 0.3058 - val_accuracy: 0.8462\n",
      "Epoch 338/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3737 - accuracy: 0.8000\n",
      "Epoch 00338: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 817us/sample - loss: 0.1999 - accuracy: 0.9375 - val_loss: 0.3574 - val_accuracy: 0.8462\n",
      "Epoch 339/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2731 - accuracy: 0.9000\n",
      "Epoch 00339: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 842us/sample - loss: 0.3207 - accuracy: 0.8542 - val_loss: 0.3236 - val_accuracy: 0.8462\n",
      "Epoch 340/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0938 - accuracy: 1.0000\n",
      "Epoch 00340: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 826us/sample - loss: 0.2127 - accuracy: 0.8958 - val_loss: 0.2624 - val_accuracy: 0.8462\n",
      "Epoch 341/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3890 - accuracy: 0.8000\n",
      "Epoch 00341: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 827us/sample - loss: 0.2928 - accuracy: 0.8333 - val_loss: 0.2433 - val_accuracy: 0.9231\n",
      "Epoch 342/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2942 - accuracy: 0.8000\n",
      "Epoch 00342: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 844us/sample - loss: 0.2838 - accuracy: 0.8542 - val_loss: 0.3043 - val_accuracy: 0.8462\n",
      "Epoch 343/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5168 - accuracy: 0.8000\n",
      "Epoch 00343: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 804us/sample - loss: 0.3579 - accuracy: 0.8958 - val_loss: 0.3205 - val_accuracy: 0.8462\n",
      "Epoch 344/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5315 - accuracy: 0.8000\n",
      "Epoch 00344: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 843us/sample - loss: 0.2083 - accuracy: 0.9583 - val_loss: 0.2656 - val_accuracy: 0.8462\n",
      "Epoch 345/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2960 - accuracy: 0.8000\n",
      "Epoch 00345: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 822us/sample - loss: 0.2780 - accuracy: 0.8333 - val_loss: 0.2603 - val_accuracy: 0.9231\n",
      "Epoch 346/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0837 - accuracy: 1.0000\n",
      "Epoch 00346: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 834us/sample - loss: 0.1821 - accuracy: 0.9167 - val_loss: 0.2771 - val_accuracy: 0.8462\n",
      "Epoch 347/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2621 - accuracy: 0.9000\n",
      "Epoch 00347: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 790us/sample - loss: 0.2134 - accuracy: 0.8958 - val_loss: 0.2478 - val_accuracy: 0.9231\n",
      "Epoch 348/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2000 - accuracy: 0.9000\n",
      "Epoch 00348: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 842us/sample - loss: 0.2683 - accuracy: 0.9167 - val_loss: 0.2471 - val_accuracy: 0.9231\n",
      "Epoch 349/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3311 - accuracy: 0.9000\n",
      "Epoch 00349: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 800us/sample - loss: 0.2849 - accuracy: 0.8750 - val_loss: 0.2647 - val_accuracy: 0.8462\n",
      "Epoch 350/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2125 - accuracy: 0.9000\n",
      "Epoch 00350: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 804us/sample - loss: 0.1950 - accuracy: 0.9375 - val_loss: 0.2517 - val_accuracy: 0.9231\n",
      "Epoch 351/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1654 - accuracy: 0.9000\n",
      "Epoch 00351: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 840us/sample - loss: 0.1715 - accuracy: 0.9167 - val_loss: 0.2688 - val_accuracy: 0.8462\n",
      "Epoch 352/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0893 - accuracy: 1.0000\n",
      "Epoch 00352: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 786us/sample - loss: 0.1969 - accuracy: 0.9375 - val_loss: 0.3002 - val_accuracy: 0.8462\n",
      "Epoch 353/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 00353: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 835us/sample - loss: 0.2277 - accuracy: 0.9167 - val_loss: 0.3233 - val_accuracy: 0.8462\n",
      "Epoch 354/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2181 - accuracy: 0.9000\n",
      "Epoch 00354: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 896us/sample - loss: 0.3010 - accuracy: 0.8125 - val_loss: 0.2520 - val_accuracy: 0.9231\n",
      "Epoch 355/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4688 - accuracy: 0.7000\n",
      "Epoch 00355: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 899us/sample - loss: 0.3295 - accuracy: 0.8542 - val_loss: 0.2445 - val_accuracy: 0.9231\n",
      "Epoch 356/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3072 - accuracy: 0.9000\n",
      "Epoch 00356: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 855us/sample - loss: 0.2535 - accuracy: 0.8750 - val_loss: 0.2775 - val_accuracy: 0.8462\n",
      "Epoch 357/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0690 - accuracy: 1.0000\n",
      "Epoch 00357: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 867us/sample - loss: 0.1594 - accuracy: 0.9167 - val_loss: 0.2998 - val_accuracy: 0.8462\n",
      "Epoch 358/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0613 - accuracy: 1.0000\n",
      "Epoch 00358: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 853us/sample - loss: 0.3612 - accuracy: 0.8542 - val_loss: 0.2617 - val_accuracy: 0.8462\n",
      "Epoch 359/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1802 - accuracy: 0.9000\n",
      "Epoch 00359: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 933us/sample - loss: 0.1961 - accuracy: 0.9167 - val_loss: 0.2851 - val_accuracy: 0.8462\n",
      "Epoch 360/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0410 - accuracy: 1.0000\n",
      "Epoch 00360: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 891us/sample - loss: 0.2012 - accuracy: 0.8958 - val_loss: 0.2498 - val_accuracy: 0.9231\n",
      "Epoch 361/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1888 - accuracy: 0.9000\n",
      "Epoch 00361: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 962us/sample - loss: 0.3447 - accuracy: 0.8542 - val_loss: 0.2294 - val_accuracy: 0.9231\n",
      "Epoch 362/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2093 - accuracy: 1.0000\n",
      "Epoch 00362: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 894us/sample - loss: 0.2203 - accuracy: 0.9167 - val_loss: 0.2715 - val_accuracy: 0.8462\n",
      "Epoch 363/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4055 - accuracy: 0.8000\n",
      "Epoch 00363: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 843us/sample - loss: 0.3102 - accuracy: 0.8542 - val_loss: 0.2797 - val_accuracy: 0.8462\n",
      "Epoch 364/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1254 - accuracy: 0.9000\n",
      "Epoch 00364: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 905us/sample - loss: 0.2028 - accuracy: 0.9167 - val_loss: 0.2486 - val_accuracy: 0.9231\n",
      "Epoch 365/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1747 - accuracy: 1.0000\n",
      "Epoch 00365: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 971us/sample - loss: 0.2069 - accuracy: 0.9375 - val_loss: 0.2302 - val_accuracy: 0.9231\n",
      "Epoch 366/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3196 - accuracy: 0.9000\n",
      "Epoch 00366: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 874us/sample - loss: 0.2822 - accuracy: 0.8542 - val_loss: 0.2418 - val_accuracy: 0.9231\n",
      "Epoch 367/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3803 - accuracy: 0.8000\n",
      "Epoch 00367: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 881us/sample - loss: 0.1926 - accuracy: 0.9375 - val_loss: 0.2609 - val_accuracy: 0.8462\n",
      "Epoch 368/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3074 - accuracy: 0.8000\n",
      "Epoch 00368: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 927us/sample - loss: 0.2490 - accuracy: 0.8958 - val_loss: 0.2844 - val_accuracy: 0.8462\n",
      "Epoch 369/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2525 - accuracy: 0.9000\n",
      "Epoch 00369: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 903us/sample - loss: 0.2235 - accuracy: 0.8958 - val_loss: 0.2708 - val_accuracy: 0.8462\n",
      "Epoch 370/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4079 - accuracy: 0.8000\n",
      "Epoch 00370: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 857us/sample - loss: 0.2294 - accuracy: 0.8958 - val_loss: 0.2222 - val_accuracy: 0.9231\n",
      "Epoch 371/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1908 - accuracy: 0.9000\n",
      "Epoch 00371: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 935us/sample - loss: 0.2516 - accuracy: 0.8750 - val_loss: 0.2005 - val_accuracy: 0.9231\n",
      "Epoch 372/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6313 - accuracy: 0.9000\n",
      "Epoch 00372: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 921us/sample - loss: 0.2588 - accuracy: 0.9375 - val_loss: 0.3012 - val_accuracy: 0.8462\n",
      "Epoch 373/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1328 - accuracy: 0.9000\n",
      "Epoch 00373: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 867us/sample - loss: 0.2360 - accuracy: 0.8750 - val_loss: 0.2985 - val_accuracy: 0.8462\n",
      "Epoch 374/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2378 - accuracy: 0.9000\n",
      "Epoch 00374: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 839us/sample - loss: 0.2263 - accuracy: 0.8958 - val_loss: 0.2774 - val_accuracy: 0.8462\n",
      "Epoch 375/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1255 - accuracy: 1.0000\n",
      "Epoch 00375: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 928us/sample - loss: 0.2433 - accuracy: 0.8958 - val_loss: 0.2416 - val_accuracy: 0.9231\n",
      "Epoch 376/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2396 - accuracy: 0.8000\n",
      "Epoch 00376: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 875us/sample - loss: 0.2274 - accuracy: 0.9167 - val_loss: 0.2408 - val_accuracy: 0.9231\n",
      "Epoch 377/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1413 - accuracy: 1.0000\n",
      "Epoch 00377: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 805us/sample - loss: 0.2236 - accuracy: 0.9375 - val_loss: 0.2537 - val_accuracy: 0.9231\n",
      "Epoch 378/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5098 - accuracy: 0.8000\n",
      "Epoch 00378: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2533 - accuracy: 0.8958 - val_loss: 0.2997 - val_accuracy: 0.8462\n",
      "Epoch 379/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1098 - accuracy: 1.0000\n",
      "Epoch 00379: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 931us/sample - loss: 0.2217 - accuracy: 0.8958 - val_loss: 0.2377 - val_accuracy: 0.9231\n",
      "Epoch 380/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5434 - accuracy: 0.8000\n",
      "Epoch 00380: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 994us/sample - loss: 0.2313 - accuracy: 0.8958 - val_loss: 0.2228 - val_accuracy: 0.9231\n",
      "Epoch 381/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1624 - accuracy: 0.9000\n",
      "Epoch 00381: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1883 - accuracy: 0.8958 - val_loss: 0.2572 - val_accuracy: 0.8462\n",
      "Epoch 382/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5974 - accuracy: 0.8000\n",
      "Epoch 00382: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2707 - accuracy: 0.9167 - val_loss: 0.2584 - val_accuracy: 0.8462\n",
      "Epoch 383/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2745 - accuracy: 0.8000\n",
      "Epoch 00383: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 962us/sample - loss: 0.1958 - accuracy: 0.8750 - val_loss: 0.2186 - val_accuracy: 0.9231\n",
      "Epoch 384/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1012 - accuracy: 0.9000\n",
      "Epoch 00384: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 972us/sample - loss: 0.1511 - accuracy: 0.9167 - val_loss: 0.2245 - val_accuracy: 0.9231\n",
      "Epoch 385/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5506 - accuracy: 0.7000\n",
      "Epoch 00385: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 931us/sample - loss: 0.2602 - accuracy: 0.8333 - val_loss: 0.2678 - val_accuracy: 0.8462\n",
      "Epoch 386/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3377 - accuracy: 0.9000\n",
      "Epoch 00386: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 940us/sample - loss: 0.2206 - accuracy: 0.9167 - val_loss: 0.2666 - val_accuracy: 0.8462\n",
      "Epoch 387/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1922 - accuracy: 0.9000\n",
      "Epoch 00387: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3182 - accuracy: 0.8750 - val_loss: 0.2079 - val_accuracy: 0.9231\n",
      "Epoch 388/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0784 - accuracy: 1.0000\n",
      "Epoch 00388: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 916us/sample - loss: 0.2644 - accuracy: 0.8958 - val_loss: 0.2127 - val_accuracy: 0.9231\n",
      "Epoch 389/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2036 - accuracy: 1.0000\n",
      "Epoch 00389: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 953us/sample - loss: 0.2388 - accuracy: 0.9167 - val_loss: 0.2852 - val_accuracy: 0.8462\n",
      "Epoch 390/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6312 - accuracy: 0.7000\n",
      "Epoch 00390: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 944us/sample - loss: 0.2448 - accuracy: 0.8958 - val_loss: 0.2217 - val_accuracy: 0.9231\n",
      "Epoch 391/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2038 - accuracy: 0.9000\n",
      "Epoch 00391: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 854us/sample - loss: 0.1481 - accuracy: 0.9375 - val_loss: 0.1972 - val_accuracy: 0.9231\n",
      "Epoch 392/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1969 - accuracy: 0.9000\n",
      "Epoch 00392: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 832us/sample - loss: 0.3216 - accuracy: 0.8542 - val_loss: 0.1979 - val_accuracy: 0.9231\n",
      "Epoch 393/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2066 - accuracy: 0.9000\n",
      "Epoch 00393: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 869us/sample - loss: 0.2624 - accuracy: 0.8542 - val_loss: 0.2750 - val_accuracy: 0.8462\n",
      "Epoch 394/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0306 - accuracy: 1.0000\n",
      "Epoch 00394: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 908us/sample - loss: 0.2467 - accuracy: 0.8750 - val_loss: 0.2918 - val_accuracy: 0.8462\n",
      "Epoch 395/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2179 - accuracy: 0.9000\n",
      "Epoch 00395: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 854us/sample - loss: 0.1890 - accuracy: 0.9167 - val_loss: 0.2458 - val_accuracy: 0.9231\n",
      "Epoch 396/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2683 - accuracy: 0.8000\n",
      "Epoch 00396: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 903us/sample - loss: 0.2183 - accuracy: 0.8958 - val_loss: 0.2275 - val_accuracy: 0.9231\n",
      "Epoch 397/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2537 - accuracy: 0.9000\n",
      "Epoch 00397: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 900us/sample - loss: 0.2428 - accuracy: 0.8958 - val_loss: 0.2963 - val_accuracy: 0.8462\n",
      "Epoch 398/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4678 - accuracy: 0.8000\n",
      "Epoch 00398: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 961us/sample - loss: 0.3124 - accuracy: 0.8542 - val_loss: 0.2843 - val_accuracy: 0.8462\n",
      "Epoch 399/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2752 - accuracy: 0.9000\n",
      "Epoch 00399: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 937us/sample - loss: 0.2927 - accuracy: 0.8958 - val_loss: 0.2116 - val_accuracy: 0.9231\n",
      "Epoch 400/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2323 - accuracy: 0.8000\n",
      "Epoch 00400: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2733 - accuracy: 0.8750 - val_loss: 0.1909 - val_accuracy: 0.9231\n",
      "Epoch 401/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1881 - accuracy: 0.9000\n",
      "Epoch 00401: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2352 - accuracy: 0.8958 - val_loss: 0.2364 - val_accuracy: 0.9231\n",
      "Epoch 402/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2158 - accuracy: 0.9000\n",
      "Epoch 00402: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 998us/sample - loss: 0.2504 - accuracy: 0.8750 - val_loss: 0.3171 - val_accuracy: 0.8462\n",
      "Epoch 403/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2524 - accuracy: 0.9000\n",
      "Epoch 00403: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 972us/sample - loss: 0.2549 - accuracy: 0.8958 - val_loss: 0.2801 - val_accuracy: 0.8462\n",
      "Epoch 404/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0524 - accuracy: 1.0000\n",
      "Epoch 00404: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 912us/sample - loss: 0.2294 - accuracy: 0.8750 - val_loss: 0.2065 - val_accuracy: 0.9231\n",
      "Epoch 405/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4034 - accuracy: 0.9000\n",
      "Epoch 00405: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2594 - accuracy: 0.9167 - val_loss: 0.2179 - val_accuracy: 0.9231\n",
      "Epoch 406/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0765 - accuracy: 1.0000\n",
      "Epoch 00406: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 991us/sample - loss: 0.2396 - accuracy: 0.8958 - val_loss: 0.2968 - val_accuracy: 0.8462\n",
      "Epoch 407/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1230 - accuracy: 1.0000\n",
      "Epoch 00407: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 881us/sample - loss: 0.1538 - accuracy: 0.9375 - val_loss: 0.3461 - val_accuracy: 0.8462\n",
      "Epoch 408/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5239 - accuracy: 0.7000\n",
      "Epoch 00408: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 0.3321 - accuracy: 0.8542 - val_loss: 0.2620 - val_accuracy: 0.8462\n",
      "Epoch 409/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2860 - accuracy: 0.9000\n",
      "Epoch 00409: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 856us/sample - loss: 0.2050 - accuracy: 0.9375 - val_loss: 0.2057 - val_accuracy: 0.9231\n",
      "Epoch 410/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3971 - accuracy: 0.8000\n",
      "Epoch 00410: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 778us/sample - loss: 0.2566 - accuracy: 0.8750 - val_loss: 0.2381 - val_accuracy: 0.9231\n",
      "Epoch 411/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4251 - accuracy: 0.6000\n",
      "Epoch 00411: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 872us/sample - loss: 0.2443 - accuracy: 0.8542 - val_loss: 0.2487 - val_accuracy: 0.8462\n",
      "Epoch 412/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1508 - accuracy: 0.9000\n",
      "Epoch 00412: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 815us/sample - loss: 0.1840 - accuracy: 0.8958 - val_loss: 0.2154 - val_accuracy: 0.9231\n",
      "Epoch 413/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1209 - accuracy: 1.0000\n",
      "Epoch 00413: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 785us/sample - loss: 0.2400 - accuracy: 0.8958 - val_loss: 0.1990 - val_accuracy: 0.9231\n",
      "Epoch 414/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2284 - accuracy: 0.9000\n",
      "Epoch 00414: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 846us/sample - loss: 0.2310 - accuracy: 0.8958 - val_loss: 0.2338 - val_accuracy: 0.9231\n",
      "Epoch 415/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1775 - accuracy: 0.9000\n",
      "Epoch 00415: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 804us/sample - loss: 0.1920 - accuracy: 0.8750 - val_loss: 0.3237 - val_accuracy: 0.8462\n",
      "Epoch 416/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1923 - accuracy: 0.9000\n",
      "Epoch 00416: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 866us/sample - loss: 0.2961 - accuracy: 0.8750 - val_loss: 0.2798 - val_accuracy: 0.8462\n",
      "Epoch 417/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1452 - accuracy: 1.0000\n",
      "Epoch 00417: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 948us/sample - loss: 0.2767 - accuracy: 0.8958 - val_loss: 0.1941 - val_accuracy: 0.9231\n",
      "Epoch 418/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2252 - accuracy: 0.9000\n",
      "Epoch 00418: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 885us/sample - loss: 0.3346 - accuracy: 0.8750 - val_loss: 0.2071 - val_accuracy: 0.9231\n",
      "Epoch 419/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3002 - accuracy: 0.8000\n",
      "Epoch 00419: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 861us/sample - loss: 0.2934 - accuracy: 0.8333 - val_loss: 0.3110 - val_accuracy: 0.8462\n",
      "Epoch 420/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4526 - accuracy: 0.9000\n",
      "Epoch 00420: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 879us/sample - loss: 0.2740 - accuracy: 0.9167 - val_loss: 0.2775 - val_accuracy: 0.8462\n",
      "Epoch 421/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4481 - accuracy: 0.8000\n",
      "Epoch 00421: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 974us/sample - loss: 0.2661 - accuracy: 0.8750 - val_loss: 0.2605 - val_accuracy: 0.8462\n",
      "Epoch 422/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2949 - accuracy: 0.8000\n",
      "Epoch 00422: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 880us/sample - loss: 0.2117 - accuracy: 0.9375 - val_loss: 0.2581 - val_accuracy: 0.9231\n",
      "Epoch 423/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0566 - accuracy: 1.0000\n",
      "Epoch 00423: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 887us/sample - loss: 0.1941 - accuracy: 0.9375 - val_loss: 0.2531 - val_accuracy: 0.9231\n",
      "Epoch 424/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1303 - accuracy: 0.9000\n",
      "Epoch 00424: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 923us/sample - loss: 0.2199 - accuracy: 0.9167 - val_loss: 0.2639 - val_accuracy: 0.8462\n",
      "Epoch 425/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1342 - accuracy: 1.0000\n",
      "Epoch 00425: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 896us/sample - loss: 0.1894 - accuracy: 0.9375 - val_loss: 0.2648 - val_accuracy: 0.8462\n",
      "Epoch 426/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3918 - accuracy: 0.8000\n",
      "Epoch 00426: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 822us/sample - loss: 0.1956 - accuracy: 0.9375 - val_loss: 0.2298 - val_accuracy: 0.9231\n",
      "Epoch 427/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1725 - accuracy: 0.9000\n",
      "Epoch 00427: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 798us/sample - loss: 0.2125 - accuracy: 0.8958 - val_loss: 0.2144 - val_accuracy: 0.9231\n",
      "Epoch 428/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2005 - accuracy: 0.9000\n",
      "Epoch 00428: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 833us/sample - loss: 0.2252 - accuracy: 0.9167 - val_loss: 0.2235 - val_accuracy: 0.9231\n",
      "Epoch 429/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1626 - accuracy: 0.9000\n",
      "Epoch 00429: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1928 - accuracy: 0.9375 - val_loss: 0.2539 - val_accuracy: 0.8462\n",
      "Epoch 430/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1091 - accuracy: 1.0000\n",
      "Epoch 00430: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 930us/sample - loss: 0.2366 - accuracy: 0.8542 - val_loss: 0.2516 - val_accuracy: 0.8462\n",
      "Epoch 431/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1225 - accuracy: 0.9000\n",
      "Epoch 00431: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 0.1718 - accuracy: 0.9375 - val_loss: 0.2263 - val_accuracy: 0.9231\n",
      "Epoch 432/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2008 - accuracy: 0.9000\n",
      "Epoch 00432: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 889us/sample - loss: 0.1963 - accuracy: 0.9167 - val_loss: 0.2133 - val_accuracy: 0.9231\n",
      "Epoch 433/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.6507 - accuracy: 0.7000\n",
      "Epoch 00433: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 924us/sample - loss: 0.2466 - accuracy: 0.8750 - val_loss: 0.2289 - val_accuracy: 0.9231\n",
      "Epoch 434/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1549 - accuracy: 0.9000\n",
      "Epoch 00434: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 874us/sample - loss: 0.1599 - accuracy: 0.9375 - val_loss: 0.2482 - val_accuracy: 0.8462\n",
      "Epoch 435/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3454 - accuracy: 0.9000\n",
      "Epoch 00435: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 792us/sample - loss: 0.1779 - accuracy: 0.9583 - val_loss: 0.2602 - val_accuracy: 0.8462\n",
      "Epoch 436/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5378 - accuracy: 0.7000\n",
      "Epoch 00436: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 840us/sample - loss: 0.2882 - accuracy: 0.8750 - val_loss: 0.2220 - val_accuracy: 0.9231\n",
      "Epoch 437/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3652 - accuracy: 0.8000\n",
      "Epoch 00437: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 881us/sample - loss: 0.2730 - accuracy: 0.8542 - val_loss: 0.2884 - val_accuracy: 0.8462\n",
      "Epoch 438/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4350 - accuracy: 0.8000\n",
      "Epoch 00438: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 815us/sample - loss: 0.2462 - accuracy: 0.8958 - val_loss: 0.2432 - val_accuracy: 0.8462\n",
      "Epoch 439/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0496 - accuracy: 1.0000\n",
      "Epoch 00439: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 808us/sample - loss: 0.3084 - accuracy: 0.8542 - val_loss: 0.2164 - val_accuracy: 0.9231\n",
      "Epoch 440/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4503 - accuracy: 0.8000\n",
      "Epoch 00440: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 770us/sample - loss: 0.2725 - accuracy: 0.8750 - val_loss: 0.2168 - val_accuracy: 0.9231\n",
      "Epoch 441/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3397 - accuracy: 0.9000\n",
      "Epoch 00441: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 871us/sample - loss: 0.2060 - accuracy: 0.9167 - val_loss: 0.2252 - val_accuracy: 0.9231\n",
      "Epoch 442/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1034 - accuracy: 1.0000\n",
      "Epoch 00442: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 846us/sample - loss: 0.1821 - accuracy: 0.9375 - val_loss: 0.2416 - val_accuracy: 0.8462\n",
      "Epoch 443/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4264 - accuracy: 0.8000\n",
      "Epoch 00443: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 785us/sample - loss: 0.2440 - accuracy: 0.8958 - val_loss: 0.2638 - val_accuracy: 0.8462\n",
      "Epoch 444/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4723 - accuracy: 0.8000\n",
      "Epoch 00444: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 952us/sample - loss: 0.2381 - accuracy: 0.8542 - val_loss: 0.2210 - val_accuracy: 0.9231\n",
      "Epoch 445/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1666 - accuracy: 0.9000\n",
      "Epoch 00445: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 802us/sample - loss: 0.1846 - accuracy: 0.9375 - val_loss: 0.2441 - val_accuracy: 0.8462\n",
      "Epoch 446/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5481 - accuracy: 0.8000\n",
      "Epoch 00446: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 848us/sample - loss: 0.2125 - accuracy: 0.9167 - val_loss: 0.2361 - val_accuracy: 0.9231\n",
      "Epoch 447/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1292 - accuracy: 1.0000\n",
      "Epoch 00447: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 839us/sample - loss: 0.1895 - accuracy: 0.9167 - val_loss: 0.2006 - val_accuracy: 0.9231\n",
      "Epoch 448/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2508 - accuracy: 0.9000\n",
      "Epoch 00448: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 824us/sample - loss: 0.1871 - accuracy: 0.9167 - val_loss: 0.1904 - val_accuracy: 0.9231\n",
      "Epoch 449/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2679 - accuracy: 0.8000\n",
      "Epoch 00449: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 871us/sample - loss: 0.2500 - accuracy: 0.8750 - val_loss: 0.2012 - val_accuracy: 0.9231\n",
      "Epoch 450/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1645 - accuracy: 0.9000\n",
      "Epoch 00450: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 821us/sample - loss: 0.2508 - accuracy: 0.8958 - val_loss: 0.2593 - val_accuracy: 0.8462\n",
      "Epoch 451/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4188 - accuracy: 0.8000\n",
      "Epoch 00451: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 923us/sample - loss: 0.2144 - accuracy: 0.8958 - val_loss: 0.2494 - val_accuracy: 0.8462\n",
      "Epoch 452/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2641 - accuracy: 0.9000\n",
      "Epoch 00452: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 844us/sample - loss: 0.1758 - accuracy: 0.9375 - val_loss: 0.2200 - val_accuracy: 0.9231\n",
      "Epoch 453/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0895 - accuracy: 1.0000\n",
      "Epoch 00453: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 782us/sample - loss: 0.2274 - accuracy: 0.8333 - val_loss: 0.2354 - val_accuracy: 0.8462\n",
      "Epoch 454/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3722 - accuracy: 0.8000\n",
      "Epoch 00454: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 874us/sample - loss: 0.2412 - accuracy: 0.8958 - val_loss: 0.2313 - val_accuracy: 0.9231\n",
      "Epoch 455/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1357 - accuracy: 0.9000\n",
      "Epoch 00455: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 856us/sample - loss: 0.1847 - accuracy: 0.8958 - val_loss: 0.2360 - val_accuracy: 0.8462\n",
      "Epoch 456/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2518 - accuracy: 0.9000\n",
      "Epoch 00456: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 782us/sample - loss: 0.1661 - accuracy: 0.9375 - val_loss: 0.2392 - val_accuracy: 0.8462\n",
      "Epoch 457/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3819 - accuracy: 0.9000\n",
      "Epoch 00457: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 815us/sample - loss: 0.2200 - accuracy: 0.9167 - val_loss: 0.2491 - val_accuracy: 0.8462\n",
      "Epoch 458/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1373 - accuracy: 0.9000\n",
      "Epoch 00458: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 907us/sample - loss: 0.2408 - accuracy: 0.8750 - val_loss: 0.2796 - val_accuracy: 0.8462\n",
      "Epoch 459/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1075 - accuracy: 1.0000\n",
      "Epoch 00459: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 853us/sample - loss: 0.2241 - accuracy: 0.9375 - val_loss: 0.2032 - val_accuracy: 0.9231\n",
      "Epoch 460/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0751 - accuracy: 1.0000\n",
      "Epoch 00460: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2569 - accuracy: 0.8958 - val_loss: 0.2070 - val_accuracy: 0.9231\n",
      "Epoch 461/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2441 - accuracy: 0.9000\n",
      "Epoch 00461: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 921us/sample - loss: 0.2337 - accuracy: 0.8542 - val_loss: 0.2593 - val_accuracy: 0.8462\n",
      "Epoch 462/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1494 - accuracy: 0.9000\n",
      "Epoch 00462: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 965us/sample - loss: 0.2264 - accuracy: 0.8750 - val_loss: 0.2380 - val_accuracy: 0.8462\n",
      "Epoch 463/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1413 - accuracy: 0.9000\n",
      "Epoch 00463: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 843us/sample - loss: 0.1550 - accuracy: 0.9167 - val_loss: 0.2050 - val_accuracy: 0.9231\n",
      "Epoch 464/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2772 - accuracy: 0.8000\n",
      "Epoch 00464: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 857us/sample - loss: 0.1905 - accuracy: 0.8958 - val_loss: 0.2017 - val_accuracy: 0.9231\n",
      "Epoch 465/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1538 - accuracy: 0.9000\n",
      "Epoch 00465: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 820us/sample - loss: 0.2450 - accuracy: 0.8958 - val_loss: 0.2295 - val_accuracy: 0.8462\n",
      "Epoch 466/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0710 - accuracy: 1.0000\n",
      "Epoch 00466: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 925us/sample - loss: 0.2234 - accuracy: 0.9167 - val_loss: 0.2250 - val_accuracy: 0.8462\n",
      "Epoch 467/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2718 - accuracy: 0.8000\n",
      "Epoch 00467: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 863us/sample - loss: 0.1878 - accuracy: 0.9167 - val_loss: 0.2276 - val_accuracy: 0.8462\n",
      "Epoch 468/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0489 - accuracy: 1.0000\n",
      "Epoch 00468: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 825us/sample - loss: 0.1933 - accuracy: 0.9167 - val_loss: 0.2187 - val_accuracy: 0.9231\n",
      "Epoch 469/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3208 - accuracy: 0.9000\n",
      "Epoch 00469: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.1986 - accuracy: 0.9167 - val_loss: 0.2497 - val_accuracy: 0.8462\n",
      "Epoch 470/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2278 - accuracy: 0.9000\n",
      "Epoch 00470: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.3068 - accuracy: 0.8333 - val_loss: 0.2135 - val_accuracy: 0.9231\n",
      "Epoch 471/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1131 - accuracy: 0.9000\n",
      "Epoch 00471: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 906us/sample - loss: 0.2251 - accuracy: 0.8542 - val_loss: 0.2238 - val_accuracy: 0.8462\n",
      "Epoch 472/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 00472: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 883us/sample - loss: 0.1653 - accuracy: 0.9375 - val_loss: 0.2369 - val_accuracy: 0.8462\n",
      "Epoch 473/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1220 - accuracy: 0.9000\n",
      "Epoch 00473: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 934us/sample - loss: 0.1576 - accuracy: 0.9375 - val_loss: 0.2753 - val_accuracy: 0.8462\n",
      "Epoch 474/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1207 - accuracy: 1.0000\n",
      "Epoch 00474: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 990us/sample - loss: 0.2924 - accuracy: 0.8333 - val_loss: 0.3064 - val_accuracy: 0.8462\n",
      "Epoch 475/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4123 - accuracy: 0.8000\n",
      "Epoch 00475: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 942us/sample - loss: 0.1891 - accuracy: 0.9583 - val_loss: 0.2034 - val_accuracy: 0.9231\n",
      "Epoch 476/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3873 - accuracy: 0.8000\n",
      "Epoch 00476: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 896us/sample - loss: 0.2275 - accuracy: 0.9375 - val_loss: 0.2045 - val_accuracy: 0.9231\n",
      "Epoch 477/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.5704 - accuracy: 0.7000\n",
      "Epoch 00477: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 944us/sample - loss: 0.3495 - accuracy: 0.8333 - val_loss: 0.3306 - val_accuracy: 0.8462\n",
      "Epoch 478/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3383 - accuracy: 0.8000\n",
      "Epoch 00478: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 902us/sample - loss: 0.3845 - accuracy: 0.8542 - val_loss: 0.2738 - val_accuracy: 0.8462\n",
      "Epoch 479/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1127 - accuracy: 1.0000\n",
      "Epoch 00479: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 962us/sample - loss: 0.1438 - accuracy: 0.9583 - val_loss: 0.1896 - val_accuracy: 0.9231\n",
      "Epoch 480/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3207 - accuracy: 0.8000\n",
      "Epoch 00480: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 1ms/sample - loss: 0.2196 - accuracy: 0.8958 - val_loss: 0.1967 - val_accuracy: 0.9231\n",
      "Epoch 481/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1314 - accuracy: 1.0000\n",
      "Epoch 00481: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 937us/sample - loss: 0.1560 - accuracy: 0.9167 - val_loss: 0.2144 - val_accuracy: 0.9231\n",
      "Epoch 482/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2149 - accuracy: 1.0000\n",
      "Epoch 00482: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 939us/sample - loss: 0.1959 - accuracy: 0.9583 - val_loss: 0.2344 - val_accuracy: 0.8462\n",
      "Epoch 483/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2062 - accuracy: 0.9000\n",
      "Epoch 00483: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 895us/sample - loss: 0.1798 - accuracy: 0.9167 - val_loss: 0.1772 - val_accuracy: 0.9231\n",
      "Epoch 484/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1609 - accuracy: 0.9000\n",
      "Epoch 00484: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 968us/sample - loss: 0.1465 - accuracy: 0.9583 - val_loss: 0.1652 - val_accuracy: 0.9231\n",
      "Epoch 485/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3289 - accuracy: 0.9000\n",
      "Epoch 00485: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 893us/sample - loss: 0.1486 - accuracy: 0.9375 - val_loss: 0.1720 - val_accuracy: 0.9231\n",
      "Epoch 486/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3637 - accuracy: 0.8000\n",
      "Epoch 00486: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 913us/sample - loss: 0.2105 - accuracy: 0.9167 - val_loss: 0.2094 - val_accuracy: 0.9231\n",
      "Epoch 487/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2067 - accuracy: 0.9000\n",
      "Epoch 00487: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 928us/sample - loss: 0.2099 - accuracy: 0.8958 - val_loss: 0.2161 - val_accuracy: 0.9231\n",
      "Epoch 488/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3527 - accuracy: 0.8000\n",
      "Epoch 00488: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 949us/sample - loss: 0.2181 - accuracy: 0.8958 - val_loss: 0.1821 - val_accuracy: 0.9231\n",
      "Epoch 489/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4700 - accuracy: 0.7000\n",
      "Epoch 00489: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 859us/sample - loss: 0.1621 - accuracy: 0.9375 - val_loss: 0.1745 - val_accuracy: 0.9231\n",
      "Epoch 490/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1742 - accuracy: 0.9000\n",
      "Epoch 00490: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 903us/sample - loss: 0.1580 - accuracy: 0.9375 - val_loss: 0.2099 - val_accuracy: 0.9231\n",
      "Epoch 491/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 00491: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 839us/sample - loss: 0.2243 - accuracy: 0.9375 - val_loss: 0.2268 - val_accuracy: 0.8462\n",
      "Epoch 492/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1911 - accuracy: 0.9000\n",
      "Epoch 00492: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 808us/sample - loss: 0.2048 - accuracy: 0.8958 - val_loss: 0.1917 - val_accuracy: 0.9231\n",
      "Epoch 493/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1775 - accuracy: 0.9000\n",
      "Epoch 00493: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 952us/sample - loss: 0.2969 - accuracy: 0.8542 - val_loss: 0.1868 - val_accuracy: 0.9231\n",
      "Epoch 494/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2207 - accuracy: 0.9000\n",
      "Epoch 00494: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 825us/sample - loss: 0.2440 - accuracy: 0.8958 - val_loss: 0.2573 - val_accuracy: 0.8462\n",
      "Epoch 495/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.1720 - accuracy: 0.9000\n",
      "Epoch 00495: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 892us/sample - loss: 0.2308 - accuracy: 0.8750 - val_loss: 0.1911 - val_accuracy: 0.9231\n",
      "Epoch 496/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3359 - accuracy: 0.8000\n",
      "Epoch 00496: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 968us/sample - loss: 0.2292 - accuracy: 0.8750 - val_loss: 0.1589 - val_accuracy: 0.9231\n",
      "Epoch 497/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.2239 - accuracy: 0.8000\n",
      "Epoch 00497: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 873us/sample - loss: 0.2809 - accuracy: 0.8333 - val_loss: 0.1699 - val_accuracy: 0.9231\n",
      "Epoch 498/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.4164 - accuracy: 0.8000\n",
      "Epoch 00498: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 922us/sample - loss: 0.1767 - accuracy: 0.9167 - val_loss: 0.2191 - val_accuracy: 0.9231\n",
      "Epoch 499/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3499 - accuracy: 0.8000\n",
      "Epoch 00499: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 812us/sample - loss: 0.2729 - accuracy: 0.8958 - val_loss: 0.2405 - val_accuracy: 0.8462\n",
      "Epoch 500/500\n",
      "10/48 [=====>........................] - ETA: 0s - loss: 0.3651 - accuracy: 0.8000\n",
      "Epoch 00500: val_accuracy did not improve from 0.92308\n",
      "48/48 [==============================] - 0s 861us/sample - loss: 0.2604 - accuracy: 0.8750 - val_loss: 0.1810 - val_accuracy: 0.9231\n",
      "Training completed in time:  0:00:22.679155\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9166667\n",
      "Testing Accuracy:  0.54545456\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.38      1.00      0.55         3\n",
      "   Pneumonia       1.00      0.38      0.55         8\n",
      "\n",
      "    accuracy                           0.55        11\n",
      "   macro avg       0.69      0.69      0.55        11\n",
      "weighted avg       0.83      0.55      0.55        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [5 3]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
