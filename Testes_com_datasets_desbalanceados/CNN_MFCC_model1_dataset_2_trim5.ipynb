{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 1\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 2 - trim5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'trim5'\n",
    "GROUP_TEST = 'trim5'\n",
    "DATASET = 'dataset_2'\n",
    "DURATION = 5\n",
    "SIZE = 216\n",
    "CSV_TRAIN = 'train2.csv'\n",
    "CSV_TEST = 'test2.csv'\n",
    "MODEL_NAME = f'CNN1_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  123  Healthy\n",
       "1  125  Healthy\n",
       "2  126  Healthy\n",
       "3  127  Healthy\n",
       "4  136  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  336  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['96' '72']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['9' '39']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 40, 216)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 40, 216, 1) (168, 2)\n",
      "(48, 40, 216, 1) (48, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 215, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 106, 32)       2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 52, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 25, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 43,570\n",
      "Trainable params: 43,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "48/48 [==============================] - 1s 19ms/sample - loss: 14.6590 - accuracy: 0.1875\n",
      "Pre-training accuracy: 18.7500%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 34 samples\n",
      "Epoch 1/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 6.7498 - accuracy: 0.5182 \n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52941, saving model to models/CNN1_dataset_2_trim5_01.h5\n",
      "134/134 [==============================] - 1s 6ms/sample - loss: 5.9205 - accuracy: 0.5149 - val_loss: 0.7133 - val_accuracy: 0.5294\n",
      "Epoch 2/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 1.3784 - accuracy: 0.4667\n",
      "Epoch 00002: val_accuracy improved from 0.52941 to 0.61765, saving model to models/CNN1_dataset_2_trim5_02.h5\n",
      "134/134 [==============================] - 0s 782us/sample - loss: 1.3768 - accuracy: 0.4627 - val_loss: 0.6447 - val_accuracy: 0.6176\n",
      "Epoch 3/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.9266 - accuracy: 0.5727\n",
      "Epoch 00003: val_accuracy did not improve from 0.61765\n",
      "134/134 [==============================] - 0s 657us/sample - loss: 0.9240 - accuracy: 0.5672 - val_loss: 0.7030 - val_accuracy: 0.5588\n",
      "Epoch 4/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.6787 - accuracy: 0.7091\n",
      "Epoch 00004: val_accuracy did not improve from 0.61765\n",
      "134/134 [==============================] - 0s 651us/sample - loss: 0.7715 - accuracy: 0.6642 - val_loss: 0.7005 - val_accuracy: 0.5294\n",
      "Epoch 5/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.7688 - accuracy: 0.6364\n",
      "Epoch 00005: val_accuracy improved from 0.61765 to 0.79412, saving model to models/CNN1_dataset_2_trim5_05.h5\n",
      "134/134 [==============================] - 0s 799us/sample - loss: 0.7239 - accuracy: 0.6642 - val_loss: 0.5590 - val_accuracy: 0.7941\n",
      "Epoch 6/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.7647 - accuracy: 0.5750\n",
      "Epoch 00006: val_accuracy did not improve from 0.79412\n",
      "134/134 [==============================] - 0s 621us/sample - loss: 0.7540 - accuracy: 0.5896 - val_loss: 0.5351 - val_accuracy: 0.7353\n",
      "Epoch 7/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.7389 - accuracy: 0.6364\n",
      "Epoch 00007: val_accuracy improved from 0.79412 to 0.97059, saving model to models/CNN1_dataset_2_trim5_07.h5\n",
      "134/134 [==============================] - 0s 816us/sample - loss: 0.7655 - accuracy: 0.6119 - val_loss: 0.5351 - val_accuracy: 0.9706\n",
      "Epoch 8/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.7635 - accuracy: 0.6091\n",
      "Epoch 00008: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 651us/sample - loss: 0.7622 - accuracy: 0.6045 - val_loss: 0.5382 - val_accuracy: 0.8235\n",
      "Epoch 9/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.6843 - accuracy: 0.6091\n",
      "Epoch 00009: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 654us/sample - loss: 0.7131 - accuracy: 0.5970 - val_loss: 0.5300 - val_accuracy: 0.9118\n",
      "Epoch 10/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5929 - accuracy: 0.6545\n",
      "Epoch 00010: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 636us/sample - loss: 0.5866 - accuracy: 0.6791 - val_loss: 0.5272 - val_accuracy: 0.8235\n",
      "Epoch 11/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4876 - accuracy: 0.7500\n",
      "Epoch 00011: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 618us/sample - loss: 0.4917 - accuracy: 0.7463 - val_loss: 0.5165 - val_accuracy: 0.7647\n",
      "Epoch 12/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4448 - accuracy: 0.7818\n",
      "Epoch 00012: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 622us/sample - loss: 0.4597 - accuracy: 0.7761 - val_loss: 0.4472 - val_accuracy: 0.9706\n",
      "Epoch 13/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5094 - accuracy: 0.7909\n",
      "Epoch 00013: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 632us/sample - loss: 0.5231 - accuracy: 0.7761 - val_loss: 0.5154 - val_accuracy: 0.6176\n",
      "Epoch 14/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5530 - accuracy: 0.7636\n",
      "Epoch 00014: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 614us/sample - loss: 0.5126 - accuracy: 0.7836 - val_loss: 0.4861 - val_accuracy: 0.6765\n",
      "Epoch 15/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5507 - accuracy: 0.7000\n",
      "Epoch 00015: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 633us/sample - loss: 0.5298 - accuracy: 0.7313 - val_loss: 0.4087 - val_accuracy: 0.9706\n",
      "Epoch 16/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4982 - accuracy: 0.7417\n",
      "Epoch 00016: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 628us/sample - loss: 0.5056 - accuracy: 0.7313 - val_loss: 0.4459 - val_accuracy: 0.7647\n",
      "Epoch 17/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.4356 - accuracy: 0.8083\n",
      "Epoch 00017: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 615us/sample - loss: 0.4239 - accuracy: 0.8060 - val_loss: 0.4854 - val_accuracy: 0.6176\n",
      "Epoch 18/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.5230 - accuracy: 0.7727\n",
      "Epoch 00018: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 633us/sample - loss: 0.5116 - accuracy: 0.7612 - val_loss: 0.5814 - val_accuracy: 0.5588\n",
      "Epoch 19/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3822 - accuracy: 0.8182\n",
      "Epoch 00019: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 617us/sample - loss: 0.4082 - accuracy: 0.7985 - val_loss: 0.4032 - val_accuracy: 0.7941\n",
      "Epoch 20/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4239 - accuracy: 0.7818\n",
      "Epoch 00020: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 630us/sample - loss: 0.4165 - accuracy: 0.7910 - val_loss: 0.3878 - val_accuracy: 0.9412\n",
      "Epoch 21/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3804 - accuracy: 0.8364\n",
      "Epoch 00021: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 675us/sample - loss: 0.3972 - accuracy: 0.8284 - val_loss: 0.4014 - val_accuracy: 0.7647\n",
      "Epoch 22/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3888 - accuracy: 0.8273\n",
      "Epoch 00022: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 636us/sample - loss: 0.3650 - accuracy: 0.8433 - val_loss: 0.5723 - val_accuracy: 0.5882\n",
      "Epoch 23/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.4385 - accuracy: 0.7818\n",
      "Epoch 00023: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 625us/sample - loss: 0.4256 - accuracy: 0.7910 - val_loss: 0.3918 - val_accuracy: 0.7647\n",
      "Epoch 24/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3169 - accuracy: 0.8727\n",
      "Epoch 00024: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 626us/sample - loss: 0.3283 - accuracy: 0.8582 - val_loss: 0.3136 - val_accuracy: 0.9412\n",
      "Epoch 25/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3496 - accuracy: 0.8455\n",
      "Epoch 00025: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 628us/sample - loss: 0.3303 - accuracy: 0.8582 - val_loss: 0.4139 - val_accuracy: 0.6471\n",
      "Epoch 26/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.2866 - accuracy: 0.8727\n",
      "Epoch 00026: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 631us/sample - loss: 0.3315 - accuracy: 0.8433 - val_loss: 0.2705 - val_accuracy: 0.9412\n",
      "Epoch 27/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.2966 - accuracy: 0.8636\n",
      "Epoch 00027: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 648us/sample - loss: 0.2899 - accuracy: 0.8582 - val_loss: 0.3529 - val_accuracy: 0.7941\n",
      "Epoch 28/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.3397 - accuracy: 0.8500\n",
      "Epoch 00028: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 755us/sample - loss: 0.3333 - accuracy: 0.8284 - val_loss: 0.4984 - val_accuracy: 0.6176\n",
      "Epoch 29/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.4004 - accuracy: 0.7889\n",
      "Epoch 00029: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 777us/sample - loss: 0.3790 - accuracy: 0.7985 - val_loss: 0.3121 - val_accuracy: 0.8529\n",
      "Epoch 30/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.2675 - accuracy: 0.8556\n",
      "Epoch 00030: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 772us/sample - loss: 0.2874 - accuracy: 0.8433 - val_loss: 0.2579 - val_accuracy: 0.9118\n",
      "Epoch 31/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2535 - accuracy: 0.8800\n",
      "Epoch 00031: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 741us/sample - loss: 0.2450 - accuracy: 0.8881 - val_loss: 0.1949 - val_accuracy: 0.9412\n",
      "Epoch 32/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2870 - accuracy: 0.8900\n",
      "Epoch 00032: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 685us/sample - loss: 0.2713 - accuracy: 0.8806 - val_loss: 0.1995 - val_accuracy: 0.9412\n",
      "Epoch 33/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.2560 - accuracy: 0.8727\n",
      "Epoch 00033: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.2641 - accuracy: 0.8731 - val_loss: 0.2111 - val_accuracy: 0.9412\n",
      "Epoch 34/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.2121 - accuracy: 0.9182\n",
      "Epoch 00034: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 622us/sample - loss: 0.1999 - accuracy: 0.9254 - val_loss: 0.1565 - val_accuracy: 0.9412\n",
      "Epoch 35/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.2142 - accuracy: 0.9364\n",
      "Epoch 00035: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 613us/sample - loss: 0.1906 - accuracy: 0.9478 - val_loss: 0.1404 - val_accuracy: 0.9412\n",
      "Epoch 36/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1930 - accuracy: 0.9091\n",
      "Epoch 00036: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 663us/sample - loss: 0.1851 - accuracy: 0.9179 - val_loss: 0.1477 - val_accuracy: 0.9412\n",
      "Epoch 37/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2297 - accuracy: 0.9100\n",
      "Epoch 00037: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 796us/sample - loss: 0.1961 - accuracy: 0.9254 - val_loss: 0.2386 - val_accuracy: 0.9412\n",
      "Epoch 38/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.3435 - accuracy: 0.8200\n",
      "Epoch 00038: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 783us/sample - loss: 0.3310 - accuracy: 0.8284 - val_loss: 0.1771 - val_accuracy: 0.9412\n",
      "Epoch 39/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2338 - accuracy: 0.8800\n",
      "Epoch 00039: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 711us/sample - loss: 0.2384 - accuracy: 0.8731 - val_loss: 0.1391 - val_accuracy: 0.9412\n",
      "Epoch 40/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1636 - accuracy: 0.9300\n",
      "Epoch 00040: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 725us/sample - loss: 0.1755 - accuracy: 0.9104 - val_loss: 0.1249 - val_accuracy: 0.9412\n",
      "Epoch 41/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1490 - accuracy: 0.9455\n",
      "Epoch 00041: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 684us/sample - loss: 0.1813 - accuracy: 0.9328 - val_loss: 0.1217 - val_accuracy: 0.9412\n",
      "Epoch 42/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1632 - accuracy: 0.9500\n",
      "Epoch 00042: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 720us/sample - loss: 0.1602 - accuracy: 0.9478 - val_loss: 0.1211 - val_accuracy: 0.9412\n",
      "Epoch 43/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1402 - accuracy: 0.9600\n",
      "Epoch 00043: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 685us/sample - loss: 0.1259 - accuracy: 0.9627 - val_loss: 0.1097 - val_accuracy: 0.9706\n",
      "Epoch 44/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1273 - accuracy: 0.9600\n",
      "Epoch 00044: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 674us/sample - loss: 0.1171 - accuracy: 0.9701 - val_loss: 0.1104 - val_accuracy: 0.9706\n",
      "Epoch 45/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1159 - accuracy: 0.9545\n",
      "Epoch 00045: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 671us/sample - loss: 0.1501 - accuracy: 0.9478 - val_loss: 0.1083 - val_accuracy: 0.9412\n",
      "Epoch 46/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1302 - accuracy: 0.9455\n",
      "Epoch 00046: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.1789 - accuracy: 0.9328 - val_loss: 0.1240 - val_accuracy: 0.9412\n",
      "Epoch 47/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.2656 - accuracy: 0.8583\n",
      "Epoch 00047: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 615us/sample - loss: 0.2571 - accuracy: 0.8582 - val_loss: 0.1251 - val_accuracy: 0.9412\n",
      "Epoch 48/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.2108 - accuracy: 0.8909\n",
      "Epoch 00048: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 627us/sample - loss: 0.1877 - accuracy: 0.9104 - val_loss: 0.1759 - val_accuracy: 0.9118\n",
      "Epoch 49/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.3452 - accuracy: 0.8556\n",
      "Epoch 00049: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 727us/sample - loss: 0.2583 - accuracy: 0.8955 - val_loss: 0.1360 - val_accuracy: 0.9412\n",
      "Epoch 50/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1083 - accuracy: 0.9600\n",
      "Epoch 00050: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 706us/sample - loss: 0.1251 - accuracy: 0.9403 - val_loss: 0.1358 - val_accuracy: 0.9412\n",
      "Epoch 51/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.1601 - accuracy: 0.9444\n",
      "Epoch 00051: val_accuracy did not improve from 0.97059\n",
      "134/134 [==============================] - 0s 769us/sample - loss: 0.1507 - accuracy: 0.9403 - val_loss: 0.1199 - val_accuracy: 0.9412\n",
      "Epoch 52/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0886 - accuracy: 0.9900\n",
      "Epoch 00052: val_accuracy improved from 0.97059 to 1.00000, saving model to models/CNN1_dataset_2_trim5_52.h5\n",
      "134/134 [==============================] - 0s 918us/sample - loss: 0.1084 - accuracy: 0.9851 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1364 - accuracy: 0.9400\n",
      "Epoch 00053: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 967us/sample - loss: 0.1392 - accuracy: 0.9403 - val_loss: 0.0867 - val_accuracy: 0.9706\n",
      "Epoch 54/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1295 - accuracy: 0.9500\n",
      "Epoch 00054: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 720us/sample - loss: 0.1294 - accuracy: 0.9403 - val_loss: 0.0983 - val_accuracy: 0.9706\n",
      "Epoch 55/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2139 - accuracy: 0.9000\n",
      "Epoch 00055: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 735us/sample - loss: 0.1766 - accuracy: 0.9254 - val_loss: 0.1130 - val_accuracy: 0.9706\n",
      "Epoch 56/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0960 - accuracy: 0.9700\n",
      "Epoch 00056: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.0974 - accuracy: 0.9627 - val_loss: 0.1081 - val_accuracy: 0.9412\n",
      "Epoch 57/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1300 - accuracy: 0.9455\n",
      "Epoch 00057: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 638us/sample - loss: 0.1196 - accuracy: 0.9552 - val_loss: 0.0954 - val_accuracy: 0.9706\n",
      "Epoch 58/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1015 - accuracy: 0.9636\n",
      "Epoch 00058: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0938 - accuracy: 0.9701 - val_loss: 0.1132 - val_accuracy: 0.9706\n",
      "Epoch 59/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1049 - accuracy: 0.9636\n",
      "Epoch 00059: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 651us/sample - loss: 0.0963 - accuracy: 0.9701 - val_loss: 0.1098 - val_accuracy: 0.9412\n",
      "Epoch 60/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1325 - accuracy: 0.9400\n",
      "Epoch 00060: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 675us/sample - loss: 0.1282 - accuracy: 0.9478 - val_loss: 0.0880 - val_accuracy: 0.9706\n",
      "Epoch 61/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0829 - accuracy: 0.9900\n",
      "Epoch 00061: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 711us/sample - loss: 0.1124 - accuracy: 0.9627 - val_loss: 0.0899 - val_accuracy: 0.9412\n",
      "Epoch 62/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0901 - accuracy: 0.9545\n",
      "Epoch 00062: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0949 - accuracy: 0.9478 - val_loss: 0.0766 - val_accuracy: 0.9706\n",
      "Epoch 63/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1355 - accuracy: 0.9091\n",
      "Epoch 00063: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 623us/sample - loss: 0.1540 - accuracy: 0.9104 - val_loss: 0.1013 - val_accuracy: 0.9412\n",
      "Epoch 64/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.2271 - accuracy: 0.9167\n",
      "Epoch 00064: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 641us/sample - loss: 0.2173 - accuracy: 0.9179 - val_loss: 0.0868 - val_accuracy: 0.9412\n",
      "Epoch 65/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1184 - accuracy: 0.9364\n",
      "Epoch 00065: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 705us/sample - loss: 0.1345 - accuracy: 0.9328 - val_loss: 0.0863 - val_accuracy: 0.9706\n",
      "Epoch 66/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0870 - accuracy: 0.9636\n",
      "Epoch 00066: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 662us/sample - loss: 0.0831 - accuracy: 0.9627 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
      "Epoch 67/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0663 - accuracy: 0.9909\n",
      "Epoch 00067: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 629us/sample - loss: 0.0607 - accuracy: 0.9925 - val_loss: 0.0717 - val_accuracy: 0.9706\n",
      "Epoch 68/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0606 - accuracy: 0.9818\n",
      "Epoch 00068: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 640us/sample - loss: 0.0583 - accuracy: 0.9851 - val_loss: 0.0955 - val_accuracy: 0.9706\n",
      "Epoch 69/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1450 - accuracy: 0.9100\n",
      "Epoch 00069: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 693us/sample - loss: 0.1563 - accuracy: 0.9030 - val_loss: 0.0946 - val_accuracy: 0.9412\n",
      "Epoch 70/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0867 - accuracy: 0.9636\n",
      "Epoch 00070: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 655us/sample - loss: 0.1302 - accuracy: 0.9403 - val_loss: 0.0816 - val_accuracy: 0.9706\n",
      "Epoch 71/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1422 - accuracy: 0.9455\n",
      "Epoch 00071: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 664us/sample - loss: 0.1339 - accuracy: 0.9478 - val_loss: 0.0740 - val_accuracy: 0.9706\n",
      "Epoch 72/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1203 - accuracy: 0.9545\n",
      "Epoch 00072: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 679us/sample - loss: 0.1144 - accuracy: 0.9552 - val_loss: 0.0922 - val_accuracy: 0.9706\n",
      "Epoch 73/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0922 - accuracy: 0.9800\n",
      "Epoch 00073: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 713us/sample - loss: 0.0834 - accuracy: 0.9776 - val_loss: 0.0796 - val_accuracy: 0.9706\n",
      "Epoch 74/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0513 - accuracy: 0.9900\n",
      "Epoch 00074: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 692us/sample - loss: 0.0501 - accuracy: 0.9925 - val_loss: 0.0601 - val_accuracy: 0.9706\n",
      "Epoch 75/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0511 - accuracy: 0.9818\n",
      "Epoch 00075: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 671us/sample - loss: 0.0498 - accuracy: 0.9851 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0835 - accuracy: 0.9636\n",
      "Epoch 00076: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 666us/sample - loss: 0.0724 - accuracy: 0.9701 - val_loss: 0.0542 - val_accuracy: 0.9706\n",
      "Epoch 77/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0753 - accuracy: 0.9636\n",
      "Epoch 00077: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 680us/sample - loss: 0.1026 - accuracy: 0.9478 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0973 - accuracy: 0.9545\n",
      "Epoch 00078: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 680us/sample - loss: 0.0866 - accuracy: 0.9552 - val_loss: 0.0710 - val_accuracy: 0.9706\n",
      "Epoch 79/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1144 - accuracy: 0.9545\n",
      "Epoch 00079: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 682us/sample - loss: 0.1061 - accuracy: 0.9552 - val_loss: 0.0758 - val_accuracy: 0.9706\n",
      "Epoch 80/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1404 - accuracy: 0.9500\n",
      "Epoch 00080: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 677us/sample - loss: 0.1137 - accuracy: 0.9627 - val_loss: 0.1168 - val_accuracy: 0.9118\n",
      "Epoch 81/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1677 - accuracy: 0.9364\n",
      "Epoch 00081: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 675us/sample - loss: 0.1476 - accuracy: 0.9403 - val_loss: 0.1496 - val_accuracy: 0.9118\n",
      "Epoch 82/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0805 - accuracy: 0.9636\n",
      "Epoch 00082: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 655us/sample - loss: 0.0777 - accuracy: 0.9627 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 83/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0747 - accuracy: 0.9727\n",
      "Epoch 00083: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 642us/sample - loss: 0.0719 - accuracy: 0.9776 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0948 - accuracy: 0.9636\n",
      "Epoch 00084: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0911 - accuracy: 0.9627 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0611 - accuracy: 0.9818\n",
      "Epoch 00085: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 630us/sample - loss: 0.0557 - accuracy: 0.9851 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 86/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0585 - accuracy: 0.9818\n",
      "Epoch 00086: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 639us/sample - loss: 0.0554 - accuracy: 0.9851 - val_loss: 0.0500 - val_accuracy: 0.9706\n",
      "Epoch 87/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1342 - accuracy: 0.9400\n",
      "Epoch 00087: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 677us/sample - loss: 0.1294 - accuracy: 0.9403 - val_loss: 0.0605 - val_accuracy: 0.9706\n",
      "Epoch 88/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1835 - accuracy: 0.9455\n",
      "Epoch 00088: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 652us/sample - loss: 0.1702 - accuracy: 0.9478 - val_loss: 0.0541 - val_accuracy: 0.9706\n",
      "Epoch 89/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1688 - accuracy: 0.9182\n",
      "Epoch 00089: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 642us/sample - loss: 0.1994 - accuracy: 0.8881 - val_loss: 0.1056 - val_accuracy: 0.9706\n",
      "Epoch 90/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1157 - accuracy: 0.9455\n",
      "Epoch 00090: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 665us/sample - loss: 0.1007 - accuracy: 0.9552 - val_loss: 0.1160 - val_accuracy: 0.9706\n",
      "Epoch 91/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0881 - accuracy: 0.9500\n",
      "Epoch 00091: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 724us/sample - loss: 0.0925 - accuracy: 0.9403 - val_loss: 0.0610 - val_accuracy: 0.9706\n",
      "Epoch 92/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 00092: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 733us/sample - loss: 0.0408 - accuracy: 0.9925 - val_loss: 0.0850 - val_accuracy: 0.9706\n",
      "Epoch 93/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0634 - accuracy: 0.9800\n",
      "Epoch 00093: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 699us/sample - loss: 0.0567 - accuracy: 0.9851 - val_loss: 0.0549 - val_accuracy: 0.9706\n",
      "Epoch 94/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0764 - accuracy: 0.9556\n",
      "Epoch 00094: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 832us/sample - loss: 0.0576 - accuracy: 0.9701 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0511 - accuracy: 0.9889\n",
      "Epoch 00095: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 866us/sample - loss: 0.0522 - accuracy: 0.9925 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0677 - accuracy: 0.9778\n",
      "Epoch 00096: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 821us/sample - loss: 0.0515 - accuracy: 0.9851 - val_loss: 0.0557 - val_accuracy: 0.9706\n",
      "Epoch 97/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0599 - accuracy: 0.9889\n",
      "Epoch 00097: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 773us/sample - loss: 0.0572 - accuracy: 0.9851 - val_loss: 0.0615 - val_accuracy: 0.9706\n",
      "Epoch 98/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0228 - accuracy: 1.0000\n",
      "Epoch 00098: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 731us/sample - loss: 0.0410 - accuracy: 0.9925 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0219 - accuracy: 1.0000\n",
      "Epoch 00099: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 734us/sample - loss: 0.0346 - accuracy: 0.9925 - val_loss: 0.0693 - val_accuracy: 0.9706\n",
      "Epoch 100/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0699 - accuracy: 0.9818\n",
      "Epoch 00100: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 641us/sample - loss: 0.0634 - accuracy: 0.9851 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0421 - accuracy: 0.9818\n",
      "Epoch 00101: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 641us/sample - loss: 0.0436 - accuracy: 0.9851 - val_loss: 0.0475 - val_accuracy: 0.9706\n",
      "Epoch 102/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0427 - accuracy: 0.9909\n",
      "Epoch 00102: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 682us/sample - loss: 0.0649 - accuracy: 0.9776 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0992 - accuracy: 0.9636\n",
      "Epoch 00103: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 652us/sample - loss: 0.0927 - accuracy: 0.9701 - val_loss: 0.0548 - val_accuracy: 0.9706\n",
      "Epoch 104/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0663 - accuracy: 0.9818\n",
      "Epoch 00104: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 673us/sample - loss: 0.0778 - accuracy: 0.9776 - val_loss: 0.0957 - val_accuracy: 0.9706\n",
      "Epoch 105/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0352 - accuracy: 0.9909\n",
      "Epoch 00105: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 698us/sample - loss: 0.0400 - accuracy: 0.9851 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0400 - accuracy: 0.9818\n",
      "Epoch 00106: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 679us/sample - loss: 0.0491 - accuracy: 0.9776 - val_loss: 0.0855 - val_accuracy: 0.9412\n",
      "Epoch 107/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0755 - accuracy: 0.9800\n",
      "Epoch 00107: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 686us/sample - loss: 0.0588 - accuracy: 0.9851 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0442 - accuracy: 0.9909\n",
      "Epoch 00108: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 670us/sample - loss: 0.0374 - accuracy: 0.9925 - val_loss: 0.0358 - val_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0407 - accuracy: 0.9909\n",
      "Epoch 00109: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 687us/sample - loss: 0.0445 - accuracy: 0.9851 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1121 - accuracy: 0.9700\n",
      "Epoch 00110: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 709us/sample - loss: 0.0924 - accuracy: 0.9776 - val_loss: 0.1390 - val_accuracy: 0.9412\n",
      "Epoch 111/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0678 - accuracy: 0.9800\n",
      "Epoch 00111: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 971us/sample - loss: 0.0673 - accuracy: 0.9776 - val_loss: 0.0507 - val_accuracy: 0.9706\n",
      "Epoch 112/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0916 - accuracy: 0.9545\n",
      "Epoch 00112: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 677us/sample - loss: 0.0805 - accuracy: 0.9627 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0463 - accuracy: 0.9700\n",
      "Epoch 00113: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 719us/sample - loss: 0.0662 - accuracy: 0.9627 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0863 - accuracy: 0.9545\n",
      "Epoch 00114: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 619us/sample - loss: 0.0734 - accuracy: 0.9627 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.0652 - accuracy: 0.9750\n",
      "Epoch 00115: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 616us/sample - loss: 0.0615 - accuracy: 0.9776 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.0267 - accuracy: 1.0000\n",
      "Epoch 00116: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 621us/sample - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0406 - accuracy: 0.9909\n",
      "Epoch 00117: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 623us/sample - loss: 0.0346 - accuracy: 0.9925 - val_loss: 0.0785 - val_accuracy: 0.9706\n",
      "Epoch 118/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0618 - accuracy: 0.9909\n",
      "Epoch 00118: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 633us/sample - loss: 0.0713 - accuracy: 0.9851 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0893 - accuracy: 0.9636\n",
      "Epoch 00119: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 620us/sample - loss: 0.0867 - accuracy: 0.9627 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1181 - accuracy: 0.9636\n",
      "Epoch 00120: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 616us/sample - loss: 0.1404 - accuracy: 0.9552 - val_loss: 0.1421 - val_accuracy: 0.9706\n",
      "Epoch 121/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1198 - accuracy: 0.9545\n",
      "Epoch 00121: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 628us/sample - loss: 0.1007 - accuracy: 0.9627 - val_loss: 0.1271 - val_accuracy: 0.9706\n",
      "Epoch 122/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0587 - accuracy: 0.9818\n",
      "Epoch 00122: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 628us/sample - loss: 0.0500 - accuracy: 0.9851 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1059 - accuracy: 0.9545\n",
      "Epoch 00123: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 638us/sample - loss: 0.0941 - accuracy: 0.9627 - val_loss: 0.0835 - val_accuracy: 0.9706\n",
      "Epoch 124/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 00124: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0569 - accuracy: 0.9818\n",
      "Epoch 00125: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 659us/sample - loss: 0.0513 - accuracy: 0.9851 - val_loss: 0.0598 - val_accuracy: 0.9706\n",
      "Epoch 126/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 00126: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0404 - accuracy: 0.9925 - val_loss: 0.1149 - val_accuracy: 0.9412\n",
      "Epoch 127/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0293 - accuracy: 0.9909\n",
      "Epoch 00127: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 623us/sample - loss: 0.0284 - accuracy: 0.9925 - val_loss: 0.1453 - val_accuracy: 0.9706\n",
      "Epoch 128/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0492 - accuracy: 0.9909\n",
      "Epoch 00128: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 650us/sample - loss: 0.0484 - accuracy: 0.9851 - val_loss: 0.0397 - val_accuracy: 0.9706\n",
      "Epoch 129/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0329 - accuracy: 0.9818\n",
      "Epoch 00129: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 657us/sample - loss: 0.0274 - accuracy: 0.9851 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0366 - accuracy: 0.9818\n",
      "Epoch 00130: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 639us/sample - loss: 0.0382 - accuracy: 0.9851 - val_loss: 0.1113 - val_accuracy: 0.9706\n",
      "Epoch 131/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0453 - accuracy: 0.9818\n",
      "Epoch 00131: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 622us/sample - loss: 0.0389 - accuracy: 0.9851 - val_loss: 0.0545 - val_accuracy: 0.9706\n",
      "Epoch 132/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0737 - accuracy: 0.9727\n",
      "Epoch 00132: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 635us/sample - loss: 0.0620 - accuracy: 0.9776 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0668 - accuracy: 0.9727\n",
      "Epoch 00133: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 623us/sample - loss: 0.0577 - accuracy: 0.9776 - val_loss: 0.0589 - val_accuracy: 0.9706\n",
      "Epoch 134/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0668 - accuracy: 0.9727\n",
      "Epoch 00134: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 631us/sample - loss: 0.0918 - accuracy: 0.9701 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0231 - accuracy: 1.0000\n",
      "Epoch 00135: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 652us/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9706\n",
      "Epoch 136/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0325 - accuracy: 0.9909\n",
      "Epoch 00136: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 655us/sample - loss: 0.0276 - accuracy: 0.9925 - val_loss: 0.0432 - val_accuracy: 0.9706\n",
      "Epoch 137/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0183 - accuracy: 1.0000\n",
      "Epoch 00137: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 677us/sample - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0652 - val_accuracy: 0.9706\n",
      "Epoch 138/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000    \n",
      "Epoch 00138: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 689us/sample - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9706\n",
      "Epoch 139/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0208 - accuracy: 0.9909\n",
      "Epoch 00139: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 623us/sample - loss: 0.0192 - accuracy: 0.9925 - val_loss: 0.1104 - val_accuracy: 0.9706\n",
      "Epoch 140/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0727 - accuracy: 0.9909\n",
      "Epoch 00140: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 639us/sample - loss: 0.0617 - accuracy: 0.9925 - val_loss: 0.0497 - val_accuracy: 0.9706\n",
      "Epoch 141/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 00141: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 706us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 00142: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 627us/sample - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0221 - accuracy: 1.0000    \n",
      "Epoch 00143: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 627us/sample - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9706\n",
      "Epoch 144/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0212 - accuracy: 1.0000    \n",
      "Epoch 00144: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 637us/sample - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0509 - accuracy: 0.9727\n",
      "Epoch 00145: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 689us/sample - loss: 0.0494 - accuracy: 0.9776 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0926 - accuracy: 0.9400\n",
      "Epoch 00146: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 706us/sample - loss: 0.0707 - accuracy: 0.9552 - val_loss: 0.2815 - val_accuracy: 0.9412\n",
      "Epoch 147/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2689 - accuracy: 0.9100\n",
      "Epoch 00147: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 661us/sample - loss: 0.2725 - accuracy: 0.9030 - val_loss: 0.0987 - val_accuracy: 0.9706\n",
      "Epoch 148/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1668 - accuracy: 0.9636\n",
      "Epoch 00148: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 663us/sample - loss: 0.1844 - accuracy: 0.9552 - val_loss: 0.2584 - val_accuracy: 0.9118\n",
      "Epoch 149/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1133 - accuracy: 0.9500\n",
      "Epoch 00149: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 713us/sample - loss: 0.0920 - accuracy: 0.9627 - val_loss: 0.0521 - val_accuracy: 0.9706\n",
      "Epoch 150/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0474 - accuracy: 0.9818\n",
      "Epoch 00150: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 673us/sample - loss: 0.0541 - accuracy: 0.9776 - val_loss: 0.1027 - val_accuracy: 0.9706\n",
      "Epoch 151/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0405 - accuracy: 0.9909\n",
      "Epoch 00151: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 639us/sample - loss: 0.0351 - accuracy: 0.9925 - val_loss: 0.1427 - val_accuracy: 0.9706\n",
      "Epoch 152/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0443 - accuracy: 0.9909\n",
      "Epoch 00152: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 629us/sample - loss: 0.0411 - accuracy: 0.9925 - val_loss: 0.1616 - val_accuracy: 0.9706\n",
      "Epoch 153/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 00153: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 653us/sample - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9706\n",
      "Epoch 154/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0411 - accuracy: 0.9909\n",
      "Epoch 00154: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 618us/sample - loss: 0.0342 - accuracy: 0.9925 - val_loss: 0.0929 - val_accuracy: 0.9706\n",
      "Epoch 155/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 00155: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 740us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9706\n",
      "Epoch 156/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0663 - accuracy: 0.9818\n",
      "Epoch 00156: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 640us/sample - loss: 0.0580 - accuracy: 0.9851 - val_loss: 0.1900 - val_accuracy: 0.9706\n",
      "Epoch 157/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0459 - accuracy: 0.9727\n",
      "Epoch 00157: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 623us/sample - loss: 0.0421 - accuracy: 0.9776 - val_loss: 0.0903 - val_accuracy: 0.9706\n",
      "Epoch 158/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0265 - accuracy: 0.9909\n",
      "Epoch 00158: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 631us/sample - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.1402 - val_accuracy: 0.9706\n",
      "Epoch 159/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0192 - accuracy: 0.9900\n",
      "Epoch 00159: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 681us/sample - loss: 0.0268 - accuracy: 0.9851 - val_loss: 0.1126 - val_accuracy: 0.9706\n",
      "Epoch 160/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0225 - accuracy: 0.9909\n",
      "Epoch 00160: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 670us/sample - loss: 0.0480 - accuracy: 0.9851 - val_loss: 0.0733 - val_accuracy: 0.9706\n",
      "Epoch 161/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0264 - accuracy: 0.9818    \n",
      "Epoch 00161: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 668us/sample - loss: 0.0366 - accuracy: 0.9776 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0543 - accuracy: 0.9727\n",
      "Epoch 00162: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 665us/sample - loss: 0.0463 - accuracy: 0.9776 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0276 - accuracy: 0.9909\n",
      "Epoch 00163: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0352 - accuracy: 0.9925 - val_loss: 0.1112 - val_accuracy: 0.9706\n",
      "Epoch 164/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0266 - accuracy: 0.9909\n",
      "Epoch 00164: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 648us/sample - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.1525 - val_accuracy: 0.9706\n",
      "Epoch 165/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0272 - accuracy: 0.9909\n",
      "Epoch 00165: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 657us/sample - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.2458 - val_accuracy: 0.9412\n",
      "Epoch 166/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0372 - accuracy: 0.9818\n",
      "Epoch 00166: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 622us/sample - loss: 0.0324 - accuracy: 0.9851 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0346 - accuracy: 0.9818    \n",
      "Epoch 00167: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 646us/sample - loss: 0.0295 - accuracy: 0.9851 - val_loss: 0.3713 - val_accuracy: 0.9412\n",
      "Epoch 168/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0713 - accuracy: 0.9636\n",
      "Epoch 00168: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 675us/sample - loss: 0.0599 - accuracy: 0.9701 - val_loss: 0.0694 - val_accuracy: 0.9706\n",
      "Epoch 169/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0159 - accuracy: 1.0000\n",
      "Epoch 00169: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 654us/sample - loss: 0.0249 - accuracy: 0.9925 - val_loss: 0.0957 - val_accuracy: 0.9706\n",
      "Epoch 170/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 00170: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 633us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9706\n",
      "Epoch 171/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0108 - accuracy: 1.0000    \n",
      "Epoch 00171: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 644us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9706\n",
      "Epoch 172/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000    \n",
      "Epoch 00172: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 645us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9706\n",
      "Epoch 173/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0186 - accuracy: 0.9909\n",
      "Epoch 00173: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 680us/sample - loss: 0.0159 - accuracy: 0.9925 - val_loss: 0.0456 - val_accuracy: 0.9706\n",
      "Epoch 174/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 00174: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 692us/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9706\n",
      "Epoch 175/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0194 - accuracy: 0.9818    \n",
      "Epoch 00175: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 656us/sample - loss: 0.0191 - accuracy: 0.9851 - val_loss: 0.1472 - val_accuracy: 0.9706\n",
      "Epoch 176/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 00176: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 673us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9706\n",
      "Epoch 177/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 00177: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 690us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9706\n",
      "Epoch 178/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000    \n",
      "Epoch 00178: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 667us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9706\n",
      "Epoch 179/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0201 - accuracy: 0.9818\n",
      "Epoch 00179: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 665us/sample - loss: 0.0205 - accuracy: 0.9851 - val_loss: 0.3105 - val_accuracy: 0.9412\n",
      "Epoch 180/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0358 - accuracy: 0.9800\n",
      "Epoch 00180: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 701us/sample - loss: 0.0362 - accuracy: 0.9776 - val_loss: 0.0311 - val_accuracy: 0.9706\n",
      "Epoch 181/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0402 - accuracy: 0.9818    \n",
      "Epoch 00181: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 654us/sample - loss: 0.0435 - accuracy: 0.9776 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0342 - accuracy: 0.9818\n",
      "Epoch 00182: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 663us/sample - loss: 0.0283 - accuracy: 0.9851 - val_loss: 0.1156 - val_accuracy: 0.9412\n",
      "Epoch 183/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0157 - accuracy: 0.9909\n",
      "Epoch 00183: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 680us/sample - loss: 0.0245 - accuracy: 0.9851 - val_loss: 0.0601 - val_accuracy: 0.9706\n",
      "Epoch 184/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 00184: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9706\n",
      "Epoch 185/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00185: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 681us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9706\n",
      "Epoch 186/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00186: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 699us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9706\n",
      "Epoch 187/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1737 - accuracy: 0.9800    \n",
      "Epoch 00187: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 705us/sample - loss: 0.1569 - accuracy: 0.9701 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0975 - accuracy: 0.9545\n",
      "Epoch 00188: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 691us/sample - loss: 0.0940 - accuracy: 0.9478 - val_loss: 0.1222 - val_accuracy: 0.9706\n",
      "Epoch 189/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0873 - accuracy: 0.9545\n",
      "Epoch 00189: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 687us/sample - loss: 0.0735 - accuracy: 0.9627 - val_loss: 0.1093 - val_accuracy: 0.9706\n",
      "Epoch 190/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0542 - accuracy: 0.9727\n",
      "Epoch 00190: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 657us/sample - loss: 0.0462 - accuracy: 0.9776 - val_loss: 0.1798 - val_accuracy: 0.9706\n",
      "Epoch 191/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0302 - accuracy: 0.9818\n",
      "Epoch 00191: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 652us/sample - loss: 0.0258 - accuracy: 0.9851 - val_loss: 0.1368 - val_accuracy: 0.9706\n",
      "Epoch 192/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000    \n",
      "Epoch 00192: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 657us/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9706\n",
      "Epoch 193/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 00193: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 665us/sample - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9706\n",
      "Epoch 194/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0110 - accuracy: 0.9909\n",
      "Epoch 00194: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 628us/sample - loss: 0.0117 - accuracy: 0.9925 - val_loss: 0.1532 - val_accuracy: 0.9706\n",
      "Epoch 195/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0320 - accuracy: 0.9909\n",
      "Epoch 00195: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 656us/sample - loss: 0.0279 - accuracy: 0.9925 - val_loss: 0.0490 - val_accuracy: 0.9706\n",
      "Epoch 196/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 00196: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 620us/sample - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9412\n",
      "Epoch 197/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000    \n",
      "Epoch 00197: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 643us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9706\n",
      "Epoch 198/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 00198: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 662us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9706\n",
      "Epoch 199/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0491 - accuracy: 0.9727\n",
      "Epoch 00199: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 666us/sample - loss: 0.0434 - accuracy: 0.9776 - val_loss: 0.1633 - val_accuracy: 0.9706\n",
      "Epoch 200/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 00200: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 767us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0925 - accuracy: 0.9600\n",
      "Epoch 00201: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 781us/sample - loss: 0.0719 - accuracy: 0.9701 - val_loss: 0.1011 - val_accuracy: 0.9706\n",
      "Epoch 202/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0310 - accuracy: 0.9900\n",
      "Epoch 00202: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 718us/sample - loss: 0.0369 - accuracy: 0.9851 - val_loss: 0.2623 - val_accuracy: 0.9412\n",
      "Epoch 203/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0659 - accuracy: 0.9700\n",
      "Epoch 00203: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 744us/sample - loss: 0.0576 - accuracy: 0.9776 - val_loss: 0.1157 - val_accuracy: 0.9706\n",
      "Epoch 204/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 00204: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 652us/sample - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0424 - accuracy: 0.9909\n",
      "Epoch 00205: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 625us/sample - loss: 0.0352 - accuracy: 0.9925 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0499 - accuracy: 0.9727\n",
      "Epoch 00206: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 630us/sample - loss: 0.0457 - accuracy: 0.9776 - val_loss: 0.0805 - val_accuracy: 0.9706\n",
      "Epoch 207/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 00207: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0306 - accuracy: 0.9900\n",
      "Epoch 00208: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.0269 - accuracy: 0.9925 - val_loss: 0.1181 - val_accuracy: 0.9706\n",
      "Epoch 209/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 00209: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 680us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9706\n",
      "Epoch 210/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 00210: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 671us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9706\n",
      "Epoch 211/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 00211: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 713us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9706\n",
      "Epoch 212/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0920 - accuracy: 0.9636\n",
      "Epoch 00212: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 625us/sample - loss: 0.0786 - accuracy: 0.9701 - val_loss: 0.3838 - val_accuracy: 0.9412\n",
      "Epoch 213/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1261 - accuracy: 0.9636\n",
      "Epoch 00213: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 631us/sample - loss: 0.1114 - accuracy: 0.9627 - val_loss: 0.2848 - val_accuracy: 0.9412\n",
      "Epoch 214/500\n",
      " 50/134 [==========>...................] - ETA: 0s - loss: 0.0319 - accuracy: 0.9800\n",
      "Epoch 00214: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 916us/sample - loss: 0.0886 - accuracy: 0.9701 - val_loss: 0.0566 - val_accuracy: 0.9706\n",
      "Epoch 215/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0577 - accuracy: 0.9727    \n",
      "Epoch 00215: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 802us/sample - loss: 0.0644 - accuracy: 0.9701 - val_loss: 0.1059 - val_accuracy: 0.9706\n",
      "Epoch 216/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 00216: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 761us/sample - loss: 0.0385 - accuracy: 0.9925 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0446 - accuracy: 0.9900\n",
      "Epoch 00217: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 770us/sample - loss: 0.0379 - accuracy: 0.9925 - val_loss: 0.0673 - val_accuracy: 0.9706\n",
      "Epoch 218/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 00218: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 769us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9706\n",
      "Epoch 219/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 00219: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 668us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 0.9706\n",
      "Epoch 220/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0372 - accuracy: 0.9800\n",
      "Epoch 00220: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 749us/sample - loss: 0.0299 - accuracy: 0.9851 - val_loss: 0.1282 - val_accuracy: 0.9706\n",
      "Epoch 221/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0173 - accuracy: 0.9909\n",
      "Epoch 00221: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 690us/sample - loss: 0.0148 - accuracy: 0.9925 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 00222: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.0185 - accuracy: 0.9925 - val_loss: 0.0606 - val_accuracy: 0.9706\n",
      "Epoch 223/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0217 - accuracy: 1.0000    \n",
      "Epoch 00223: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 664us/sample - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9706\n",
      "Epoch 224/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 00224: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 662us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 0.9706\n",
      "Epoch 225/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000    \n",
      "Epoch 00225: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 700us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9706\n",
      "Epoch 226/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 00226: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 660us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 0.9706\n",
      "Epoch 227/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000    \n",
      "Epoch 00227: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 682us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9706\n",
      "Epoch 228/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000    \n",
      "Epoch 00228: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 697us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9706\n",
      "Epoch 229/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0213 - accuracy: 0.9900\n",
      "Epoch 00229: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 683us/sample - loss: 0.0160 - accuracy: 0.9925 - val_loss: 0.0654 - val_accuracy: 0.9706\n",
      "Epoch 230/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 00230: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 641us/sample - loss: 0.0331 - accuracy: 0.9851 - val_loss: 0.1277 - val_accuracy: 0.9706\n",
      "Epoch 231/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1755 - accuracy: 0.9545\n",
      "Epoch 00231: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 685us/sample - loss: 0.1458 - accuracy: 0.9627 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0471 - accuracy: 0.9800\n",
      "Epoch 00232: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 750us/sample - loss: 0.0518 - accuracy: 0.9776 - val_loss: 0.0701 - val_accuracy: 0.9706\n",
      "Epoch 233/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 00233: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 715us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9706\n",
      "Epoch 234/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0176 - accuracy: 0.9900\n",
      "Epoch 00234: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 740us/sample - loss: 0.0172 - accuracy: 0.9925 - val_loss: 0.1047 - val_accuracy: 0.9706\n",
      "Epoch 235/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0120 - accuracy: 0.9900\n",
      "Epoch 00235: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 739us/sample - loss: 0.0123 - accuracy: 0.9925 - val_loss: 0.1678 - val_accuracy: 0.9706\n",
      "Epoch 236/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 00236: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 644us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9706\n",
      "Epoch 237/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 00237: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 638us/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9706\n",
      "Epoch 238/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000    \n",
      "Epoch 00238: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 666us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9706\n",
      "Epoch 239/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0446 - accuracy: 0.9727\n",
      "Epoch 00239: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 661us/sample - loss: 0.0386 - accuracy: 0.9776 - val_loss: 0.2472 - val_accuracy: 0.9706\n",
      "Epoch 240/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0428 - accuracy: 0.9727\n",
      "Epoch 00240: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 631us/sample - loss: 0.0354 - accuracy: 0.9776 - val_loss: 0.0360 - val_accuracy: 0.9706\n",
      "Epoch 241/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 00241: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 00242: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 656us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9706\n",
      "Epoch 243/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 00243: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 617us/sample - loss: 0.0123 - accuracy: 0.9925 - val_loss: 0.1231 - val_accuracy: 0.9706\n",
      "Epoch 244/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0284 - accuracy: 0.9909\n",
      "Epoch 00244: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 639us/sample - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.1590 - val_accuracy: 0.9706\n",
      "Epoch 245/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0294 - accuracy: 0.9909\n",
      "Epoch 00245: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 628us/sample - loss: 0.0258 - accuracy: 0.9925 - val_loss: 0.2795 - val_accuracy: 0.9412\n",
      "Epoch 246/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0242 - accuracy: 0.9909    \n",
      "Epoch 00246: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 633us/sample - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.2412 - val_accuracy: 0.9412\n",
      "Epoch 247/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000    \n",
      "Epoch 00247: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9706\n",
      "Epoch 248/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 00248: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 621us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 0.9706\n",
      "Epoch 249/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000    \n",
      "Epoch 00249: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 643us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9412\n",
      "Epoch 250/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000    \n",
      "Epoch 00250: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 623us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1817 - val_accuracy: 0.9706\n",
      "Epoch 251/500\n",
      "120/134 [=========================>....] - ETA: 0s - loss: 0.0075 - accuracy: 0.9917\n",
      "Epoch 00251: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 616us/sample - loss: 0.0068 - accuracy: 0.9925 - val_loss: 0.2068 - val_accuracy: 0.9706\n",
      "Epoch 252/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000    \n",
      "Epoch 00252: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 644us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2476 - val_accuracy: 0.9706\n",
      "Epoch 253/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0142 - accuracy: 0.9909\n",
      "Epoch 00253: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 638us/sample - loss: 0.0124 - accuracy: 0.9925 - val_loss: 0.3505 - val_accuracy: 0.9706\n",
      "Epoch 254/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0159 - accuracy: 0.9909\n",
      "Epoch 00254: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 644us/sample - loss: 0.0212 - accuracy: 0.9851 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0131 - accuracy: 0.9909\n",
      "Epoch 00255: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 639us/sample - loss: 0.0144 - accuracy: 0.9925 - val_loss: 0.0671 - val_accuracy: 0.9706\n",
      "Epoch 256/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0326 - accuracy: 0.9909    \n",
      "Epoch 00256: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 638us/sample - loss: 0.0321 - accuracy: 0.9925 - val_loss: 0.4531 - val_accuracy: 0.9412\n",
      "Epoch 257/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0660 - accuracy: 0.9818\n",
      "Epoch 00257: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 637us/sample - loss: 0.0797 - accuracy: 0.9776 - val_loss: 0.4945 - val_accuracy: 0.9118\n",
      "Epoch 258/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0828 - accuracy: 0.9727\n",
      "Epoch 00258: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 627us/sample - loss: 0.0797 - accuracy: 0.9701 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1317 - accuracy: 0.9455\n",
      "Epoch 00259: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 630us/sample - loss: 0.1091 - accuracy: 0.9552 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1222 - accuracy: 0.9636\n",
      "Epoch 00260: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 632us/sample - loss: 0.1264 - accuracy: 0.9627 - val_loss: 0.1584 - val_accuracy: 0.9706\n",
      "Epoch 261/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1425 - accuracy: 0.9273    \n",
      "Epoch 00261: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 638us/sample - loss: 0.1195 - accuracy: 0.9403 - val_loss: 0.0362 - val_accuracy: 0.9706\n",
      "Epoch 262/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0823 - accuracy: 0.9818\n",
      "Epoch 00262: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 627us/sample - loss: 0.0854 - accuracy: 0.9776 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0389 - accuracy: 0.9818\n",
      "Epoch 00263: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 626us/sample - loss: 0.0441 - accuracy: 0.9776 - val_loss: 0.0405 - val_accuracy: 0.9706\n",
      "Epoch 264/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0176 - accuracy: 1.0000\n",
      "Epoch 00264: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 616us/sample - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9706\n",
      "Epoch 265/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0350 - accuracy: 0.9727\n",
      "Epoch 00265: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 634us/sample - loss: 0.0352 - accuracy: 0.9701 - val_loss: 0.2406 - val_accuracy: 0.9706\n",
      "Epoch 266/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0769 - accuracy: 0.9727\n",
      "Epoch 00266: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 618us/sample - loss: 0.0646 - accuracy: 0.9776 - val_loss: 0.0311 - val_accuracy: 0.9706\n",
      "Epoch 267/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0312 - accuracy: 0.9909\n",
      "Epoch 00267: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 649us/sample - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.1573 - val_accuracy: 0.9706\n",
      "Epoch 268/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0414 - accuracy: 0.9818\n",
      "Epoch 00268: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 634us/sample - loss: 0.0385 - accuracy: 0.9851 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0207 - accuracy: 0.9818\n",
      "Epoch 00269: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 654us/sample - loss: 0.0172 - accuracy: 0.9851 - val_loss: 0.0441 - val_accuracy: 0.9706\n",
      "Epoch 270/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0199 - accuracy: 0.9900\n",
      "Epoch 00270: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 690us/sample - loss: 0.0182 - accuracy: 0.9925 - val_loss: 0.1160 - val_accuracy: 0.9706\n",
      "Epoch 271/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0107 - accuracy: 0.9909    \n",
      "Epoch 00271: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 657us/sample - loss: 0.0098 - accuracy: 0.9925 - val_loss: 0.0359 - val_accuracy: 0.9706\n",
      "Epoch 272/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0178 - accuracy: 0.9909\n",
      "Epoch 00272: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 628us/sample - loss: 0.0146 - accuracy: 0.9925 - val_loss: 0.1107 - val_accuracy: 0.9706\n",
      "Epoch 273/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000    \n",
      "Epoch 00273: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9706\n",
      "Epoch 274/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000    \n",
      "Epoch 00274: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 641us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9706\n",
      "Epoch 275/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 00275: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 745us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9706\n",
      "Epoch 276/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
      "Epoch 00276: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9706\n",
      "Epoch 277/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00277: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 748us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9706\n",
      "Epoch 278/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0091 - accuracy: 0.9900\n",
      "Epoch 00278: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 744us/sample - loss: 0.0074 - accuracy: 0.9925 - val_loss: 0.1303 - val_accuracy: 0.9706\n",
      "Epoch 279/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 00279: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 692us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9706\n",
      "Epoch 280/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0126 - accuracy: 0.9909\n",
      "Epoch 00280: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 639us/sample - loss: 0.0105 - accuracy: 0.9925 - val_loss: 0.0870 - val_accuracy: 0.9706\n",
      "Epoch 281/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00281: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 642us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9706\n",
      "Epoch 282/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00282: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9706\n",
      "Epoch 283/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 00283: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 628us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9706\n",
      "Epoch 284/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 00284: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 639us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9706\n",
      "Epoch 285/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000    \n",
      "Epoch 00285: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 654us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9706\n",
      "Epoch 286/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00286: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 626us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9706\n",
      "Epoch 287/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00287: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9706\n",
      "Epoch 288/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00288: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 928us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9706\n",
      "Epoch 289/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000    \n",
      "Epoch 00289: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 720us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9706\n",
      "Epoch 290/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 00290: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 789us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9706\n",
      "Epoch 291/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000    \n",
      "Epoch 00291: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 688us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9706\n",
      "Epoch 292/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 00292: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 712us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00293: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 725us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0406 - val_accuracy: 0.9706\n",
      "Epoch 294/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00294: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 652us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9706\n",
      "Epoch 295/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 2.0298e-04 - accuracy: 1.0000\n",
      "Epoch 00295: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 659us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0648 - val_accuracy: 0.9706\n",
      "Epoch 296/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 9.1974e-04 - accuracy: 1.0000\n",
      "Epoch 00296: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 650us/sample - loss: 7.7429e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9706\n",
      "Epoch 297/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00297: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 624us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9706\n",
      "Epoch 298/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000    \n",
      "Epoch 00298: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 627us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9706\n",
      "Epoch 299/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00299: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 704us/sample - loss: 0.0075 - accuracy: 0.9925 - val_loss: 0.0653 - val_accuracy: 0.9706\n",
      "Epoch 300/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0217 - accuracy: 0.9909\n",
      "Epoch 00300: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 652us/sample - loss: 0.0179 - accuracy: 0.9925 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0184 - accuracy: 0.9909    \n",
      "Epoch 00301: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 642us/sample - loss: 0.0179 - accuracy: 0.9925 - val_loss: 0.1222 - val_accuracy: 0.9706\n",
      "Epoch 302/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 00302: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 640us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0337 - accuracy: 0.9818\n",
      "Epoch 00303: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 670us/sample - loss: 0.0278 - accuracy: 0.9851 - val_loss: 0.0679 - val_accuracy: 0.9706\n",
      "Epoch 304/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0089 - accuracy: 0.9909\n",
      "Epoch 00304: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 665us/sample - loss: 0.0077 - accuracy: 0.9925 - val_loss: 0.0378 - val_accuracy: 0.9706\n",
      "Epoch 305/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000    \n",
      "Epoch 00305: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 683us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9706\n",
      "Epoch 306/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000    \n",
      "Epoch 00306: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 676us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9706\n",
      "Epoch 307/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 00307: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9706\n",
      "Epoch 308/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00308: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 673us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9706\n",
      "Epoch 309/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 00309: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 693us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9706\n",
      "Epoch 310/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000    \n",
      "Epoch 00310: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 686us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9706\n",
      "Epoch 311/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 00311: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 733us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1656 - val_accuracy: 0.9706\n",
      "Epoch 312/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000    \n",
      "Epoch 00312: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 702us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9706\n",
      "Epoch 313/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000    \n",
      "Epoch 00313: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3177 - val_accuracy: 0.9706\n",
      "Epoch 314/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
      "Epoch 00314: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 662us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0683 - accuracy: 0.9900    \n",
      "Epoch 00315: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 727us/sample - loss: 0.0567 - accuracy: 0.9925 - val_loss: 0.4390 - val_accuracy: 0.9412\n",
      "Epoch 316/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.3694 - accuracy: 0.9200\n",
      "Epoch 00316: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 706us/sample - loss: 0.2825 - accuracy: 0.9403 - val_loss: 0.5050 - val_accuracy: 0.9412\n",
      "Epoch 317/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1541 - accuracy: 0.9455\n",
      "Epoch 00317: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 677us/sample - loss: 0.1547 - accuracy: 0.9403 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1319 - accuracy: 0.9500    \n",
      "Epoch 00318: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 692us/sample - loss: 0.1809 - accuracy: 0.9403 - val_loss: 0.0971 - val_accuracy: 0.9706\n",
      "Epoch 319/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.2279 - accuracy: 0.9600\n",
      "Epoch 00319: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 694us/sample - loss: 0.1735 - accuracy: 0.9701 - val_loss: 0.0389 - val_accuracy: 0.9706\n",
      "Epoch 320/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.1937 - accuracy: 0.9000\n",
      "Epoch 00320: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 736us/sample - loss: 0.1869 - accuracy: 0.9104 - val_loss: 0.0367 - val_accuracy: 0.9706\n",
      "Epoch 321/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.3749 - accuracy: 0.8727\n",
      "Epoch 00321: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 665us/sample - loss: 0.3119 - accuracy: 0.8955 - val_loss: 0.1437 - val_accuracy: 0.9412\n",
      "Epoch 322/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0433 - accuracy: 0.9909\n",
      "Epoch 00322: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 681us/sample - loss: 0.0378 - accuracy: 0.9925 - val_loss: 0.1985 - val_accuracy: 0.9412\n",
      "Epoch 323/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 00323: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 709us/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9706\n",
      "Epoch 324/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0221 - accuracy: 0.9900\n",
      "Epoch 00324: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 689us/sample - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.1862 - val_accuracy: 0.9412\n",
      "Epoch 325/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 00325: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 682us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9706\n",
      "Epoch 326/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0447 - accuracy: 0.9727    \n",
      "Epoch 00326: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 685us/sample - loss: 0.0458 - accuracy: 0.9776 - val_loss: 0.2180 - val_accuracy: 0.9706\n",
      "Epoch 327/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 00327: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 666us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9706\n",
      "Epoch 328/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0169 - accuracy: 1.0000\n",
      "Epoch 00328: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 682us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9706\n",
      "Epoch 329/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0231 - accuracy: 0.9900    \n",
      "Epoch 00329: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 687us/sample - loss: 0.0185 - accuracy: 0.9925 - val_loss: 0.0675 - val_accuracy: 0.9706\n",
      "Epoch 330/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0322 - accuracy: 0.9900\n",
      "Epoch 00330: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 691us/sample - loss: 0.0248 - accuracy: 0.9925 - val_loss: 0.1606 - val_accuracy: 0.9706\n",
      "Epoch 331/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0145 - accuracy: 0.9900    \n",
      "Epoch 00331: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 726us/sample - loss: 0.0145 - accuracy: 0.9925 - val_loss: 0.1531 - val_accuracy: 0.9706\n",
      "Epoch 332/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0266 - accuracy: 0.9900\n",
      "Epoch 00332: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 740us/sample - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.1679 - val_accuracy: 0.9706\n",
      "Epoch 333/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 00333: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 716us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9706\n",
      "Epoch 334/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 00334: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 729us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1580 - val_accuracy: 0.9706\n",
      "Epoch 335/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000    \n",
      "Epoch 00335: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 712us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9706\n",
      "Epoch 336/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 00336: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 748us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9706\n",
      "Epoch 337/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000    \n",
      "Epoch 00337: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 704us/sample - loss: 0.0275 - accuracy: 0.9925 - val_loss: 0.0864 - val_accuracy: 0.9706\n",
      "Epoch 338/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000    \n",
      "Epoch 00338: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 754us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9706\n",
      "Epoch 339/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000    \n",
      "Epoch 00339: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9706\n",
      "Epoch 340/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000    \n",
      "Epoch 00340: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 742us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9706\n",
      "Epoch 341/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0063 - accuracy: 1.0000    \n",
      "Epoch 00341: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 679us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9706\n",
      "Epoch 342/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000    \n",
      "Epoch 00342: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1657 - val_accuracy: 0.9706\n",
      "Epoch 343/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000    \n",
      "Epoch 00343: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 662us/sample - loss: 0.0114 - accuracy: 0.9925 - val_loss: 0.1545 - val_accuracy: 0.9706\n",
      "Epoch 344/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 00344: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 725us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.2845 - val_accuracy: 0.9412\n",
      "Epoch 345/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 00345: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 726us/sample - loss: 0.0116 - accuracy: 0.9925 - val_loss: 0.1863 - val_accuracy: 0.9706\n",
      "Epoch 346/500\n",
      " 90/134 [===================>..........] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000    \n",
      "Epoch 00346: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 770us/sample - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9706\n",
      "Epoch 347/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000    \n",
      "Epoch 00347: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 690us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0162 - accuracy: 0.9900    \n",
      "Epoch 00348: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 724us/sample - loss: 0.0125 - accuracy: 0.9925 - val_loss: 0.2154 - val_accuracy: 0.9706\n",
      "Epoch 349/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 00349: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 667us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9706\n",
      "Epoch 350/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00350: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 699us/sample - loss: 0.0094 - accuracy: 0.9925 - val_loss: 0.0857 - val_accuracy: 0.9706\n",
      "Epoch 351/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 00351: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 686us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2887 - val_accuracy: 0.9412\n",
      "Epoch 352/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000    \n",
      "Epoch 00352: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 687us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9412\n",
      "Epoch 353/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00353: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 713us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9706\n",
      "Epoch 354/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000    \n",
      "Epoch 00354: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 891us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9412\n",
      "Epoch 355/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 00355: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 699us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9706\n",
      "Epoch 356/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00356: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 710us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 0.9706\n",
      "Epoch 357/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00357: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 715us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9706\n",
      "Epoch 358/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000    \n",
      "Epoch 00358: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 680us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9706\n",
      "Epoch 359/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 00359: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 694us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9706\n",
      "Epoch 360/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000    \n",
      "Epoch 00360: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 695us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9706\n",
      "Epoch 361/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0113 - accuracy: 0.9900    \n",
      "Epoch 00361: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 679us/sample - loss: 0.0090 - accuracy: 0.9925 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0104 - accuracy: 0.9900\n",
      "Epoch 00362: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 706us/sample - loss: 0.0082 - accuracy: 0.9925 - val_loss: 0.2226 - val_accuracy: 0.9706\n",
      "Epoch 363/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000    \n",
      "Epoch 00363: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 693us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9706\n",
      "Epoch 364/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 00364: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 684us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1999 - val_accuracy: 0.9412\n",
      "Epoch 365/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0195 - accuracy: 0.9909\n",
      "Epoch 00365: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 716us/sample - loss: 0.0162 - accuracy: 0.9925 - val_loss: 0.3170 - val_accuracy: 0.9412\n",
      "Epoch 366/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    \n",
      "Epoch 00366: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 688us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9706\n",
      "Epoch 367/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 00367: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 684us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2986 - val_accuracy: 0.9706\n",
      "Epoch 368/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000    \n",
      "Epoch 00368: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 685us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9706\n",
      "Epoch 369/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 6.8983e-04 - accuracy: 1.0000\n",
      "Epoch 00369: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 710us/sample - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0424 - accuracy: 0.9727    \n",
      "Epoch 00370: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 724us/sample - loss: 0.0527 - accuracy: 0.9627 - val_loss: 0.4448 - val_accuracy: 0.9412\n",
      "Epoch 371/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0626 - accuracy: 0.9900\n",
      "Epoch 00371: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 688us/sample - loss: 0.0471 - accuracy: 0.9925 - val_loss: 0.3318 - val_accuracy: 0.9412\n",
      "Epoch 372/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0424 - accuracy: 0.9900\n",
      "Epoch 00372: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 710us/sample - loss: 0.0361 - accuracy: 0.9925 - val_loss: 0.0608 - val_accuracy: 0.9706\n",
      "Epoch 373/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0281 - accuracy: 0.9818\n",
      "Epoch 00373: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 683us/sample - loss: 0.0250 - accuracy: 0.9851 - val_loss: 0.1797 - val_accuracy: 0.9412\n",
      "Epoch 374/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000    \n",
      "Epoch 00374: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 727us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9412\n",
      "Epoch 375/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 00375: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 692us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9412\n",
      "Epoch 376/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00376: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 732us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9412\n",
      "Epoch 377/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0214 - accuracy: 0.9900\n",
      "Epoch 00377: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 715us/sample - loss: 0.0160 - accuracy: 0.9925 - val_loss: 0.3164 - val_accuracy: 0.9412\n",
      "Epoch 378/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0309 - accuracy: 0.9900\n",
      "Epoch 00378: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 710us/sample - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.0494 - val_accuracy: 0.9706\n",
      "Epoch 379/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0149 - accuracy: 0.9900    \n",
      "Epoch 00379: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 737us/sample - loss: 0.0121 - accuracy: 0.9925 - val_loss: 0.2092 - val_accuracy: 0.9706\n",
      "Epoch 380/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0490 - accuracy: 0.9818\n",
      "Epoch 00380: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 699us/sample - loss: 0.0410 - accuracy: 0.9851 - val_loss: 0.2130 - val_accuracy: 0.9706\n",
      "Epoch 381/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000    \n",
      "Epoch 00381: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 721us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9706\n",
      "Epoch 382/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 9.6211e-04 - accuracy: 1.0000\n",
      "Epoch 00382: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 740us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9706\n",
      "Epoch 383/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 00383: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 679us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9412\n",
      "Epoch 384/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 00384: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 682us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9706\n",
      "Epoch 385/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00385: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 721us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9706\n",
      "Epoch 386/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000    \n",
      "Epoch 00386: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 732us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9706\n",
      "Epoch 387/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000    \n",
      "Epoch 00387: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 700us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9706\n",
      "Epoch 388/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000    \n",
      "Epoch 00388: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 691us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9706\n",
      "Epoch 389/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 7.6208e-04 - accuracy: 1.0000\n",
      "Epoch 00389: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 740us/sample - loss: 7.7251e-04 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9706\n",
      "Epoch 390/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 3.7601e-04 - accuracy: 1.0000\n",
      "Epoch 00390: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 666us/sample - loss: 5.8526e-04 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 0.9706\n",
      "Epoch 391/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 00391: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 667us/sample - loss: 9.4900e-04 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9706\n",
      "Epoch 392/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 6.7611e-04 - accuracy: 1.0000\n",
      "Epoch 00392: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 726us/sample - loss: 9.1689e-04 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9706\n",
      "Epoch 393/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 9.8833e-04 - accuracy: 1.0000\n",
      "Epoch 00393: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 678us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9706\n",
      "Epoch 394/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00394: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 689us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9706\n",
      "Epoch 395/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00395: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 743us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9706\n",
      "Epoch 396/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 4.4686e-04 - accuracy: 1.0000\n",
      "Epoch 00396: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 681us/sample - loss: 4.1824e-04 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9706\n",
      "Epoch 397/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 6.9234e-04 - accuracy: 1.0000\n",
      "Epoch 00397: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 686us/sample - loss: 6.2542e-04 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9706\n",
      "Epoch 398/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000    \n",
      "Epoch 00398: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 726us/sample - loss: 0.0166 - accuracy: 0.9925 - val_loss: 0.1266 - val_accuracy: 0.9412\n",
      "Epoch 399/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000    \n",
      "Epoch 00399: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 702us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9412\n",
      "Epoch 400/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00400: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 727us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9412\n",
      "Epoch 401/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0427 - accuracy: 0.9800\n",
      "Epoch 00401: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 736us/sample - loss: 0.0319 - accuracy: 0.9851 - val_loss: 0.0487 - val_accuracy: 0.9706\n",
      "Epoch 402/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 4.7122e-04 - accuracy: 1.0000\n",
      "Epoch 00402: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 709us/sample - loss: 0.0257 - accuracy: 0.9851 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0201 - accuracy: 0.9909    \n",
      "Epoch 00403: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 711us/sample - loss: 0.0172 - accuracy: 0.9925 - val_loss: 0.0715 - val_accuracy: 0.9706\n",
      "Epoch 404/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000    \n",
      "Epoch 00404: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 677us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9706\n",
      "Epoch 405/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000    \n",
      "Epoch 00405: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 713us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9706\n",
      "Epoch 406/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0109 - accuracy: 0.9900    \n",
      "Epoch 00406: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 698us/sample - loss: 0.0089 - accuracy: 0.9925 - val_loss: 0.1564 - val_accuracy: 0.9706\n",
      "Epoch 407/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00407: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 706us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9706\n",
      "Epoch 408/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 00408: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 708us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9706\n",
      "Epoch 409/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0160 - accuracy: 0.9900\n",
      "Epoch 00409: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 667us/sample - loss: 0.0121 - accuracy: 0.9925 - val_loss: 0.1823 - val_accuracy: 0.9706\n",
      "Epoch 410/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0209 - accuracy: 0.9900    \n",
      "Epoch 00410: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 1ms/sample - loss: 0.0159 - accuracy: 0.9925 - val_loss: 0.0265 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000    \n",
      "Epoch 00411: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 699us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9706\n",
      "Epoch 412/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0116 - accuracy: 0.9909    \n",
      "Epoch 00412: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 686us/sample - loss: 0.0102 - accuracy: 0.9925 - val_loss: 0.1840 - val_accuracy: 0.9412\n",
      "Epoch 413/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00413: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 694us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9412\n",
      "Epoch 414/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00414: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 695us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9706\n",
      "Epoch 415/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 00415: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 696us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9706\n",
      "Epoch 416/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 7.8332e-04 - accuracy: 1.0000\n",
      "Epoch 00416: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 698us/sample - loss: 7.6644e-04 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9706\n",
      "Epoch 417/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 3.6284e-04 - accuracy: 1.0000\n",
      "Epoch 00417: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9706\n",
      "Epoch 418/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 3.8067e-04 - accuracy: 1.0000\n",
      "Epoch 00418: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 696us/sample - loss: 3.9276e-04 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9706\n",
      "Epoch 419/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 8.1414e-04 - accuracy: 1.0000\n",
      "Epoch 00419: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 701us/sample - loss: 7.8411e-04 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9706\n",
      "Epoch 420/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 9.7017e-04 - accuracy: 1.0000\n",
      "Epoch 00420: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 675us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9706\n",
      "Epoch 421/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
      "Epoch 00421: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 691us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9706\n",
      "Epoch 422/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 2.7246e-04 - accuracy: 1.0000\n",
      "Epoch 00422: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 683us/sample - loss: 2.6301e-04 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9706\n",
      "Epoch 423/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 7.8225e-04 - accuracy: 1.0000\n",
      "Epoch 00423: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 726us/sample - loss: 6.8774e-04 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9706\n",
      "Epoch 424/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 4.0314e-04 - accuracy: 1.0000\n",
      "Epoch 00424: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 694us/sample - loss: 6.9283e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9706\n",
      "Epoch 425/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 7.3939e-04 - accuracy: 1.0000\n",
      "Epoch 00425: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 695us/sample - loss: 7.0292e-04 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9706\n",
      "Epoch 426/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00426: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 699us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9706\n",
      "Epoch 427/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00427: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 676us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 0.9706\n",
      "Epoch 428/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0085 - accuracy: 0.9900    \n",
      "Epoch 00428: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 702us/sample - loss: 0.0096 - accuracy: 0.9925 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 3.8343e-04 - accuracy: 1.0000\n",
      "Epoch 00429: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 702us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 0.9706\n",
      "Epoch 430/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0220 - accuracy: 0.9909    \n",
      "Epoch 00430: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 671us/sample - loss: 0.0509 - accuracy: 0.9776 - val_loss: 0.0832 - val_accuracy: 0.9706\n",
      "Epoch 431/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0728 - accuracy: 0.9455    \n",
      "Epoch 00431: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 671us/sample - loss: 0.1630 - accuracy: 0.9478 - val_loss: 0.2172 - val_accuracy: 0.9412\n",
      "Epoch 432/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0715 - accuracy: 0.9800\n",
      "Epoch 00432: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 684us/sample - loss: 0.0619 - accuracy: 0.9776 - val_loss: 0.2486 - val_accuracy: 0.9706\n",
      "Epoch 433/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0141 - accuracy: 0.9900    \n",
      "Epoch 00433: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 700us/sample - loss: 0.0112 - accuracy: 0.9925 - val_loss: 0.0931 - val_accuracy: 0.9412\n",
      "Epoch 434/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 00434: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 727us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9706\n",
      "Epoch 435/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00435: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 694us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9706\n",
      "Epoch 436/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 00436: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 704us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9706\n",
      "Epoch 437/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00437: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 731us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9706\n",
      "Epoch 438/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000    \n",
      "Epoch 00438: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 692us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9706\n",
      "Epoch 439/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0162 - accuracy: 0.9900    \n",
      "Epoch 00439: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 676us/sample - loss: 0.0217 - accuracy: 0.9851 - val_loss: 0.0283 - val_accuracy: 0.9706\n",
      "Epoch 440/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0206 - accuracy: 0.9900    \n",
      "Epoch 00440: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 685us/sample - loss: 0.0282 - accuracy: 0.9851 - val_loss: 0.0989 - val_accuracy: 0.9706\n",
      "Epoch 441/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0460 - accuracy: 0.9800    \n",
      "Epoch 00441: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 674us/sample - loss: 0.0362 - accuracy: 0.9851 - val_loss: 0.0221 - val_accuracy: 0.9706\n",
      "Epoch 442/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0830 - accuracy: 0.9818\n",
      "Epoch 00442: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 691us/sample - loss: 0.1187 - accuracy: 0.9776 - val_loss: 0.0986 - val_accuracy: 0.9706\n",
      "Epoch 443/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.1021 - accuracy: 0.9545    \n",
      "Epoch 00443: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 684us/sample - loss: 0.0886 - accuracy: 0.9627 - val_loss: 0.3760 - val_accuracy: 0.9118\n",
      "Epoch 444/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0833 - accuracy: 0.9818    \n",
      "Epoch 00444: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 703us/sample - loss: 0.0764 - accuracy: 0.9776 - val_loss: 0.0430 - val_accuracy: 0.9706\n",
      "Epoch 445/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0768 - accuracy: 0.9636\n",
      "Epoch 00445: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 659us/sample - loss: 0.0765 - accuracy: 0.9627 - val_loss: 0.2085 - val_accuracy: 0.9706\n",
      "Epoch 446/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 00446: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 670us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9706\n",
      "Epoch 447/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000    \n",
      "Epoch 00447: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 668us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2238 - val_accuracy: 0.9706\n",
      "Epoch 448/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00448: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 700us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1831 - val_accuracy: 0.9706\n",
      "Epoch 449/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 00449: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 712us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9706\n",
      "Epoch 450/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 6.2041e-04 - accuracy: 1.0000\n",
      "Epoch 00450: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 710us/sample - loss: 7.1339e-04 - accuracy: 1.0000 - val_loss: 0.1672 - val_accuracy: 0.9706\n",
      "Epoch 451/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0053 - accuracy: 1.0000    \n",
      "Epoch 00451: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 680us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 0.9706\n",
      "Epoch 452/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 00452: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 672us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9706\n",
      "Epoch 453/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
      "Epoch 00453: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 702us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9706\n",
      "Epoch 454/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000    \n",
      "Epoch 00454: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 683us/sample - loss: 0.0279 - accuracy: 0.9925 - val_loss: 0.1708 - val_accuracy: 0.9706\n",
      "Epoch 455/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00455: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 694us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9412\n",
      "Epoch 456/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000    \n",
      "Epoch 00456: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 681us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 0.9706\n",
      "Epoch 457/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 2.1767e-04 - accuracy: 1.0000\n",
      "Epoch 00457: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 707us/sample - loss: 7.7534e-04 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9706\n",
      "Epoch 458/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00458: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 680us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9706\n",
      "Epoch 459/500\n",
      " 70/134 [==============>...............] - ETA: 0s - loss: 8.9005e-04 - accuracy: 1.0000\n",
      "Epoch 00459: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 912us/sample - loss: 8.7490e-04 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9706\n",
      "Epoch 460/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 9.4081e-04 - accuracy: 1.0000\n",
      "Epoch 00460: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 717us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9706\n",
      "Epoch 461/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00461: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 697us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9706\n",
      "Epoch 462/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000    \n",
      "Epoch 00462: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 706us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9706\n",
      "Epoch 463/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 9.1747e-04 - accuracy: 1.0000\n",
      "Epoch 00463: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 700us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 0.9706\n",
      "Epoch 464/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 5.6588e-04 - accuracy: 1.0000\n",
      "Epoch 00464: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 700us/sample - loss: 8.5163e-04 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 0.9706\n",
      "Epoch 465/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
      "Epoch 00465: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 677us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9706\n",
      "Epoch 466/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 5.3403e-04 - accuracy: 1.0000\n",
      "Epoch 00466: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 675us/sample - loss: 4.5921e-04 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9706\n",
      "Epoch 467/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000    \n",
      "Epoch 00467: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 686us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9706\n",
      "Epoch 468/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    \n",
      "Epoch 00468: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 675us/sample - loss: 9.0535e-04 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9706\n",
      "Epoch 469/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000    \n",
      "Epoch 00469: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 669us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9706\n",
      "Epoch 470/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 00470: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 676us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 0.9706\n",
      "Epoch 471/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000    \n",
      "Epoch 00471: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 669us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9706\n",
      "Epoch 472/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0096 - accuracy: 0.9900    \n",
      "Epoch 00472: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 686us/sample - loss: 0.0072 - accuracy: 0.9925 - val_loss: 0.1427 - val_accuracy: 0.9706\n",
      "Epoch 473/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 4.7874e-04 - accuracy: 1.0000\n",
      "Epoch 00473: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 675us/sample - loss: 0.0104 - accuracy: 0.9925 - val_loss: 0.0981 - val_accuracy: 0.9706\n",
      "Epoch 474/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0148 - accuracy: 0.9909    \n",
      "Epoch 00474: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 643us/sample - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.3054 - val_accuracy: 0.9706\n",
      "Epoch 475/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0109 - accuracy: 0.9900\n",
      "Epoch 00475: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 688us/sample - loss: 0.0084 - accuracy: 0.9925 - val_loss: 0.2349 - val_accuracy: 0.9706\n",
      "Epoch 476/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00476: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 681us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9706\n",
      "Epoch 477/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00477: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 700us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9706\n",
      "Epoch 478/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
      "Epoch 00478: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 691us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9706\n",
      "Epoch 479/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 7.6204e-04 - accuracy: 1.0000\n",
      "Epoch 00479: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 692us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9706\n",
      "Epoch 480/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 00480: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 705us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2571 - val_accuracy: 0.9706\n",
      "Epoch 481/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000    \n",
      "Epoch 00481: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 672us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2114 - val_accuracy: 0.9706\n",
      "Epoch 482/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 6.5891e-04 - accuracy: 1.0000\n",
      "Epoch 00482: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 693us/sample - loss: 5.5139e-04 - accuracy: 1.0000 - val_loss: 0.1633 - val_accuracy: 0.9706\n",
      "Epoch 483/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 3.1701e-04 - accuracy: 1.0000\n",
      "Epoch 00483: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 697us/sample - loss: 3.6513e-04 - accuracy: 1.0000 - val_loss: 0.1584 - val_accuracy: 0.9706\n",
      "Epoch 484/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 6.3363e-04 - accuracy: 1.0000\n",
      "Epoch 00484: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 664us/sample - loss: 5.8171e-04 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9706\n",
      "Epoch 485/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00485: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 674us/sample - loss: 9.3518e-04 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9706\n",
      "Epoch 486/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 2.8348e-04 - accuracy: 1.0000\n",
      "Epoch 00486: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 670us/sample - loss: 2.3742e-04 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9706\n",
      "Epoch 487/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 2.6596e-04 - accuracy: 1.0000\n",
      "Epoch 00487: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 698us/sample - loss: 2.0267e-04 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9706\n",
      "Epoch 488/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 2.1452e-04 - accuracy: 1.0000\n",
      "Epoch 00488: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 731us/sample - loss: 1.9439e-04 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9706\n",
      "Epoch 489/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 2.5875e-04 - accuracy: 1.0000\n",
      "Epoch 00489: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 698us/sample - loss: 2.5954e-04 - accuracy: 1.0000 - val_loss: 0.1738 - val_accuracy: 0.9706\n",
      "Epoch 490/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000    \n",
      "Epoch 00490: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 676us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9706\n",
      "Epoch 491/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 5.1938e-04 - accuracy: 1.0000\n",
      "Epoch 00491: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 725us/sample - loss: 4.3612e-04 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9706\n",
      "Epoch 492/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 3.8831e-04 - accuracy: 1.0000\n",
      "Epoch 00492: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 690us/sample - loss: 3.0309e-04 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9706\n",
      "Epoch 493/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 6.4041e-04 - accuracy: 1.0000\n",
      "Epoch 00493: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 678us/sample - loss: 5.8151e-04 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9706\n",
      "Epoch 494/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    \n",
      "Epoch 00494: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 692us/sample - loss: 8.0724e-04 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9706\n",
      "Epoch 495/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 6.3289e-04 - accuracy: 1.0000\n",
      "Epoch 00495: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 681us/sample - loss: 5.1950e-04 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9706\n",
      "Epoch 496/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 4.5609e-04 - accuracy: 1.0000\n",
      "Epoch 00496: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 693us/sample - loss: 4.0136e-04 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9706\n",
      "Epoch 497/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 5.4087e-04 - accuracy: 1.0000\n",
      "Epoch 00497: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 701us/sample - loss: 4.1844e-04 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9706\n",
      "Epoch 498/500\n",
      "100/134 [=====================>........] - ETA: 0s - loss: 1.7763e-04 - accuracy: 1.0000\n",
      "Epoch 00498: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 713us/sample - loss: 1.8854e-04 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9706\n",
      "Epoch 499/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.1603e-04 - accuracy: 1.0000\n",
      "Epoch 00499: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 671us/sample - loss: 7.8587e-04 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9706\n",
      "Epoch 500/500\n",
      "110/134 [=======================>......] - ETA: 0s - loss: 1.9811e-04 - accuracy: 1.0000\n",
      "Epoch 00500: val_accuracy did not improve from 1.00000\n",
      "134/134 [==============================] - 0s 696us/sample - loss: 5.7946e-04 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 0.9706\n",
      "Training completed in time:  0:00:46.864411\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.375\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.18      0.67      0.29         9\n",
      "   Pneumonia       0.80      0.31      0.44        39\n",
      "\n",
      "    accuracy                           0.38        48\n",
      "   macro avg       0.49      0.49      0.37        48\n",
      "weighted avg       0.68      0.38      0.41        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  3]\n",
      " [27 12]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
