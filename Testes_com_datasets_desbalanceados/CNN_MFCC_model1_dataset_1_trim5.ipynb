{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 1\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 1 - trim5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'trim5'\n",
    "GROUP_TEST = 'trim5'\n",
    "DATASET = 'dataset_1'\n",
    "DURATION = 5\n",
    "SIZE = 216\n",
    "CSV_TRAIN = 'train1.csv'\n",
    "CSV_TEST = 'test1.csv'\n",
    "MODEL_NAME = f'CNN1_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  102  Healthy\n",
       "1  121  Healthy\n",
       "2  123  Healthy\n",
       "3  125  Healthy\n",
       "4  126  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  366  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['96' '87']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['9' '24']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAHwCAYAAABkJOM0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deZhtZ1kn7N9DwhAMJECOMQlIQECGNIMeZsUIOIAoYEPERglIm6ZbQIYWcGhpcYJuPmZQ06AERaYQZBRBJIDIlEAwBlAiYyDDAQIkMiY83x9rVVJUqs6penOq9qnkvq+rrtrrXcN+1t6rdv32u9+1dnV3AACAjbvKogsAAIDtSpgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEzDFURV/WlV/a9F17HdVdUZVXX0ouu4PKrq5Kr6rxtc55Ljp6qOrqqzNqGuq1fVR6rqsL297b1tsx6DK4qqelRVPW3RdcC+QJiGbaCqPlVVX6+qC6rqy1X1T1X1iKq65G+4ux/R3b+/yDrXq6oOq6oXVdXZ8z59rKp+r6q+Z5Pv939X1V/tbpnuvlV3nzy4/ftW1WlV9dWq+kJV/UNV3Wio2E0yPwbfrqoLl/08YYuOn+OSvLO7z55reXFVdVXdYVl9N6mqy/UFCPM+dlXdcQPrdFXd5PLc776iqh5aVf+4xryTq+ob8/P+hao6af57/K1lx8M3quriZdNnzOsuf4z+X5IHV9X3btV+wb5KmIbt42e7+1pJbpjkqUmemORFiy1p46rquknek+SAJHee9+knkhyc5AcWWdvlMYeMlyR5fJKDktwoyfOTXLzIutbwiu4+cNnP/9mi+31Ekr9c0falJH+wt+6gqirJQ+btPmRvbXdfVVX7D6z2yO4+MMlNkhyY5Ond/UdLx0Om5+k9y46PW63cQHd/I8nf5krwGMOeCNOwzXT3V7r7dUl+IcmxVXVUckkv3x/Mtw+pqjfMvdhfqqp3LfViV9XhVfXqqtpVVZ+sqkcvbbuq7lBV75nXO7uqnldVV5vnVVU9s6rOm3teT19231evqqdX1Weq6tx5yMABa+zC45JckOSXuvtT8z59trt/vbv/ed7eXarqA1X1lfn3XZbV+Kmquuey6Ut6m6vqyLn37Ni5li9U1W/P8346yW8l+YW5t+3DqxW3fPvztl9ZVS+Ze9DPqKqda+zXbZN8srvf1pMLuvvV3f2ZZY/Rs6rq8/PPs6rq6vO8y/QkLu8FnJ/b51fVG+c63ldVP7Bs2Z+oqXf/K1X1vCS1Ro1rWn78rDJvT8fMKfMxcW5VPWONbXx/khsned+KWSckuXVV/dhu7vt183F8ZlX96h525UeTHJbk0UketHT8ztu6SVW9Y36cvlBVr5jb3zkv8uH52PiFZes8fj7mz66qhy1rf3FVvaCq/nZe591V9X3z83r+/HzcbtnyT6qqf5+fv49U1f3X2oE9HCtHV9VZVfXEqjonyV/s4fFYU3d/OcnfZDp2R5yc5GdG7x+uKIRp2Ka6+/1JzsoUHlZ6/DxvR5JDM4XIrilQvz7Jh5MckeQeSR5TVT81r3dxkscmOSTJnef5/2Oe95NJ7pbkZpl6Xo9J8sV53lPn9ttm6u06IsnvrlH6PZOc1N3fWW1mTT3Xb0zynCTXS/KMJG+squut/Whcxo8k+cG5/t+tqlt095uT/FEu7ZW9zTq39XNJXp6p5/x1SZ63xnIfTHLz+Q3Hj1fVgSvm/3aSO2V6jG6T5A5JfmcD+/SgJL+X5DpJzkzyh8n0xinJSfO2Dkny70nuuoHt7tY6jplnJ3l2d1870ycLr1xjU/8pySe6+6IV7V/L9Lz84RrrvTzTsXx4kgck+aOquvtuSj52rnepjp9dNu/3k7wl02N4/STPTZLuvts8/zbzsfGKefr7Mh3rRyR5eJLnV9V1lm3vmFz6uH8z0ycuH5ynT8x07C7590x/qwdleh7/qtYeO76nY+X7klw306dUx639UOze/Df185mOpxEfneuDKzVhGra3z2f6p7rStzP1zt2wu7/d3e/q7k5y+yQ7uvsp3f2t7v5EprGPD0qS7j61u9/b3RfNvcZ/luTHlm3zWklunqS6+6PdfXZVVaZ/6I/t7i919wWZwtGD1qj5eknO3s0+/UySj3f3X851vCzJx/LdoWhPfq+7v97dH84UAi/PP/x/7O43dffFmYYorLqt+bE8OlPwemWSL8y9l0uh+sFJntLd53X3rkyB6pc3UMdruvv9cxh9aS7tTbx3kjO6+8Tu/naSZyU5Zw/bOqamTx+Wfg7fzbK7PWYyHRc3qapDuvvC7n7vGts5ONMnEqv5syTfX1X3Wt5YVTfI9Mbgid39je4+LckLs8bQgqq6ZpIHJvnr+bE4ccWy384UQA+ft7fquOIVyz9l/ht6U5ILM71JW/Ka+W/mG0lek+Qb3f2S+Vh5RZJLeqa7+1Xd/fnu/s4c1j+eKSSvZk/HyneSPLm7v9ndX9/DPqzmOVX1lSRfyBT8HzWwjWR6Pg8aXBeuMIRp2N6OyDQ2dKX/m6m36S1V9YmqetLcfsMkhy8PUpl6rQ9Nkqq6WU3DQ86pqq9mCsWHJEl3/0OmXtnnJzmvqo6vqmtn6v2+ZpJTl23zzXP7ar6YKeiv5fAkn17R9ul5X9dreZj8WqZxoaNWbusatcY41fmNyDHdvSNTL+TdMvUyJpfdr0/PbaN1LO3T4Uk+u6yGXj69hld298HLfj6/m2V3e8xk6rG9WZKP1TQk5z5rbOf8TG/GLqO7v5mp13jlCZCHJ1l6g7Zkd8fC/ZNclORN8/RLk9yrqpaOxSdkGgLz/pqG7PzKGttZ8sUVPekrj6Vzl93++irTlyxbVQ+p6eTUpcfwqMx/W6vY07Gyaw7wox7d3QcluXUu7aUfca0kX7kcdcAVgjAN21RV3T5TqLhM79o8Xvfx3X3jTMMUHldV98gUsj65Ikhdq7vvPa/6J5l6gW86f2z/W1k2/ra7n9PdP5zklpkC1G9k6t36epJbLdvmQfOJTKv5+yT3r2VXIlnh85kC3HLfn+Rz8+3/yBTel3zfGttZzeW6SsRGdPcHMg2/OGpuWrlf3z+3JSv2qao2sk9nJ7nBsnVr+fResNtjprs/3t2/mOR7kzwtyYm1+lVZ/jnJjdZ6I5Jp7O/BmYYdLPl8kutW1fIQvvxYWOnYTAH2M/N44lcluWqS/zLXek53/2p3H57kvyV5QW3BFTyq6oaZevMfmeR63X1wkn/J2mPbd3esJHvpOO7u0zOd/Pn8+bjZqFtk+uQHrtSEadhmqurac+/fy5P81fwPceUy95lPtqpMPUcXZ/po+P1JLphPXjqgqvarqqPmYJ5MPU1fTXJhVd08yX9fts3bV9Udq+qqmcLfN5J8Zx77/P+SPLPmy2RV1RHLxtSu9Iwk105ywhwylpZ/RlXdOlOv4s2q6r9U1f7zyWC3TPKGef3TMp1YdtWaTgZ8wAYevnOTHLmbID+sqn6kqn512WNw80xvZJaGPbwsye9U1Y55nPPvJlm6TN+Hk9yqqm5bVddI8r83cNdvnNf9+TmoPjobe4OxJ7s9Zqrql6pqx3wcfHle5zLj4bv7rEyflqw6tGHuAX5ypqvULLV9Nsk/JfnjqrrGfHw8PJc+bpeoqqXx3PfJNARmabzx0zIP9aiqB1bVUi/s+ZlC6VKt52Y6QXIzfM98X7vmOh6WS99krWZ3x8p61fyYXfKzxnInZPqU4ec2uP1kGgL2twPrwRWKMA3bx+ur6oJMPYW/nSmUPmyNZW+aqQf4wkwnRb2gu98+j+VcChufzNSr/MJcOu7xf2bqxbsgU0B+xbJtXntuOz/Tx85fzDScJJkC0JlJ3jsPD/n7fPfY0kt095eS3CXTeNT3zfv0tkyh/8zu/uJc4+Pn+3hCkvt09xfmTfyvTCe6nZ9pLOlfr/mIXdar5t9frKoPbmC99fhypkByelVdmGmoy2uSLF127g+SnJKph/b0TCeq/UGSdPe/JXlKpsft41nl04a1zI/LAzOdBPrFTM/9uy//7lyy/T0dMz+d5Ix5n5+d5EG7Gcf7Z9n9OPGX5bLj6X8xyZGZemZfk2ms8N+vsu4vJzmtu98y90Cf093nZDqR9dY1XXnm9pmOuQsznUz66/MY8GR6A3PCPAzjmN3UuGHd/ZEk/1+mv8VzM52MubvnaM1jZQPukukTo0t+VvtUoLu/lel529AXPs3h/N6ZwjhcqdU0vA4ANldNl3f7UJJ79PzFLWxPVfWoJDfo7icsuhZYNGEaAAAGGeYBAACDhGkAABgkTAMAwCBhGgAABq118fzLrar+PNPllM7r7qPmtutmutTWkUk+leSY7j5/vhbuszNdZudrSR7a3Xu8bNUhhxzSRx555KbUDwAAS0499dQvzN9w+102LUwneXGmrx5+ybK2JyV5W3c/df564ydluj7tvTJdG/WmSe6Y6VvY7rinOzjyyCNzyimn7OWyAQDgu1XVp1dr37RhHt39ziRfWtF831x6gfcTktxvWftLevLeJAdX1WGbVRsAAOwNWz1m+tBlF+o/J9NXmCbJEZm+1W3JWXPbZVTVcVV1SlWdsmvXrs2rFAAA9mBhJyD29G0xG/7GmO4+vrt3dvfOHTsuM2wFAAC2zFaH6XOXhm/Mv8+b2z+X5AbLlrv+3AYAAPusrQ7Tr0ty7Hz72CSvXdb+kJrcKclXlg0HAQCAfdJmXhrvZUmOTnJIVZ2V5MlJnprklVX18CSfTnLMvPibMl0W78xMl8Z72GbVBQAAe8umhenu/sU1Zt1jlWU7ya9tVi0AALAZfAMiAAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABi0/6IL2K6e+dZ/W3QJwDbz2J+42aJLAGAv0zMNAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMGj/RRcAwJXTM9/6b4suAdhmHvsTN1t0CZehZxoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMGghYbqqHltVZ1TVv1TVy6rqGlV1o6p6X1WdWVWvqKqrLaI2AABYry0P01V1RJJHJ9nZ3Ucl2S/Jg5I8Lckzu/smSc5P8vCtrg0AADZiUcM89k9yQFXtn+SaSc5OcvckJ87zT0hyvwXVBgAA67LlYbq7P5fk6Uk+kylEfyXJqUm+3N0XzYudleSIra4NAAA2YhHDPK6T5L5JbpTk8CTfk+SnN7D+cVV1SlWdsmvXrk2qEgAA9mwRwzzumeST3b2ru7+d5KQkd01y8DzsI0mun+Rzq63c3cd3987u3rljx46tqRgAAFaxiDD9mSR3qqprVlUluUeSjyR5e5IHzMscm+S1C6gNAADWbRFjpt+X6UTDDyY5fa7h+CRPTPK4qjozyfWSvGirawMAgI3Yf8+L7H3d/eQkT17R/Ikkd1hAOQAAMMQ3IAIAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAxaSJiuqoOr6sSq+lhVfbSq7lxV162qt1bVx+ff11lEbQAAsF6L6pl+dpI3d/fNk9wmyUeTPCnJ27r7pkneNk8DAMA+a8vDdFUdlORuSV6UJN39re7+cpL7JjlhXuyEJPfb6toAAGAjFtEzfaMku5L8RVV9qKpeWFXfk+TQ7j57XuacJIcuoDYAAFi3RYTp/ZP8UJI/6e7bJfmPrBjS0d2dpFdbuaqOq6pTquqUXbt2bXqxAACwlkWE6bOSnNXd75unT8wUrs+tqsOSZP593mord/fx3b2zu3fu2LFjSwoGAIDVbHmY7u5zkny2qn5wbrpHko8keV2SY+e2Y5O8dqtrAwCAjdh/Qff7qCQvraqrJflEkodlCvavrKqHJ/l0kmMWVBsAAKzLQsJ0d5+WZOcqs+6x1bUAAMAo34AIAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADFpXmK6qu66nDQAArkzW2zP93HW2AQDAlcb+u5tZVXdOcpckO6rqcctmXTvJfptZGAAA7Ot2G6aTXC3JgfNy11rW/tUkD9isogAAYDvYbZju7nckeUdVvbi7P71FNQEAwLawp57pJVevquOTHLl8ne6++2YUBQAA28F6w/SrkvxpkhcmuXjzygEAgO1jvWH6ou7+k02tBAAAtpn1Xhrv9VX1P6rqsKq67tLPplYGAAD7uPX2TB87//6NZW2d5MZ7txwAANg+1hWmu/tGm10IAABsN+sK01X1kNXau/sle7ccAADYPtY7zOP2y25fI8k9knwwiTANAMCV1nqHeTxq+XRVHZzk5ZtSEQAAbBPrvZrHSv+RxDhqAACu1NY7Zvr1ma7ekST7JblFklduVlEAALAdrHfM9NOX3b4oyae7+6xNqAcAALaNdQ3z6O53JPlYkmsluU6Sb21mUQAAsB2sK0xX1TFJ3p/kgUmOSfK+qnrAZhYGAAD7uvUO8/jtJLfv7vOSpKp2JPn7JCduVmEAALCvW+/VPK6yFKRnX9zAugAAcIW03p7pN1fV3yV52Tz9C0netDklAQDA9rDbMF1VN0lyaHf/RlX9fJIfmWe9J8lLN7s4AADYl+2pZ/pZSX4zSbr7pCQnJUlV/ad53s9uanUAALAP29O450O7+/SVjXPbkZtSEQAAbBN7CtMH72beAXuzEAAA2G72FKZPqapfXdlYVf81yambUxIAAGwPexoz/Zgkr6mqB+fS8LwzydWS3H8zCwMAgH3dbsN0d5+b5C5V9eNJjpqb39jd/7DplQEAwD5uXdeZ7u63J3n7JtcCAADbim8xBACAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQQsL01W1X1V9qKreME/fqKreV1VnVtUrqupqi6oNAADWY5E907+e5KPLpp+W5JndfZMk5yd5+EKqAgCAdVpImK6q6yf5mSQvnKcryd2TnDgvckKS+y2iNgAAWK9F9Uw/K8kTknxnnr5eki9390Xz9FlJjlhtxao6rqpOqapTdu3atfmVAgDAGrY8TFfVfZKc192njqzf3cd3987u3rljx469XB0AAKzf/gu4z7sm+bmquneSayS5dpJnJzm4qvafe6evn+RzC6gNAADWbct7prv7N7v7+t19ZJIHJfmH7n5wkrcnecC82LFJXrvVtQEAwEbsS9eZfmKSx1XVmZnGUL9owfUAAMBuLWKYxyW6++QkJ8+3P5HkDousBwAANmJf6pkGAIBtRZgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg7Y8TFfVDarq7VX1kao6o6p+fW6/blW9tao+Pv++zlbXBgAAG7GInumLkjy+u2+Z5E5Jfq2qbpnkSUne1t03TfK2eRoAAPZZWx6mu/vs7v7gfPuCJB9NckSS+yY5YV7shCT32+raAABgIxY6ZrqqjkxyuyTvS3Jod589zzonyaELKgsAANZlYWG6qg5M8uokj+nury6f192dpNdY77iqOqWqTtm1a9cWVAoAAKtbSJiuqqtmCtIv7e6T5uZzq+qwef5hSc5bbd3uPr67d3b3zh07dmxNwQAAsIpFXM2jkrwoyUe7+xnLZr0uybHz7WOTvHarawMAgI3YfwH3edckv5zk9Ko6bW77rSRPTfLKqnp4kk8nOWYBtQEAwLpteZju7n9MUmvMvsdW1gIAAJeHb0AEAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMAgYRoAAAYJ0wAAMEiYBgCAQcI0AAAMEqYBAGCQMA0AAIOEaQAAGCRMAwDAIGEaAAAGCdMAADBImAYAgEHCNAAADBKmAQBgkDANAACDhGkAABgkTAMAwCBhGgAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYtE+F6ar66ar616o6s6qetOh6AABgd/aZMF1V+yV5fpJ7Jbllkl+sqlsutioAAFjbPhOmk9whyZnd/Ynu/laSlye574JrAgCANe1LYfqIJJ9dNn3W3AYAAPuk/RddwEZV1XFJjpsnL6yqf11kPbCKQ5J8YdFFsO953KILgO3D6yirWvDr6A1Xa9yXwvTnktxg2fT157bv0t3HJzl+q4qCjaqqU7p756LrANiuvI6ynexLwzw+kOSmVXWjqrpakgcled2CawIAgDXtMz3T3X1RVT0yyd8l2S/Jn3f3GQsuCwAA1rTPhOkk6e43JXnTouuAy8kwJIDLx+so20Z196JrAACAbWlfGjMNAADbijANSarqwhXTD62q5w1u6+iqesOy23dZNu/FVfWAy1ctwNarqour6rSq+peqelVVXXPRNa1HVe2squcsug6uuIRp2FxHJ7nLnhYC2Aa+3t237e6jknwrySMWXdB6dPcp3f3oRdfBFZcwDXtQVTuq6tVV9YH5565z+x2q6j1V9aGq+qeq+sEV6x2Z6Z/NY+fenB+dZ91tXv4TS73UVfWSqrrfsnVfWlX33ZIdBNi4dyW5yfzp28lVdWJVfWx+7aokqaofrqp3VNWpVfV3VXXY3H5yVe2cbx9SVZ+abz+0qv6mqt5aVZ+qqkdW1ePm19j3VtV15+VuO0//c1W9pqqus2y7T6uq91fVvy295q74tHC3r9swQpiGyQFz4D2tqk5L8pRl856d5Jndffsk/znJC+f2jyX50e6+XZLfTfJHyzfY3Z9K8qfzurft7nfNsw5L8iNJ7pPkqXPbi5I8NEmq6qBMvdlv3Kt7CLAXVNX+Se6V5PS56XZJHpPklklunOSuVXXVJM9N8oDu/uEkf57kD9ex+aOS/HyS28/Lf21+jX1PkofMy7wkyRO7+9ZzDU9etv7+3X2HuZ7l7Ut2+7oNI/apS+PBAn29u2+7NFFVD02y9O1b90xyy7mzJUmuXVUHJjkoyQlVddMkneSq67yvv+nu7yT5SFUdmiTd/Y6qekFV7cgU2F/d3Rdd3p0C2IsOmDsbkqln+kWZ3vi/v7vPSpJ5/pFJvpwpGL91fu3cL8nZ67iPt3f3BUkuqKqvJHn93H56klvPnQ0Hd/c75vYTkrxq2fonzb9PnetYafR1G9YkTMOeXSXJnbr7G8sb5xMU397d95+HdJy8zu19c/lmlnEv9QAAAAOtSURBVN1+SZJfyvTtnw8bLRZgk3xXp0OSzEF5+WvaxZmyRSU5o7vvvMp2Lsqln4xfY8W85dv6zrLp72R9mWVp+aU6Vvr9jL1uw5oM84A9e0uSRy1NVNXSP5ODknxuvv3QNda9IMm11nk/L8700WS6+yMbLRJgH/KvSXZU1Z2TpKquWlW3mud9KskPz7c3dHWj7v5KkvOXnYPyy0nesZtVVlrP6zZsiDANe/boJDvnk10+kkvPYP8/Sf64qj6UtXtMXp/k/itOQFxVd5+b5KNJ/mIv1Q2wEN39rUxB+WlV9eEkp+XSKxs9Pcl/n187DxnY/LFJ/m9V/XOS2+a7z3HZk/W8bsOG+AZE2EfM12w9PckPzb0vAMA+Ts807AOq6p6ZeqWfK0gDwPahZxoAAAbpmQYAgEHCNAAADBKmAQBgkDANsA1U1cXzJRbPqKoPV9Xjq+oq87ydVfWcRdcIcGXkBESAbaCqLuzuA+fb35vkr5O8u7ufvNjKAK7c9EwDbDPdfV6S45I8siZHV9UbkqSqfmzuwT6tqj5UVdea23+jqj4wf/nQ7y1tq6r+pqpOnXu8j5vb9quqF1fVv1TV6VX12Ln9B6rqzfPy76qqm2/93gPsW3z7D8A21N2fqKr9knzviln/M8mvdfe7q+rAJN+oqp9MctMkd0hSSV5XVXfr7ncm+ZXu/lJVHZDkA1X16iRHJjmiu49Kkqo6eN728Uke0d0fr6o7JnlBkrtv8q4C7NOEaYArlncneUZVvTTJSd191hymfzLJh+ZlDswUrt+Z5NFVdf+5/QZz+78muXFVPTfJG5O8ZQ7md0nyqqpauq+rb8UOAezLhGmAbaiqbpzk4iTnJbnFUnt3P7Wq3pjk3kneXVU/lak3+o+7+89WbOPoJPdMcufu/lpVnZzkGt19flXdJslPJXlEkmOSPCbJl7v7tpu+cwDbiDHTANtMVe1I8qdJntcrziKvqh/o7tO7+2lJPpDk5kn+LsmvzL3Lqaoj5pMYD0py/hykb57kTvP8Q5JcpbtfneR3kvxQd381ySer6oHzMjUHboArNT3TANvDAVV1WpKrJrkoyV8mecYqyz2mqn48yXeSnJHkb7v7m1V1iyTvmYdoXJjkl5K8OckjquqjmYZ2vHfexhFJ/mLp0ntJfnP+/eAkf1JVvzPX8fIkH967uwmwvbg0HgAADDLMAwAABgnTAAAwSJgGAIBBwjQAAAwSpgEAYJAwDQAAg4RpAAAYJEwDAMCg/x9vD1TnFui7IgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 40, 216)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183, 40, 216, 1) (183, 2)\n",
      "(33, 40, 216, 1) (33, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 215, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 106, 32)       2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 52, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 25, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 43,570\n",
      "Trainable params: 43,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "33/33 [==============================] - 1s 29ms/sample - loss: 1.3606 - accuracy: 0.7273\n",
      "Pre-training accuracy: 72.7273%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146 samples, validate on 37 samples\n",
      "Epoch 1/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 6.3010 - accuracy: 0.5300\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.35135, saving model to models/CNN2_dataset_1_trim5_01.h5\n",
      "146/146 [==============================] - 1s 6ms/sample - loss: 5.5612 - accuracy: 0.5068 - val_loss: 1.0023 - val_accuracy: 0.3514\n",
      "Epoch 2/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 2.5543 - accuracy: 0.5600\n",
      "Epoch 00002: val_accuracy improved from 0.35135 to 0.51351, saving model to models/CNN2_dataset_1_trim5_02.h5\n",
      "146/146 [==============================] - 0s 850us/sample - loss: 2.4998 - accuracy: 0.5411 - val_loss: 1.2454 - val_accuracy: 0.5135\n",
      "Epoch 3/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 1.0710 - accuracy: 0.6111\n",
      "Epoch 00003: val_accuracy did not improve from 0.51351\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 1.1222 - accuracy: 0.5616 - val_loss: 1.0033 - val_accuracy: 0.5135\n",
      "Epoch 4/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.9349 - accuracy: 0.6000\n",
      "Epoch 00004: val_accuracy improved from 0.51351 to 0.56757, saving model to models/CNN2_dataset_1_trim5_04.h5\n",
      "146/146 [==============================] - 0s 913us/sample - loss: 0.8667 - accuracy: 0.5959 - val_loss: 0.6346 - val_accuracy: 0.5676\n",
      "Epoch 5/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.7520 - accuracy: 0.6444\n",
      "Epoch 00005: val_accuracy improved from 0.56757 to 0.83784, saving model to models/CNN2_dataset_1_trim5_05.h5\n",
      "146/146 [==============================] - 0s 834us/sample - loss: 0.7829 - accuracy: 0.6438 - val_loss: 0.5754 - val_accuracy: 0.8378\n",
      "Epoch 6/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.7572 - accuracy: 0.6375\n",
      "Epoch 00006: val_accuracy did not improve from 0.83784\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.7799 - accuracy: 0.6233 - val_loss: 0.5977 - val_accuracy: 0.6757\n",
      "Epoch 7/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 1.1753 - accuracy: 0.5667\n",
      "Epoch 00007: val_accuracy improved from 0.83784 to 0.86486, saving model to models/CNN2_dataset_1_trim5_07.h5\n",
      "146/146 [==============================] - 0s 873us/sample - loss: 1.0401 - accuracy: 0.6027 - val_loss: 0.5571 - val_accuracy: 0.8649\n",
      "Epoch 8/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.7258 - accuracy: 0.5889\n",
      "Epoch 00008: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 698us/sample - loss: 0.7554 - accuracy: 0.5616 - val_loss: 0.5347 - val_accuracy: 0.8378\n",
      "Epoch 9/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.6310 - accuracy: 0.7200\n",
      "Epoch 00009: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 655us/sample - loss: 0.6003 - accuracy: 0.7329 - val_loss: 0.5311 - val_accuracy: 0.6486\n",
      "Epoch 10/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.6113 - accuracy: 0.7250\n",
      "Epoch 00010: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.5987 - accuracy: 0.7055 - val_loss: 0.5594 - val_accuracy: 0.6216\n",
      "Epoch 11/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5848 - accuracy: 0.6889\n",
      "Epoch 00011: val_accuracy did not improve from 0.86486\n",
      "146/146 [==============================] - 0s 692us/sample - loss: 0.5854 - accuracy: 0.6918 - val_loss: 0.4076 - val_accuracy: 0.8649\n",
      "Epoch 12/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3901 - accuracy: 0.8111\n",
      "Epoch 00012: val_accuracy improved from 0.86486 to 0.91892, saving model to models/CNN2_dataset_1_trim5_12.h5\n",
      "146/146 [==============================] - 0s 920us/sample - loss: 0.4070 - accuracy: 0.8014 - val_loss: 0.3133 - val_accuracy: 0.9189\n",
      "Epoch 13/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.3622 - accuracy: 0.8600\n",
      "Epoch 00013: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.3693 - accuracy: 0.8562 - val_loss: 0.3225 - val_accuracy: 0.8378\n",
      "Epoch 14/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.4540 - accuracy: 0.7700\n",
      "Epoch 00014: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.4242 - accuracy: 0.7877 - val_loss: 0.2618 - val_accuracy: 0.9189\n",
      "Epoch 15/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.3864 - accuracy: 0.8333\n",
      "Epoch 00015: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 702us/sample - loss: 0.3517 - accuracy: 0.8356 - val_loss: 0.2548 - val_accuracy: 0.9189\n",
      "Epoch 16/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.2360 - accuracy: 0.9273\n",
      "Epoch 00016: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 655us/sample - loss: 0.2404 - accuracy: 0.8973 - val_loss: 0.2232 - val_accuracy: 0.9189\n",
      "Epoch 17/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2698 - accuracy: 0.8778\n",
      "Epoch 00017: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.2642 - accuracy: 0.8836 - val_loss: 0.2239 - val_accuracy: 0.9189\n",
      "Epoch 18/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2362 - accuracy: 0.8800\n",
      "Epoch 00018: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 0.2549 - accuracy: 0.8699 - val_loss: 0.1954 - val_accuracy: 0.9189\n",
      "Epoch 19/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2386 - accuracy: 0.8900\n",
      "Epoch 00019: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.2113 - accuracy: 0.9110 - val_loss: 0.1765 - val_accuracy: 0.9189\n",
      "Epoch 20/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2760 - accuracy: 0.8778\n",
      "Epoch 00020: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 0.2298 - accuracy: 0.9041 - val_loss: 0.2252 - val_accuracy: 0.8919\n",
      "Epoch 21/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2144 - accuracy: 0.9333\n",
      "Epoch 00021: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 744us/sample - loss: 0.2071 - accuracy: 0.9315 - val_loss: 0.1585 - val_accuracy: 0.9189\n",
      "Epoch 22/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2493 - accuracy: 0.8700\n",
      "Epoch 00022: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 660us/sample - loss: 0.2579 - accuracy: 0.8630 - val_loss: 0.2207 - val_accuracy: 0.9189\n",
      "Epoch 23/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1544 - accuracy: 0.9300\n",
      "Epoch 00023: val_accuracy did not improve from 0.91892\n",
      "146/146 [==============================] - 0s 650us/sample - loss: 0.1420 - accuracy: 0.9384 - val_loss: 0.1770 - val_accuracy: 0.9189\n",
      "Epoch 24/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.2402 - accuracy: 0.8889\n",
      "Epoch 00024: val_accuracy improved from 0.91892 to 0.94595, saving model to models/CNN2_dataset_1_trim5_24.h5\n",
      "146/146 [==============================] - 0s 854us/sample - loss: 0.2512 - accuracy: 0.8836 - val_loss: 0.1644 - val_accuracy: 0.9459\n",
      "Epoch 25/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2093 - accuracy: 0.9000\n",
      "Epoch 00025: val_accuracy did not improve from 0.94595\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.2117 - accuracy: 0.9041 - val_loss: 0.1858 - val_accuracy: 0.9189\n",
      "Epoch 26/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.2795 - accuracy: 0.9000\n",
      "Epoch 00026: val_accuracy did not improve from 0.94595\n",
      "146/146 [==============================] - 0s 836us/sample - loss: 0.2317 - accuracy: 0.9178 - val_loss: 0.1569 - val_accuracy: 0.9189\n",
      "Epoch 27/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1501 - accuracy: 0.9444\n",
      "Epoch 00027: val_accuracy did not improve from 0.94595\n",
      "146/146 [==============================] - 0s 782us/sample - loss: 0.1540 - accuracy: 0.9384 - val_loss: 0.1469 - val_accuracy: 0.9189\n",
      "Epoch 28/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1692 - accuracy: 0.9000\n",
      "Epoch 00028: val_accuracy did not improve from 0.94595\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.1871 - accuracy: 0.8973 - val_loss: 0.1881 - val_accuracy: 0.9189\n",
      "Epoch 29/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2313 - accuracy: 0.8900\n",
      "Epoch 00029: val_accuracy did not improve from 0.94595\n",
      "146/146 [==============================] - 0s 692us/sample - loss: 0.2277 - accuracy: 0.8973 - val_loss: 0.3299 - val_accuracy: 0.8108\n",
      "Epoch 30/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1662 - accuracy: 0.9300\n",
      "Epoch 00030: val_accuracy did not improve from 0.94595\n",
      "146/146 [==============================] - 0s 697us/sample - loss: 0.1637 - accuracy: 0.9315 - val_loss: 0.1437 - val_accuracy: 0.9459\n",
      "Epoch 31/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1062 - accuracy: 0.9700\n",
      "Epoch 00031: val_accuracy improved from 0.94595 to 0.97297, saving model to models/CNN2_dataset_1_trim5_31.h5\n",
      "146/146 [==============================] - 0s 855us/sample - loss: 0.1600 - accuracy: 0.9384 - val_loss: 0.1285 - val_accuracy: 0.9730\n",
      "Epoch 32/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1679 - accuracy: 0.9100\n",
      "Epoch 00032: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 753us/sample - loss: 0.1698 - accuracy: 0.9178 - val_loss: 0.1648 - val_accuracy: 0.9189\n",
      "Epoch 33/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1714 - accuracy: 0.9444\n",
      "Epoch 00033: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 828us/sample - loss: 0.1399 - accuracy: 0.9589 - val_loss: 0.1447 - val_accuracy: 0.9189\n",
      "Epoch 34/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1996 - accuracy: 0.9333\n",
      "Epoch 00034: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 780us/sample - loss: 0.1845 - accuracy: 0.9384 - val_loss: 0.1410 - val_accuracy: 0.9189\n",
      "Epoch 35/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1183 - accuracy: 0.9556\n",
      "Epoch 00035: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 766us/sample - loss: 0.1135 - accuracy: 0.9658 - val_loss: 0.1473 - val_accuracy: 0.9189\n",
      "Epoch 36/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1749 - accuracy: 0.9300\n",
      "Epoch 00036: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 753us/sample - loss: 0.1438 - accuracy: 0.9384 - val_loss: 0.1817 - val_accuracy: 0.9189\n",
      "Epoch 37/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1149 - accuracy: 0.9556\n",
      "Epoch 00037: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 751us/sample - loss: 0.2089 - accuracy: 0.9041 - val_loss: 0.1297 - val_accuracy: 0.9730\n",
      "Epoch 38/500\n",
      "140/146 [===========================>..] - ETA: 0s - loss: 0.1466 - accuracy: 0.9500\n",
      "Epoch 00038: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 915us/sample - loss: 0.1465 - accuracy: 0.9521 - val_loss: 0.1148 - val_accuracy: 0.9459\n",
      "Epoch 39/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1504 - accuracy: 0.9300\n",
      "Epoch 00039: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.1186 - accuracy: 0.9521 - val_loss: 0.1041 - val_accuracy: 0.9730\n",
      "Epoch 40/500\n",
      " 80/146 [===============>..............] - ETA: 0s - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 877us/sample - loss: 0.0758 - accuracy: 0.9726 - val_loss: 0.1088 - val_accuracy: 0.9459\n",
      "Epoch 41/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1058 - accuracy: 0.9778\n",
      "Epoch 00041: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 837us/sample - loss: 0.0853 - accuracy: 0.9795 - val_loss: 0.0982 - val_accuracy: 0.9730\n",
      "Epoch 42/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0653 - accuracy: 0.9778\n",
      "Epoch 00042: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 835us/sample - loss: 0.0642 - accuracy: 0.9726 - val_loss: 0.1132 - val_accuracy: 0.9459\n",
      "Epoch 43/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0752 - accuracy: 0.9600\n",
      "Epoch 00043: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 0.0755 - accuracy: 0.9589 - val_loss: 0.0951 - val_accuracy: 0.9730\n",
      "Epoch 44/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1453 - accuracy: 0.9333\n",
      "Epoch 00044: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 712us/sample - loss: 0.1220 - accuracy: 0.9384 - val_loss: 0.0895 - val_accuracy: 0.9730\n",
      "Epoch 45/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0881 - accuracy: 0.9700\n",
      "Epoch 00045: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.0957 - accuracy: 0.9589 - val_loss: 0.0923 - val_accuracy: 0.9730\n",
      "Epoch 46/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1690 - accuracy: 0.9111\n",
      "Epoch 00046: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.2233 - accuracy: 0.8973 - val_loss: 0.1699 - val_accuracy: 0.8919\n",
      "Epoch 47/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.6007 - accuracy: 0.7667\n",
      "Epoch 00047: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 794us/sample - loss: 0.5146 - accuracy: 0.7877 - val_loss: 0.1321 - val_accuracy: 0.9459\n",
      "Epoch 48/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2084 - accuracy: 0.9100\n",
      "Epoch 00048: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 754us/sample - loss: 0.1941 - accuracy: 0.9110 - val_loss: 0.1376 - val_accuracy: 0.9189\n",
      "Epoch 49/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1080 - accuracy: 0.9500\n",
      "Epoch 00049: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.0881 - accuracy: 0.9658 - val_loss: 0.1193 - val_accuracy: 0.9459\n",
      "Epoch 50/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1307 - accuracy: 0.9556\n",
      "Epoch 00050: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 740us/sample - loss: 0.1226 - accuracy: 0.9452 - val_loss: 0.1818 - val_accuracy: 0.9189\n",
      "Epoch 51/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1663 - accuracy: 0.9300\n",
      "Epoch 00051: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 698us/sample - loss: 0.1303 - accuracy: 0.9452 - val_loss: 0.2275 - val_accuracy: 0.9189\n",
      "Epoch 52/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1292 - accuracy: 0.9300\n",
      "Epoch 00052: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 768us/sample - loss: 0.1406 - accuracy: 0.9315 - val_loss: 0.2048 - val_accuracy: 0.9189\n",
      "Epoch 53/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1512 - accuracy: 0.9300\n",
      "Epoch 00053: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.1691 - accuracy: 0.9247 - val_loss: 0.0973 - val_accuracy: 0.9730\n",
      "Epoch 54/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1468 - accuracy: 0.9700\n",
      "Epoch 00054: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 755us/sample - loss: 0.1121 - accuracy: 0.9795 - val_loss: 0.0917 - val_accuracy: 0.9730\n",
      "Epoch 55/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9889\n",
      "Epoch 00055: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 785us/sample - loss: 0.0894 - accuracy: 0.9795 - val_loss: 0.1165 - val_accuracy: 0.9189\n",
      "Epoch 56/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0725 - accuracy: 0.9667\n",
      "Epoch 00056: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 775us/sample - loss: 0.0658 - accuracy: 0.9726 - val_loss: 0.1254 - val_accuracy: 0.9189\n",
      "Epoch 57/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0375 - accuracy: 1.0000\n",
      "Epoch 00057: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.0577 - accuracy: 0.9863 - val_loss: 0.1605 - val_accuracy: 0.9189\n",
      "Epoch 58/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0493 - accuracy: 0.9667\n",
      "Epoch 00058: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 0.0671 - accuracy: 0.9658 - val_loss: 0.1496 - val_accuracy: 0.9189\n",
      "Epoch 59/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0400 - accuracy: 0.9800\n",
      "Epoch 00059: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.0674 - accuracy: 0.9726 - val_loss: 0.1023 - val_accuracy: 0.9459\n",
      "Epoch 60/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0526 - accuracy: 0.9900\n",
      "Epoch 00060: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0663 - accuracy: 0.9795 - val_loss: 0.1555 - val_accuracy: 0.9189\n",
      "Epoch 61/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0937 - accuracy: 0.9444\n",
      "Epoch 00061: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 718us/sample - loss: 0.1081 - accuracy: 0.9384 - val_loss: 0.1305 - val_accuracy: 0.9189\n",
      "Epoch 62/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0691 - accuracy: 0.9889\n",
      "Epoch 00062: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 718us/sample - loss: 0.0690 - accuracy: 0.9795 - val_loss: 0.1253 - val_accuracy: 0.9459\n",
      "Epoch 63/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1229 - accuracy: 0.9667\n",
      "Epoch 00063: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 759us/sample - loss: 0.1347 - accuracy: 0.9589 - val_loss: 0.1779 - val_accuracy: 0.9189\n",
      "Epoch 64/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1153 - accuracy: 0.9556\n",
      "Epoch 00064: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 771us/sample - loss: 0.1090 - accuracy: 0.9521 - val_loss: 0.1456 - val_accuracy: 0.9189\n",
      "Epoch 65/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1142 - accuracy: 0.9556    \n",
      "Epoch 00065: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 786us/sample - loss: 0.1507 - accuracy: 0.9384 - val_loss: 0.1852 - val_accuracy: 0.9189\n",
      "Epoch 66/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1224 - accuracy: 0.9444\n",
      "Epoch 00066: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 755us/sample - loss: 0.1502 - accuracy: 0.9384 - val_loss: 0.0947 - val_accuracy: 0.9459\n",
      "Epoch 67/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0824 - accuracy: 0.9700\n",
      "Epoch 00067: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.0694 - accuracy: 0.9795 - val_loss: 0.1046 - val_accuracy: 0.9459\n",
      "Epoch 68/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0915 - accuracy: 0.9556\n",
      "Epoch 00068: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 809us/sample - loss: 0.0815 - accuracy: 0.9589 - val_loss: 0.1325 - val_accuracy: 0.9189\n",
      "Epoch 69/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1026 - accuracy: 0.9556\n",
      "Epoch 00069: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 808us/sample - loss: 0.0874 - accuracy: 0.9658 - val_loss: 0.1191 - val_accuracy: 0.9459\n",
      "Epoch 70/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0671 - accuracy: 0.9889\n",
      "Epoch 00070: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.0833 - accuracy: 0.9795 - val_loss: 0.0904 - val_accuracy: 0.9459\n",
      "Epoch 71/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0789 - accuracy: 0.9667\n",
      "Epoch 00071: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 793us/sample - loss: 0.0741 - accuracy: 0.9658 - val_loss: 0.1354 - val_accuracy: 0.9189\n",
      "Epoch 72/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0649 - accuracy: 0.9778\n",
      "Epoch 00072: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 808us/sample - loss: 0.0755 - accuracy: 0.9726 - val_loss: 0.1942 - val_accuracy: 0.9189\n",
      "Epoch 73/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1216 - accuracy: 0.9556\n",
      "Epoch 00073: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 785us/sample - loss: 0.0976 - accuracy: 0.9658 - val_loss: 0.1202 - val_accuracy: 0.9189\n",
      "Epoch 74/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 00074: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 672us/sample - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.1290 - val_accuracy: 0.9189\n",
      "Epoch 75/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0721 - accuracy: 0.9667\n",
      "Epoch 00075: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 715us/sample - loss: 0.0658 - accuracy: 0.9658 - val_loss: 0.1291 - val_accuracy: 0.9189\n",
      "Epoch 76/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0836 - accuracy: 0.9700\n",
      "Epoch 00076: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.0646 - accuracy: 0.9795 - val_loss: 0.1925 - val_accuracy: 0.9189\n",
      "Epoch 77/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1418 - accuracy: 0.9300\n",
      "Epoch 00077: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.1208 - accuracy: 0.9452 - val_loss: 0.2056 - val_accuracy: 0.9189\n",
      "Epoch 78/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1042 - accuracy: 0.9600\n",
      "Epoch 00078: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 742us/sample - loss: 0.0837 - accuracy: 0.9726 - val_loss: 0.1622 - val_accuracy: 0.9189\n",
      "Epoch 79/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1140 - accuracy: 0.9556\n",
      "Epoch 00079: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 786us/sample - loss: 0.0883 - accuracy: 0.9589 - val_loss: 0.1510 - val_accuracy: 0.9189\n",
      "Epoch 80/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1269 - accuracy: 0.9667\n",
      "Epoch 00080: val_accuracy did not improve from 0.97297\n",
      "146/146 [==============================] - 0s 786us/sample - loss: 0.0834 - accuracy: 0.9795 - val_loss: 0.0745 - val_accuracy: 0.9730\n",
      "Epoch 81/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0279 - accuracy: 1.0000    \n",
      "Epoch 00081: val_accuracy improved from 0.97297 to 1.00000, saving model to models/CNN2_dataset_1_trim5_81.h5\n",
      "146/146 [==============================] - 0s 920us/sample - loss: 0.0690 - accuracy: 0.9726 - val_loss: 0.0553 - val_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1087 - accuracy: 0.9500\n",
      "Epoch 00082: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 0.1075 - accuracy: 0.9452 - val_loss: 0.1098 - val_accuracy: 0.9189\n",
      "Epoch 83/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1137 - accuracy: 0.9556\n",
      "Epoch 00083: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.1209 - accuracy: 0.9589 - val_loss: 0.1429 - val_accuracy: 0.9189\n",
      "Epoch 84/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 00084: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 0.0413 - accuracy: 0.9932 - val_loss: 0.1232 - val_accuracy: 0.9189\n",
      "Epoch 85/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0700 - accuracy: 0.9667\n",
      "Epoch 00085: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 768us/sample - loss: 0.0820 - accuracy: 0.9589 - val_loss: 0.0645 - val_accuracy: 0.9730\n",
      "Epoch 86/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1002 - accuracy: 0.9700\n",
      "Epoch 00086: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 758us/sample - loss: 0.0962 - accuracy: 0.9658 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
      "Epoch 87/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0937 - accuracy: 0.9778\n",
      "Epoch 00087: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 793us/sample - loss: 0.0799 - accuracy: 0.9726 - val_loss: 0.1323 - val_accuracy: 0.9459\n",
      "Epoch 88/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1204 - accuracy: 0.9700\n",
      "Epoch 00088: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.0869 - accuracy: 0.9795 - val_loss: 0.1644 - val_accuracy: 0.9189\n",
      "Epoch 89/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0759 - accuracy: 0.9667\n",
      "Epoch 00089: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 779us/sample - loss: 0.0649 - accuracy: 0.9726 - val_loss: 0.1565 - val_accuracy: 0.9189\n",
      "Epoch 90/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0753 - accuracy: 0.9667\n",
      "Epoch 00090: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.0568 - accuracy: 0.9795 - val_loss: 0.0772 - val_accuracy: 0.9730\n",
      "Epoch 91/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0543 - accuracy: 0.9900\n",
      "Epoch 00091: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.0682 - accuracy: 0.9795 - val_loss: 0.0753 - val_accuracy: 0.9730\n",
      "Epoch 92/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0300 - accuracy: 0.9900\n",
      "Epoch 00092: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 712us/sample - loss: 0.0408 - accuracy: 0.9863 - val_loss: 0.0805 - val_accuracy: 0.9459\n",
      "Epoch 93/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0446 - accuracy: 0.9700\n",
      "Epoch 00093: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.0383 - accuracy: 0.9795 - val_loss: 0.0882 - val_accuracy: 0.9459\n",
      "Epoch 94/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0502 - accuracy: 0.9800\n",
      "Epoch 00094: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 787us/sample - loss: 0.0506 - accuracy: 0.9795 - val_loss: 0.1446 - val_accuracy: 0.9189\n",
      "Epoch 95/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0527 - accuracy: 0.9778\n",
      "Epoch 00095: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 818us/sample - loss: 0.0566 - accuracy: 0.9795 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0717 - accuracy: 0.9778\n",
      "Epoch 00096: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 0.0942 - accuracy: 0.9795 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0832 - accuracy: 0.9667\n",
      "Epoch 00097: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.0570 - accuracy: 0.9795 - val_loss: 0.1274 - val_accuracy: 0.9189\n",
      "Epoch 98/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0508 - accuracy: 0.9778\n",
      "Epoch 00098: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 776us/sample - loss: 0.0578 - accuracy: 0.9795 - val_loss: 0.0691 - val_accuracy: 0.9730\n",
      "Epoch 99/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0451 - accuracy: 0.9900\n",
      "Epoch 00099: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.0713 - accuracy: 0.9795 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0772 - accuracy: 0.9667\n",
      "Epoch 00100: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.1234 - accuracy: 0.9521 - val_loss: 0.0856 - val_accuracy: 0.9459\n",
      "Epoch 101/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0479 - accuracy: 0.9778\n",
      "Epoch 00101: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 809us/sample - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.1264 - val_accuracy: 0.9189\n",
      "Epoch 102/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0817 - accuracy: 0.9778\n",
      "Epoch 00102: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 760us/sample - loss: 0.1448 - accuracy: 0.9452 - val_loss: 0.2768 - val_accuracy: 0.9189\n",
      "Epoch 103/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1553 - accuracy: 0.9200\n",
      "Epoch 00103: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 742us/sample - loss: 0.1195 - accuracy: 0.9384 - val_loss: 0.1404 - val_accuracy: 0.9459\n",
      "Epoch 104/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0670 - accuracy: 0.9800\n",
      "Epoch 00104: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.0600 - accuracy: 0.9863 - val_loss: 0.0829 - val_accuracy: 0.9730\n",
      "Epoch 105/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0581 - accuracy: 0.9800\n",
      "Epoch 00105: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 763us/sample - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.0896 - val_accuracy: 0.9459\n",
      "Epoch 106/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0547 - accuracy: 0.9900\n",
      "Epoch 00106: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 774us/sample - loss: 0.0448 - accuracy: 0.9932 - val_loss: 0.1498 - val_accuracy: 0.9189\n",
      "Epoch 107/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0316 - accuracy: 0.9900\n",
      "Epoch 00107: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 710us/sample - loss: 0.0445 - accuracy: 0.9863 - val_loss: 0.0721 - val_accuracy: 0.9730\n",
      "Epoch 108/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0358 - accuracy: 0.9889\n",
      "Epoch 00108: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 768us/sample - loss: 0.0333 - accuracy: 0.9932 - val_loss: 0.1458 - val_accuracy: 0.9189\n",
      "Epoch 109/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 00109: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 756us/sample - loss: 0.0359 - accuracy: 0.9932 - val_loss: 0.0581 - val_accuracy: 0.9730\n",
      "Epoch 110/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0322 - accuracy: 0.9900\n",
      "Epoch 00110: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.0514 - accuracy: 0.9863 - val_loss: 0.0800 - val_accuracy: 0.9459\n",
      "Epoch 111/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0956 - accuracy: 0.9600\n",
      "Epoch 00111: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 801us/sample - loss: 0.0729 - accuracy: 0.9726 - val_loss: 0.0854 - val_accuracy: 0.9730\n",
      "Epoch 112/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 00112: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.0423 - accuracy: 0.9932 - val_loss: 0.1302 - val_accuracy: 0.9459\n",
      "Epoch 113/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 00113: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 688us/sample - loss: 0.0313 - accuracy: 0.9932 - val_loss: 0.1063 - val_accuracy: 0.9459\n",
      "Epoch 114/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 00114: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0350 - accuracy: 0.9932 - val_loss: 0.0902 - val_accuracy: 0.9459\n",
      "Epoch 115/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0449 - accuracy: 0.9800\n",
      "Epoch 00115: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 742us/sample - loss: 0.0610 - accuracy: 0.9658 - val_loss: 0.1750 - val_accuracy: 0.9189\n",
      "Epoch 116/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 00116: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 0.0531 - accuracy: 0.9863 - val_loss: 0.2461 - val_accuracy: 0.9189\n",
      "Epoch 117/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1172 - accuracy: 0.9800\n",
      "Epoch 00117: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 0.0906 - accuracy: 0.9863 - val_loss: 0.0654 - val_accuracy: 0.9730\n",
      "Epoch 118/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0397 - accuracy: 0.9900\n",
      "Epoch 00118: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.0358 - accuracy: 0.9932 - val_loss: 0.0787 - val_accuracy: 0.9459\n",
      "Epoch 119/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0268 - accuracy: 0.9778    \n",
      "Epoch 00119: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 768us/sample - loss: 0.0268 - accuracy: 0.9863 - val_loss: 0.0766 - val_accuracy: 0.9459\n",
      "Epoch 120/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0199 - accuracy: 0.9900\n",
      "Epoch 00120: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.0418 - accuracy: 0.9863 - val_loss: 0.0626 - val_accuracy: 0.9730\n",
      "Epoch 121/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0337 - accuracy: 0.9800\n",
      "Epoch 00121: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.0266 - accuracy: 0.9863 - val_loss: 0.1170 - val_accuracy: 0.9189\n",
      "Epoch 122/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 00122: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 757us/sample - loss: 0.0244 - accuracy: 0.9932 - val_loss: 0.0575 - val_accuracy: 0.9730\n",
      "Epoch 123/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0265 - accuracy: 0.9900\n",
      "Epoch 00123: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 767us/sample - loss: 0.0285 - accuracy: 0.9863 - val_loss: 0.1456 - val_accuracy: 0.9189\n",
      "Epoch 124/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0230 - accuracy: 0.9900\n",
      "Epoch 00124: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 777us/sample - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.0670 - val_accuracy: 0.9730\n",
      "Epoch 125/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 00125: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.0620 - accuracy: 0.9932 - val_loss: 0.0536 - val_accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0328 - accuracy: 0.9900\n",
      "Epoch 00126: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 764us/sample - loss: 0.0450 - accuracy: 0.9863 - val_loss: 0.0849 - val_accuracy: 0.9459\n",
      "Epoch 127/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 00127: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 763us/sample - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.2079 - val_accuracy: 0.9189\n",
      "Epoch 128/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0973 - accuracy: 0.9556    \n",
      "Epoch 00128: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 790us/sample - loss: 0.1298 - accuracy: 0.9521 - val_loss: 0.1298 - val_accuracy: 0.9459\n",
      "Epoch 129/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1740 - accuracy: 0.9400\n",
      "Epoch 00129: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.1716 - accuracy: 0.9452 - val_loss: 0.1126 - val_accuracy: 0.9459\n",
      "Epoch 130/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0706 - accuracy: 0.9700\n",
      "Epoch 00130: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 731us/sample - loss: 0.0589 - accuracy: 0.9795 - val_loss: 0.0617 - val_accuracy: 0.9730\n",
      "Epoch 131/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1150 - accuracy: 0.9700\n",
      "Epoch 00131: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.1039 - accuracy: 0.9658 - val_loss: 0.1075 - val_accuracy: 0.9459\n",
      "Epoch 132/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1376 - accuracy: 0.9500\n",
      "Epoch 00132: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 755us/sample - loss: 0.1211 - accuracy: 0.9589 - val_loss: 0.2286 - val_accuracy: 0.9189\n",
      "Epoch 133/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1231 - accuracy: 0.9400\n",
      "Epoch 00133: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.1009 - accuracy: 0.9521 - val_loss: 0.1961 - val_accuracy: 0.9189\n",
      "Epoch 134/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1173 - accuracy: 0.9600\n",
      "Epoch 00134: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 776us/sample - loss: 0.1246 - accuracy: 0.9589 - val_loss: 0.0917 - val_accuracy: 0.9730\n",
      "Epoch 135/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0653 - accuracy: 0.9800\n",
      "Epoch 00135: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 757us/sample - loss: 0.0718 - accuracy: 0.9726 - val_loss: 0.0645 - val_accuracy: 0.9730\n",
      "Epoch 136/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0445 - accuracy: 0.9800\n",
      "Epoch 00136: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 755us/sample - loss: 0.0398 - accuracy: 0.9863 - val_loss: 0.1532 - val_accuracy: 0.9459\n",
      "Epoch 137/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1245 - accuracy: 0.9800\n",
      "Epoch 00137: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 759us/sample - loss: 0.0941 - accuracy: 0.9795 - val_loss: 0.1846 - val_accuracy: 0.9189\n",
      "Epoch 138/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0823 - accuracy: 0.9778\n",
      "Epoch 00138: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 803us/sample - loss: 0.0630 - accuracy: 0.9795 - val_loss: 0.0767 - val_accuracy: 0.9730\n",
      "Epoch 139/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0425 - accuracy: 0.9900\n",
      "Epoch 00139: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 768us/sample - loss: 0.0356 - accuracy: 0.9932 - val_loss: 0.2048 - val_accuracy: 0.9189\n",
      "Epoch 140/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0327 - accuracy: 0.9900\n",
      "Epoch 00140: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 764us/sample - loss: 0.0412 - accuracy: 0.9795 - val_loss: 0.0600 - val_accuracy: 0.9730\n",
      "Epoch 141/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0307 - accuracy: 0.9800\n",
      "Epoch 00141: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 740us/sample - loss: 0.0573 - accuracy: 0.9795 - val_loss: 0.1411 - val_accuracy: 0.9459\n",
      "Epoch 142/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0823 - accuracy: 0.9600    \n",
      "Epoch 00142: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 723us/sample - loss: 0.0748 - accuracy: 0.9589 - val_loss: 0.2600 - val_accuracy: 0.8919\n",
      "Epoch 143/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0387 - accuracy: 0.9900\n",
      "Epoch 00143: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 0.0317 - accuracy: 0.9932 - val_loss: 0.0534 - val_accuracy: 0.9730\n",
      "Epoch 144/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0333 - accuracy: 0.9900\n",
      "Epoch 00144: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 745us/sample - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.1239 - val_accuracy: 0.9459\n",
      "Epoch 145/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0152 - accuracy: 1.0000\n",
      "Epoch 00145: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 801us/sample - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9730\n",
      "Epoch 146/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0359 - accuracy: 0.9900\n",
      "Epoch 00146: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 733us/sample - loss: 0.0336 - accuracy: 0.9932 - val_loss: 0.1875 - val_accuracy: 0.9189\n",
      "Epoch 147/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0238 - accuracy: 0.9900\n",
      "Epoch 00147: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 0.0400 - accuracy: 0.9863 - val_loss: 0.1026 - val_accuracy: 0.9459\n",
      "Epoch 148/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0437 - accuracy: 0.9889    \n",
      "Epoch 00148: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 780us/sample - loss: 0.0381 - accuracy: 0.9863 - val_loss: 0.1360 - val_accuracy: 0.9189\n",
      "Epoch 149/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0210 - accuracy: 0.9900\n",
      "Epoch 00149: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 745us/sample - loss: 0.0158 - accuracy: 0.9932 - val_loss: 0.1055 - val_accuracy: 0.9459\n",
      "Epoch 150/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0275 - accuracy: 0.9889\n",
      "Epoch 00150: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 785us/sample - loss: 0.0333 - accuracy: 0.9863 - val_loss: 0.1606 - val_accuracy: 0.9189\n",
      "Epoch 151/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0415 - accuracy: 0.9818\n",
      "Epoch 00151: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 714us/sample - loss: 0.0326 - accuracy: 0.9863 - val_loss: 0.0709 - val_accuracy: 0.9459\n",
      "Epoch 152/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0294 - accuracy: 0.9889\n",
      "Epoch 00152: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 812us/sample - loss: 0.0252 - accuracy: 0.9932 - val_loss: 0.1392 - val_accuracy: 0.9189\n",
      "Epoch 153/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0453 - accuracy: 0.9900\n",
      "Epoch 00153: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 727us/sample - loss: 0.0341 - accuracy: 0.9932 - val_loss: 0.1751 - val_accuracy: 0.9189\n",
      "Epoch 154/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0328 - accuracy: 0.9900\n",
      "Epoch 00154: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 0.0409 - accuracy: 0.9863 - val_loss: 0.0711 - val_accuracy: 0.9459\n",
      "Epoch 155/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0381 - accuracy: 0.9800\n",
      "Epoch 00155: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.0269 - accuracy: 0.9863 - val_loss: 0.1426 - val_accuracy: 0.9459\n",
      "Epoch 156/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0291 - accuracy: 0.9900\n",
      "Epoch 00156: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 728us/sample - loss: 0.0250 - accuracy: 0.9932 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 00157: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 744us/sample - loss: 0.0383 - accuracy: 0.9932 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0221 - accuracy: 1.0000\n",
      "Epoch 00158: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 755us/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9189\n",
      "Epoch 159/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0207 - accuracy: 0.9900\n",
      "Epoch 00159: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.0172 - accuracy: 0.9932 - val_loss: 0.1010 - val_accuracy: 0.9459\n",
      "Epoch 160/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 00160: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9730\n",
      "Epoch 161/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 00161: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9459\n",
      "Epoch 162/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 00162: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.0794 - val_accuracy: 0.9459\n",
      "Epoch 163/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0256 - accuracy: 0.9889    \n",
      "Epoch 00163: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 743us/sample - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.1537 - val_accuracy: 0.9459\n",
      "Epoch 164/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0481 - accuracy: 0.9900\n",
      "Epoch 00164: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 804us/sample - loss: 0.0492 - accuracy: 0.9863 - val_loss: 0.1221 - val_accuracy: 0.9459\n",
      "Epoch 165/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0676 - accuracy: 0.9700\n",
      "Epoch 00165: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 718us/sample - loss: 0.0565 - accuracy: 0.9795 - val_loss: 0.2424 - val_accuracy: 0.9189\n",
      "Epoch 166/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0383 - accuracy: 0.9900\n",
      "Epoch 00166: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 745us/sample - loss: 0.0371 - accuracy: 0.9932 - val_loss: 0.0917 - val_accuracy: 0.9459\n",
      "Epoch 167/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 00167: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 764us/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9730\n",
      "Epoch 168/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0316 - accuracy: 0.9900\n",
      "Epoch 00168: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.1187 - val_accuracy: 0.9459\n",
      "Epoch 169/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 00169: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 755us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9459\n",
      "Epoch 170/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 00170: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      " 70/146 [=============>................] - ETA: 0s - loss: 0.0282 - accuracy: 0.9857    \n",
      "Epoch 00171: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 937us/sample - loss: 0.0210 - accuracy: 0.9863 - val_loss: 0.0822 - val_accuracy: 0.9459\n",
      "Epoch 172/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 00172: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.0225 - accuracy: 0.9932 - val_loss: 0.0459 - val_accuracy: 0.9730\n",
      "Epoch 173/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0279 - accuracy: 0.9889\n",
      "Epoch 00173: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 789us/sample - loss: 0.0402 - accuracy: 0.9795 - val_loss: 0.0775 - val_accuracy: 0.9730\n",
      "Epoch 174/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0237 - accuracy: 0.9889\n",
      "Epoch 00174: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 731us/sample - loss: 0.0216 - accuracy: 0.9863 - val_loss: 0.0888 - val_accuracy: 0.9730\n",
      "Epoch 175/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 00175: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9730\n",
      "Epoch 176/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 00176: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 713us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9730\n",
      "Epoch 177/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000    \n",
      "Epoch 00177: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 740us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9730\n",
      "Epoch 178/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0340 - accuracy: 0.9889    \n",
      "Epoch 00178: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.0349 - accuracy: 0.9863 - val_loss: 0.0489 - val_accuracy: 0.9730\n",
      "Epoch 179/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0693 - accuracy: 0.9800\n",
      "Epoch 00179: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 758us/sample - loss: 0.1504 - accuracy: 0.9658 - val_loss: 0.1010 - val_accuracy: 0.9459\n",
      "Epoch 180/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.1200 - accuracy: 0.9222\n",
      "Epoch 00180: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 774us/sample - loss: 0.0925 - accuracy: 0.9452 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1259 - accuracy: 0.9400\n",
      "Epoch 00181: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.1061 - accuracy: 0.9521 - val_loss: 0.0914 - val_accuracy: 0.9459\n",
      "Epoch 182/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0689 - accuracy: 0.9700\n",
      "Epoch 00182: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 713us/sample - loss: 0.1197 - accuracy: 0.9452 - val_loss: 0.0713 - val_accuracy: 0.9459\n",
      "Epoch 183/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0792 - accuracy: 0.9700\n",
      "Epoch 00183: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 786us/sample - loss: 0.1001 - accuracy: 0.9589 - val_loss: 0.1279 - val_accuracy: 0.9730\n",
      "Epoch 184/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0570 - accuracy: 0.9600\n",
      "Epoch 00184: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.0427 - accuracy: 0.9726 - val_loss: 0.2642 - val_accuracy: 0.9189\n",
      "Epoch 185/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1090 - accuracy: 0.9800\n",
      "Epoch 00185: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 719us/sample - loss: 0.0837 - accuracy: 0.9863 - val_loss: 0.0673 - val_accuracy: 0.9730\n",
      "Epoch 186/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 00186: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.0155 - accuracy: 0.9932 - val_loss: 0.2306 - val_accuracy: 0.9459\n",
      "Epoch 187/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0608 - accuracy: 0.9800\n",
      "Epoch 00187: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 750us/sample - loss: 0.0426 - accuracy: 0.9863 - val_loss: 0.0881 - val_accuracy: 0.9730\n",
      "Epoch 188/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 00188: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 771us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9730\n",
      "Epoch 189/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 00189: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 728us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9730\n",
      "Epoch 190/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 00190: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.0149 - accuracy: 0.9932 - val_loss: 0.0490 - val_accuracy: 0.9730\n",
      "Epoch 191/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 00191: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.0143 - accuracy: 0.9932 - val_loss: 0.1211 - val_accuracy: 0.9730\n",
      "Epoch 192/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0390 - accuracy: 0.9909\n",
      "Epoch 00192: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 675us/sample - loss: 0.0307 - accuracy: 0.9932 - val_loss: 0.0675 - val_accuracy: 0.9730\n",
      "Epoch 193/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 00193: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9730\n",
      "Epoch 194/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0235 - accuracy: 0.9900\n",
      "Epoch 00194: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.0309 - accuracy: 0.9795 - val_loss: 0.1320 - val_accuracy: 0.9730\n",
      "Epoch 195/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0196 - accuracy: 0.9900\n",
      "Epoch 00195: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 718us/sample - loss: 0.0149 - accuracy: 0.9932 - val_loss: 0.0908 - val_accuracy: 0.9730\n",
      "Epoch 196/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 00196: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9730\n",
      "Epoch 197/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 00197: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 774us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.1497 - val_accuracy: 0.9730\n",
      "Epoch 198/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00198: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9730\n",
      "Epoch 199/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 00199: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 759us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9730\n",
      "Epoch 200/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000    \n",
      "Epoch 00200: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9730\n",
      "Epoch 201/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0109 - accuracy: 0.9889    \n",
      "Epoch 00201: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 727us/sample - loss: 0.0081 - accuracy: 0.9932 - val_loss: 0.0435 - val_accuracy: 0.9730\n",
      "Epoch 202/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 00202: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 785us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9730\n",
      "Epoch 203/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 00203: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 738us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0766 - accuracy: 0.9700\n",
      "Epoch 00204: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 753us/sample - loss: 0.0713 - accuracy: 0.9726 - val_loss: 0.2746 - val_accuracy: 0.9459\n",
      "Epoch 205/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0809 - accuracy: 0.9889    \n",
      "Epoch 00205: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 745us/sample - loss: 0.0596 - accuracy: 0.9863 - val_loss: 0.2398 - val_accuracy: 0.9730\n",
      "Epoch 206/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 00206: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 762us/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9730\n",
      "Epoch 207/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 00207: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.0453 - accuracy: 0.9863 - val_loss: 0.0572 - val_accuracy: 0.9730\n",
      "Epoch 208/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0351 - accuracy: 0.9900\n",
      "Epoch 00208: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 760us/sample - loss: 0.0265 - accuracy: 0.9932 - val_loss: 0.1082 - val_accuracy: 0.9730\n",
      "Epoch 209/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 00209: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 702us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9730\n",
      "Epoch 210/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 00210: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9730\n",
      "Epoch 211/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 00211: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9730\n",
      "Epoch 212/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00212: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9730\n",
      "Epoch 213/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 00213: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9730\n",
      "Epoch 214/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 00214: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 752us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 0.9730\n",
      "Epoch 215/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0209 - accuracy: 0.9900\n",
      "Epoch 00215: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 731us/sample - loss: 0.0166 - accuracy: 0.9932 - val_loss: 0.0976 - val_accuracy: 0.9730\n",
      "Epoch 216/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000    \n",
      "Epoch 00216: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9730\n",
      "Epoch 217/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 00217: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0150 - accuracy: 0.9932 - val_loss: 0.2383 - val_accuracy: 0.9459\n",
      "Epoch 218/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0178 - accuracy: 0.9900\n",
      "Epoch 00218: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 0.0133 - accuracy: 0.9932 - val_loss: 0.0721 - val_accuracy: 0.9730\n",
      "Epoch 219/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0262 - accuracy: 0.9900    \n",
      "Epoch 00219: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.0287 - accuracy: 0.9863 - val_loss: 0.2357 - val_accuracy: 0.9730\n",
      "Epoch 220/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0203 - accuracy: 0.9900\n",
      "Epoch 00220: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 750us/sample - loss: 0.0407 - accuracy: 0.9863 - val_loss: 0.1053 - val_accuracy: 0.9730\n",
      "Epoch 221/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0919 - accuracy: 0.9700    \n",
      "Epoch 00221: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.0803 - accuracy: 0.9726 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0728 - accuracy: 0.9778\n",
      "Epoch 00222: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 747us/sample - loss: 0.1616 - accuracy: 0.9521 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1876 - accuracy: 0.9200\n",
      "Epoch 00223: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 729us/sample - loss: 0.1590 - accuracy: 0.9247 - val_loss: 0.4332 - val_accuracy: 0.8649\n",
      "Epoch 224/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1680 - accuracy: 0.9400\n",
      "Epoch 00224: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 764us/sample - loss: 0.1168 - accuracy: 0.9589 - val_loss: 0.1325 - val_accuracy: 0.9730\n",
      "Epoch 225/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0201 - accuracy: 1.0000\n",
      "Epoch 00225: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.2024 - val_accuracy: 0.9459\n",
      "Epoch 226/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0254 - accuracy: 0.9900\n",
      "Epoch 00226: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 742us/sample - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.1876 - val_accuracy: 0.9730\n",
      "Epoch 227/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0306 - accuracy: 0.9900    \n",
      "Epoch 00227: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.0268 - accuracy: 0.9863 - val_loss: 0.0698 - val_accuracy: 0.9730\n",
      "Epoch 228/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0282 - accuracy: 0.9900    \n",
      "Epoch 00228: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.0430 - accuracy: 0.9863 - val_loss: 0.2782 - val_accuracy: 0.8919\n",
      "Epoch 229/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0361 - accuracy: 0.9900\n",
      "Epoch 00229: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.0273 - accuracy: 0.9932 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0413 - accuracy: 0.9889\n",
      "Epoch 00230: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 777us/sample - loss: 0.0329 - accuracy: 0.9863 - val_loss: 0.1094 - val_accuracy: 0.9730\n",
      "Epoch 231/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0119 - accuracy: 0.9889    \n",
      "Epoch 00231: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 727us/sample - loss: 0.0100 - accuracy: 0.9932 - val_loss: 0.1238 - val_accuracy: 0.9459\n",
      "Epoch 232/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 00232: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9730\n",
      "Epoch 233/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 00233: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 729us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9730\n",
      "Epoch 234/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 00234: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 766us/sample - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9730\n",
      "Epoch 235/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000    \n",
      "Epoch 00235: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9730\n",
      "Epoch 236/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 00236: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 739us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9730\n",
      "Epoch 237/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 00237: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.0096 - accuracy: 0.9932 - val_loss: 0.0898 - val_accuracy: 0.9730\n",
      "Epoch 238/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00238: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 770us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9730\n",
      "Epoch 239/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000    \n",
      "Epoch 00239: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9730\n",
      "Epoch 240/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000    \n",
      "Epoch 00240: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9730\n",
      "Epoch 241/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0157 - accuracy: 0.9900    \n",
      "Epoch 00241: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0121 - accuracy: 0.9932 - val_loss: 0.1755 - val_accuracy: 0.9730\n",
      "Epoch 242/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 00242: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9730\n",
      "Epoch 243/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 00243: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 782us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9730\n",
      "Epoch 244/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000    \n",
      "Epoch 00244: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.1839 - val_accuracy: 0.9730\n",
      "Epoch 245/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000    \n",
      "Epoch 00245: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9730\n",
      "Epoch 246/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000    \n",
      "Epoch 00246: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 706us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9730\n",
      "Epoch 247/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000    \n",
      "Epoch 00247: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9730\n",
      "Epoch 248/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 00248: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 729us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9730\n",
      "Epoch 249/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
      "Epoch 00249: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 761us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9730\n",
      "Epoch 250/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 00250: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1029 - val_accuracy: 0.9730\n",
      "Epoch 251/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000    \n",
      "Epoch 00251: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 721us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9730\n",
      "Epoch 252/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 00252: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9730\n",
      "Epoch 253/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 00253: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9730\n",
      "Epoch 254/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 00254: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.0080 - accuracy: 0.9932 - val_loss: 0.1193 - val_accuracy: 0.9730\n",
      "Epoch 255/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0413 - accuracy: 0.9900\n",
      "Epoch 00255: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 715us/sample - loss: 0.0294 - accuracy: 0.9932 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0394 - accuracy: 0.9800\n",
      "Epoch 00256: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0386 - accuracy: 0.9863 - val_loss: 0.2306 - val_accuracy: 0.9459\n",
      "Epoch 257/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0145 - accuracy: 0.9900\n",
      "Epoch 00257: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0357 - accuracy: 0.9863 - val_loss: 0.0258 - val_accuracy: 0.9730\n",
      "Epoch 258/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 00258: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1404 - val_accuracy: 0.9730\n",
      "Epoch 259/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000    \n",
      "Epoch 00259: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 731us/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9730\n",
      "Epoch 260/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 00260: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.0154 - accuracy: 0.9932 - val_loss: 0.1395 - val_accuracy: 0.9730\n",
      "Epoch 261/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 6.5326e-04 - accuracy: 1.0000\n",
      "Epoch 00261: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.0171 - accuracy: 0.9863 - val_loss: 0.0769 - val_accuracy: 0.9730\n",
      "Epoch 262/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000    \n",
      "Epoch 00262: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 705us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9730\n",
      "Epoch 263/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 00263: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9730\n",
      "Epoch 264/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0107 - accuracy: 1.0000    \n",
      "Epoch 00264: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0276 - accuracy: 0.9932 - val_loss: 0.1081 - val_accuracy: 0.9730\n",
      "Epoch 265/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 00265: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0133 - accuracy: 0.9932 - val_loss: 0.0608 - val_accuracy: 0.9730\n",
      "Epoch 266/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0164 - accuracy: 0.9909\n",
      "Epoch 00266: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 705us/sample - loss: 0.0272 - accuracy: 0.9863 - val_loss: 0.0313 - val_accuracy: 0.9730\n",
      "Epoch 267/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0492 - accuracy: 0.9800\n",
      "Epoch 00267: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 702us/sample - loss: 0.0352 - accuracy: 0.9863 - val_loss: 0.1472 - val_accuracy: 0.9730\n",
      "Epoch 268/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0179 - accuracy: 0.9900    \n",
      "Epoch 00268: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 687us/sample - loss: 0.0137 - accuracy: 0.9932 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0179 - accuracy: 0.9900\n",
      "Epoch 00269: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 0.0253 - accuracy: 0.9863 - val_loss: 0.1343 - val_accuracy: 0.9730\n",
      "Epoch 270/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0290 - accuracy: 0.9909    \n",
      "Epoch 00270: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 679us/sample - loss: 0.0247 - accuracy: 0.9932 - val_loss: 0.3036 - val_accuracy: 0.9189\n",
      "Epoch 271/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0384 - accuracy: 0.9700\n",
      "Epoch 00271: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0408 - accuracy: 0.9726 - val_loss: 0.0635 - val_accuracy: 0.9730\n",
      "Epoch 272/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0312 - accuracy: 0.9800\n",
      "Epoch 00272: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.0583 - accuracy: 0.9726 - val_loss: 0.0730 - val_accuracy: 0.9459\n",
      "Epoch 273/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0522 - accuracy: 0.9800\n",
      "Epoch 00273: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 757us/sample - loss: 0.0530 - accuracy: 0.9726 - val_loss: 0.1583 - val_accuracy: 0.9730\n",
      "Epoch 274/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0209 - accuracy: 0.9900\n",
      "Epoch 00274: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 768us/sample - loss: 0.0172 - accuracy: 0.9932 - val_loss: 0.1071 - val_accuracy: 0.9730\n",
      "Epoch 275/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0087 - accuracy: 1.0000    \n",
      "Epoch 00275: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 699us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9730\n",
      "Epoch 276/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 00276: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9730\n",
      "Epoch 277/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0187 - accuracy: 0.9900\n",
      "Epoch 00277: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.0148 - accuracy: 0.9932 - val_loss: 0.0699 - val_accuracy: 0.9730\n",
      "Epoch 278/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00278: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 727us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1741 - val_accuracy: 0.9730\n",
      "Epoch 279/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000    \n",
      "Epoch 00279: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9730\n",
      "Epoch 280/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000    \n",
      "Epoch 00280: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9730\n",
      "Epoch 281/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00281: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9730\n",
      "Epoch 282/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 6.2585e-04 - accuracy: 1.0000\n",
      "Epoch 00282: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9730\n",
      "Epoch 283/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000    \n",
      "Epoch 00283: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 0.9730\n",
      "Epoch 284/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 2.7013e-04 - accuracy: 1.0000\n",
      "Epoch 00284: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 0.9730\n",
      "Epoch 285/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 00285: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1913 - val_accuracy: 0.9730\n",
      "Epoch 286/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000    \n",
      "Epoch 00286: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9730\n",
      "Epoch 287/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0118 - accuracy: 0.9900\n",
      "Epoch 00287: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 719us/sample - loss: 0.0082 - accuracy: 0.9932 - val_loss: 0.2935 - val_accuracy: 0.9459\n",
      "Epoch 288/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0391 - accuracy: 0.9900\n",
      "Epoch 00288: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.0270 - accuracy: 0.9932 - val_loss: 0.0575 - val_accuracy: 0.9730\n",
      "Epoch 289/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0202 - accuracy: 0.9900\n",
      "Epoch 00289: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 721us/sample - loss: 0.0157 - accuracy: 0.9932 - val_loss: 0.2659 - val_accuracy: 0.9730\n",
      "Epoch 290/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 00290: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 743us/sample - loss: 0.0127 - accuracy: 0.9932 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0292 - accuracy: 0.9700    \n",
      "Epoch 00291: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 710us/sample - loss: 0.0222 - accuracy: 0.9795 - val_loss: 0.3627 - val_accuracy: 0.9189\n",
      "Epoch 292/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0206 - accuracy: 0.9909\n",
      "Epoch 00292: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 692us/sample - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.0270 - val_accuracy: 0.9730\n",
      "Epoch 293/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0203 - accuracy: 0.9909\n",
      "Epoch 00293: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.0154 - accuracy: 0.9932 - val_loss: 0.2379 - val_accuracy: 0.9730\n",
      "Epoch 294/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0084 - accuracy: 0.9909    \n",
      "Epoch 00294: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.0065 - accuracy: 0.9932 - val_loss: 0.1194 - val_accuracy: 0.9730\n",
      "Epoch 295/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000    \n",
      "Epoch 00295: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 707us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9730\n",
      "Epoch 296/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 00296: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9730\n",
      "Epoch 297/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00297: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 667us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 0.9730\n",
      "Epoch 298/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000    \n",
      "Epoch 00298: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9730\n",
      "Epoch 299/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0029 - accuracy: 1.0000    \n",
      "Epoch 00299: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9730\n",
      "Epoch 300/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0222 - accuracy: 0.9900    \n",
      "Epoch 00300: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 692us/sample - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0319 - accuracy: 0.9900\n",
      "Epoch 00301: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 676us/sample - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.4443 - val_accuracy: 0.8649\n",
      "Epoch 302/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
      "Epoch 00302: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 934us/sample - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0208 - accuracy: 0.9889    \n",
      "Epoch 00303: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 749us/sample - loss: 0.0196 - accuracy: 0.9863 - val_loss: 0.2237 - val_accuracy: 0.9459\n",
      "Epoch 304/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00304: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 740us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9730\n",
      "Epoch 305/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0363 - accuracy: 0.9800\n",
      "Epoch 00305: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 689us/sample - loss: 0.0250 - accuracy: 0.9863 - val_loss: 0.0502 - val_accuracy: 0.9730\n",
      "Epoch 306/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000    \n",
      "Epoch 00306: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 0.8919\n",
      "Epoch 307/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 00307: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9459\n",
      "Epoch 308/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 00308: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 688us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9730\n",
      "Epoch 309/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 6.4515e-04 - accuracy: 1.0000\n",
      "Epoch 00309: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9459\n",
      "Epoch 310/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000    \n",
      "Epoch 00310: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 713us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9730\n",
      "Epoch 311/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000    \n",
      "Epoch 00311: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 807us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9730\n",
      "Epoch 312/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000    \n",
      "Epoch 00312: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9730\n",
      "Epoch 313/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000    \n",
      "Epoch 00313: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 763us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9730\n",
      "Epoch 314/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000    \n",
      "Epoch 00314: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 712us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9730\n",
      "Epoch 315/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 00315: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1654 - val_accuracy: 0.9730\n",
      "Epoch 316/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 7.4000e-04 - accuracy: 1.0000\n",
      "Epoch 00316: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 721us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9730\n",
      "Epoch 317/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 8.3467e-04 - accuracy: 1.0000\n",
      "Epoch 00317: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 711us/sample - loss: 6.9398e-04 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9730\n",
      "Epoch 318/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0067 - accuracy: 1.0000    \n",
      "Epoch 00318: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9730\n",
      "Epoch 319/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0136 - accuracy: 0.9900\n",
      "Epoch 00319: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 728us/sample - loss: 0.0160 - accuracy: 0.9863 - val_loss: 0.0819 - val_accuracy: 0.9730\n",
      "Epoch 320/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000    \n",
      "Epoch 00320: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 733us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9730\n",
      "Epoch 321/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 9.5255e-04 - accuracy: 1.0000\n",
      "Epoch 00321: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9730\n",
      "Epoch 322/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0415 - accuracy: 0.9900\n",
      "Epoch 00322: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0310 - accuracy: 0.9932 - val_loss: 0.0648 - val_accuracy: 0.9459\n",
      "Epoch 323/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0226 - accuracy: 0.9900\n",
      "Epoch 00323: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.0327 - accuracy: 0.9863 - val_loss: 0.1504 - val_accuracy: 0.9730\n",
      "Epoch 324/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0856 - accuracy: 0.9800\n",
      "Epoch 00324: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 712us/sample - loss: 0.0641 - accuracy: 0.9795 - val_loss: 0.2497 - val_accuracy: 0.9459\n",
      "Epoch 325/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0710 - accuracy: 0.9600    \n",
      "Epoch 00325: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0520 - accuracy: 0.9726 - val_loss: 0.3751 - val_accuracy: 0.8919\n",
      "Epoch 326/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.1539 - accuracy: 0.9400\n",
      "Epoch 00326: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 750us/sample - loss: 0.1730 - accuracy: 0.9452 - val_loss: 0.9128 - val_accuracy: 0.8378\n",
      "Epoch 327/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.5403 - accuracy: 0.9000\n",
      "Epoch 00327: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.3888 - accuracy: 0.9178 - val_loss: 0.1798 - val_accuracy: 0.9730\n",
      "Epoch 328/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0278 - accuracy: 0.9800\n",
      "Epoch 00328: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.0196 - accuracy: 0.9863 - val_loss: 0.1557 - val_accuracy: 0.9730\n",
      "Epoch 329/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0623 - accuracy: 0.9900\n",
      "Epoch 00329: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 0.0536 - accuracy: 0.9863 - val_loss: 0.2560 - val_accuracy: 0.9730\n",
      "Epoch 330/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0156 - accuracy: 0.9900\n",
      "Epoch 00330: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 712us/sample - loss: 0.0123 - accuracy: 0.9932 - val_loss: 0.1573 - val_accuracy: 0.9730\n",
      "Epoch 331/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0323 - accuracy: 0.9800\n",
      "Epoch 00331: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 664us/sample - loss: 0.0286 - accuracy: 0.9795 - val_loss: 0.1002 - val_accuracy: 0.9730\n",
      "Epoch 332/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 00332: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9730\n",
      "Epoch 333/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0158 - accuracy: 0.9900\n",
      "Epoch 00333: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0142 - accuracy: 0.9932 - val_loss: 0.0427 - val_accuracy: 0.9730\n",
      "Epoch 334/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 00334: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9730\n",
      "Epoch 335/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000    \n",
      "Epoch 00335: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 787us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9730\n",
      "Epoch 336/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 00336: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 698us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 0.9730\n",
      "Epoch 337/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 00337: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 746us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9730\n",
      "Epoch 338/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0218 - accuracy: 0.9909\n",
      "Epoch 00338: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 673us/sample - loss: 0.0188 - accuracy: 0.9932 - val_loss: 0.0667 - val_accuracy: 0.9730\n",
      "Epoch 339/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0201 - accuracy: 0.9909\n",
      "Epoch 00339: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 637us/sample - loss: 0.0160 - accuracy: 0.9932 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00340: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 657us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9730\n",
      "Epoch 341/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0108 - accuracy: 0.9909\n",
      "Epoch 00341: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 631us/sample - loss: 0.0084 - accuracy: 0.9932 - val_loss: 0.0386 - val_accuracy: 0.9730\n",
      "Epoch 342/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000    \n",
      "Epoch 00342: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9730\n",
      "Epoch 343/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 00343: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 672us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9730\n",
      "Epoch 344/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    \n",
      "Epoch 00344: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9730\n",
      "Epoch 345/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    \n",
      "Epoch 00345: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9730\n",
      "Epoch 346/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000    \n",
      "Epoch 00346: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 721us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9730\n",
      "Epoch 347/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 00347: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9730\n",
      "Epoch 348/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 00348: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 687us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9730\n",
      "Epoch 349/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 6.2905e-04 - accuracy: 1.0000\n",
      "Epoch 00349: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 706us/sample - loss: 7.2401e-04 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9730\n",
      "Epoch 350/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 8.4094e-04 - accuracy: 1.0000\n",
      "Epoch 00350: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9730\n",
      "Epoch 351/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 8.3002e-04 - accuracy: 1.0000\n",
      "Epoch 00351: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 687us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9730\n",
      "Epoch 352/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 9.2314e-04 - accuracy: 1.0000\n",
      "Epoch 00352: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 650us/sample - loss: 9.6448e-04 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9730\n",
      "Epoch 353/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 00353: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9730\n",
      "Epoch 354/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 5.4145e-04 - accuracy: 1.0000\n",
      "Epoch 00354: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 666us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9730\n",
      "Epoch 355/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0122 - accuracy: 0.9900\n",
      "Epoch 00355: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 0.0086 - accuracy: 0.9932 - val_loss: 0.1113 - val_accuracy: 0.9730\n",
      "Epoch 356/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00356: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9730\n",
      "Epoch 357/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 00357: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9730\n",
      "Epoch 358/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 6.2080e-04 - accuracy: 1.0000\n",
      "Epoch 00358: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 681us/sample - loss: 0.0140 - accuracy: 0.9932 - val_loss: 0.0582 - val_accuracy: 0.9730\n",
      "Epoch 359/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0151 - accuracy: 1.0000    \n",
      "Epoch 00359: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9730\n",
      "Epoch 360/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 00360: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9730\n",
      "Epoch 361/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 7.6917e-04 - accuracy: 1.0000\n",
      "Epoch 00361: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 7.0143e-04 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9730\n",
      "Epoch 362/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0098 - accuracy: 0.9889\n",
      "Epoch 00362: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.0062 - accuracy: 0.9932 - val_loss: 0.0569 - val_accuracy: 0.9730\n",
      "Epoch 363/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 00363: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9730\n",
      "Epoch 364/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00364: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9730\n",
      "Epoch 365/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
      "Epoch 00365: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 702us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9730\n",
      "Epoch 366/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
      "Epoch 00366: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9730\n",
      "Epoch 367/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00367: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 715us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9730\n",
      "Epoch 368/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0056 - accuracy: 1.0000    \n",
      "Epoch 00368: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 673us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9730\n",
      "Epoch 369/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 6.3901e-04 - accuracy: 1.0000\n",
      "Epoch 00369: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 729us/sample - loss: 4.4896e-04 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9730\n",
      "Epoch 370/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 00370: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9730\n",
      "Epoch 371/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00371: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 710us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9730\n",
      "Epoch 372/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0097 - accuracy: 1.0000    \n",
      "Epoch 00372: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 731us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9730\n",
      "Epoch 373/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000    \n",
      "Epoch 00373: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9730\n",
      "Epoch 374/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 9.5486e-04 - accuracy: 1.0000\n",
      "Epoch 00374: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 753us/sample - loss: 7.5531e-04 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9730\n",
      "Epoch 375/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 00375: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 706us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9730\n",
      "Epoch 376/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 00376: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9730\n",
      "Epoch 377/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0272 - accuracy: 0.9778\n",
      "Epoch 00377: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 0.0200 - accuracy: 0.9863 - val_loss: 0.0541 - val_accuracy: 0.9730\n",
      "Epoch 378/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 6.7663e-04 - accuracy: 1.0000\n",
      "Epoch 00378: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 5.7557e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9730\n",
      "Epoch 379/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 4.8252e-04 - accuracy: 1.0000\n",
      "Epoch 00379: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 697us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9730\n",
      "Epoch 380/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0085 - accuracy: 0.9900    \n",
      "Epoch 00380: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 666us/sample - loss: 0.0066 - accuracy: 0.9932 - val_loss: 0.2398 - val_accuracy: 0.9730\n",
      "Epoch 381/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0192 - accuracy: 0.9900\n",
      "Epoch 00381: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 668us/sample - loss: 0.0199 - accuracy: 0.9863 - val_loss: 0.0621 - val_accuracy: 0.9730\n",
      "Epoch 382/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00382: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 651us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9730\n",
      "Epoch 383/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0085 - accuracy: 0.9909\n",
      "Epoch 00383: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 657us/sample - loss: 0.0064 - accuracy: 0.9932 - val_loss: 0.0365 - val_accuracy: 0.9730\n",
      "Epoch 384/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000    \n",
      "Epoch 00384: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 713us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9730\n",
      "Epoch 385/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0124 - accuracy: 1.0000    \n",
      "Epoch 00385: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9730\n",
      "Epoch 386/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000    \n",
      "Epoch 00386: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 737us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9730\n",
      "Epoch 387/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00387: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9730\n",
      "Epoch 388/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00388: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9730\n",
      "Epoch 389/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 9.6827e-04 - accuracy: 1.0000\n",
      "Epoch 00389: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 683us/sample - loss: 8.3044e-04 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9730\n",
      "Epoch 390/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 3.7411e-04 - accuracy: 1.0000\n",
      "Epoch 00390: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 786us/sample - loss: 8.5607e-04 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9730\n",
      "Epoch 391/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 4.0855e-04 - accuracy: 1.0000\n",
      "Epoch 00391: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9730\n",
      "Epoch 392/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00392: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0355 - val_accuracy: 0.9730\n",
      "Epoch 393/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    \n",
      "Epoch 00393: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 691us/sample - loss: 8.9761e-04 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000    \n",
      "Epoch 00394: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 652us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9730\n",
      "Epoch 395/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 7.7692e-04 - accuracy: 1.0000\n",
      "Epoch 00395: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 655us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9730\n",
      "Epoch 396/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000    \n",
      "Epoch 00396: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 645us/sample - loss: 0.0070 - accuracy: 0.9932 - val_loss: 0.2033 - val_accuracy: 0.9730\n",
      "Epoch 397/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 00397: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 653us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9730\n",
      "Epoch 398/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000    \n",
      "Epoch 00398: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 660us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9730\n",
      "Epoch 399/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 1.0820e-04 - accuracy: 1.0000\n",
      "Epoch 00399: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 635us/sample - loss: 1.2341e-04 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 0.9730\n",
      "Epoch 400/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 3.1755e-04 - accuracy: 1.0000\n",
      "Epoch 00400: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 732us/sample - loss: 2.2904e-04 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 0.9730\n",
      "Epoch 401/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 00401: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 676us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9730\n",
      "Epoch 402/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000    \n",
      "Epoch 00402: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 660us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9730\n",
      "Epoch 403/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 7.4719e-04 - accuracy: 1.0000\n",
      "Epoch 00403: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 725us/sample - loss: 5.3751e-04 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9730\n",
      "Epoch 404/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 7.6736e-04 - accuracy: 1.0000\n",
      "Epoch 00404: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9730\n",
      "Epoch 405/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 1.5099e-04 - accuracy: 1.0000\n",
      "Epoch 00405: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0268 - val_accuracy: 0.9730\n",
      "Epoch 406/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0092 - accuracy: 0.9909    \n",
      "Epoch 00406: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.0279 - accuracy: 0.9863 - val_loss: 0.0446 - val_accuracy: 0.9730\n",
      "Epoch 407/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0243 - accuracy: 0.9900    \n",
      "Epoch 00407: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.0167 - accuracy: 0.9932 - val_loss: 0.0747 - val_accuracy: 0.9730\n",
      "Epoch 408/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
      "Epoch 00408: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 702us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9730\n",
      "Epoch 409/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 9.0843e-04 - accuracy: 1.0000\n",
      "Epoch 00409: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 6.3714e-04 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9730\n",
      "Epoch 410/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 9.9009e-04 - accuracy: 1.0000\n",
      "Epoch 00410: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 672us/sample - loss: 8.0007e-04 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9730\n",
      "Epoch 411/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 9.5802e-04 - accuracy: 1.0000\n",
      "Epoch 00411: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 6.8289e-04 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9730\n",
      "Epoch 412/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 2.7057e-04 - accuracy: 1.0000\n",
      "Epoch 00412: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 2.2359e-04 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9730\n",
      "Epoch 413/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 8.3410e-04 - accuracy: 1.0000\n",
      "Epoch 00413: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 8.0498e-04 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9730\n",
      "Epoch 414/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 4.8007e-04 - accuracy: 1.0000\n",
      "Epoch 00414: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 6.2990e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9730\n",
      "Epoch 415/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 3.2701e-04 - accuracy: 1.0000\n",
      "Epoch 00415: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 698us/sample - loss: 2.3781e-04 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9730\n",
      "Epoch 416/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 2.5290e-04 - accuracy: 1.0000\n",
      "Epoch 00416: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 722us/sample - loss: 3.7032e-04 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9730\n",
      "Epoch 417/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 3.1765e-04 - accuracy: 1.0000\n",
      "Epoch 00417: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 2.3881e-04 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9730\n",
      "Epoch 418/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 6.7974e-05 - accuracy: 1.0000\n",
      "Epoch 00418: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 1.1383e-04 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9730\n",
      "Epoch 419/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 9.6235e-05 - accuracy: 1.0000\n",
      "Epoch 00419: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 710us/sample - loss: 3.0319e-04 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9730\n",
      "Epoch 420/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000    \n",
      "Epoch 00420: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9730\n",
      "Epoch 421/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 6.6298e-04 - accuracy: 1.0000\n",
      "Epoch 00421: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 743us/sample - loss: 0.0065 - accuracy: 0.9932 - val_loss: 0.1557 - val_accuracy: 0.9730\n",
      "Epoch 422/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0126 - accuracy: 0.9909    \n",
      "Epoch 00422: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 688us/sample - loss: 0.0095 - accuracy: 0.9932 - val_loss: 0.0195 - val_accuracy: 0.9730\n",
      "Epoch 423/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0161 - accuracy: 0.9900\n",
      "Epoch 00423: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 0.0129 - accuracy: 0.9932 - val_loss: 0.2924 - val_accuracy: 0.9189\n",
      "Epoch 424/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 00424: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9189\n",
      "Epoch 425/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 00425: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 704us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 0.9189\n",
      "Epoch 426/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 6.1874e-04 - accuracy: 1.0000\n",
      "Epoch 00426: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 9.9525e-04 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9459\n",
      "Epoch 427/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    \n",
      "Epoch 00427: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9730\n",
      "Epoch 428/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 00428: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9730\n",
      "Epoch 429/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0203 - accuracy: 0.9900    \n",
      "Epoch 00429: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 700us/sample - loss: 0.0214 - accuracy: 0.9863 - val_loss: 0.7938 - val_accuracy: 0.8649\n",
      "Epoch 430/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0953 - accuracy: 0.9900    \n",
      "Epoch 00430: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 675us/sample - loss: 0.1799 - accuracy: 0.9726 - val_loss: 0.5216 - val_accuracy: 0.8649\n",
      "Epoch 431/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.2839 - accuracy: 0.9300\n",
      "Epoch 00431: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 708us/sample - loss: 0.2005 - accuracy: 0.9452 - val_loss: 0.0485 - val_accuracy: 0.9730\n",
      "Epoch 432/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0277 - accuracy: 0.9818\n",
      "Epoch 00432: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 633us/sample - loss: 0.0211 - accuracy: 0.9863 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0085 - accuracy: 1.0000    \n",
      "Epoch 00433: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 723us/sample - loss: 0.0159 - accuracy: 0.9932 - val_loss: 0.0308 - val_accuracy: 0.9730\n",
      "Epoch 434/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000    \n",
      "Epoch 00434: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 668us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 0.9730\n",
      "Epoch 435/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 00435: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 00436: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 702us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9730\n",
      "Epoch 437/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000    \n",
      "Epoch 00437: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 687us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9730\n",
      "Epoch 438/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000    \n",
      "Epoch 00438: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 713us/sample - loss: 0.0115 - accuracy: 0.9932 - val_loss: 0.0836 - val_accuracy: 0.9730\n",
      "Epoch 439/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0119 - accuracy: 0.9900    \n",
      "Epoch 00439: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 672us/sample - loss: 0.0088 - accuracy: 0.9932 - val_loss: 0.0535 - val_accuracy: 0.9730\n",
      "Epoch 440/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000    \n",
      "Epoch 00440: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 748us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9730\n",
      "Epoch 441/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 5.1207e-04 - accuracy: 1.0000\n",
      "Epoch 00441: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 0.0095 - accuracy: 0.9932 - val_loss: 0.0735 - val_accuracy: 0.9730\n",
      "Epoch 442/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000    \n",
      "Epoch 00442: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 744us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9730\n",
      "Epoch 443/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000    \n",
      "Epoch 00443: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 670us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9730\n",
      "Epoch 444/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0102 - accuracy: 0.9900    \n",
      "Epoch 00444: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 728us/sample - loss: 0.0071 - accuracy: 0.9932 - val_loss: 0.0818 - val_accuracy: 0.9730\n",
      "Epoch 445/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 5.7560e-04 - accuracy: 1.0000\n",
      "Epoch 00445: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 668us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9730\n",
      "Epoch 446/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 3.9540e-04 - accuracy: 1.0000\n",
      "Epoch 00446: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 738us/sample - loss: 8.0627e-04 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9730\n",
      "Epoch 447/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 5.2943e-04 - accuracy: 1.0000\n",
      "Epoch 00447: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 668us/sample - loss: 4.2091e-04 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9730\n",
      "Epoch 448/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 00448: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 696us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1454 - val_accuracy: 0.9730\n",
      "Epoch 449/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00449: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 687us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9730\n",
      "Epoch 450/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 3.7546e-04 - accuracy: 1.0000\n",
      "Epoch 00450: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 2.8080e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9730\n",
      "Epoch 451/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 00451: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 665us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9730\n",
      "Epoch 452/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000    \n",
      "Epoch 00452: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 622us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9730\n",
      "Epoch 453/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 5.0740e-04 - accuracy: 1.0000\n",
      "Epoch 00453: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 665us/sample - loss: 5.1877e-04 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9730\n",
      "Epoch 454/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000    \n",
      "Epoch 00454: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 645us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9730\n",
      "Epoch 455/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 2.7559e-04 - accuracy: 1.0000\n",
      "Epoch 00455: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 641us/sample - loss: 3.6918e-04 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9730\n",
      "Epoch 456/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 5.1124e-04 - accuracy: 1.0000\n",
      "Epoch 00456: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 644us/sample - loss: 6.6168e-04 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9730\n",
      "Epoch 457/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00457: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 728us/sample - loss: 9.4211e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9730\n",
      "Epoch 458/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000    \n",
      "Epoch 00458: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9730\n",
      "Epoch 459/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0135 - accuracy: 0.9900    \n",
      "Epoch 00459: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 703us/sample - loss: 0.0102 - accuracy: 0.9932 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0287 - accuracy: 0.9900\n",
      "Epoch 00460: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 773us/sample - loss: 0.0242 - accuracy: 0.9932 - val_loss: 0.2256 - val_accuracy: 0.9730\n",
      "Epoch 461/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
      "Epoch 00461: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 695us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9730\n",
      "Epoch 462/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00462: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 673us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 0.9730\n",
      "Epoch 463/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000    \n",
      "Epoch 00463: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 706us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 0.9730\n",
      "Epoch 464/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 2.0988e-04 - accuracy: 1.0000\n",
      "Epoch 00464: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 709us/sample - loss: 5.5324e-04 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9730\n",
      "Epoch 465/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0365 - accuracy: 0.9818\n",
      "Epoch 00465: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 0.0495 - accuracy: 0.9726 - val_loss: 0.0538 - val_accuracy: 0.9730\n",
      "Epoch 466/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0537 - accuracy: 0.9667    \n",
      "Epoch 00466: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.0384 - accuracy: 0.9795 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 00467: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 727us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9730\n",
      "Epoch 468/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000    \n",
      "Epoch 00468: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 739us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9730\n",
      "Epoch 469/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00469: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 660us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 0.9730\n",
      "Epoch 470/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 5.3083e-04 - accuracy: 1.0000\n",
      "Epoch 00470: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 712us/sample - loss: 6.3337e-04 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9730\n",
      "Epoch 471/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 9.0748e-04 - accuracy: 1.0000\n",
      "Epoch 00471: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 711us/sample - loss: 6.8475e-04 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9730\n",
      "Epoch 472/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0089 - accuracy: 0.9909\n",
      "Epoch 00472: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 655us/sample - loss: 0.0133 - accuracy: 0.9863 - val_loss: 0.0274 - val_accuracy: 0.9730\n",
      "Epoch 473/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0065 - accuracy: 1.0000    \n",
      "Epoch 00473: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9730\n",
      "Epoch 474/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000    \n",
      "Epoch 00474: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 712us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9730\n",
      "Epoch 475/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 00475: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 661us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9730\n",
      "Epoch 476/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 8.1749e-04 - accuracy: 1.0000\n",
      "Epoch 00476: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 678us/sample - loss: 0.0150 - accuracy: 0.9932 - val_loss: 0.0207 - val_accuracy: 0.9730\n",
      "Epoch 477/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000    \n",
      "Epoch 00477: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 666us/sample - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.0334 - val_accuracy: 0.9730\n",
      "Epoch 478/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 5.0942e-04 - accuracy: 1.0000\n",
      "Epoch 00478: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 660us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9189\n",
      "Epoch 479/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000    \n",
      "Epoch 00479: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 659us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000    \n",
      "Epoch 00480: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 687us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9730\n",
      "Epoch 481/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 6.8822e-04 - accuracy: 1.0000\n",
      "Epoch 00481: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 678us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9730\n",
      "Epoch 482/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 00482: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 719us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9730\n",
      "Epoch 483/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
      "Epoch 00483: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 712us/sample - loss: 9.9541e-04 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9730\n",
      "Epoch 484/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 2.2254e-04 - accuracy: 1.0000\n",
      "Epoch 00484: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 667us/sample - loss: 1.9097e-04 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 0.9730\n",
      "Epoch 485/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 1.5669e-04 - accuracy: 1.0000\n",
      "Epoch 00485: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 2.6470e-04 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9730\n",
      "Epoch 486/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 1.3153e-04 - accuracy: 1.0000\n",
      "Epoch 00486: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 1.1809e-04 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9730\n",
      "Epoch 487/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 4.0688e-04 - accuracy: 1.0000\n",
      "Epoch 00487: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 665us/sample - loss: 3.1094e-04 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 0.9730\n",
      "Epoch 488/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 1.8399e-04 - accuracy: 1.0000\n",
      "Epoch 00488: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 641us/sample - loss: 1.5772e-04 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9730\n",
      "Epoch 489/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 2.2589e-04 - accuracy: 1.0000\n",
      "Epoch 00489: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 648us/sample - loss: 3.6204e-04 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9730\n",
      "Epoch 490/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 3.7215e-04 - accuracy: 1.0000\n",
      "Epoch 00490: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 637us/sample - loss: 2.9609e-04 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9730\n",
      "Epoch 491/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000    \n",
      "Epoch 00491: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9730\n",
      "Epoch 492/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
      "Epoch 00492: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 751us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 0.9730\n",
      "Epoch 493/500\n",
      " 90/146 [=================>............] - ETA: 0s - loss: 2.3913e-04 - accuracy: 1.0000\n",
      "Epoch 00493: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 701us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9730\n",
      "Epoch 494/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 2.2966e-04 - accuracy: 1.0000\n",
      "Epoch 00494: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 2.4939e-04 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9730\n",
      "Epoch 495/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 1.1466e-04 - accuracy: 1.0000\n",
      "Epoch 00495: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 1.8173e-04 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9730\n",
      "Epoch 496/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
      "Epoch 00496: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 699us/sample - loss: 7.8318e-04 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9730\n",
      "Epoch 497/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 8.6075e-04 - accuracy: 1.0000\n",
      "Epoch 00497: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 6.6736e-04 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9730\n",
      "Epoch 498/500\n",
      "110/146 [=====================>........] - ETA: 0s - loss: 9.0129e-05 - accuracy: 1.0000\n",
      "Epoch 00498: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 655us/sample - loss: 7.8792e-05 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9730\n",
      "Epoch 499/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 9.7650e-04 - accuracy: 1.0000\n",
      "Epoch 00499: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 662us/sample - loss: 6.8856e-04 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9730\n",
      "Epoch 500/500\n",
      "100/146 [===================>..........] - ETA: 0s - loss: 4.1837e-04 - accuracy: 1.0000\n",
      "Epoch 00500: val_accuracy did not improve from 1.00000\n",
      "146/146 [==============================] - 0s 739us/sample - loss: 3.1248e-04 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9730\n",
      "Training completed in time:  0:00:54.124591\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3dd5wU9f3H8ddn9/pxtOOkw4moCKEpNjA/sXdjLFFjjMZCNInGNGsSTTFRfz8xEpOoMWoSY1diV2yoBBWPCEgRUWlHPQ643nb3+/tj5u72CnAHt1fm3s/Hg8fuzs7OfGfZe893vvOd75hzDhERCZ5QRxdAREQSQwEvIhJQCngRkYBSwIuIBJQCXkQkoBTwIiIBpYCXbs3Mcs3MmVlSC+a92Mzm7OlyRNqLAl66DDNbZWbVZtav0fSP/XDN7ZiSiXROCnjpalYC59e+MLOxQEbHFUek81LAS1fzT+Dbca8vAv4RP4OZ9TKzf5hZgZmtNrOfm1nIfy9sZv9nZlvM7EvglGY++zcz22Bm68zst2YWbm0hzWyQmT1vZlvN7HMzuzzuvUPMLM/Mis1sk5lN96enmdkjZlZoZtvN7CMz69/adYvUUsBLV/MB0NPMDvCD9zzgkUbz/BHoBYwAjsTbIXzHf+9y4FRgIjAJOLvRZx8GIsBIf57jgct2o5yPA/nAIH8dvzOzo/337gbuds71BPYBnvSnX+SXeyiQDVwBVOzGukUABbx0TbW1+OOAZcC62jfiQv8G51yJc24VcCdwoT/LN4A/OOfWOue2Ar+P+2x/4GTgGudcmXNuM3CXv7wWM7OhwBTgOudcpXNuAfAA9UceNcBIM+vnnCt1zn0QNz0bGOmcizrn5jvniluzbpF4Cnjpiv4JfBO4mEbNM0A/IBlYHTdtNTDYfz4IWNvovVrD/c9u8JtItgP3AXu1snyDgK3OuZIdlOFSYD/gU78Z5tS47XoNeNzM1pvZHWaW3Mp1i9RRwEuX45xbjXey9WTg2UZvb8GrCQ+PmzaM+lr+BrwmkPj3aq0FqoB+zrne/r+ezrkxrSzieqCvmWU1Vwbn3Arn3Pl4O47bgafNLNM5V+Oc+5VzbjQwGa8p6duI7CYFvHRVlwJHO+fK4ic656J4bdq3mlmWmQ0Hfkx9O/2TwNVmNsTM+gDXx312AzALuNPMeppZyMz2MbMjW1Mw59xaYC7we//E6Ti/vI8AmNm3zCzHORcDtvsfi5nZUWY21m9mKsbbUcVas26ReAp46ZKcc1845/J28PZVQBnwJTAHeBR40H/vr3jNIAuB/9L0CODbQAqwFNgGPA0M3I0ing/k4tXmZwI3O+fe8N87EVhiZqV4J1zPc85VAAP89RXjnVt4B6/ZRmS3mG74ISISTKrBi4gElAJeRCSgFPAiIgGlgBcRCahONbRpv379XG5ubkcXQ0Sky5g/f/4W51xOc+91qoDPzc0lL29HPd9ERKQxM1u9o/fURCMiElAKeBGRgFLAi4gEVKdqg29OTU0N+fn5VFZWdnRREi4tLY0hQ4aQnKwBBEVkz3X6gM/PzycrK4vc3FzMrKOLkzDOOQoLC8nPz2fvvffu6OKISAB0+iaayspKsrOzAx3uAGZGdnZ2tzhSEZH20ekDHgh8uNfqLtspIu2jSwT8rmwqrqSksqajiyEi0qkEIuALSqoorYq0+XILCwuZMGECEyZMYMCAAQwePLjudXV19U4/m5eXx9VXX93mZRIRaalOf5K1pRIxrH12djYLFiwA4JZbbqFHjx789Kc/rXs/EomQlNT8Vzhp0iQmTZrU9oUSEWmhQNTg27Pl+uKLL+aKK67g0EMP5dprr2XevHkcfvjhTJw4kcmTJ7N8+XIAZs+ezamnevdSvuWWW7jkkkuYOnUqI0aMYMaMGe1YYhHprrpUDf5XLyxh6friJtPLqyMkhUKkJLV+fzV6UE9uPq1191TOz89n7ty5hMNhiouLee+990hKSuKNN97gxhtv5JlnnmnymU8//ZS3336bkpIS9t9/f6688kr1dxeRhOpSAd9ZnHPOOYTDYQCKioq46KKLWLFiBWZGTU3zJ3tPOeUUUlNTSU1NZa+99mLTpk0MGTKkPYstIt1Mlwr4HdW0l6wvok9GCoN6p7dLOTIzM+ue/+IXv+Coo45i5syZrFq1iqlTpzb7mdTU1Lrn4XCYSKTtTwqLiMQLRBs8QEfdOryoqIjBgwcD8PDDD3dQKUREmgpEwBvWYQl/7bXXcsMNNzBx4kTVykWkUzGXiP6Fu2nSpEmu8Q0/li1bxgEHHLDTzy1dX0yv9CQG98lIZPHaRUu2V0SklpnNd8412yc7EDV46LgmGhGRzioYAa8hXEREmghEwCvfRUSaCkTAA2qjERFpJDABr3wXEWkoEAGvJhoRkaa61JWs7a2wsJBjjjkGgI0bNxIOh8nJyQFg3rx5pKSk7PTzs2fPJiUlhcmTJye8rCIijQUj4BNUhd/VcMG7Mnv2bHr06KGAF5EOkdAmGjNbZWafmNkCM8vb9Sd2X3u1wc+fP58jjzySgw46iBNOOIENGzYAMGPGDEaPHs24ceM477zzWLVqFffeey933XUXEyZM4L333munEoqIeNqjBn+Uc25Lmyzpleth4ydNJg+rjhAKGSSFW7/MAWPhpNtaNKtzjquuuornnnuOnJwcnnjiCW666SYefPBBbrvtNlauXElqairbt2+nd+/eXHHFFa2u9YuItJVgNNG0k6qqKhYvXsxxxx0HQDQaZeDAgQCMGzeOCy64gDPOOIMzzjijI4spIgIkPuAdMMvMHHCfc+7+xjOY2TRgGsCwYcN2vrQd1LTXbiwhPTnEsOzMZt9vK845xowZw/vvv9/kvZdeeol3332XF154gVtvvZVPPml6pCEi0p4S3U3yCOfcgcBJwPfN7H8az+Ccu985N8k5N6m2h8ruaI82+NTUVAoKCuoCvqamhiVLlhCLxVi7di1HHXUUt99+O0VFRZSWlpKVlUVJSUk7lExEpKmEBrxzbp3/uBmYCRySyPUlWigU4umnn+a6665j/PjxTJgwgblz5xKNRvnWt77F2LFjmThxIldffTW9e/fmtNNOY+bMmTrJKiIdImFNNGaWCYSccyX+8+OBXydmXYlYakO33HJL3fN33323yftz5sxpMm2//fZj0aJFiSyWiMgOJbINvj8w07z0TQIedc69msD1iYhInIQFvHPuS2B8opbfdH3ttSYRka6hS4xF05nuOpVI3WU7RaR9dPqAT0tLo7CwcKfhF4TBxpxzFBYWkpaW1tFFEZGA6PQXOg0ZMoT8/HwKCgp2OM/m4krCIaOiILUdS9b20tLSGDJkSEcXQ0QCotMHfHJyMnvvvfdO57n2j3Po1yOFh74zoZ1KJSLS+XX6JpqWCJlu+CEi0lggAh4zYkp4EZEGAhHwIVMPFBGRxgIR8Ib6wYuINBaMgDfDqRVeRKSBQAS810TT0aUQEelcAhHwhhFTwouINBCMgFcNXkSkCQW8iEhABSLgQzrJKiLSRCAC3gxd6CQi0kgwAh7ThU4iIo0EI+A1Fo2ISBMBCXiNRSMi0lggAj6ksQpERJoIRMAbOskqItJYIAJe3SRFRJoKRMCbQSzW0aUQEelcAhHwYKq/i4g0EoiA1w0/RESaCkTAaywaEZGmAhHwOskqItJUIAJeY9GIiDSV8IA3s7CZfWxmLyZwHWqDFxFppD1q8D8EliVyBbqQVUSkqYQGvJkNAU4BHkjwetQCLyLSSKJr8H8ArgV2eBmSmU0zszwzyysoKNitlaibpIhIUwkLeDM7FdjsnJu/s/mcc/c75yY55ybl5OTs3rrQSVYRkcYSWYOfApxuZquAx4GjzeyRRKxI3SRFRJpKWMA7525wzg1xzuUC5wFvOee+lZCVaSwaEZEmAtEPPmTW0UUQEel0ktpjJc652cDsRC3fa4NXE42ISLxA1OA1Fo2ISFOBCPiQmWrwIiKNBCLgzVAfGhGRRgIS8KYmGhGRRoIR8OhKVhGRxgIR8CGNRSMi0kQgAt4bD14RLyISLxABH1IbvIhIE4EIeFANXkSksUAEvBnqJyki0kggAl4nWUVEmgpEwGssGhGRpgIR8KGQTrKKiDQWiIBXDV5EpKlgBLza4EVEmghIwGuoAhGRxoIR8Gg8eBGRxgIR8OomKSLSVCACXmPRiIg0FZCAVzdJEZHGghHw/qNOtIqI1AtEwIfMi3jlu4hIvUAEvJ/vaocXEYkTjID3HxXvIiL1AhHwoZCaaEREGgtEwNdSE42ISL2EBbyZpZnZPDNbaGZLzOxXiVpX7UlWERGpl5TAZVcBRzvnSs0sGZhjZq845z5o6xXpJKuISFMJC3jndUov9V8m+/8SksB+E7za4EVE4rSoicbMMs0s5D/fz8xO92vlu/pc2MwWAJuB151zHzYzzzQzyzOzvIKCgtaW31uG349GNXgRkXotbYN/F0gzs8HALOBC4OFdfcg5F3XOTQCGAIeY2Veamed+59wk59yknJyclpc8Tm0TjeJdRKReSwPenHPlwJnAn51z5wBjWroS59x24G3gxNYXsQWF05WsIiJNtDjgzexw4ALgJX9aeBcfyDGz3v7zdOA44NPdLehO1+U/aiwaEZF6LT3Jeg1wAzDTObfEzEbg1ch3ZiDwdzML4+1InnTOvbj7Rd0xnWQVEWmqRQHvnHsHeAfAP9m6xTl39S4+swiYuMclbIHaJhqdZBURqdfSXjSPmllPM8sEFgNLzexniS1ay4V0klVEpImWtsGPds4VA2cArwB74/Wk6RxUgxcRaaKlAZ/s93s/A3jeOVdDJ6owhzScpIhIEy0N+PuAVUAm8K6ZDQeKE1Wo1qq/0KmDCyIi0om09CTrDGBG3KTVZnZUYorUevUXOinhRURqtfQkay8zm147pICZ3YlXm+8U1E1SRKSpljbRPAiUAN/w/xUDDyWqUK2lsWhERJpq6YVO+zjnzop7/St/ELFOwVSDFxFpoqU1+AozO6L2hZlNASoSU6TW01g0IiJNtbQGfwXwDzPr5b/eBlyUmCK1XkgnWUVEmmhpL5qFwHgz6+m/Ljaza4BFiSxcS9Xf0aljyyEi0pm06p6szrli/4pWgB8noDy7pfYkq0aTFBGptyc33e40d7rWPVlFRJrak4DvNGmaFPI2Ixrr4IKIiHQiO22DN7MSmg9yA9ITUqLdEPZ3U1E1wouI1NlpwDvnstqrIHsipNEkRUSa2JMmmk4j7PeTVA1eRKReIAI+VBvwqsGLiNQJRMAn+QEfUw1eRKROIAI+7LfBRxTwIiJ1AhHwIdXgRUSaCETAh9UGLyLSRCACvrabpHrRiIjUC0TA19bg1Q9eRKReIAK+thdNJKqAFxGpFYiA15WsIiJNBSLg669k7eCCiIh0IgkLeDMbamZvm9lSM1tiZj9M1LrqBhtTDV5EpE5Lb9m3OyLAT5xz/zWzLGC+mb3unFva1iuqa6JRLxoRkToJq8E75zY45/7rPy8BlgGDE7Gu2vHgdSWriEi9dmmDN7NcYCLwYTPvTTOzPDPLKygo2K3l+/muGryISJyEB7yZ9QCeAa6Ju59rHefc/c65Sc65STk5Obu1Dl3JKiLSVEID3syS8cL9X865ZxO1nrCuZBURaSKRvWgM+BuwzDk3PVHrgbjBxlSDFxGpk8ga/BTgQuBoM1vg/zs5EStK0h2dRESaSFg3SefcHLybcydcSAEvItJEMK5kVRu8iEgTwQh49aIREWkiEAGvK1lFRJoKRMBrsDERkaYCEfB+vhONKeFFRGoFIuDNjHDI1AYvIhInEAEPXk8aNdGIiNQLTMCHQrqSVUQkXmAC3qvBK+BFRGoFJ+BDCngRkXgKeBGRgApWwKsNXkSkTmACPmSmK1lFROIEJuDVRCMi0lBgAj5kaqIREYkXmIBPCqsGLyISLzABr37wIiINBSbgQyHTlawiInECE/CqwYuINBSggHcabExEJE4wAn7xM7y8/XT6VK3r6JKIiHQawQj4RU8CMLh6ZQcXRESk8whGwPucUxuNiEitQAV8crSyo4sgItJpBCrgM2LFHV0EEZFOIxgB7zfNpNYo4EVEaiUs4M3sQTPbbGaLE7WOOlUlAKTWFCV8VSIiXUUia/APAycmcPn1yrcCkB4pYlNxJd/9Zx4llTXtsmoRkc4qYQHvnHsX2Jqo5TdQsQ2AjGgxd85azmtLNvHcgvXtsmoRkc6qw9vgzWyameWZWV5BQUHrF+BcXcD3sjJKKiP+ctuylCIiXU+HB7xz7n7n3CTn3KScnJzWL8AMblzHxpwppFPFtvJqwBsfXkSkO+vwgG8TSanEMvqRSSXby7229xoNTCPdXflWKNvS0aWQDpTU0QVoK+HUHqRYfQ2+tqlGpNu6Y2/v8Rb1LuuuEtlN8jHgfWB/M8s3s0sTtS6A5PQeZFLJpuIqAIor1ItGRLq3hNXgnXPnJ2rZzcno0Ys0qyZEjBghilWDF5FuLhht8EBaZk8A0vFq8OoHLyLdXWACnpRMADLwBhxTDV6kG/vNXvDv73V0KTpcgAK+BwDDs7zeM6rBi3Rj0SpY8K+OLkWHC1DAezX4py8Zz9cmDKKwtLqDCyQi0rECF/BUlzGgVxobiypxTjfhFpHuK0AB7zXRUF3GwJ5pVEdjFJapFi8i3VeAAr62Bl/KgF7pAGws0h2epJuKduNOBrFoR5eg0whOwKf39R63rWZQr1QAlm8s6cACiXSgSFzlprsFXlQdLGoFJ+Cz+kNGNrxxMyMX/wGAnzy1kNnLN3dwwUQ6QKSq/nl3C7xoXNNsTfc+ig9OwANMvBCAjA//wMunVPObtEd49IPVHVwokQ4QX4OPdrNzUfE7tMruPQ5PsAL+qJvgW89CKInRb17MhbxMVfGmNl9NJBojFlMPHenEGgR8N67BK+ADJCkFRh4DZ95fP6mk7e/sNPKmV5j2z/ltvlyRNtOta/Bx21tV3HHl6ASCFfC1vnIWTHsHgLTyDQnpD//GsrY/MhBpM9054GNxPYhqyjuuHJ1AMAMeoOdgAHLcForacOhg3Uiki6mphNLduBVkZ5H3EGz+tPWf00lWj06yBlRmP6KhFAZaIcdOf5e3Pm2bGnepBjHrWh7/JvzfyI4uxe5xDl68Bu77aus/2x1r8K/eCJ+/2XB7IxUdV55OILgBb0ZNj8EMtQK2lFbx4ycXtslidaeoLuaLN73HrtgXvDakdyeg42rwhcWlbVSgTqymAj74EzxyZsMjFtXggyt10BhG2RoADNqkLb5Yo1R2TVWd+KK3WAxeuwm2rGg4vWYPap/VZXVP//Lmst1fTlexLa47dIMmGrXBB5YNGMuI0Ea+MbycbeU1bC6p2vHMy1+BjYt3uUzV4LuoztybYttKeP8eeOJbDafHhXSrbV9T/7w7NNFsW+U9pmQ1rMFHVIMPrv5fAeCOTZdhxPhi804OVR87D+6dsstFapz5LqqyHQN+0ZOQn7fr+WoqoSgfnH/ivnEQ70ntc9vKuqfp4S7YPNVatQGf1qtRE007t8FXFnWq5sBgB/x+J8CAcQCMttW881lB8xcotaKmFH+nqOpIB/aoKdkEr/+y6/eQcA6K1rV8/lgM3psOpa0cgqKqBNYvgLd+27rP7Y5nL4cHjtn1fE9/B+4aA+t2cE1F44D/8H5YO69lZdi6kpiFAUgPdYOeX7VHLBZqdJK1HWvw0QjcNgxe/ln7rXMXgh3w4WS44CmchXgg5U4ee/cTLnpoHvnbyjngF6/yjfve5/Wlm4htW7PrZfnia/BlVR3YXPPq9fCfu+HL2TueZ/mrsObD3Vu+c3BLL5j189Z/dvXclof2Rw/AXaNh09KWzb9lObz5K/jbcTueZ+MnULal4c6vqhj+djy8+7+JrdW15qTe8pe9x5nf9R6L10PFNlgyE0o2QnWjgH/9l97/eUtsW8W2jFwAvrf+Bnj/zy0vV1vatqp1O/DdVbm9/rGj2uBry/DxI+23zl0IdsADZA3Azn6QgbaV11KvI+uLF1kz/Rh+6e5l7coVXP6PPP7wzJvNfjR/WzlVkYaHW/Ft8JHlr8GDJ+1+P+tYrOkfcUtV+81NO2pbdg6evwreub3594vXe+uPVMG9R8DCJ+LKFa2vIc/9Y+vKFYvBQyfBX49u2fy1IfeXw2HJv3c9f4X/R7Rtlbeuxj5/w9ue/92n4T05q0q827iBF6K7a8Gj3o5vRydtSzfu/rIjlXDHPvDUxfDwqQ13RHPv8br8rfvvzpcRi3nNUUVr2ZA6on76azfsfrn2xN3jvR34rsR3gIjFGp40bYna30VVccPvbU970TgHT18Kn73W8jJY54nVzlOSRBrzdSJTf85A28qfU2YwObyU85Pe5p6UGRwbms/WdZ/XzxupYvnGElaszue8O57guqcXNVjUpuL6H0zPd38Fa+bC2zs47K/Y5h1SF2+on7b0OfjPDC8g7p0Cf5m8e2N3+4ffFOU3//72NVC2GUqb6f9fvB6mH+CF/9aVXo135jSvHKvnwu8GwZ37+esJeTWwT19uuIwd9UiqDbiWBl2DEJux6/njw7m2xhQv/kT5J0/W/7E9c2nzy2gsFvW+k8Ivmn//3f/zHnf0vZe0cLsbf5+1nF+hKFwBc6bXT591k7/89V5NvmSj19b/zv96v7GCz7z3Z0yA24cD8Hny/i0rS1tZvwC+eLv1n6upgDtHeU1Q29fCGzfD3eNg05KWLyN+zJmy+grXhyv28OihugwWPw2PfgP+dQ6seGMnZagNeNuzdbahpI4uQHtJmvoz6JsLz15WN+2g0AoeSLmzwXyv3fYN/lx2NDOS72FO6mZGLvgHfzhvYt372eve5K/Jz/GryLdJ3e51a/ty0X9IOaKcIYVzvZDskQMOeMCrxVb3n0DKld7QCTz5be8xIxs2+80SC/4FB13UsMD/mQHhFDj0u83/YGprkNvXQFUpJKV6TVK18j/yHpsL+EJvh7Ztzl/5uGggdXXtJc967cfx0nrBI2dBwTK4fo3XfJCaBU9fAt/7APY6oOH8S59rur5GnHNsL6+hT2ZKw0Po2A52dNXlkJLhPY8P9dLNkOHfB6CmEqaP8soWJ0qIMI1q+jsK+PfuhNm319f0b97ufffb18CLP4JRp+L9x7LjQaxK4nbmn74Eww73vsPb94ap18Hh3/eOVJ66qPnPx1v9n+an/+durya/6j3v9du/9Xb4N6yF7fU134/tAM6I/1zZFsjst+v1tlbtBVnzH/ZeT3sHnp0G5zxUP8+SmTDm681/ft18r0Lwys+8f7XWfAD9x+x6/Vu/hE2f1L8u9kK9wqWwsbCZSkBrlG+pf75iFqx8F27a2PzfZCeswXebgAdg3DnQZzi8fjMLV29ifawvJ4W9INyYPJQBNWs5ITKbE1Jn131kSmgJXxYcw4icHlRUR7lgywz6hws5LuwdKueFxnFA9XIem7uAyz46q9nVuo1L2PzWn9grN+7H+tz3cKk9cT36E3rpxzBiKrGXfwbDpxAafji8/gtvvr0OgKyB8PdT4VvPQHUZlQMPJrZlNRlA2cYVZP7eG5aBEVPhgmfgs1dg1RxvWtkWb6cTTvKC4YN7vaABMiPbmfvRPI729wvuxR/R5GcbjXjhDnDHiIYh/OfD4JtPegE4/jyvpv/q9fXv5+d5f7yHTGvwB/HovDXcNHMxb/90KrlVJfXrrO19UFUKix73jjQysuG1G+H4W72d2pbl9csv2wyM8sJ9/cdecDcK71jMEW68UcXrvRrw8pe9G8XsdwIkp8N7d9WHO3h/zF+86QXI5294y649cnnwBBh5HEz+gfe9A/z9NO8ztR7/pvd45PVQVeRtx8GXtSzcd6U23Gu5KMyrH2SP9D78p2wIr0QPrvuNk/8R7H/SzpcbqYZPX/R2FOPOg54Dve93y3IYON7bsW1aAgPGejXlviNgzfv14Q5eTbdsMyx8rH7aUxd7XZFdDM56oOE6V7/ffFnWf7zzstaa4VfABk+CdXnw4b0AFJNBOlXEYo5QaCe16hVvwCvXwvmPQ2oP6DnIm15dBi/+uH6+Hv29ClNZAfTYCwqWe7+JoYd6v+/ayodzXlPemDMhOW3H660u93Z8ZjDkYMge2ea1f+tMN6aeNGmSy8trQfeyNrBsQzH/XbONCw7sT9HHz9LzgKOxxy8gUvglz1YdzIaaDC5JmkXUGasyxzGhRxF/r5jM14ofpbfV97r5rV3Oz91fm13HOpdNpUthn9CGZt//qM+p3FZwOM8k3cT2Qf9D7/VeOFQOOIi0jX7PiqN+7h2W5z1Y97lb+93BdQXXk2TNtEGfcie89JOG036yHF6/2QtNgNFfa1DTrnLJpNoe9sbZ/xQYeXTTdQP85DPvhiwAaz7ksedeYNaGNFalj2FW9DKSidtpfPt5+MfpLVvn6DMgOQOWPV9/TmIHilIH06tqJ4fre43xvuf4HUSvoVC0dtfl6LcfjD0H3r511/NOewfuPxKS0tq4h4dB72F1NXiX+1X2X/F9qqNRJuUYT1dc4q1v+BTI/aq3Q+41xDvqi9Z4TVLZI+FfZ8OXfjPLgLFw8cvwz697wbnv8V64+zVkQkneDn7uH+s/Ey9rYMMjmlo3b/cqCm/+Gg44zdsR9smF3sNhw0KveQq8Pu0/XOitL1IFQw/2z7s4CPlNlOVb4Y69veeHXlEX7gCfxwax3mUz5ro3ye7h3eWNaA189DeYcL7321n6XMPmO/B2FAPHNfibY7+TYOK34IkL4JJZMPQQuHWA951e9hYMOQjm/RVe/mn9Z6beWFeZouAzWPSEVxkYPgXm3u2NM1R7xJXWG65dCaHW1/7NbL5zblKz73XXgG+WcxCLUB41Zrz5OVeMiVL61BUMKF7cIEznj76eaxfsRbKr5tGLxtL38VMA+Pe4ezkiaRmVi2by9dLrqCSVa/bdxKVrb6LA9SLHiigK9ebyiqv46oQDmP5xjBCORamXkWlVFLkMepnXZPFGdCITe2wju2IVLqMfFneoGHNGyBy/rzmfG5IfY0eqewwlpXQtFb33I337Zw3e25w0iNXVPTg49BnvRsdyQGgNOdYGY2cnZ8Lh3/N6q9RK6w0jjgTqnX4AABI4SURBVPTax7fuoG17Z4YcXN/ktBvuTbuMiqzh/KjgF7ue+aibYNIlcP9UL9zT+3o3dO89dMdNJrtj6g0w+/dNp0+6FA77HtxzUPOfO/UuCCXDJ095NcYNC73XWQOhqL432PbxlzPhw6MAGNInnTn7PwMLGvXu2Pd4rzlh9fveEUbtDm3KD71a6ePfbLqTS+/TfBPXMb+EoYfBwyfvetuzR3pHfdFqrxkyWg2XvAbDDvN2IH+ZHLfcm71eU+A1jbxwjXeEOuECrxxbVng7H4Cv/tRrqvR3tAti+1BFMr2+9zqjBvT0zg88cqZ3FDFwvPfdgVfuAWMh72/ejt7FvJ1KfHPgDxd6O4d7JsEZf/HKWnvkcMqd8JWzvR3de/8X9/2e4O24CpZ533GsxtuJHfNLb6cyYBwceS1k7+ud09n32F1/d83YWcAntInGzE4E7gbCwAPOudsSub49ZgbhZDLCcP1JowAou3QWB9/1FuHKIo5IWsJVk/sz/qjvMP3wKFvLquk7ai/cd15l+huf88d5PYFD/X8wrG8Gl15yNrc9lM19n/XgyuEbmbU2xOduAPM+BgiR0zONL8LjGVcxj8djxzDZPmFsaBXvx0azsLiK7yWt58voEAaEHNmxQgBC5ng+ejgPR08g1zayf04qB257tW4zLrebuWBCH/7yQSFPpP6mSbgDvFA5ns2uNweHPqNq5IlEssph0Z/4Z+RYLkxqeiJpzflvE83en9xP7sbeuZ3qIZNJyZ/bZL5N477LTZ9P4QHiAr5ye4va5gvHX0H2wvoaGN99z6shVRbDv5pv/gK8P5DcI7waVq+h8Op13qGvr0/v3rxS2I8fNf5M4Qr4QR5s+ay+OWXgBK+duk+uF2z7nwRn/BmWPt98wCel73BAq/XhQZR9/R/s+/Sx0GfvBhcfMfac5gP+0O9Cv5Fw5ftez6LGJl7o1boPvNALt3smeaGW0dcL+GNvgTdu4eaPvHa3fXIy+aKgjFkjb+T4xgG/Ylb986GHwdoPvOcHXgTZ+8CZD3hlHHQgHHQxvHC1V+7apqBrFsPaD73va+8jvaavxvYaA5sbnSwtjOvUEK32jgQG+WHZx6+N9+gPWH24A/zpkPr+7h/82Wu+C6fWv19TAcf8oi7gi10Gva2UqhWz4aO3YH7cOYHacD/0Su8zKZneY2rP+maS+KODzBwIJeEw7N9XNtyel37S/JHrite8ne/AcV6lISnF2wnM/SP0HOIdzdXW2Pca1fTzbSBhNXgzCwOfAccB+cBHwPnOuR12eO7wGvxO5K3ayqDe6Qzqnd7s+xXVUf75wSpSwiGG9s1g1MCeZKUl0TMtmfLqCM5BZmoS0ZjjiY/WcuPMT7jp5AP4zpRckiq3Uv7G75nT/0J+91weDx7tGHrEufw9bwu/e3kZMQcHpebzg/6LWZx5OF/NXMu38/bm3K9+hY3FVbywcD0p1HBZ+CVeih3Gajegrlzj7XM2uGwmhj7nf3pu5D/FOZwQzuPmmos4ceJIjndzmPz1K0lLTubaO+7m6e0j6ZmWzKk1r7IycyJnVTzJrXY5hdVeYBgx+ibXUBJN5tzQW/wm6UFmpF3BlJH9WBraj9/MT6E6GuMgW85hwzL52aZrAfg4NpJ5fU/nOxUPUVVZSZZ5ofjK1xZywxMfEMKxlZ68/JXZRLat5er1x1KcMZyfnbA/++T0YGj5YgY+dVrddr0cPYRUakjuM4TBJ/2UvsNG8+WWMjYVV1JVE+Gfc1fyQMH59LVS3hzzey6dP5yhqeW8Z5cRc8a8015nVOFbrBx1OX0yUxm8+W1qSgrZPOIs+vRIJfPTp0j64M/wzce9pgznKJ7/JD1fnFZXhjXDz+Tjib/FORj1wtcYFfNPutswbq06hw9ioxk5dCB3nTaMihrHmF5VkJ9HtLSA0JSrqKqs4LlH7uHcdfVNOyu+/V9G7j0CM/O6Y/qWZh+Hi0YZdPkT3slp8NqIfzcIjvgR7itnsXTRR5TvdwZ/fvgfvFO5D8P7ZdEzPZmFa72a6D0DX+XUbf9g4/dWsK1wIwc8UT9KZeyG9YQWP4Ur/BI7/tcNftvFFdWkhyJseOk2QodfyaDCD3GhMOHRpzWYr7I6Am//jrSqLXzZ9whq8hcw8Gu3kPfiXzl6yY0N/2Bu3OAd5c2ZDham8sYCkkJGUjiE+/gRbOhhxF68htCq91g08Gy+Mrw/oYWPeidqj/+td7SdnAGhELGPHiL00jUUjzqXnufdj7vvSGzDAv6dchpnVL9Qt0qXvS/bBkwhpc9gMub/BTfpMtzUG0gK76RZxP8/mHfRSgb3Sadm+nhyQy0YmbbvPt7Ryal3wXB/R73yPe9cGnhHikdeu+vltECHNNGY2eHALc65E/zXNwA455qptng6c8C3JeccpVURstKSm0zfXFJF/571J2ZiMUfe6m3k9stgr6yG083AzCiurGHR2iJWbinl9PGD+e+abSzdUMw3DxlGRU2Uu17/jKUbiklJCrF2aznHje7Peyu2cPtZ45gysr5XRWlVhNLKCFvLqtleXs2YQb349YtLmflxPucdMozlG0vYsL2CA4f3ITMliZKKKjbkr+Tjosy6ZQzPzuC2M8fxx7dWMPeLQgZQSCS5B1tq6mtaKeEQc05Yz159esHYs/l8cwnHTo87ObkDKdRwTvgdhvXL4t6SI9hWXkPIoLmLkzNSwtx3bApfDX/CF8PP4fLHPyMcMg5Nz2fWasdm+jSYPzls1EQbLigtOURmShIx54hEHWXVEU4Pf8Dx/bbw6ua+PB+rb0roRSmXJb/Kd0PP8YvU6xh15DdITQpz48z63h2pSSF6pCaxrbyapHCIWMwRiTkeTf4tk8NL+VPkdP43ci4ZKUlEYo7cWD4XJb3OBaHXOLDyXrbSE4DeGclEY45YzJHuyqkOp5McTqKwzLvAxwymf2M8X584hBcWrueqx7yTlUaMDKoow6uk3JF0HxWk8LfoyWwIDSArLZniihoyUsL0TE8mEnXURGMUllWTkhSqu3I7IyVMJOrIyfL+T2POEXOOoooaKmti9EpPrrsHQ+33OtpWsd31YERoIwVpuZSm5JBVU8Cr0Wn8m6P4SfU0Ys6RnZlCZU2MaMwxls842s1jeuRssjIzyUgNE4t5fycxB1HncM6RWbWJd8Lf58yqW1ifNY6kSBmZFes4d+qBHPXhZfSJFtLbyphW/SNmxQ4GIJMKakJppCQn0yez4d9hvIvKHmaK+y8nVd9OSlKIae4Zfpr8FM9Ej+DJ8Kn0jWxhFF8QCaVzMnModFkcEV7C6UxnY/JwksMhksJG2Iw0Kriv9IeUWSY/ybiVilBG3Xr6ZqTw9JWTd1iOnemogD8bONE5d5n/+kLgUOfcDxrNNw2YBjBs2LCDVq/WTbI7m5LKGrLS/FBxjuRGNZ5ozLGqsIzC0moOzu2DmeGcY2NxJfNWbuW40f3JSEmiqKKGj9dsIystmYOGNwzY8uoIG4sq+WxTKaMGZBF1joyUMGsKy9laVk1xZQ3Owd79Mhk7pBfOeYG5oaiSvNVbWbWlnP4900gKGwN7pTFmUC/61tZ0GykoqeKtTzdRXh1lcO90NpdUsbqwjPSUJNKSQySHQlTWRCmpilBWFSEcMpJCIdKSQxw7uj8ThvTmjWWbGNgrnc82lbC6sIzTJwxmaN90Sioj9M1Iqeu1MW/lVj74spBNxZWEQ0Yk5oVYdSRGUtiYvE8/hmdnkJbsnTR8YeF61mwtJyUcIhQyLp6cS2ZqEve/8wVfGdyL5RtL2FxSVRcaoZBRHYlRVhVhQK80KqqjHDi8DyePHdhgm9dvryBkRv62chavKyIcDjF5n2ye/GgtOVmpbCmtpqSyhp7pyZRWRiitipAcNpLD3k6pqKKG0YN6UloVIX9bBVmpSRSUVhEyI2QQMiMtOUzvjGQ2FVfSKz2FiuoIGalJ9EpPZnNxFT1Sw8QcbK+oprwqSmpyiMxYKdWWQkZGD1KTQmwuqcIMMlPCFFdEGD2oJ30zU5izYgvV0ZjXimrmrTfkrTs9Ocx+A7JYXVjG5mKvF9SInB5893+8C73eWLaJFcsWsCV1KHv3y6SqJkZlTZSy6ijFlTVUVjc/dozD+41NHtmP+au24oABPVM4Z1AhT67PYUNRBZU1MfpmprC9vJqj9t+LSGUZZas+4tPUcVRUR4nEHJGYt8MCyEpLprIm6m1L3Lqy0pL5/Zljd/m32JxOHfDxuksNXkSkrews4BPZI38dMDTu9RB/moiItINEBvxHwL5mtreZpQDnAc8ncH0iIhInYd0knXMRM/sB8BpeN8kHnXOtGFxCRET2REL7wTvnXgZ2MKqSiIgkUucZFUdERNqUAl5EJKAU8CIiAaWAFxEJqE41mqSZFQC7eylrP2DLLucKFm1z96Bt7h52d5uHO+dymnujUwX8njCzvB1dzRVU2ubuQdvcPSRim9VEIyISUAp4EZGAClLA37/rWQJH29w9aJu7hzbf5sC0wYuISENBqsGLiEgcBbyISEB1+YA3sxPNbLmZfW5m13d0edqKmT1oZpvNbHHctL5m9rqZrfAf+/jTzcxm+N/BIjM7sONKvvvMbKiZvW1mS81siZn90J8e2O02szQzm2dmC/1t/pU/fW8z+9Dftif8Ibcxs1T/9ef++7kdWf49YWZhM/vYzF70Xwd6m81slZl9YmYLzCzPn5bQ33aXDnj/xt5/Ak4CRgPnm9noji1Vm3kYOLHRtOuBN51z+wJv+q/B2/59/X/TgL+0UxnbWgT4iXNuNHAY8H3//zPI210FHO2cGw9MAE40s8OA24G7nHMjgW3Apf78lwLb/Ol3+fN1VT8ElsW97g7bfJRzbkJcf/fE/radf+ParvgPOBx4Le71DcANHV2uNty+XGBx3OvlwED/+UBguf/8PuD85ubryv+A54Djust2AxnAf4FD8a5oTPKn1/3O8e6vcLj/PMmfzzq67LuxrUP8QDsaeBGwbrDNq4B+jaYl9LfdpWvwwGBgbdzrfH9aUPV3zm3wn28E+vvPA/c9+IfhE4EPCfh2+00VC4DNwOvAF8B251zEnyV+u+q22X+/CMhu3xK3iT8A1wIx/3U2wd9mB8wys/lmNs2fltDfdkJv+CGJ45xzZhbIPq5m1gN4BrjGOVdsVn//+SBut3MuCkwws97ATGBUBxcpoczsVGCzc26+mU3t6PK0oyOcc+vMbC/gdTP7NP7NRPy2u3oNvrvd2HuTmQ0E8B83+9MD8z2YWTJeuP/LOfesPznw2w3gnNsOvI3XPNHbzGorYPHbVbfN/vu9gMJ2LuqemgKcbmargMfxmmnuJtjbjHNunf+4GW9HfggJ/m139YDvbjf2fh64yH9+EV4bde30b/tn3g8DiuIO+7oM86rqfwOWOeemx70V2O02sxy/5o6ZpeOdc1iGF/Rn+7M13uba7+Js4C3nN9J2Fc65G5xzQ5xzuXh/s2855y4gwNtsZplmllX7HDgeWEyif9sdfeKhDU5cnAx8htdueVNHl6cNt+sxYANQg9f+dileu+ObwArgDaCvP6/h9Sb6AvgEmNTR5d/NbT4Cr51yEbDA/3dykLcbGAd87G/zYuCX/vQRwDzgc+ApINWfnua//tx/f0RHb8Mebv9U4MWgb7O/bQv9f0tqsyrRv20NVSAiElBdvYlGRER2QAEvIhJQCngRkYBSwIuIBJQCXkQkoBTw0q2YWdQfza/2X5uNQGpmuRY3+qdIR9NQBdLdVDjnJnR0IUTag2rwItSN1X2HP173PDMb6U/PNbO3/DG53zSzYf70/mY20x/HfaGZTfYXFTazv/pju8/yr04V6RAKeOlu0hs10Zwb916Rc24scA/eaIcAfwT+7pwbB/wLmOFPnwG847xx3A/EuzoRvPG7/+ScGwNsB85K8PaI7JCuZJVuxcxKnXM9mpm+Cu/GG1/6A55tdM5lm9kWvHG4a/zpG5xz/cysABjinKuKW0Yu8Lrzbt6AmV0HJDvnfpv4LRNpSjV4kXpuB89boyrueRSd55IOpIAXqXdu3OP7/vO5eCMeAlwAvOc/fxO4Eupu2NGrvQop0lKqXUh3k+7fPanWq8652q6SfcxsEV4t/Hx/2lXAQ2b2M6AA+I4//YfA/WZ2KV5N/Uq80T9FOg21wYtQ1wY/yTm3paPLItJW1EQjIhJQqsGLiASUavAiIgGlgBcRCSgFvIhIQCngRUQCSgEvIhJQ/w9XsHSej2NfoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.6060606\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.36      0.56      0.43         9\n",
      "   Pneumonia       0.79      0.62      0.70        24\n",
      "\n",
      "    accuracy                           0.61        33\n",
      "   macro avg       0.57      0.59      0.57        33\n",
      "weighted avg       0.67      0.61      0.63        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  4]\n",
      " [ 9 15]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
