{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DtXp3DMyU4u2",
    "outputId": "9a02581f-ebc9-4307-c524-f915fc001341"
   },
   "source": [
    "# Rede CNN - Modelo 2\n",
    "\n",
    "## Dataset Respiratory_Sound_Database_Pneumo_Healthy_Only - Dataset 2 - slide10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "sxUgP6_bSR0C"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# Necessário na minha máquina. Estava ocorrendo um erro devido à GPU e esse código resolveu.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_TRAIN = 'slide10'\n",
    "GROUP_TEST = 'slide10'\n",
    "DATASET = 'dataset_2'\n",
    "DURATION = 10\n",
    "SIZE = 431\n",
    "CSV_TRAIN = 'train2.csv'\n",
    "CSV_TEST = 'test2.csv'\n",
    "MODEL_NAME = f'CNN2_{DATASET}_{GROUP_TRAIN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mMb5_PxwSR0N"
   },
   "outputs": [],
   "source": [
    "train_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TRAIN}/train/**/*.wav', recursive=True)\n",
    "train_file_names = [os.path.splitext(os.path.basename(p))[0] for p in train_file_paths]\n",
    "\n",
    "test_file_paths = glob.glob(f'../datasets/{DATASET}/{GROUP_TEST}/test/**/*.wav', recursive=True)\n",
    "test_file_names = [os.path.splitext(os.path.basename(p))[0] for p in test_file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTf5HxHzSR0U"
   },
   "outputs": [],
   "source": [
    "train_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "test_p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in train_file_names:\n",
    "    train_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "for name in test_file_names:\n",
    "    test_p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "train_p_id_in_file = np.array(train_p_id_in_file)\n",
    "test_p_id_in_file = np.array(test_p_id_in_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbK7vc1kSR0c"
   },
   "outputs": [],
   "source": [
    "max_pad_len = SIZE\n",
    "\n",
    "os.makedirs(\"features/\", exist_ok=True)\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "    feature = os.path.splitext(os.path.basename(file_name))[0] + \".npy\"\n",
    "#     if (os.path.isfile(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))):\n",
    "#         return np.load(os.path.join(\"./Respiratory_Sound_Database/features/\", feature))\n",
    "    \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=DURATION) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    np.save(os.path.join(\"./features/\", feature), mfccs)\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkBHJzJDSR0h"
   },
   "outputs": [],
   "source": [
    "#filepaths = [join(mypath, f) for f in filenames] # full paths of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQjbbn7MSR0n"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1\n",
       "0  123  Healthy\n",
       "1  125  Healthy\n",
       "2  126  Healthy\n",
       "3  127  Healthy\n",
       "4  136  Healthy"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TRAIN}\", header=None) # patient diagnosis file\n",
    "test_p_diag = pd.read_csv(f\"../Respiratory_Sound_Database/Respiratory_Sound_Database_Pneumo_Healthy_Only/{CSV_TEST}\", header=None) # patient diagnosis file\n",
    "train_p_diag.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yskEMhphSR0s"
   },
   "outputs": [],
   "source": [
    "train_labels = np.array([train_p_diag[train_p_diag[0] == x][1].values[0] for x in train_p_id_in_file]) \n",
    "test_labels = np.array([test_p_diag[test_p_diag[0] == x][1].values[0] for x in test_p_id_in_file]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yIlzZ5gRSR0w",
    "outputId": "e42143d5-d247-457f-c891-0c714e51cb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  896  files\n"
     ]
    }
   ],
   "source": [
    "train_features = [] \n",
    "test_features = []\n",
    "\n",
    "for file_name in train_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    train_features.append(data)\n",
    "\n",
    "for file_name in test_file_paths:\n",
    "    data = extract_features(file_name)\n",
    "    test_features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', (len(train_features)+len(train_features)), ' files')\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "aPWfXalkSR00",
    "outputId": "0741865f-420e-4c29-8cb1-42b0fe8302cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an MFCC\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(train_features[7], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Healthy', 'Pneumonia'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YAHg4HTzSR1C",
    "outputId": "be27b27d-3389-4d26-b8ee-d795b2259a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Healthy' 'Pneumonia']\n",
      " ['256' '192']]\n",
      "[['Healthy' 'Pneumonia']\n",
      " ['24' '104']]\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(train_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "unique_elements_test, counts_elements_test = np.unique(test_labels, return_counts=True)\n",
    "print(np.asarray((unique_elements_test, counts_elements_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "mtNpDgBOSR1G",
    "outputId": "0f7584a0-d821-4196-c22f-3847fa3031b6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot class counts\n",
    "y_pos = np.arange(len(unique_elements))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.bar(unique_elements, counts_elements, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, unique_elements)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Disease')\n",
    "plt.title('Disease Count in Sound Files (No Asthma or LRTI)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WtqGtxmPSR1K"
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels_cat = to_categorical(le.transform(train_labels)) \n",
    "test_labels_cat = to_categorical(le.transform(test_labels)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 40, 431)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_features.shape[1]*train_features.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MgH8aGqeSR1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448, 40, 431, 1) (448, 2)\n",
      "(128, 40, 431, 1) (128, 2)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.reshape(train_features, (*train_features.shape,1)) \n",
    "print(train_features.shape, train_labels_cat.shape)\n",
    "test_features = np.reshape(test_features, (*test_features.shape,1)) \n",
    "print(test_features.shape, test_labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFPaVmUESR1T"
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_features, train_labels_cat, test_size=0.2, random_state = 42)\n",
    "x_test, y_test = test_features, test_labels_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SN1ipKhfSR1X"
   },
   "source": [
    "**CNN model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ5PcMOrcV1B"
   },
   "outputs": [],
   "source": [
    "num_labels = train_labels_cat.shape[1]\n",
    "\n",
    "num_rows = 40\n",
    "num_columns = SIZE\n",
    "num_channels = 1\n",
    "\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=filter_size,\n",
    "                 input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=8, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=4, kernel_size=filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcSipiVsSR1c"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "colab_type": "code",
    "id": "UvvyonaaSR1h",
    "outputId": "9c2154c5-f927-4c3d-e89e-951ba479c079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 39, 430, 32)       160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 215, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 19, 215, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 214, 16)       2064      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 107, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9, 107, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 106, 8)         520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 53, 8)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 53, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 52, 4)          132       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 26, 4)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 26, 4)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 2,886\n",
      "Trainable params: 2,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "128/128 [==============================] - 1s 8ms/sample - loss: 3.5014 - accuracy: 0.8125\n",
      "Pre-training accuracy: 81.2500%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVtD0mcDSR1j"
   },
   "source": [
    "**Training**\n",
    "\n",
    "Here we will train the model. If we have a trained model, we can load it instead from the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ruRXrsrhSR1k",
    "outputId": "ec26a26d-ad59-4e89-c88f-6277e4d0c283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 358 samples, validate on 90 samples\n",
      "Epoch 1/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 10.0817 - accuracy: 0.5290\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.43333, saving model to models/CNN2_dataset_2_slide10_01.h5\n",
      "358/358 [==============================] - 1s 3ms/sample - loss: 8.8899 - accuracy: 0.5391 - val_loss: 1.1761 - val_accuracy: 0.4333\n",
      "Epoch 2/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.9748 - accuracy: 0.6033\n",
      "Epoch 00002: val_accuracy did not improve from 0.43333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.9305 - accuracy: 0.6117 - val_loss: 0.7240 - val_accuracy: 0.4333\n",
      "Epoch 3/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.7360 - accuracy: 0.6133\n",
      "Epoch 00003: val_accuracy did not improve from 0.43333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.7240 - accuracy: 0.6201 - val_loss: 0.7402 - val_accuracy: 0.4333\n",
      "Epoch 4/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.7432 - accuracy: 0.5967\n",
      "Epoch 00004: val_accuracy did not improve from 0.43333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.7536 - accuracy: 0.5866 - val_loss: 0.7162 - val_accuracy: 0.4333\n",
      "Epoch 5/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.6648 - accuracy: 0.6387\n",
      "Epoch 00005: val_accuracy did not improve from 0.43333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.6618 - accuracy: 0.6425 - val_loss: 0.7138 - val_accuracy: 0.4333\n",
      "Epoch 6/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.6738 - accuracy: 0.6194\n",
      "Epoch 00006: val_accuracy did not improve from 0.43333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.6811 - accuracy: 0.6145 - val_loss: 0.6968 - val_accuracy: 0.4333\n",
      "Epoch 7/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.6578 - accuracy: 0.6333\n",
      "Epoch 00007: val_accuracy did not improve from 0.43333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.6510 - accuracy: 0.6425 - val_loss: 0.6984 - val_accuracy: 0.4333\n",
      "Epoch 8/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.6445 - accuracy: 0.6516\n",
      "Epoch 00008: val_accuracy improved from 0.43333 to 0.45556, saving model to models/CNN2_dataset_2_slide10_08.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.6475 - accuracy: 0.6369 - val_loss: 0.6890 - val_accuracy: 0.4556\n",
      "Epoch 9/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.6094 - accuracy: 0.6567\n",
      "Epoch 00009: val_accuracy improved from 0.45556 to 0.53333, saving model to models/CNN2_dataset_2_slide10_09.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.5909 - accuracy: 0.6760 - val_loss: 0.6801 - val_accuracy: 0.5333\n",
      "Epoch 10/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.6510 - accuracy: 0.6323\n",
      "Epoch 00010: val_accuracy did not improve from 0.53333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.6381 - accuracy: 0.6425 - val_loss: 0.6836 - val_accuracy: 0.5000\n",
      "Epoch 11/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.5948 - accuracy: 0.6618\n",
      "Epoch 00011: val_accuracy did not improve from 0.53333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.6047 - accuracy: 0.6564 - val_loss: 0.6860 - val_accuracy: 0.4444\n",
      "Epoch 12/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.5876 - accuracy: 0.6914\n",
      "Epoch 00012: val_accuracy did not improve from 0.53333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.5885 - accuracy: 0.6927 - val_loss: 0.6693 - val_accuracy: 0.5222\n",
      "Epoch 13/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.6000 - accuracy: 0.7114\n",
      "Epoch 00013: val_accuracy improved from 0.53333 to 0.54444, saving model to models/CNN2_dataset_2_slide10_13.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.6001 - accuracy: 0.7095 - val_loss: 0.6661 - val_accuracy: 0.5444\n",
      "Epoch 14/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.5688 - accuracy: 0.7114\n",
      "Epoch 00014: val_accuracy improved from 0.54444 to 0.62222, saving model to models/CNN2_dataset_2_slide10_14.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.5661 - accuracy: 0.7151 - val_loss: 0.6330 - val_accuracy: 0.6222\n",
      "Epoch 15/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.5354 - accuracy: 0.7171\n",
      "Epoch 00015: val_accuracy improved from 0.62222 to 0.63333, saving model to models/CNN2_dataset_2_slide10_15.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.5351 - accuracy: 0.7179 - val_loss: 0.6194 - val_accuracy: 0.6333\n",
      "Epoch 16/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.5086 - accuracy: 0.7529\n",
      "Epoch 00016: val_accuracy improved from 0.63333 to 0.68889, saving model to models/CNN2_dataset_2_slide10_16.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.5130 - accuracy: 0.7542 - val_loss: 0.5820 - val_accuracy: 0.6889\n",
      "Epoch 17/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.4947 - accuracy: 0.7500\n",
      "Epoch 00017: val_accuracy did not improve from 0.68889\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4918 - accuracy: 0.7598 - val_loss: 0.5744 - val_accuracy: 0.6778\n",
      "Epoch 18/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.4784 - accuracy: 0.7600\n",
      "Epoch 00018: val_accuracy did not improve from 0.68889\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4829 - accuracy: 0.7598 - val_loss: 0.5522 - val_accuracy: 0.6889\n",
      "Epoch 19/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.4808 - accuracy: 0.7469\n",
      "Epoch 00019: val_accuracy did not improve from 0.68889\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4848 - accuracy: 0.7458 - val_loss: 0.5561 - val_accuracy: 0.6889\n",
      "Epoch 20/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.4649 - accuracy: 0.7613\n",
      "Epoch 00020: val_accuracy improved from 0.68889 to 0.70000, saving model to models/CNN2_dataset_2_slide10_20.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4727 - accuracy: 0.7570 - val_loss: 0.5699 - val_accuracy: 0.7000\n",
      "Epoch 21/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.4768 - accuracy: 0.7516\n",
      "Epoch 00021: val_accuracy did not improve from 0.70000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4666 - accuracy: 0.7570 - val_loss: 0.5993 - val_accuracy: 0.6333\n",
      "Epoch 22/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.4488 - accuracy: 0.8029\n",
      "Epoch 00022: val_accuracy improved from 0.70000 to 0.72222, saving model to models/CNN2_dataset_2_slide10_22.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4493 - accuracy: 0.8017 - val_loss: 0.5409 - val_accuracy: 0.7222\n",
      "Epoch 23/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.4485 - accuracy: 0.7548\n",
      "Epoch 00023: val_accuracy did not improve from 0.72222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4512 - accuracy: 0.7514 - val_loss: 0.5751 - val_accuracy: 0.6667\n",
      "Epoch 24/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.4062 - accuracy: 0.8057\n",
      "Epoch 00024: val_accuracy did not improve from 0.72222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4070 - accuracy: 0.8017 - val_loss: 0.5353 - val_accuracy: 0.7111\n",
      "Epoch 25/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.3936 - accuracy: 0.8300\n",
      "Epoch 00025: val_accuracy improved from 0.72222 to 0.76667, saving model to models/CNN2_dataset_2_slide10_25.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3965 - accuracy: 0.8184 - val_loss: 0.4986 - val_accuracy: 0.7667\n",
      "Epoch 26/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.4347 - accuracy: 0.7833\n",
      "Epoch 00026: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4536 - accuracy: 0.7737 - val_loss: 0.5155 - val_accuracy: 0.7667\n",
      "Epoch 27/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.4377 - accuracy: 0.8100\n",
      "Epoch 00027: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4216 - accuracy: 0.8184 - val_loss: 0.5648 - val_accuracy: 0.6778\n",
      "Epoch 28/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.3884 - accuracy: 0.8194\n",
      "Epoch 00028: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3815 - accuracy: 0.8268 - val_loss: 0.5249 - val_accuracy: 0.7222\n",
      "Epoch 29/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.3746 - accuracy: 0.8250\n",
      "Epoch 00029: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3840 - accuracy: 0.8268 - val_loss: 0.4977 - val_accuracy: 0.7556\n",
      "Epoch 30/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.4096 - accuracy: 0.8000\n",
      "Epoch 00030: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.4123 - accuracy: 0.7961 - val_loss: 0.5501 - val_accuracy: 0.6667\n",
      "Epoch 31/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.3674 - accuracy: 0.8065\n",
      "Epoch 00031: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3647 - accuracy: 0.8101 - val_loss: 0.5105 - val_accuracy: 0.7222\n",
      "Epoch 32/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8200\n",
      "Epoch 00032: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3740 - accuracy: 0.8240 - val_loss: 0.4959 - val_accuracy: 0.7222\n",
      "Epoch 33/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.3689 - accuracy: 0.8281\n",
      "Epoch 00033: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3584 - accuracy: 0.8324 - val_loss: 0.4844 - val_accuracy: 0.7111\n",
      "Epoch 34/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.8486\n",
      "Epoch 00034: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3463 - accuracy: 0.8492 - val_loss: 0.5072 - val_accuracy: 0.7000\n",
      "Epoch 35/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.3669 - accuracy: 0.8088\n",
      "Epoch 00035: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3645 - accuracy: 0.8101 - val_loss: 0.4709 - val_accuracy: 0.7444\n",
      "Epoch 36/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.3722 - accuracy: 0.8100\n",
      "Epoch 00036: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3778 - accuracy: 0.8073 - val_loss: 0.5084 - val_accuracy: 0.7000\n",
      "Epoch 37/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.3560 - accuracy: 0.8313\n",
      "Epoch 00037: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3449 - accuracy: 0.8408 - val_loss: 0.4935 - val_accuracy: 0.7111\n",
      "Epoch 38/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.3541 - accuracy: 0.8333\n",
      "Epoch 00038: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3565 - accuracy: 0.8324 - val_loss: 0.4586 - val_accuracy: 0.7111\n",
      "Epoch 39/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.3756 - accuracy: 0.8324\n",
      "Epoch 00039: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3674 - accuracy: 0.8380 - val_loss: 0.4506 - val_accuracy: 0.7444\n",
      "Epoch 40/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.3242 - accuracy: 0.8531\n",
      "Epoch 00040: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3148 - accuracy: 0.8603 - val_loss: 0.4556 - val_accuracy: 0.7333\n",
      "Epoch 41/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.3206 - accuracy: 0.8516\n",
      "Epoch 00041: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3255 - accuracy: 0.8464 - val_loss: 0.4721 - val_accuracy: 0.7222\n",
      "Epoch 42/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.3308 - accuracy: 0.8548\n",
      "Epoch 00042: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3292 - accuracy: 0.8603 - val_loss: 0.4490 - val_accuracy: 0.7333\n",
      "Epoch 43/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.3237 - accuracy: 0.8645\n",
      "Epoch 00043: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3291 - accuracy: 0.8603 - val_loss: 0.4461 - val_accuracy: 0.7333\n",
      "Epoch 44/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.3342 - accuracy: 0.8343\n",
      "Epoch 00044: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3325 - accuracy: 0.8352 - val_loss: 0.4482 - val_accuracy: 0.7111\n",
      "Epoch 45/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.2833 - accuracy: 0.8909\n",
      "Epoch 00045: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2898 - accuracy: 0.8855 - val_loss: 0.4483 - val_accuracy: 0.7000\n",
      "Epoch 46/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.3019 - accuracy: 0.8559\n",
      "Epoch 00046: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3120 - accuracy: 0.8492 - val_loss: 0.4587 - val_accuracy: 0.6778\n",
      "Epoch 47/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2689 - accuracy: 0.8900\n",
      "Epoch 00047: val_accuracy did not improve from 0.76667\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2882 - accuracy: 0.8771 - val_loss: 0.4576 - val_accuracy: 0.6778\n",
      "Epoch 48/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2980 - accuracy: 0.8419\n",
      "Epoch 00048: val_accuracy improved from 0.76667 to 0.78889, saving model to models/CNN2_dataset_2_slide10_48.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3106 - accuracy: 0.8380 - val_loss: 0.4197 - val_accuracy: 0.7889\n",
      "Epoch 49/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2955 - accuracy: 0.8657\n",
      "Epoch 00049: val_accuracy improved from 0.78889 to 0.81111, saving model to models/CNN2_dataset_2_slide10_49.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2970 - accuracy: 0.8659 - val_loss: 0.4096 - val_accuracy: 0.8111\n",
      "Epoch 50/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.3068 - accuracy: 0.8559\n",
      "Epoch 00050: val_accuracy improved from 0.81111 to 0.82222, saving model to models/CNN2_dataset_2_slide10_50.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3084 - accuracy: 0.8547 - val_loss: 0.4065 - val_accuracy: 0.8222\n",
      "Epoch 51/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.8714\n",
      "Epoch 00051: val_accuracy did not improve from 0.82222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2962 - accuracy: 0.8687 - val_loss: 0.4570 - val_accuracy: 0.7111\n",
      "Epoch 52/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2802 - accuracy: 0.8645\n",
      "Epoch 00052: val_accuracy did not improve from 0.82222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2684 - accuracy: 0.8771 - val_loss: 0.4355 - val_accuracy: 0.7444\n",
      "Epoch 53/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2747 - accuracy: 0.8667\n",
      "Epoch 00053: val_accuracy did not improve from 0.82222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2638 - accuracy: 0.8799 - val_loss: 0.3939 - val_accuracy: 0.7667\n",
      "Epoch 54/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.3112 - accuracy: 0.8613\n",
      "Epoch 00054: val_accuracy did not improve from 0.82222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3014 - accuracy: 0.8631 - val_loss: 0.3975 - val_accuracy: 0.7667\n",
      "Epoch 55/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2465 - accuracy: 0.8800\n",
      "Epoch 00055: val_accuracy did not improve from 0.82222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2512 - accuracy: 0.8799 - val_loss: 0.4157 - val_accuracy: 0.7111\n",
      "Epoch 56/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2459 - accuracy: 0.8886\n",
      "Epoch 00056: val_accuracy improved from 0.82222 to 0.87778, saving model to models/CNN2_dataset_2_slide10_56.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2457 - accuracy: 0.8911 - val_loss: 0.3369 - val_accuracy: 0.8778\n",
      "Epoch 57/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2598 - accuracy: 0.8871\n",
      "Epoch 00057: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2527 - accuracy: 0.8855 - val_loss: 0.3914 - val_accuracy: 0.7222\n",
      "Epoch 58/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.3182 - accuracy: 0.8514\n",
      "Epoch 00058: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.3204 - accuracy: 0.8520 - val_loss: 0.3830 - val_accuracy: 0.7556\n",
      "Epoch 59/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2287 - accuracy: 0.9065\n",
      "Epoch 00059: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2225 - accuracy: 0.9078 - val_loss: 0.3953 - val_accuracy: 0.7111\n",
      "Epoch 60/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2313 - accuracy: 0.8914\n",
      "Epoch 00060: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2312 - accuracy: 0.8911 - val_loss: 0.3312 - val_accuracy: 0.8222\n",
      "Epoch 61/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2228 - accuracy: 0.9000\n",
      "Epoch 00061: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2331 - accuracy: 0.8939 - val_loss: 0.3310 - val_accuracy: 0.8333\n",
      "Epoch 62/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2331 - accuracy: 0.8833\n",
      "Epoch 00062: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2315 - accuracy: 0.8883 - val_loss: 0.3413 - val_accuracy: 0.8000\n",
      "Epoch 63/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2437 - accuracy: 0.8900\n",
      "Epoch 00063: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2308 - accuracy: 0.8994 - val_loss: 0.3760 - val_accuracy: 0.7222\n",
      "Epoch 64/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2313 - accuracy: 0.9097\n",
      "Epoch 00064: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2232 - accuracy: 0.9162 - val_loss: 0.3380 - val_accuracy: 0.7889\n",
      "Epoch 65/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.2760 - accuracy: 0.8788\n",
      "Epoch 00065: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2781 - accuracy: 0.8715 - val_loss: 0.4744 - val_accuracy: 0.7222\n",
      "Epoch 66/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2416 - accuracy: 0.8871\n",
      "Epoch 00066: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2258 - accuracy: 0.8966 - val_loss: 0.4084 - val_accuracy: 0.7222\n",
      "Epoch 67/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2114 - accuracy: 0.9000\n",
      "Epoch 00067: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2171 - accuracy: 0.8994 - val_loss: 0.3192 - val_accuracy: 0.8222\n",
      "Epoch 68/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2118 - accuracy: 0.9000\n",
      "Epoch 00068: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2138 - accuracy: 0.8994 - val_loss: 0.3376 - val_accuracy: 0.7778\n",
      "Epoch 69/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.8943\n",
      "Epoch 00069: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2098 - accuracy: 0.8939 - val_loss: 0.3612 - val_accuracy: 0.7111\n",
      "Epoch 70/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2084 - accuracy: 0.9161\n",
      "Epoch 00070: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2059 - accuracy: 0.9162 - val_loss: 0.3339 - val_accuracy: 0.7778\n",
      "Epoch 71/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1794 - accuracy: 0.9290\n",
      "Epoch 00071: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1924 - accuracy: 0.9246 - val_loss: 0.3075 - val_accuracy: 0.8111\n",
      "Epoch 72/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2412 - accuracy: 0.9000\n",
      "Epoch 00072: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2512 - accuracy: 0.8883 - val_loss: 0.3161 - val_accuracy: 0.8222\n",
      "Epoch 73/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.2451 - accuracy: 0.9061\n",
      "Epoch 00073: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2410 - accuracy: 0.9078 - val_loss: 0.3119 - val_accuracy: 0.8222\n",
      "Epoch 74/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.2248 - accuracy: 0.9212\n",
      "Epoch 00074: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2249 - accuracy: 0.9190 - val_loss: 0.3015 - val_accuracy: 0.8778\n",
      "Epoch 75/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2084 - accuracy: 0.9257\n",
      "Epoch 00075: val_accuracy did not improve from 0.87778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2061 - accuracy: 0.9274 - val_loss: 0.3060 - val_accuracy: 0.8556\n",
      "Epoch 76/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.2178 - accuracy: 0.8774\n",
      "Epoch 00076: val_accuracy improved from 0.87778 to 0.91111, saving model to models/CNN2_dataset_2_slide10_76.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2013 - accuracy: 0.8911 - val_loss: 0.2736 - val_accuracy: 0.9111\n",
      "Epoch 77/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2061 - accuracy: 0.9229\n",
      "Epoch 00077: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2058 - accuracy: 0.9218 - val_loss: 0.2835 - val_accuracy: 0.8778\n",
      "Epoch 78/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1700 - accuracy: 0.9200\n",
      "Epoch 00078: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1597 - accuracy: 0.9246 - val_loss: 0.2691 - val_accuracy: 0.8667\n",
      "Epoch 79/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1963 - accuracy: 0.9267\n",
      "Epoch 00079: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2046 - accuracy: 0.9190 - val_loss: 0.3038 - val_accuracy: 0.7778\n",
      "Epoch 80/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2155 - accuracy: 0.9000\n",
      "Epoch 00080: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1968 - accuracy: 0.9106 - val_loss: 0.2582 - val_accuracy: 0.8667\n",
      "Epoch 81/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1830 - accuracy: 0.9200\n",
      "Epoch 00081: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2070 - accuracy: 0.9134 - val_loss: 0.2292 - val_accuracy: 0.9111\n",
      "Epoch 82/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2388 - accuracy: 0.9233\n",
      "Epoch 00082: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2367 - accuracy: 0.9246 - val_loss: 0.2779 - val_accuracy: 0.8667\n",
      "Epoch 83/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1577 - accuracy: 0.9467\n",
      "Epoch 00083: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1601 - accuracy: 0.9385 - val_loss: 0.2453 - val_accuracy: 0.9111\n",
      "Epoch 84/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2438 - accuracy: 0.9133\n",
      "Epoch 00084: val_accuracy did not improve from 0.91111\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2243 - accuracy: 0.9190 - val_loss: 0.2641 - val_accuracy: 0.8889\n",
      "Epoch 85/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1551 - accuracy: 0.9355\n",
      "Epoch 00085: val_accuracy improved from 0.91111 to 0.92222, saving model to models/CNN2_dataset_2_slide10_85.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1681 - accuracy: 0.9330 - val_loss: 0.2224 - val_accuracy: 0.9222\n",
      "Epoch 86/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1650 - accuracy: 0.9314\n",
      "Epoch 00086: val_accuracy did not improve from 0.92222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1639 - accuracy: 0.9302 - val_loss: 0.2246 - val_accuracy: 0.9222\n",
      "Epoch 87/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2045 - accuracy: 0.9167\n",
      "Epoch 00087: val_accuracy did not improve from 0.92222\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2152 - accuracy: 0.9106 - val_loss: 0.2306 - val_accuracy: 0.9222\n",
      "Epoch 88/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.2042 - accuracy: 0.9200\n",
      "Epoch 00088: val_accuracy improved from 0.92222 to 0.93333, saving model to models/CNN2_dataset_2_slide10_88.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2056 - accuracy: 0.9190 - val_loss: 0.2392 - val_accuracy: 0.9333\n",
      "Epoch 89/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.9371\n",
      "Epoch 00089: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1765 - accuracy: 0.9385 - val_loss: 0.2400 - val_accuracy: 0.9000\n",
      "Epoch 90/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1987 - accuracy: 0.9200\n",
      "Epoch 00090: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1954 - accuracy: 0.9218 - val_loss: 0.2911 - val_accuracy: 0.7778\n",
      "Epoch 91/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1770 - accuracy: 0.9323\n",
      "Epoch 00091: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1638 - accuracy: 0.9358 - val_loss: 0.2363 - val_accuracy: 0.8778\n",
      "Epoch 92/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9457\n",
      "Epoch 00092: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1565 - accuracy: 0.9413 - val_loss: 0.2015 - val_accuracy: 0.9333\n",
      "Epoch 93/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1897 - accuracy: 0.9097\n",
      "Epoch 00093: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1931 - accuracy: 0.9078 - val_loss: 0.2909 - val_accuracy: 0.8000\n",
      "Epoch 94/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.2369 - accuracy: 0.8967\n",
      "Epoch 00094: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.2142 - accuracy: 0.9106 - val_loss: 0.2573 - val_accuracy: 0.8556\n",
      "Epoch 95/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1713 - accuracy: 0.9333\n",
      "Epoch 00095: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1659 - accuracy: 0.9330 - val_loss: 0.2089 - val_accuracy: 0.9333\n",
      "Epoch 96/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1316 - accuracy: 0.9571\n",
      "Epoch 00096: val_accuracy did not improve from 0.93333\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1428 - accuracy: 0.9553 - val_loss: 0.2066 - val_accuracy: 0.9222\n",
      "Epoch 97/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1689 - accuracy: 0.9323\n",
      "Epoch 00097: val_accuracy improved from 0.93333 to 0.95556, saving model to models/CNN2_dataset_2_slide10_97.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1652 - accuracy: 0.9358 - val_loss: 0.1990 - val_accuracy: 0.9556\n",
      "Epoch 98/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1191 - accuracy: 0.9600\n",
      "Epoch 00098: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1251 - accuracy: 0.9553 - val_loss: 0.2043 - val_accuracy: 0.9111\n",
      "Epoch 99/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1958 - accuracy: 0.9333\n",
      "Epoch 00099: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1907 - accuracy: 0.9358 - val_loss: 0.2682 - val_accuracy: 0.7889\n",
      "Epoch 100/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1891 - accuracy: 0.9200\n",
      "Epoch 00100: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1851 - accuracy: 0.9218 - val_loss: 0.2276 - val_accuracy: 0.8889\n",
      "Epoch 101/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9486\n",
      "Epoch 00101: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1330 - accuracy: 0.9469 - val_loss: 0.1939 - val_accuracy: 0.9111\n",
      "Epoch 102/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1757 - accuracy: 0.9300\n",
      "Epoch 00102: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1780 - accuracy: 0.9274 - val_loss: 0.1964 - val_accuracy: 0.9111\n",
      "Epoch 103/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1327 - accuracy: 0.9500\n",
      "Epoch 00103: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1328 - accuracy: 0.9525 - val_loss: 0.1848 - val_accuracy: 0.9556\n",
      "Epoch 104/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1344 - accuracy: 0.9467\n",
      "Epoch 00104: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1381 - accuracy: 0.9469 - val_loss: 0.1729 - val_accuracy: 0.9333\n",
      "Epoch 105/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1548 - accuracy: 0.9500\n",
      "Epoch 00105: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1541 - accuracy: 0.9497 - val_loss: 0.2080 - val_accuracy: 0.9000\n",
      "Epoch 106/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1115 - accuracy: 0.9567\n",
      "Epoch 00106: val_accuracy did not improve from 0.95556\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1147 - accuracy: 0.9497 - val_loss: 0.1760 - val_accuracy: 0.9222\n",
      "Epoch 107/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1302 - accuracy: 0.9467\n",
      "Epoch 00107: val_accuracy improved from 0.95556 to 0.97778, saving model to models/CNN2_dataset_2_slide10_107.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1378 - accuracy: 0.9441 - val_loss: 0.1556 - val_accuracy: 0.9778\n",
      "Epoch 108/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1825 - accuracy: 0.9129\n",
      "Epoch 00108: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1631 - accuracy: 0.9246 - val_loss: 0.1889 - val_accuracy: 0.9222\n",
      "Epoch 109/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1721 - accuracy: 0.9400\n",
      "Epoch 00109: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1687 - accuracy: 0.9413 - val_loss: 0.1664 - val_accuracy: 0.9778\n",
      "Epoch 110/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1594 - accuracy: 0.9353\n",
      "Epoch 00110: val_accuracy did not improve from 0.97778\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1562 - accuracy: 0.9358 - val_loss: 0.1723 - val_accuracy: 0.9444\n",
      "Epoch 111/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9457\n",
      "Epoch 00111: val_accuracy improved from 0.97778 to 1.00000, saving model to models/CNN2_dataset_2_slide10_111.h5\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1561 - accuracy: 0.9469 - val_loss: 0.1580 - val_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1688 - accuracy: 0.9300\n",
      "Epoch 00112: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1535 - accuracy: 0.9413 - val_loss: 0.1793 - val_accuracy: 0.9111\n",
      "Epoch 113/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1032 - accuracy: 0.9600\n",
      "Epoch 00113: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1103 - accuracy: 0.9581 - val_loss: 0.1712 - val_accuracy: 0.9111\n",
      "Epoch 114/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1530 - accuracy: 0.9400\n",
      "Epoch 00114: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1565 - accuracy: 0.9358 - val_loss: 0.1750 - val_accuracy: 0.9222\n",
      "Epoch 115/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1535 - accuracy: 0.9567\n",
      "Epoch 00115: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1426 - accuracy: 0.9553 - val_loss: 0.1634 - val_accuracy: 0.9222\n",
      "Epoch 116/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1544 - accuracy: 0.9367\n",
      "Epoch 00116: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1459 - accuracy: 0.9385 - val_loss: 0.1522 - val_accuracy: 0.9667\n",
      "Epoch 117/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1629 - accuracy: 0.9323\n",
      "Epoch 00117: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1639 - accuracy: 0.9330 - val_loss: 0.1969 - val_accuracy: 0.9000\n",
      "Epoch 118/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.1546 - accuracy: 0.9333\n",
      "Epoch 00118: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1482 - accuracy: 0.9358 - val_loss: 0.1567 - val_accuracy: 0.9222\n",
      "Epoch 119/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1110 - accuracy: 0.9500\n",
      "Epoch 00119: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1070 - accuracy: 0.9553 - val_loss: 0.1494 - val_accuracy: 0.9778\n",
      "Epoch 120/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1433 - accuracy: 0.9500\n",
      "Epoch 00120: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1381 - accuracy: 0.9525 - val_loss: 0.1396 - val_accuracy: 0.9889\n",
      "Epoch 121/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1376 - accuracy: 0.9613\n",
      "Epoch 00121: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1353 - accuracy: 0.9609 - val_loss: 0.1445 - val_accuracy: 0.9889\n",
      "Epoch 122/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1209 - accuracy: 0.9600\n",
      "Epoch 00122: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1357 - accuracy: 0.9525 - val_loss: 0.1434 - val_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1257 - accuracy: 0.9433\n",
      "Epoch 00123: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1278 - accuracy: 0.9413 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1094 - accuracy: 0.9467\n",
      "Epoch 00124: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1055 - accuracy: 0.9525 - val_loss: 0.1332 - val_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1049 - accuracy: 0.9588\n",
      "Epoch 00125: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1011 - accuracy: 0.9609 - val_loss: 0.1495 - val_accuracy: 0.9778\n",
      "Epoch 126/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9286\n",
      "Epoch 00126: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1473 - accuracy: 0.9302 - val_loss: 0.1287 - val_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.1249 - accuracy: 0.9455\n",
      "Epoch 00127: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1205 - accuracy: 0.9497 - val_loss: 0.1506 - val_accuracy: 0.9556\n",
      "Epoch 128/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0866 - accuracy: 0.9818\n",
      "Epoch 00128: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0841 - accuracy: 0.9832 - val_loss: 0.1220 - val_accuracy: 0.9889\n",
      "Epoch 129/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.1073 - accuracy: 0.9515\n",
      "Epoch 00129: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1141 - accuracy: 0.9497 - val_loss: 0.0977 - val_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9486\n",
      "Epoch 00130: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1411 - accuracy: 0.9469 - val_loss: 0.1257 - val_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0873 - accuracy: 0.9733\n",
      "Epoch 00131: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1058 - accuracy: 0.9693 - val_loss: 0.1271 - val_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1284 - accuracy: 0.9400\n",
      "Epoch 00132: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1199 - accuracy: 0.9469 - val_loss: 0.1369 - val_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9743\n",
      "Epoch 00133: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0801 - accuracy: 0.9749 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0937 - accuracy: 0.9700\n",
      "Epoch 00134: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0990 - accuracy: 0.9637 - val_loss: 0.1182 - val_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0809 - accuracy: 0.9600\n",
      "Epoch 00135: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0824 - accuracy: 0.9581 - val_loss: 0.0982 - val_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1035 - accuracy: 0.9600\n",
      "Epoch 00136: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0989 - accuracy: 0.9637 - val_loss: 0.1416 - val_accuracy: 0.9222\n",
      "Epoch 137/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1047 - accuracy: 0.9543\n",
      "Epoch 00137: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1029 - accuracy: 0.9553 - val_loss: 0.1352 - val_accuracy: 0.9222\n",
      "Epoch 138/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1280 - accuracy: 0.9571\n",
      "Epoch 00138: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1263 - accuracy: 0.9581 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9486\n",
      "Epoch 00139: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1176 - accuracy: 0.9497 - val_loss: 0.1084 - val_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1018 - accuracy: 0.9533\n",
      "Epoch 00140: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0967 - accuracy: 0.9553 - val_loss: 0.1143 - val_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0736 - accuracy: 0.9588\n",
      "Epoch 00141: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0724 - accuracy: 0.9609 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0951 - accuracy: 0.9571\n",
      "Epoch 00142: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0932 - accuracy: 0.9581 - val_loss: 0.1143 - val_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1118 - accuracy: 0.9581\n",
      "Epoch 00143: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1075 - accuracy: 0.9609 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.1294 - accuracy: 0.9500\n",
      "Epoch 00144: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1200 - accuracy: 0.9525 - val_loss: 0.0929 - val_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1189 - accuracy: 0.9543\n",
      "Epoch 00145: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1171 - accuracy: 0.9553 - val_loss: 0.1282 - val_accuracy: 0.9667\n",
      "Epoch 146/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1061 - accuracy: 0.9543\n",
      "Epoch 00146: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1056 - accuracy: 0.9553 - val_loss: 0.1199 - val_accuracy: 0.9556\n",
      "Epoch 147/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.1051 - accuracy: 0.9485\n",
      "Epoch 00147: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0976 - accuracy: 0.9525 - val_loss: 0.1126 - val_accuracy: 0.9889\n",
      "Epoch 148/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9829\n",
      "Epoch 00148: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0715 - accuracy: 0.9804 - val_loss: 0.1143 - val_accuracy: 0.9222\n",
      "Epoch 149/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1480 - accuracy: 0.9514\n",
      "Epoch 00149: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1450 - accuracy: 0.9525 - val_loss: 0.1090 - val_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0888 - accuracy: 0.9667\n",
      "Epoch 00150: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0881 - accuracy: 0.9665 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0933 - accuracy: 0.9636\n",
      "Epoch 00151: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0915 - accuracy: 0.9665 - val_loss: 0.1190 - val_accuracy: 0.9889\n",
      "Epoch 152/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0914 - accuracy: 0.9706\n",
      "Epoch 00152: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0916 - accuracy: 0.9693 - val_loss: 0.1017 - val_accuracy: 0.9889\n",
      "Epoch 153/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.1010 - accuracy: 0.9636\n",
      "Epoch 00153: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0996 - accuracy: 0.9637 - val_loss: 0.1103 - val_accuracy: 0.9889\n",
      "Epoch 154/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0893 - accuracy: 0.9613\n",
      "Epoch 00154: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0859 - accuracy: 0.9637 - val_loss: 0.1287 - val_accuracy: 0.9667\n",
      "Epoch 155/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0672 - accuracy: 0.9806\n",
      "Epoch 00155: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0773 - accuracy: 0.9777 - val_loss: 0.1028 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0737 - accuracy: 0.9677\n",
      "Epoch 00156: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0710 - accuracy: 0.9693 - val_loss: 0.1248 - val_accuracy: 0.9222\n",
      "Epoch 157/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.1199 - accuracy: 0.9613\n",
      "Epoch 00157: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1192 - accuracy: 0.9609 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0614 - accuracy: 0.9774\n",
      "Epoch 00158: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0691 - accuracy: 0.9693 - val_loss: 0.0827 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0761 - accuracy: 0.9667\n",
      "Epoch 00159: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0771 - accuracy: 0.9665 - val_loss: 0.0896 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.1365 - accuracy: 0.9457\n",
      "Epoch 00160: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1342 - accuracy: 0.9469 - val_loss: 0.1327 - val_accuracy: 0.9222\n",
      "Epoch 161/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.1097 - accuracy: 0.9515\n",
      "Epoch 00161: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1042 - accuracy: 0.9553 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.9771\n",
      "Epoch 00162: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0714 - accuracy: 0.9777 - val_loss: 0.0991 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.1123 - accuracy: 0.9606\n",
      "Epoch 00163: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1171 - accuracy: 0.9553 - val_loss: 0.1343 - val_accuracy: 0.9111\n",
      "Epoch 164/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0662 - accuracy: 0.9733\n",
      "Epoch 00164: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0658 - accuracy: 0.9721 - val_loss: 0.1080 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0835 - accuracy: 0.9727\n",
      "Epoch 00165: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0823 - accuracy: 0.9721 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0699 - accuracy: 0.9743\n",
      "Epoch 00166: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0686 - accuracy: 0.9749 - val_loss: 0.0795 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0766 - accuracy: 0.9700\n",
      "Epoch 00167: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0700 - accuracy: 0.9749 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0729 - accuracy: 0.9656\n",
      "Epoch 00168: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0820 - accuracy: 0.9581 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1111 - accuracy: 0.9706\n",
      "Epoch 00169: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1079 - accuracy: 0.9721 - val_loss: 0.1065 - val_accuracy: 0.9889\n",
      "Epoch 170/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0760 - accuracy: 0.9688\n",
      "Epoch 00170: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0743 - accuracy: 0.9721 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0690 - accuracy: 0.9758\n",
      "Epoch 00171: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0676 - accuracy: 0.9777 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 172/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0639 - accuracy: 0.9750\n",
      "Epoch 00172: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0617 - accuracy: 0.9777 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0832 - accuracy: 0.9750\n",
      "Epoch 00173: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0843 - accuracy: 0.9721 - val_loss: 0.0738 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0738 - accuracy: 0.9677\n",
      "Epoch 00174: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0797 - accuracy: 0.9665 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0926 - accuracy: 0.9656\n",
      "Epoch 00175: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0911 - accuracy: 0.9665 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0860 - accuracy: 0.9594\n",
      "Epoch 00176: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0817 - accuracy: 0.9609 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0649 - accuracy: 0.9812\n",
      "Epoch 00177: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0711 - accuracy: 0.9749 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0655 - accuracy: 0.9767\n",
      "Epoch 00178: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0703 - accuracy: 0.9749 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0915 - accuracy: 0.9618\n",
      "Epoch 00179: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0943 - accuracy: 0.9609 - val_loss: 0.0792 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0772 - accuracy: 0.9667\n",
      "Epoch 00180: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0746 - accuracy: 0.9693 - val_loss: 0.0920 - val_accuracy: 0.9889\n",
      "Epoch 181/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 0.9800\n",
      "Epoch 00181: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0722 - accuracy: 0.9777 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9771\n",
      "Epoch 00182: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0602 - accuracy: 0.9749 - val_loss: 0.0813 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0815 - accuracy: 0.9600\n",
      "Epoch 00183: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0823 - accuracy: 0.9581 - val_loss: 0.0526 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0572 - accuracy: 0.9735\n",
      "Epoch 00184: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0609 - accuracy: 0.9721 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0636 - accuracy: 0.9824\n",
      "Epoch 00185: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0719 - accuracy: 0.9804 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0742 - accuracy: 0.9765\n",
      "Epoch 00186: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0717 - accuracy: 0.9777 - val_loss: 0.0842 - val_accuracy: 0.9889\n",
      "Epoch 187/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0734 - accuracy: 0.9758\n",
      "Epoch 00187: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0745 - accuracy: 0.9749 - val_loss: 0.0807 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0502 - accuracy: 0.9824\n",
      "Epoch 00188: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0526 - accuracy: 0.9804 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0396 - accuracy: 0.9853\n",
      "Epoch 00189: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0399 - accuracy: 0.9860 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0527 - accuracy: 0.9794\n",
      "Epoch 00190: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0530 - accuracy: 0.9804 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0521 - accuracy: 0.9758\n",
      "Epoch 00191: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0547 - accuracy: 0.9721 - val_loss: 0.0568 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0572 - accuracy: 0.9794\n",
      "Epoch 00192: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0797 - accuracy: 0.9794\n",
      "Epoch 00193: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0778 - accuracy: 0.9804 - val_loss: 0.0909 - val_accuracy: 0.9889\n",
      "Epoch 194/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0804 - accuracy: 0.9647\n",
      "Epoch 00194: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0776 - accuracy: 0.9665 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0626 - accuracy: 0.9758\n",
      "Epoch 00195: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0643 - accuracy: 0.9777 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9686\n",
      "Epoch 00196: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0680 - accuracy: 0.9693 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0855 - accuracy: 0.9706\n",
      "Epoch 00197: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0928 - accuracy: 0.9693 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0569 - accuracy: 0.9857\n",
      "Epoch 00198: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0557 - accuracy: 0.9860 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0565 - accuracy: 0.9735\n",
      "Epoch 00199: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0577 - accuracy: 0.9721 - val_loss: 0.0867 - val_accuracy: 0.9889\n",
      "Epoch 200/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9800\n",
      "Epoch 00200: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0529 - accuracy: 0.9804 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0594 - accuracy: 0.9879\n",
      "Epoch 00201: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0555 - accuracy: 0.9888 - val_loss: 0.0755 - val_accuracy: 0.9889\n",
      "Epoch 202/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0795 - accuracy: 0.9727\n",
      "Epoch 00202: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0743 - accuracy: 0.9749 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0894 - accuracy: 0.9667\n",
      "Epoch 00203: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0959 - accuracy: 0.9637 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9800\n",
      "Epoch 00204: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0669 - accuracy: 0.9804 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9771\n",
      "Epoch 00205: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0744 - accuracy: 0.9777 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0794 - accuracy: 0.9727\n",
      "Epoch 00206: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0765 - accuracy: 0.9749 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0875 - accuracy: 0.9647\n",
      "Epoch 00207: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0865 - accuracy: 0.9637 - val_loss: 0.0665 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0804 - accuracy: 0.9750\n",
      "Epoch 00208: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0783 - accuracy: 0.9749 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0677 - accuracy: 0.9706\n",
      "Epoch 00209: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0651 - accuracy: 0.9721 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0462 - accuracy: 0.9774\n",
      "Epoch 00210: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0467 - accuracy: 0.9777 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0708 - accuracy: 0.9676\n",
      "Epoch 00211: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0702 - accuracy: 0.9665 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0898 - accuracy: 0.9735\n",
      "Epoch 00212: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0868 - accuracy: 0.9749 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
      "Epoch 213/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0936 - accuracy: 0.9706\n",
      "Epoch 00213: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0896 - accuracy: 0.9721 - val_loss: 0.0728 - val_accuracy: 0.9889\n",
      "Epoch 214/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0463 - accuracy: 0.9848\n",
      "Epoch 00214: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0581 - accuracy: 0.9721 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0597 - accuracy: 0.9800\n",
      "Epoch 00215: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0583 - accuracy: 0.9804 - val_loss: 0.0954 - val_accuracy: 0.9667\n",
      "Epoch 216/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0666 - accuracy: 0.9824\n",
      "Epoch 00216: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0639 - accuracy: 0.9832 - val_loss: 0.0877 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0584 - accuracy: 0.9794\n",
      "Epoch 00217: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0594 - accuracy: 0.9777 - val_loss: 0.0702 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0497 - accuracy: 0.9844\n",
      "Epoch 00218: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0478 - accuracy: 0.9860 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9743\n",
      "Epoch 00219: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0614 - accuracy: 0.9749 - val_loss: 0.0827 - val_accuracy: 0.9889\n",
      "Epoch 220/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0549 - accuracy: 0.9771\n",
      "Epoch 00220: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0548 - accuracy: 0.9777 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0506 - accuracy: 0.9879\n",
      "Epoch 00221: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0471 - accuracy: 0.9888 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0563 - accuracy: 0.9867\n",
      "Epoch 00222: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0504 - accuracy: 0.9888 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0583 - accuracy: 0.9727\n",
      "Epoch 00223: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0603 - accuracy: 0.9721 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0494 - accuracy: 0.9853\n",
      "Epoch 00224: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0475 - accuracy: 0.9860 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0343 - accuracy: 0.9909\n",
      "Epoch 00225: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0342 - accuracy: 0.9916 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0325 - accuracy: 0.9875\n",
      "Epoch 00226: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0330 - accuracy: 0.9860 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0485 - accuracy: 0.9853\n",
      "Epoch 00227: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0490 - accuracy: 0.9860 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0540 - accuracy: 0.9758\n",
      "Epoch 00228: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0554 - accuracy: 0.9721 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0417 - accuracy: 0.9933\n",
      "Epoch 00229: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0451 - accuracy: 0.9916 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0377 - accuracy: 0.9824\n",
      "Epoch 00230: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0378 - accuracy: 0.9832 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0224 - accuracy: 0.9912\n",
      "Epoch 00231: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0226 - accuracy: 0.9916 - val_loss: 0.0449 - val_accuracy: 0.9889\n",
      "Epoch 232/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0440 - accuracy: 0.9800\n",
      "Epoch 00232: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0560 - accuracy: 0.9777 - val_loss: 0.0562 - val_accuracy: 0.9889\n",
      "Epoch 233/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9914\n",
      "Epoch 00233: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.0357 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0513 - accuracy: 0.9812\n",
      "Epoch 00234: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0495 - accuracy: 0.9804 - val_loss: 0.0713 - val_accuracy: 0.9889\n",
      "Epoch 235/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0413 - accuracy: 0.9912\n",
      "Epoch 00235: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0401 - accuracy: 0.9916 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0605 - accuracy: 0.9735\n",
      "Epoch 00236: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0578 - accuracy: 0.9749 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0612 - accuracy: 0.9735\n",
      "Epoch 00237: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0584 - accuracy: 0.9749 - val_loss: 0.0636 - val_accuracy: 0.9889\n",
      "Epoch 238/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0617 - accuracy: 0.9765\n",
      "Epoch 00238: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0590 - accuracy: 0.9777 - val_loss: 0.0458 - val_accuracy: 0.9889\n",
      "Epoch 239/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0606 - accuracy: 0.9800\n",
      "Epoch 00239: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0640 - accuracy: 0.9777 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0212 - accuracy: 0.9937\n",
      "Epoch 00240: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.0606 - val_accuracy: 0.9889\n",
      "Epoch 241/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9800\n",
      "Epoch 00241: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0419 - accuracy: 0.9804 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0271 - accuracy: 0.9882\n",
      "Epoch 00242: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0262 - accuracy: 0.9888 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0487 - accuracy: 0.9818\n",
      "Epoch 00243: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0501 - accuracy: 0.9804 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0459 - accuracy: 0.9710\n",
      "Epoch 00244: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0490 - accuracy: 0.9721 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.1256 - accuracy: 0.9676\n",
      "Epoch 00245: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1224 - accuracy: 0.9665 - val_loss: 0.1061 - val_accuracy: 0.9222\n",
      "Epoch 246/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 0.9829\n",
      "Epoch 00246: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0427 - accuracy: 0.9832 - val_loss: 0.0745 - val_accuracy: 0.9778\n",
      "Epoch 247/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0305 - accuracy: 0.9882\n",
      "Epoch 00247: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0294 - accuracy: 0.9888 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9857\n",
      "Epoch 00248: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0582 - accuracy: 0.9860 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9886\n",
      "Epoch 00249: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0427 - accuracy: 0.9888 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0955 - accuracy: 0.9618\n",
      "Epoch 00250: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0913 - accuracy: 0.9637 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0325 - accuracy: 1.0000\n",
      "Epoch 00251: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0401 - accuracy: 0.9867\n",
      "Epoch 00252: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0385 - accuracy: 0.9860 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 00253: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0502 - accuracy: 0.9824\n",
      "Epoch 00254: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0502 - accuracy: 0.9804 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9857\n",
      "Epoch 00255: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0367 - accuracy: 0.9860 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0820 - accuracy: 0.9767\n",
      "Epoch 00256: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0765 - accuracy: 0.9777 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9857\n",
      "Epoch 00257: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0469 - accuracy: 0.9860 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0351 - accuracy: 0.9879\n",
      "Epoch 00258: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0337 - accuracy: 0.9888 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9800\n",
      "Epoch 00259: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0739 - accuracy: 0.9777 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0491 - accuracy: 0.9788\n",
      "Epoch 00260: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0484 - accuracy: 0.9777 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0799 - accuracy: 0.9806\n",
      "Epoch 00261: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0742 - accuracy: 0.9804 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0749 - accuracy: 0.9833\n",
      "Epoch 00262: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0682 - accuracy: 0.9860 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9886\n",
      "Epoch 00263: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0425 - accuracy: 0.9888 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0327 - accuracy: 0.9970\n",
      "Epoch 00264: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0379 - accuracy: 0.9944 - val_loss: 0.0489 - val_accuracy: 0.9889\n",
      "Epoch 265/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0425 - accuracy: 0.9818\n",
      "Epoch 00265: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0419 - accuracy: 0.9832 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0345 - accuracy: 0.9939\n",
      "Epoch 00266: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0319 - accuracy: 0.9944 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0953 - accuracy: 0.9667\n",
      "Epoch 00267: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0967 - accuracy: 0.9665 - val_loss: 0.1207 - val_accuracy: 0.9111\n",
      "Epoch 268/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0693 - accuracy: 0.9697\n",
      "Epoch 00268: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0651 - accuracy: 0.9721 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0399 - accuracy: 0.9909\n",
      "Epoch 00269: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0371 - accuracy: 0.9916 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0591 - accuracy: 0.9735\n",
      "Epoch 00270: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0590 - accuracy: 0.9749 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0432 - accuracy: 0.9781\n",
      "Epoch 00271: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0393 - accuracy: 0.9804 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0402 - accuracy: 0.9824\n",
      "Epoch 00272: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0385 - accuracy: 0.9832 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9857\n",
      "Epoch 00273: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0307 - accuracy: 0.9860 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9829\n",
      "Epoch 00274: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0466 - accuracy: 0.9832 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9886\n",
      "Epoch 00275: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0473 - accuracy: 0.9888 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0295 - accuracy: 0.9912\n",
      "Epoch 00276: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9943\n",
      "Epoch 00277: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0212 - accuracy: 0.9944 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0163 - accuracy: 0.9939\n",
      "Epoch 00278: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0205 - accuracy: 0.9939\n",
      "Epoch 00279: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0404 - accuracy: 0.9818\n",
      "Epoch 00280: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0427 - accuracy: 0.9804 - val_loss: 0.0439 - val_accuracy: 0.9889\n",
      "Epoch 281/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9829\n",
      "Epoch 00281: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0425 - accuracy: 0.9832 - val_loss: 0.0443 - val_accuracy: 0.9889\n",
      "Epoch 282/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0305 - accuracy: 0.9879\n",
      "Epoch 00282: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0286 - accuracy: 0.9888 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9914\n",
      "Epoch 00283: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0709 - accuracy: 0.9645\n",
      "Epoch 00284: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0644 - accuracy: 0.9665 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0254 - accuracy: 0.9939\n",
      "Epoch 00285: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0288 - accuracy: 0.9906\n",
      "Epoch 00286: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0393 - accuracy: 0.9844\n",
      "Epoch 00287: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.0291 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0618 - accuracy: 0.9839\n",
      "Epoch 00288: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0539 - accuracy: 0.9860 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0287 - accuracy: 0.9909\n",
      "Epoch 00289: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0702 - accuracy: 0.9645\n",
      "Epoch 00290: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0699 - accuracy: 0.9665 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0396 - accuracy: 0.9909\n",
      "Epoch 00291: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0386 - accuracy: 0.9916 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0329 - accuracy: 0.9900\n",
      "Epoch 00292: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9857\n",
      "Epoch 00293: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0368 - accuracy: 0.9860 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0198 - accuracy: 0.9971\n",
      "Epoch 00294: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0295 - accuracy: 0.9944 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9829\n",
      "Epoch 00295: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0402 - accuracy: 0.9804 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0213 - accuracy: 0.9909\n",
      "Epoch 00296: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.0240 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0280 - accuracy: 0.9933\n",
      "Epoch 00297: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0320 - accuracy: 0.9916 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0328 - accuracy: 0.9912\n",
      "Epoch 00298: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0312 - accuracy: 0.9916 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9800\n",
      "Epoch 00299: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0468 - accuracy: 0.9804 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0291 - accuracy: 0.9848\n",
      "Epoch 00300: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0320 - accuracy: 0.9832 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9914\n",
      "Epoch 00301: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 00302: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0438 - accuracy: 0.9774\n",
      "Epoch 00303: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0449 - accuracy: 0.9749 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0463 - accuracy: 0.9867\n",
      "Epoch 00304: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0701 - accuracy: 0.9777 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0245 - accuracy: 0.9900\n",
      "Epoch 00305: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0265 - accuracy: 0.9888 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0947 - accuracy: 0.9735\n",
      "Epoch 00306: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0922 - accuracy: 0.9721 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0267 - accuracy: 0.9937\n",
      "Epoch 00307: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0353 - accuracy: 0.9860 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0273 - accuracy: 0.9939\n",
      "Epoch 00308: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0335 - accuracy: 0.9888 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9914\n",
      "Epoch 00309: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.1187 - accuracy: 0.9700\n",
      "Epoch 00310: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.1054 - accuracy: 0.9721 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0517 - accuracy: 0.9794\n",
      "Epoch 00311: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0495 - accuracy: 0.9804 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0258 - accuracy: 0.9912\n",
      "Epoch 00312: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0199 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0322 - accuracy: 0.9882\n",
      "Epoch 00313: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0320 - accuracy: 0.9888 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0173 - accuracy: 0.9971\n",
      "Epoch 00314: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0170 - accuracy: 0.9972 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0409 - accuracy: 0.9824\n",
      "Epoch 00315: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0395 - accuracy: 0.9832 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0148 - accuracy: 0.9971\n",
      "Epoch 00316: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0330 - accuracy: 0.9909\n",
      "Epoch 00317: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0322 - accuracy: 0.9916 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0400 - accuracy: 0.9879\n",
      "Epoch 00318: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0275 - accuracy: 0.9844\n",
      "Epoch 00319: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0262 - accuracy: 0.9860 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0220 - accuracy: 0.9933\n",
      "Epoch 00320: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0207 - accuracy: 0.9944 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 00321: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0236 - accuracy: 0.9912\n",
      "Epoch 00322: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9943\n",
      "Epoch 00323: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0238 - accuracy: 0.9944 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9886\n",
      "Epoch 00324: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0457 - accuracy: 0.9888 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0408 - accuracy: 0.9767\n",
      "Epoch 00325: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0352 - accuracy: 0.9804 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9971\n",
      "Epoch 00326: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0146 - accuracy: 0.9972 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9971\n",
      "Epoch 00327: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0190 - accuracy: 0.9969\n",
      "Epoch 00328: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0171 - accuracy: 0.9972 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0218 - accuracy: 0.9909\n",
      "Epoch 00329: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0225 - accuracy: 0.9888 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0364 - accuracy: 0.9824\n",
      "Epoch 00330: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0350 - accuracy: 0.9832 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9943\n",
      "Epoch 00331: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0140 - accuracy: 0.9944 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0098 - accuracy: 0.9967\n",
      "Epoch 00332: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0260 - accuracy: 0.9888 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0552 - accuracy: 0.9806\n",
      "Epoch 00333: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0550 - accuracy: 0.9804 - val_loss: 0.0395 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0361 - accuracy: 0.9933\n",
      "Epoch 00334: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0365 - accuracy: 0.9916 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0367 - accuracy: 0.9800\n",
      "Epoch 00335: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0375 - accuracy: 0.9804 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9800\n",
      "Epoch 00336: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0454 - accuracy: 0.9804 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9857\n",
      "Epoch 00337: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.0213 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0195 - accuracy: 0.9939\n",
      "Epoch 00338: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0466 - accuracy: 0.9916 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9943\n",
      "Epoch 00339: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0290 - accuracy: 0.9944 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0244 - accuracy: 0.9912\n",
      "Epoch 00340: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9886\n",
      "Epoch 00341: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0239 - accuracy: 0.9888 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9886\n",
      "Epoch 00342: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0306 - accuracy: 0.9888 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9914\n",
      "Epoch 00343: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0325 - accuracy: 0.9916 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 00344: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0168 - accuracy: 0.9933\n",
      "Epoch 00345: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0170 - accuracy: 0.9916 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9886\n",
      "Epoch 00346: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0293 - accuracy: 0.9888 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9857\n",
      "Epoch 00347: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0293 - accuracy: 0.9860 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0161 - accuracy: 0.9971\n",
      "Epoch 00348: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.0186 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0219 - accuracy: 0.9867\n",
      "Epoch 00349: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0190 - accuracy: 0.9888 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0122 - accuracy: 0.9935\n",
      "Epoch 00350: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0110 - accuracy: 0.9944 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9829\n",
      "Epoch 00351: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0244 - accuracy: 0.9832 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0351 - accuracy: 0.9871\n",
      "Epoch 00352: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0338 - accuracy: 0.9888 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0255 - accuracy: 0.9912\n",
      "Epoch 00353: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0271 - accuracy: 0.9888 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0739 - accuracy: 0.9727\n",
      "Epoch 00354: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0826 - accuracy: 0.9721 - val_loss: 0.0172 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0271 - accuracy: 0.9903\n",
      "Epoch 00355: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0810 - val_accuracy: 0.9333\n",
      "Epoch 356/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0402 - accuracy: 0.9853\n",
      "Epoch 00356: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0390 - accuracy: 0.9860 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9914\n",
      "Epoch 00357: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0291 - accuracy: 0.9916 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0361 - accuracy: 0.9882\n",
      "Epoch 00358: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0344 - accuracy: 0.9888 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0183 - accuracy: 0.9939\n",
      "Epoch 00359: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9971\n",
      "Epoch 00360: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9914\n",
      "Epoch 00361: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0156 - accuracy: 0.9916 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9971\n",
      "Epoch 00362: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0249 - accuracy: 0.9972 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0279 - accuracy: 0.9867\n",
      "Epoch 00363: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0242 - accuracy: 0.9888 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9886\n",
      "Epoch 00364: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0308 - accuracy: 0.9888 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0229 - accuracy: 0.9867\n",
      "Epoch 00365: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0350 - accuracy: 0.9832 - val_loss: 0.0502 - val_accuracy: 0.9778\n",
      "Epoch 366/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0444 - accuracy: 0.9875\n",
      "Epoch 00366: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0532 - accuracy: 0.9804 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9829\n",
      "Epoch 00367: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0525 - accuracy: 0.9832 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0311 - accuracy: 0.9903\n",
      "Epoch 00368: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0350 - accuracy: 0.9888 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0365 - accuracy: 0.9900\n",
      "Epoch 00369: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0313 - accuracy: 0.9916 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9914\n",
      "Epoch 00370: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0341 - accuracy: 0.9833\n",
      "Epoch 00371: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0457 - accuracy: 0.9804 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9829\n",
      "Epoch 00372: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0957 - accuracy: 0.9777 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0403 - accuracy: 0.9806\n",
      "Epoch 00373: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0426 - accuracy: 0.9804 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0261 - accuracy: 0.9912\n",
      "Epoch 00374: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9971\n",
      "Epoch 00375: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0162 - accuracy: 0.9967\n",
      "Epoch 00376: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0175 - accuracy: 0.9972 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0356 - accuracy: 0.9903\n",
      "Epoch 00377: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0311 - accuracy: 0.9916 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0235 - accuracy: 0.9871\n",
      "Epoch 00378: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0271 - accuracy: 0.9860 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0099 - accuracy: 0.9971\n",
      "Epoch 00379: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 00380: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 00381: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9943\n",
      "Epoch 00382: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0126 - accuracy: 0.9944 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9943\n",
      "Epoch 00383: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0228 - accuracy: 0.9944 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9971\n",
      "Epoch 00384: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0164 - accuracy: 0.9972 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0090 - accuracy: 0.9967\n",
      "Epoch 00385: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9886\n",
      "Epoch 00386: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0200 - accuracy: 0.9888 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0334 - accuracy: 0.9933\n",
      "Epoch 00387: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0326 - accuracy: 0.9916 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0380 - accuracy: 0.9867\n",
      "Epoch 00388: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0392 - accuracy: 0.9860 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0169 - accuracy: 0.9935\n",
      "Epoch 00389: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9971\n",
      "Epoch 00390: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0253 - accuracy: 0.9871\n",
      "Epoch 00391: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0261 - accuracy: 0.9860 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0206 - accuracy: 0.9967\n",
      "Epoch 00392: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0196 - accuracy: 0.9972 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9914\n",
      "Epoch 00393: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9829\n",
      "Epoch 00394: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0460 - accuracy: 0.9832 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0255 - accuracy: 0.9867\n",
      "Epoch 00395: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0229 - accuracy: 0.9888 - val_loss: 0.0150 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0316 - accuracy: 0.9903\n",
      "Epoch 00396: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0378 - accuracy: 0.9888 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0396 - accuracy: 0.9833\n",
      "Epoch 00397: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0336 - accuracy: 0.9860 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 00398: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0392 - accuracy: 0.9806\n",
      "Epoch 00399: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0402 - accuracy: 0.9777 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0090 - accuracy: 0.9967\n",
      "Epoch 00400: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0100 - accuracy: 0.9968\n",
      "Epoch 00401: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0095 - accuracy: 0.9933\n",
      "Epoch 00402: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0090 - accuracy: 0.9944 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9857\n",
      "Epoch 00403: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0238 - accuracy: 0.9860 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0700 - accuracy: 0.9743\n",
      "Epoch 00404: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0685 - accuracy: 0.9749 - val_loss: 0.0785 - val_accuracy: 0.9556\n",
      "Epoch 405/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0373 - accuracy: 0.9774\n",
      "Epoch 00405: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0328 - accuracy: 0.9804 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0493 - accuracy: 0.9806\n",
      "Epoch 00406: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0438 - accuracy: 0.9832 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0303 - accuracy: 0.9903\n",
      "Epoch 00407: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0151 - accuracy: 0.9967\n",
      "Epoch 00408: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 00409: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0143 - accuracy: 0.9972 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0499 - accuracy: 0.9833\n",
      "Epoch 00410: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0477 - accuracy: 0.9832 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0120 - accuracy: 0.9968\n",
      "Epoch 00411: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 00412: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 00413: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0136 - accuracy: 0.9941\n",
      "Epoch 00414: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0130 - accuracy: 0.9944 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0567 - accuracy: 0.9848\n",
      "Epoch 00415: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0525 - accuracy: 0.9860 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 00416: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0132 - accuracy: 0.9935\n",
      "Epoch 00417: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0164 - accuracy: 0.9916 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0373 - accuracy: 0.9903\n",
      "Epoch 00418: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0331 - accuracy: 0.9916 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0100 - accuracy: 0.9967\n",
      "Epoch 00419: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0136 - accuracy: 0.9967\n",
      "Epoch 00420: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0394 - accuracy: 0.9871\n",
      "Epoch 00421: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0184 - accuracy: 0.9935\n",
      "Epoch 00422: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0181 - accuracy: 0.9909\n",
      "Epoch 00423: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0171 - accuracy: 0.9916 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9943\n",
      "Epoch 00424: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 00425: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0175 - accuracy: 0.9900\n",
      "Epoch 00426: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0201 - accuracy: 0.9888 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0377 - accuracy: 0.9935\n",
      "Epoch 00427: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0327 - accuracy: 0.9944 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9886\n",
      "Epoch 00428: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0250 - accuracy: 0.9888 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 00429: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9914\n",
      "Epoch 00430: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0240 - accuracy: 0.9888 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9971\n",
      "Epoch 00431: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 00432: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0312 - accuracy: 0.9871\n",
      "Epoch 00433: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0296 - accuracy: 0.9860 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0170 - accuracy: 0.9935\n",
      "Epoch 00434: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0150 - accuracy: 0.9944 - val_loss: 0.0280 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0163 - accuracy: 0.9900\n",
      "Epoch 00435: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0141 - accuracy: 0.9916 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0204 - accuracy: 0.9903\n",
      "Epoch 00436: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0220 - accuracy: 0.9888 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0228 - accuracy: 0.9900\n",
      "Epoch 00437: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0201 - accuracy: 0.9916 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0126 - accuracy: 0.9933\n",
      "Epoch 00438: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0116 - accuracy: 0.9944 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0282 - accuracy: 0.9903\n",
      "Epoch 00439: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9943\n",
      "Epoch 00440: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0332 - accuracy: 0.9944 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0067 - accuracy: 0.9971\n",
      "Epoch 00441: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0064 - accuracy: 0.9972 - val_loss: 0.0470 - val_accuracy: 0.9889\n",
      "Epoch 442/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9914\n",
      "Epoch 00442: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0147 - accuracy: 0.9916 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 00443: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0161 - accuracy: 0.9903\n",
      "Epoch 00444: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0141 - accuracy: 0.9916 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0064 - accuracy: 0.9967\n",
      "Epoch 00445: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0107 - accuracy: 0.9944 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 00446: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9971\n",
      "Epoch 00447: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0169 - accuracy: 0.9972 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0142 - accuracy: 0.9933\n",
      "Epoch 00448: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0136 - accuracy: 0.9944 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 00449: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9971\n",
      "Epoch 00450: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0630 - accuracy: 0.9742\n",
      "Epoch 00451: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0576 - accuracy: 0.9777 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9914\n",
      "Epoch 00452: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0357 - accuracy: 0.9916 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "320/358 [=========================>....] - ETA: 0s - loss: 0.0327 - accuracy: 0.9906\n",
      "Epoch 00453: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0296 - accuracy: 0.9916 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9971\n",
      "Epoch 00454: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0063 - accuracy: 0.9972 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 00455: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0289 - accuracy: 0.9903\n",
      "Epoch 00456: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0460 - accuracy: 0.9774\n",
      "Epoch 00457: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0400 - accuracy: 0.9804 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 00458: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 00459: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 00460: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0246 - accuracy: 0.9903\n",
      "Epoch 00461: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0224 - accuracy: 0.9916 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0160 - accuracy: 0.9967\n",
      "Epoch 00462: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0154 - accuracy: 0.9972 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0450 - accuracy: 0.9839\n",
      "Epoch 00463: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0495 - accuracy: 0.9832 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0120 - accuracy: 0.9967\n",
      "Epoch 00464: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0120 - accuracy: 0.9972 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0110 - accuracy: 0.9967\n",
      "Epoch 00465: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00466: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 00467: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0603 - accuracy: 0.9806\n",
      "Epoch 00468: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0528 - accuracy: 0.9832 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0087 - accuracy: 0.9968\n",
      "Epoch 00469: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0127 - accuracy: 0.9967\n",
      "Epoch 00470: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0083 - accuracy: 0.9968\n",
      "Epoch 00471: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0076 - accuracy: 0.9972 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0072 - accuracy: 0.9968\n",
      "Epoch 00472: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0068 - accuracy: 0.9972 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0181 - accuracy: 0.9935\n",
      "Epoch 00473: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0122 - accuracy: 0.9933\n",
      "Epoch 00474: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0106 - accuracy: 0.9944 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0221 - accuracy: 0.9935\n",
      "Epoch 00475: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0350 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0340 - accuracy: 0.9871\n",
      "Epoch 00476: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0365 - accuracy: 0.9860 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0192 - accuracy: 0.9912\n",
      "Epoch 00477: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0183 - accuracy: 0.9916 - val_loss: 0.0525 - val_accuracy: 0.9778\n",
      "Epoch 478/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0148 - accuracy: 0.9933\n",
      "Epoch 00478: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0219 - accuracy: 0.9888 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "340/358 [===========================>..] - ETA: 0s - loss: 0.0300 - accuracy: 0.9941\n",
      "Epoch 00479: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0285 - accuracy: 0.9944 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0359 - accuracy: 0.9829\n",
      "Epoch 00480: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0352 - accuracy: 0.9832 - val_loss: 0.0540 - val_accuracy: 0.9667\n",
      "Epoch 481/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0114 - accuracy: 0.9970\n",
      "Epoch 00481: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "330/358 [==========================>...] - ETA: 0s - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 00482: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "350/358 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9943\n",
      "Epoch 00483: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0190 - accuracy: 0.9944 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 00484: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0049 - accuracy: 0.9967\n",
      "Epoch 00485: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0045 - accuracy: 0.9972 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0068 - accuracy: 0.9968\n",
      "Epoch 00486: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0110 - accuracy: 0.9944 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0177 - accuracy: 0.9933\n",
      "Epoch 00487: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0177 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 00488: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 998us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0239 - accuracy: 0.9900\n",
      "Epoch 00489: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0206 - accuracy: 0.9916 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 00490: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0064 - accuracy: 0.9967\n",
      "Epoch 00491: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0056 - accuracy: 0.9972 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 00492: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0506 - accuracy: 0.9900\n",
      "Epoch 00493: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0776 - accuracy: 0.9888 - val_loss: 0.0797 - val_accuracy: 0.9667\n",
      "Epoch 494/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000\n",
      "Epoch 00494: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 997us/sample - loss: 0.0197 - accuracy: 0.9944 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0193 - accuracy: 0.9933\n",
      "Epoch 00495: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0300 - accuracy: 0.9916 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0384 - accuracy: 0.9935\n",
      "Epoch 00496: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0334 - accuracy: 0.9944 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0314 - accuracy: 0.9900\n",
      "Epoch 00497: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0221 - accuracy: 0.9871\n",
      "Epoch 00498: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 991us/sample - loss: 0.0194 - accuracy: 0.9888 - val_loss: 0.0547 - val_accuracy: 0.9667\n",
      "Epoch 499/500\n",
      "300/358 [========================>.....] - ETA: 0s - loss: 0.0396 - accuracy: 0.9833\n",
      "Epoch 00499: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 1ms/sample - loss: 0.0337 - accuracy: 0.9860 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "310/358 [========================>.....] - ETA: 0s - loss: 0.0102 - accuracy: 0.9935\n",
      "Epoch 00500: val_accuracy did not improve from 1.00000\n",
      "358/358 [==============================] - 0s 990us/sample - loss: 0.0118 - accuracy: 0.9944 - val_loss: 0.0282 - val_accuracy: 1.0000\n",
      "Training completed in time:  0:03:17.117269\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "num_epochs = 500\n",
    "num_batch_size = 10\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='models/' + MODEL_NAME + '_{epoch:02d}.h5',\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_accuracy` score has improved.\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,\n",
    "                    validation_data=(x_val, y_val), callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot accuracies and losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deXxcV3338c9vRvu+epVt2fGS2CS2E8XZgxNCCSHQtEAbIBAgNK+kJYEWCATKQ2jLw1JWUyikkKYUyhbIEwgQnISszeLIifd9jeVNsmxr32bm9/wxV7KssR3J9ljS1ff9eumlucvce448/s6Zc++cY+6OiIiET2S4CyAiIumhgBcRCSkFvIhISCngRURCSgEvIhJSCngRkZBSwMuYZmbVZuZmljGIfd9vZs+e6nFEzhQFvIwaZrbDzLrNrGLA+leCcK0enpKJjEwKeBlttgPv6l0ws3OBvOErjsjIpYCX0ea/gff1W74Z+FH/Hcys2Mx+ZGYNZrbTzP7RzCLBtqiZfdXMDpjZNuAtx3juD81sr5ntNrN/MbPoUAtpZpPM7DdmdtDMtpjZ3/TbtsjMas2s2cz2m9nXg/U5ZvZjM2s0s8Nm9pKZjR/quUV6KeBltHkBKDKzc4LgvRH48YB9vg0UAzOA15N8Q/hAsO1vgOuBhUAN8I4Bz70fiAEzg33+DPjQSZTzZ0AdMCk4x/81s6uDbd8CvuXuRcBZwC+C9TcH5Z4ClAO3AR0ncW4RQAEvo1NvK/6NwHpgd++GfqF/t7u3uPsO4GvAe4Nd/gr4prvvcveDwBf7PXc8cB3wUXdvc/d64BvB8QbNzKYAlwGfdPdOd18B/IAjnzx6gJlmVuHure7+Qr/15cBMd4+7+3J3bx7KuUX6U8DLaPTfwLuB9zOgewaoADKBnf3W7QQmB48nAbsGbOs1LXju3qCL5DDwfWDcEMs3CTjo7i3HKcMtwGxgQ9ANc32/ev0R+JmZ7TGzr5hZ5hDPLdJHAS+jjrvvJHmx9Trg1wM2HyDZEp7Wb91UjrTy95LsAum/rdcuoAuocPeS4KfI3ecNsYh7gDIzKzxWGdx9s7u/i+Qbx5eBB8ws39173P3z7j4XuJRkV9L7EDlJCngZrW4Brnb3tv4r3T1Osk/7C2ZWaGbTgH/gSD/9L4A7zazKzEqBT/V77l5gKfA1Mysys4iZnWVmrx9Kwdx9F/Ac8MXgwul5QXl/DGBmN5lZpbsngMPB0xJmdpWZnRt0MzWTfKNKDOXcIv0p4GVUcvet7l57nM13AG3ANuBZ4H+A+4Jt/0GyG2Ql8DKpnwDeB2QB64BDwAPAxJMo4ruAapKt+QeBz7n7Y8G2a4G1ZtZK8oLrje7eAUwIztdM8trCUyS7bUROimnCDxGRcFILXkQkpBTwIiIhpYAXEQkpBbyISEiNqKFNKyoqvLq6eriLISIyaixfvvyAu1cea9uICvjq6mpqa49355uIiAxkZjuPt01dNCIiIaWAFxEJKQW8iEhIjag++GPp6emhrq6Ozs7O4S5K2uXk5FBVVUVmpgYQFJFTN+IDvq6ujsLCQqqrqzGz4S5O2rg7jY2N1NXVMX369OEujoiEwIjvouns7KS8vDzU4Q5gZpSXl4+JTyoicmaM+IAHQh/uvcZKPUXkzBgVAf9a9jd30tLZM9zFEBEZUUIR8A0tXbR2xU77cRsbG1mwYAELFixgwoQJTJ48uW+5u7v7hM+tra3lzjvvPO1lEhEZrBF/kXXQ0jCsfXl5OStWrADgnnvuoaCggI9//ON922OxGBkZx/4T1tTUUFNTc/oLJSIySKFowUNa8v2Y3v/+93Pbbbdx0UUXcdddd7Fs2TIuueQSFi5cyKWXXsrGjRsBePLJJ7n++uRcyvfccw8f/OAHWbx4MTNmzGDJkiVnqLQiMpaNqhb853+7lnV7mlPWt3XHyIxEyMoY+vvV3ElFfO6tQ5tTua6ujueee45oNEpzczPPPPMMGRkZPPbYY3z605/mV7/6VcpzNmzYwBNPPEFLSwtz5szh9ttv1/3uIpJWoyrgR4p3vvOdRKNRAJqamrj55pvZvHkzZkZPz7Ev9r7lLW8hOzub7Oxsxo0bx/79+6mqqjqTxRaRMWZUBfzxWtprdzdRmp/FpJLcM1KO/Pz8vsef/exnueqqq3jwwQfZsWMHixcvPuZzsrOz+x5Ho1FisdN/UVhEpL/Q9MEPl6amJiZPngzA/fffP7yFERHpJxwBP4zfD7rrrru4++67WbhwoVrlIjKimPuZuv/ktdXU1PjACT/Wr1/POeecc8Lnrd3TRGnemeuiSafB1FdEpJeZLXf3Y96THY4WPGfuNkkRkdEiNAEvIiJHC0XAG6gJLyIyQCgCflivsoqIjFAhCXhQE15E5GghCngREelvVH2T9UTS0X5vbGzkDW94AwD79u0jGo1SWVkJwLJly8jKyjrh85988kmysrK49NJL01A6EZETC03Ap8NrDRf8Wp588kkKCgoU8CIyLNLaRWNmf29ma81sjZn91Mxy0nOitBz1mJYvX87rX/96LrjgAt70pjexd+9eAJYsWcLcuXM577zzuPHGG9mxYwff+973+MY3vsGCBQt45plnzlwhRURIYwvezCYDdwJz3b3DzH4B3Ajcf9IH/cOnYN/qlNXTumNkRAwyokM/5oRz4c1fGtSu7s4dd9zBQw89RGVlJT//+c/5zGc+w3333ceXvvQltm/fTnZ2NocPH6akpITbbrttyK1+EZHTJd1dNBlArpn1AHnAnjSfL626urpYs2YNb3zjGwGIx+NMnDgRgPPOO4/3vOc93HDDDdxwww3DWUwRESCNAe/uu83sq8CrQAew1N2XDtzPzG4FbgWYOnXqiQ96nJb2q3ubKczOoKos7xRLfWLuzrx583j++edTtv3ud7/j6aef5re//S1f+MIXWL069ZOGiMiZlLY+eDMrBf4cmA5MAvLN7KaB+7n7ve5e4+41vXeojFTZ2dk0NDT0BXxPTw9r164lkUiwa9currrqKr785S/T1NREa2srhYWFtLS0DHOpRWSsSudF1muA7e7e4O49wK+BtN1Ocia+5hSJRHjggQf45Cc/yfz581mwYAHPPfcc8Xicm266iXPPPZeFCxdy5513UlJSwlvf+lYefPBBXWQVkWGRzj74V4GLzSyPZBfNG4DaEz9l5Lrnnnv6Hj/99NMp25999tmUdbNnz2bVqlXpLJaIyHGlrQXv7i8CDwAvA6uDc92bjnNpJBoRkVRpvYvG3T8HfC6d5xARkWMbFWPRjKRZp9JprNRTRM6MER/wOTk5NDY2njj8QtBH4+40NjaSk5OeL/uKyNgz4seiqaqqoq6ujoaGhuPus6+pk6yMCK37Tzz410iXk5NDVVXVcBdDREJixAd8ZmYm06dPP+E+t/3rEyycUsI3b9Rk1SIivUZ8F81gqfdaRORooQh4A3R9UkTkaOEIeDO14EVEBghHwKNbDEVEBgpFwGPqgxcRGSgUAW+ghBcRGSAcAW+GK+FFRI4SjoBHd9GIiAwUjoAPwVAFIiKnWygCHtSCFxEZKBQBb6gPXkRkoHAEvKkFLyIyUCgCHnSXpIjIQKEIeDNTC15EZIBwBDygNryIyNHCEfDqgxcRSRGagBcRkaOFIuBBHTQiIgOFIuAN03DBIiIDhCPgNVywiEiKcAQ8usgqIjJQKAIeTdknIpIiFAGvKftERFKFI+B1m6SISIpwBDzqgxcRGSgcAa8mvIhIilAEPKDx4EVEBghFwKuLRkQkVTgCXoONiYikCEfAa8o+EZEUoQh41IIXEUmR1oA3sxIze8DMNpjZejO7JC3nQWPRiIgMlJHm438LeMTd32FmWUBeOk5iBp5Ix5FFREavtAW8mRUDVwLvB3D3bqA7LedSG15EJEU6u2imAw3Af5rZK2b2AzPLT9fJdJFVRORo6Qz4DOB84N/dfSHQBnxq4E5mdquZ1ZpZbUNDw0mdSLdJioikSmfA1wF17v5isPwAycA/irvf6+417l5TWVl5UifShB8iIqnSFvDuvg/YZWZzglVvANal41yask9EJFW676K5A/hJcAfNNuAD6TiJWvAiIqnSGvDuvgKoSec5jpzrTJxFRGT0CMU3WU1T9omIpAhHwIOa8CIiA4Qj4DXfh4hIilAEPOgiq4jIQKEIeE34ISKSKhwBbxoPXkRkoHAEPGrBi4gMFI6A11g0IiIpQhHwoPvgRUQGCkXAJ1vwingRkf7CEfDDXQARkREoFAEvIiKpQhHwusgqIpIqHAGP7oMXERkoHAGvFryISIrwBPxwF0JEZIQJR8Bryj4RkRShCHjUghcRSRGKgE9O+DHcpRARGVnCEfCa8UNEJEUoAh7UgBcRGWhQAW9m+WYWCR7PNrO3mVlmeos2eMnhghXxIiL9DbYF/zSQY2aTgaXAe4H701WoodJtkiIiqQYb8Obu7cBfAt9193cC89JXrKHRhB8iIqkGHfBmdgnwHuB3wbpoeoo0dJqyT0Qk1WAD/qPA3cCD7r7WzGYAT6SvWEOjFryISKqMwezk7k8BTwEEF1sPuPud6SzYkGgsGhGRFIO9i+Z/zKzIzPKBNcA6M/tEeos2eKYpP0REUgy2i2auuzcDNwB/AKaTvJNGRERGqMEGfGZw3/sNwG/cvYcRdGei5mQVEUk12ID/PrADyAeeNrNpQHO6CjVUxgh6txERGSEGe5F1CbCk36qdZnZVeoo0dJrwQ0Qk1WAvshab2dfNrDb4+RrJ1vyIoCn7RERSDbaL5j6gBfir4KcZ+M90FWqo1IIXEUk1qC4a4Cx3f3u/5c+b2Yp0FOhkaCwaEZFUg23Bd5jZ5b0LZnYZ0JGeIp0MUwteRGSAwbbgbwN+ZGbFwfIh4ObBPNHMokAtsNvdrx96EQdzjnQcVURkdBvsXTQrgflmVhQsN5vZR4FVg3j6R4D1QNFJl3JQ1IQXEelvSDM6uXtz8I1WgH94rf3NrAp4C/CDkyjboGmwMRGRVKcyZd9gOka+CdwFJI57ELNbe2+/bGhoOLmC6CKriEiKUwn4E2aqmV0P1Lv78hMexP1ed69x95rKysqTKohhGqpARGSAE/bBm1kLxw5yA3Jf49iXAW8zs+uAHKDIzH7s7jedVElPQC14EZFUJwx4dy882QO7+90kJwnBzBYDH09HuIP64EVEjuVUumhGDDN10YiIDDTY++BPibs/CTyZ1nOk8+AiIqNQSFrww10CEZGRJxQBD6gJLyIyQCgCPjlcsIiI9BeOgNeUfSIiKcIR8KiHRkRkoHAEvCb8EBFJEZKA15R9IiIDhSPgUQteRGSgUAT8oMa1FBEZY8IR8Ogiq4jIQKEIeEPDSYqIDBSOgDd0kVVEZIBwBDy6yCoiMlA4Al49NCIiKcIR8JqyT0QkRTgCXi14EZEU4Qh41AcvIjJQKAJeM36IiKQKR8CLiEiKUAR8b/tdF1pFRI4IR8AHCa98FxE5IhwBH7Thle8iIkeEI+D7WvCKeBGRXuEI+OC34l1E5IhwBLz64EVEUoQk4Hv74JXwIiK9QhHwIiKSKlQBry4aEZEjQhHwGqlARCRVOAK+9z54teBFRPqEI+B776LRRVYRkT7hCPjgt1rwIiJHhCPg+1rwIiLSKxwB39cHr4gXEekVjoDXXTQiIinSFvBmNsXMnjCzdWa21sw+kq5z9VL7XUTkiIw0HjsGfMzdXzazQmC5mT3q7uvSdUL10IiIHJG2Fry773X3l4PHLcB6YHI6zmW6yioikuKM9MGbWTWwEHjxGNtuNbNaM6ttaGg4ueMHv3UfvIjIEWkPeDMrAH4FfNTdmwdud/d73b3G3WsqKytP8hy9xzqFgoqIhExaA97MMkmG+0/c/ddpO0/wW/kuInJEOu+iMeCHwHp3/3q6zhOcC9B98CIi/aWzBX8Z8F7gajNbEfxcl44T6RqriEiqtN0m6e7PcqT3REREzrBwfJM1+K0eGhGRI0IR8GhOVhGRFKEI+L5+IOW7iEifcAS8LrKKiKQIR8Bryj4RkRThCHhN2ScikiIcAR/8VgteROSIcAS87rYXEUkRioDvpQa8iMgRoQh4zckqIpIqFAGPhgsWEUkRioBXF7yISKp0zsl6xrx16ZXsz7gC96uGuygiIiNGSFrwTjFtug9eRKSfUAR8T2YhRdauPngRkX7CEfAZhRTSrva7iEg/4Qj4oAUvIiJHhCLgY5lBC159NCIifUIR8InsIoqsnfbu+HAXRURkxAhFwOcUlFJIO7sOqptGRKRXKAK+oKScAutk14Hm4S6KiMiIEYqAzykoA+AXS5+kqaNnmEsjIjIyhCLgySkG4LHsu9h2/+2w8RHoaoF4TAPUiMiYFYqhCpjzZupmvof9m5Zx3r5fw09/iUcysEQcxs+DC2+Bmg8OdylFRM6ocAR8bglVN32X52t3cdsDTzErspvLImuozI3wFx2vkPnw30P9erj2SxCJQiIOnoBo5nCXXEQkbWwk3TteU1PjtbW1p3QMd+f7T2/jS3/YAECUOF/L+xE3JB6F2dfColvhj5+G9oNw1d1wwQdgzyvJln40S9NDicioYmbL3b3mWNvC0YLvx8y49YoZZESMWeMLeWjFbj768gfoKinlr7b9Ftv0yJGdH/572PkcrP4l5JZCRi68/Qcw9eJk370nICNr+CojInIKQteCP5YnN9Zz24+Xc052I++bvJfCOVdyZdNvyFr3a2jZc/TOFgEMPA5ZhfD2/4ApF0FrPYw7e+gn378OCidAXtlpqYuISH8nasGPiYAHWLenmc/8v9Ws3d1MdzxBflaU66cbb4/9jicKruPj07YRzSuF7U/Byp/2e6ZBZi7EOmFyDfS0Q8NGuPSOZLfO0/8Kf/4dqDrG3zcRh38qg8KJ8LENaamXiIxtCvh+4gnnxW2NLPnTZl7YdrBv/bxJRXT0xPnqO+ezcEoJnY276EpEKKldkrzlsuNgMuQx6G6FupeOPnBuKcz6M6icAwXjYeFNULccfnB1cvs/rIeiSWmtm4iMPQr4Y3B3vvHYZp7YUE9xbibPbjnQt23epCLqW7rojiWYWJzD+dNK+eS1Z9PY2kVFYTZFmcBLP4S9K2H6FfD4P6d29Vx5Fzz9lSPLZ70heRH3bd+GgsozUkcRCT8F/GtIJJxN9S3sb+7iiQ31PLO5gZ648+rBdioLs2lo6Tpq//lTShhXmE1FQTaXzSzn7AmFRJ9bwvQVX+FbeR/mzs7vYYnYkSeUVsOhHYAl+/irLkx275z9lmSLf9MjcP77ITrgmnd78KkhkglZ+ZCVl+a/hIiMNgr4k+TutHbF+OeH1zG9ogDH+cojG4+5r5HgsnE9PFufzcfntfDhRcXEpl7Gh374LDdMPMQN0xNQNp2uR/+Z7s4OChtXHn2Akql4+yHs7LfAdf+aXLdkAbQ3QmY+JGJw19bk76X/CJfemXxzEJExTQF/Gu040EZ3PEFFQTb52VG+tnQTD6/cw56mzqP2K8zOoKXrSCv+fZdMo7o8n68u3Uh7d5zLJkf5p5LfU5I4SOnOR4gkjoyh0503nqz2/Snnjs24hoz80uRtnWUz4N2/hJyi5Je4Zrz+2AXubE7uIyKhpIA/Aw63d1N3qIM9hzt4aOUexhfm0NET42BbN21dcVbsOkxrEPgXTCtlx4E2Gtu6ASignQ9EH+GpxHyujKxifmQrm7yK2sQcPpS1lMtYycPxi7k++gIAm3wKM62OCI5jWDBZYWPudLor51FEO55VQKRoAnkv30vb1V8g//K/TX6Jy4xEZwtGAssu0he7REY5BfwI4O7sb+5i+c5DXPu6CXTF4vzvlkY+/D8vc/7UUu6+7mz+/Dv/2zc22i2XT+e5rY1s3HuYyZGD5FVU01S/kynWwCqfwTzbwcWRdVwXXcZZtodc6+47V49HOUgh4+1w37oYURJE6cksIL8neffQnvGLef5gAQty9jPx7EXkte6ie/cKXim8mglzL2dqRSHrdu4lsruW8VNn80hdFnUtCT5x5TisuxV2LWNf9jTaF97Cvl/dTf70C5lc/xTFi+8gc/olxOMJmg41UFYx/oz+rU9VIuE88MJG3rTwLIpzhzCcxd5VyWsmUxalr3Aky9feE6cgO3TfU5STMGwBb2bXAt8CosAP3P1LJ9o/zAF/PO3dMXIzo5gZbV0xsjMiOJAZTQ702dLZw+H2HiYW5/DTl3bxq+V1XDmrgs5Ygi31rbR2xXhp+wHeNLGDz7z3ehr27+azv9/O2oYe7l4Yo6ComNpnHuHC7FfJzckiu3U3U6yes20XmZacAavHo32P424YELHBvy6aPI/ifnPidngWeyZew9R9j5JJD46xtvRqejrbaMqeRHvpOYyr+yPV2S2sK7ycjNwCxnduI14ynVmXvx0iUXYs/S6xpv3sK6vhpYO53Fq5DspnsHzVKuq9jMJJs9jSns+MuRfwur0Pkrn+QVryqqi2fXSddS2ZGRlEzlpMpLuZruqryS8sAZJvtAY4YPXrSGQV0dAeo6m1jYl5UFg1j+dqa1n48HXUlr+N133wu3zsgVXcvvgsLqwu40BrF09vauDC6jJW1x0i0dbI/DkzmVKWB/ckRzVt/sReCnJziUSO/enI3Wlo6WJcUQ4A+5s7aeuKMaOy4Lj7L995iP96fieLZ1eyt6mDry7dxEufuYbKwuxB/zv11X8In9qe2VRP4cv/zoJr3g0Vs06477/9aTPbD7Tz1XeeN6RzHFM8xp6n7mPcoreTUVB+ascaymkTTvQ4/26ny5ql95NXXsWMC645LccbloA3syiwCXgjUAe8BLzL3dcd7zljMeBPh9au5JtE7wuzsydOW1eM8oLkf/6N+1qYXJpLQXYGL+04yPaGNnKzoux59sdcc9nF/GJ3GZtW/C/nRzZjC2/izdMj/OzR59jR2Mbtc+NUTRzHT/ZW8eQr65hTGmFOSYJIVi4v7zjAxO6dXB99gaacyRy2Yv7UMpW/y3iIMmumzFoBeCFxDvNt61GfMhq8iEpr7rdcTKU1peXvs99Lsaw8WuKZxBMJZvPqUdvjbkSDN7QDVk5hoolsS3an1XsJRoK9Xs7hzAlM6tnJYQrYlpjIgsgWZkd2s9MnEM3IpCq+C0i+4W3LmMGhwrOZ0byMpqLZlM66hIM7VlHQtJHseBv1PTlEiiaxuqOC3K4Geshg+sRyGrMmETUo8lY2teUxftw49jb3ULb7cbYmJlFqrcyPbGVzYjLNZa+joryCnM56ZnauoT5nOiVzriC3q4Ha7Y1M69nG5IVvpK3HeLm9nPi+DeTWPUNX2dnsihWRiOZyxcxypr/6AI05U8iZVsOGjjKmVBZRkpvFps0bqa19ns9m/pguy+Y353yNRRXd5BxYw6aSy5m86tvsa4nTnjsBn3Ae67ZsZa69ir3uLymtmsWrrREuPnsqlaWlrGvopigvm0MdPax66RkmVVWTm5cHr77Ins2vMC+xic3jr2VDzgLee345B1c9wrmrvwjAhvHX01i2kA0NXfz1je/jhTVbWLfsMS5YuJCm3GlE4t1YrJOzJxaQnV/M+mWPU1I+HiaeR0XnTrpXPUj27MUcjueQ3bSdrO1/YlxBBtHLPkx34VS62w7h8RiPbz7EUy+t4J2zIlxYdJCV+7opL8xlxoQyXmyfTOvq33DOrNkUVkziuy8c5MqLF3FJaQstZa+jefUfsA2/ZUL7RtqjxURzCuhZ9Lfkz76CRHYJnXvX0dHeQVniALkP/Q0Av5/1T1xZ933ao4XkXHIrRZfdclKv7+EK+EuAe9z9TcHy3QDu/sXjPUcBP3K4O93xBNkZ0b513bEEWRlHphCIJ5J3GXX1xPveTLpicRpbuuiJJ6jMj5CdncuaPU2UZMGM8SX07FnFwdZOKmbWsG/VY3Ts2UBHxbmMP+dSXn7qIV7dtp7q4ijj8qJMWfRWDu7eQt6BlayMTWNf9jTeNDlGTnEluZlRcvcuY9fGWna1Z3L+Ne9mw669bM8+h8jBLeTUryS75zBdCWNS23r2t3QzP7KNtqwKtrXnkesdXBDZTGckF8suZG/RfH6xu4xFkQ1cE32ZLYWL+G3rHBYm1lEY7SYS62CW1bEycRbl2XEmxurYnzWNjAlzYd9qpnRvIYdutpZewZrmHBYlVjLR69kYnc202HZyrIeYRzhkxRR7Myt8JlXWwHgOEQ+mZTDo+yQ1WnRZDq2eQznJ7sA4EaIkTtvxOz2THDu9k/gc8CKyiFFk6Znis84r6PQsZkb2vPbOgcMUkvmxteQXFg/5fMMV8O8ArnX3DwXL7wUucvcPD9jvVuBWgKlTp16wc+fOtJRHpFdTRw+JhFOYk0FG9Mgb1s7GNsrys8iPJohEM0gQCa5LGz3xBC/tOMhF08uP/RE+HksOY9F7x5J7sj8+M5f6w62s2V7H+KJc5lZPYte+BgpLKujsiTGxIIPuWIwsixOPxbBYJ4daO8grLie3cS0HOiNs3b6VCy66kvihXWRPvYCDnVCa7bTtWsX2w3FKC/PIKqsiKwL7Vj5OV04ZU0tzafJ8Xq3bSX5uLuN6dtNhecxaeAUW64SOw8R6OtnX1IWVTOFAe5xDe3fwuoImdh9so6Wzh6kTx1NZVko8r4Ls3Hza9m1lRX2MRMFE5navpmzSDLKqL8bdObx9OYUZCaKT5rOm9hm6Wg8xMTfGpl17obud8hwnFouRGYHpU6eyo243GRHInHohE8ePo7u7i507ttFzqI5DXQa5JSy6+i8pLqtk9dY69u/eRlmsnsZX1+NZBfiE+RQfXkvE43g0m8KCAlq6umk71MCc2edQ19iMH64j7tAx9UryD2+hMC+LjrYmes7+C2q37mNy/VOUZfaQsCiR3BJ6Whu5cN4cdrTn8Ov943nDOeN4efsBEu2NXBjZSFH1AlYdzCSjaQfVmYdobWujNVpMRdcu4hVzmFlzLYf2bmXS5Kn8ceMhivc8Q/zQTiZFmmgsmEVnT5ye9sN4wXhq5s5malMtOyZdR3zbs6zJvZB3XHHeSb2eR3TA96cWvIjI0Jwo4NM5Zd9uYEq/5apgnYiInAHpDPiXgFlmNt3MsoAbgd+k8XwiItJP2m6kdfeYmX0Y+Gf+qe8AAAWZSURBVCPJ2yTvc/e16TqfiIgcLa3flHD33wO/T+c5RETk2NLZRSMiIsNIAS8iElIKeBGRkFLAi4iE1IgaTdLMGoCT/SprBXDgNfcKF9V5bFCdx4aTrfM0dz/mPKAjKuBPhZnVHu/bXGGlOo8NqvPYkI46q4tGRCSkFPAiIiEVpoC/d7gLMAxU57FBdR4bTnudQ9MHLyIiRwtTC15ERPpRwIuIhNSoD3gzu9bMNprZFjP71HCX53Qxs/vMrN7M1vRbV2Zmj5rZ5uB3abDezGxJ8DdYZWbnD1/JT56ZTTGzJ8xsnZmtNbOPBOtDW28zyzGzZWa2Mqjz54P1083sxaBuPw+G3MbMsoPlLcH26uEs/6kws6iZvWJmDwfLoa6zme0ws9VmtsLMaoN1aX1tj+qADyb2/g7wZmAu8C4zmzu8pTpt7geuHbDuU8Dj7j4LeDxYhmT9ZwU/twL/fobKeLrFgI+5+1zgYuDvgn/PMNe7C7ja3ecDC4Brzexi4MvAN9x9JnAI6J2R+RbgULD+G8F+o9VHgPX9lsdCna9y9wX97ndP72vb3UftD3AJ8Md+y3cDdw93uU5j/aqBNf2WNwITg8cTgY3B4+8D7zrWfqP5B3gIeONYqTeQB7wMXETyG40Zwfq+1znJ+RUuCR5nBPvZcJf9JOpaFQTa1cDDJOccD3uddwAVA9al9bU9qlvwwGRgV7/lumBdWI13973B433A+OBx6P4OwcfwhcCLhLzeQVfFCqAeeBTYChx291iwS/969dU52N4ElJ/ZEp8W3wTuAhLBcjnhr7MDS81suZndGqxL62s7rRN+SPq4u5tZKO9xNbMC4FfAR9292cz6toWx3u4eBxaYWQnwIHD2MBcprczseqDe3Zeb2eLhLs8ZdLm77zazccCjZrah/8Z0vLZHewt+rE3svd/MJgIEv+uD9aH5O5hZJslw/4m7/zpYHfp6A7j7YeAJkt0TJWbW2wDrX6++Ogfbi4HGM1zUU3UZ8DYz2wH8jGQ3zbcId51x993B73qSb+SLSPNre7QH/Fib2Ps3wM3B45tJ9lH3rn9fcOX9YqCp38e+UcOSTfUfAuvd/ev9NoW23mZWGbTcMbNcktcc1pMM+ncEuw2sc+/f4h3AnzzopB0t3P1ud69y92qS/2f/5O7vIcR1NrN8MyvsfQz8GbCGdL+2h/vCw2m4cHEdsIlkv+Vnhrs8p7FePwX2Aj0k+99uIdnv+DiwGXgMKAv2NZJ3E20FVgM1w13+k6zz5ST7KVcBK4Kf68Jcb+A84JWgzmuA/xOsnwEsA7YAvwSyg/U5wfKWYPuM4a7DKdZ/MfBw2Osc1G1l8LO2N6vS/drWUAUiIiE12rtoRETkOBTwIiIhpYAXEQkpBbyISEgp4EVEQkoBL2OKmcWD0fx6f07bCKRmVm39Rv8UGW4aqkDGmg53XzDchRA5E9SCF6FvrO6vBON1LzOzmcH6ajP7UzAm9+NmNjVYP97MHgzGcV9pZpcGh4qa2X8EY7svDb6dKjIsFPAy1uQO6KL5637bmtz9XODfSI52CPBt4L/c/TzgJ8CSYP0S4ClPjuN+PslvJ0Jy/O7vuPs84DDw9jTXR+S49E1WGVPMrNXdC46xfgfJiTe2BQOe7XP3cjM7QHIc7p5g/V53rzCzBqDK3bv6HaMaeNSTkzdgZp8EMt39X9JfM5FUasGLHOHHeTwUXf0ex9F1LhlGCniRI/663+/ng8fPkRzxEOA9wDPB48eB26Fvwo7iM1VIkcFS60LGmtxg9qRej7h7762SpWa2imQr/F3BujuA/zSzTwANwAeC9R8B7jWzW0i21G8nOfqnyIihPngR+vrga9z9wHCXReR0UReNiEhIqQUvIhJSasGLiISUAl5EJKQU8CIiIaWAFxEJKQW8iEhI/X9fHEs/zREqgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diDQglrhSR1n"
   },
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Qyg7uylzSR1p",
    "outputId": "4b953e0d-5437-422d-cbc5-6b19a29879f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  1.0\n",
      "Testing Accuracy:  0.40625\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KnzqoZRbSR1v"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test) # label scores \n",
    "\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "\n",
    "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
    "\n",
    "n_classes=2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMrG8FeJSR14"
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOZSWEULSR17"
   },
   "outputs": [],
   "source": [
    "c_names = ['Bronchiectasis', 'Bronchiolitis', 'COPD', 'Healthy', 'Pneumonia', 'URTI']\n",
    "c_names = ['Healthy', 'Pneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 851
    },
    "colab_type": "code",
    "id": "HY5qEVRrSR2A",
    "outputId": "9c5341de-bbdf-4c87-c999-82ee08ddd1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC curves\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve for Each Class')\n",
    "for i in range(n_classes):\n",
    "    ax.plot(fpr[i], tpr[i], linewidth=3, label='ROC curve (area = %0.2f) for %s' % (roc_auc[i], c_names[i]))\n",
    "ax.legend(loc=\"best\", fontsize='x-large')\n",
    "ax.grid(alpha=.4)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "qlQ12gHQSR2D",
    "outputId": "42af0b0e-037c-4177-a382-aff8a8550509"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.19      0.67      0.30        24\n",
      "   Pneumonia       0.82      0.35      0.49       104\n",
      "\n",
      "    accuracy                           0.41       128\n",
      "   macro avg       0.50      0.51      0.39       128\n",
      "weighted avg       0.70      0.41      0.45       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(classification_report(y_testclass, classpreds, target_names=c_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "jGzk3U9kSR2G",
    "outputId": "cd147c90-fc8e-47c5-9cd0-6e3e224b3def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  8]\n",
      " [68 36]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(y_testclass, classpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, unique_labels, show=True, output=None,\n",
    "                          title='Confusion matrix', cmap=plt.cm.Oranges):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(cm.shape[1])\n",
    "    plt.xticks(tick_marks, rotation=45)\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels((ax.get_xticks() + 1).astype(str))\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    ax.set_xticklabels(unique_labels)\n",
    "    ax.set_yticklabels(unique_labels)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.1f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output is not None:\n",
    "        plt.savefig(output)\n",
    "    plt.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_testclass, classpreds), unique_labels=[\"Healthy\", \"Pneumonia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Corona-Disease Classification by CNN using MFCC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
